Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act()
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act()
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act()
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::leaky_relu encountered 35 time(s)
Unsupported operator aten::sub encountered 35 time(s)
Unsupported operator aten::mul encountered 35 time(s)
Unsupported operator aten::add encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
no checkpoint found in manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default, ignoring auto resume
Start training
tag: Orientation (274) - type: short (3) - value: b'\x00\x01'
tag: XResolution (282) - type: rational (5) Tag Location: 34 - Data Location: 98 - value: b'\x00\x00\x00F\x00\x00\x00\x01'
tag: YResolution (283) - type: rational (5) Tag Location: 46 - Data Location: 106 - value: b'\x00\x00\x00F\x00\x00\x00\x01'
tag: ResolutionUnit (296) - type: short (3) - value: b'\x00\x03'
tag: Software (305) - type: string (2) Tag Location: 70 - Data Location: 114 - value: b'Adobe Photoshop Elements 2.0\x00'
tag: DateTime (306) - type: string (2) Tag Location: 82 - Data Location: 143 - value: b'2005:08:20 12:34:15\x00'
tag: ExifIFD (34665) - type: long (4) - value: b'\x00\x00\x00\xa4'
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 256
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: true
  ACT_FROM_SEARCH: false
  ACT_FUN: relu6
  ACT_LIST:
  - 0.0
  - 1.0
  - 0.0
  - 0.0
  - 1.0
  - 1.0
  - 0.0
  - 1.0
  - 0.0
  - 1.0
  - 0.0
  - 1.0
  - 1.0
  - 0.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.7
  L1_WEIGHT: 0.0
  LAT_AFTER: []
  LAT_BEFORE: []
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: ''
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.8
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 4.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 4.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act()
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act()
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act()
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::leaky_relu encountered 35 time(s)
Unsupported operator aten::sub encountered 35 time(s)
Unsupported operator aten::mul encountered 35 time(s)
Unsupported operator aten::add encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
no checkpoint found in manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default, ignoring auto resume
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 256
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: false
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 41.78
  - 5.45
  - 6.68
  - 3.23
  - 4.12
  - 4.12
  - 2.38
  - 2.72
  - 2.72
  - 2.72
  - 3.75
  - 5.04
  - 5.04
  - 3.44
  - 2.8
  - 2.8
  - 4.38
  - 0
  LAT_BEFORE:
  - 0
  - 56.97
  - 138.79
  - 82.45
  - 47.03
  - 34.51
  - 34.51
  - 21.19
  - 17.91
  - 17.91
  - 17.91
  - 20.75
  - 31.27
  - 31.27
  - 16.67
  - 14.21
  - 14.21
  - 18.77
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: ''
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.8
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 4.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 4.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108795
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
no checkpoint found in manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default, ignoring auto resume
Start training
Train: [0/180][0/625]	eta 5:04:58 lr 0.800000	data 21.5369 (21.5369)	batch 29.2770 (29.2770)	loss 6.9304 (6.9304)	grad_norm 0.5060 (0.5060)	mem 44912MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 256
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: false
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 41.78
  - 5.45
  - 6.68
  - 3.23
  - 4.12
  - 4.12
  - 2.38
  - 2.72
  - 2.72
  - 2.72
  - 3.75
  - 5.04
  - 5.04
  - 3.44
  - 2.8
  - 2.8
  - 4.38
  - 0
  LAT_BEFORE:
  - 0
  - 56.97
  - 138.79
  - 82.45
  - 47.03
  - 34.51
  - 34.51
  - 21.19
  - 17.91
  - 17.91
  - 17.91
  - 20.75
  - 31.27
  - 31.27
  - 16.67
  - 14.21
  - 14.21
  - 18.77
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: ''
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.8
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 4.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 4.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108795
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
no checkpoint found in manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default, ignoring auto resume
Start training
Train: [0/180][0/625]	eta 5:05:19 lr 0.800000	data 19.7512 (19.7512)	batch 29.3118 (29.3118)	loss 6.9304 (6.9304)	grad_norm 0.5060 (0.5060)	mem 44912MB
Train: [0/180][50/625]	eta 0:17:30 lr 0.800000	data 0.0005 (0.3879)	batch 1.2559 (1.8273)	loss 6.3902 (6.7277)	grad_norm 0.4187 (0.5510)	mem 44912MB
Train: [0/180][100/625]	eta 0:13:30 lr 0.799998	data 0.0006 (0.1962)	batch 1.2620 (1.5445)	loss 5.9036 (6.4407)	grad_norm 0.4820 (0.5080)	mem 44912MB
Train: [0/180][150/625]	eta 0:11:28 lr 0.799996	data 0.0010 (0.1315)	batch 1.2543 (1.4499)	loss 5.7140 (6.2292)	grad_norm 0.4245 (0.5008)	mem 44912MB
Train: [0/180][200/625]	eta 0:09:55 lr 0.799994	data 0.0006 (0.0989)	batch 1.2543 (1.4023)	loss 5.5234 (6.0513)	grad_norm 0.4602 (0.4986)	mem 44912MB
Train: [0/180][250/625]	eta 0:08:35 lr 0.799990	data 0.0007 (0.0794)	batch 1.2298 (1.3742)	loss 5.2101 (5.8913)	grad_norm 0.5220 (0.4999)	mem 44912MB
Train: [0/180][300/625]	eta 0:07:20 lr 0.799986	data 0.0008 (0.0663)	batch 1.2631 (1.3550)	loss 4.9166 (5.7486)	grad_norm 0.4811 (0.5002)	mem 44912MB
Train: [0/180][350/625]	eta 0:06:08 lr 0.799981	data 0.0007 (0.0570)	batch 1.2652 (1.3412)	loss 4.7000 (5.6152)	grad_norm 0.5208 (0.4996)	mem 44912MB
Train: [0/180][400/625]	eta 0:04:59 lr 0.799975	data 0.0007 (0.0500)	batch 1.2180 (1.3306)	loss 4.4933 (5.4932)	grad_norm 0.5375 (0.4993)	mem 44912MB
Train: [0/180][450/625]	eta 0:03:51 lr 0.799968	data 0.0010 (0.0445)	batch 1.2672 (1.3233)	loss 4.2062 (5.3751)	grad_norm 0.5580 (0.4987)	mem 44912MB
Train: [0/180][500/625]	eta 0:02:44 lr 0.799961	data 0.0009 (0.0402)	batch 1.2693 (1.3167)	loss 4.1421 (5.2621)	grad_norm 0.4602 (0.4984)	mem 44912MB
Train: [0/180][550/625]	eta 0:01:38 lr 0.799953	data 0.0011 (0.0366)	batch 1.2500 (1.3113)	loss 4.1362 (5.1514)	grad_norm 0.5045 (0.4970)	mem 44912MB
Train: [0/180][600/625]	eta 0:00:32 lr 0.799944	data 0.0013 (0.0336)	batch 1.2569 (1.3066)	loss 3.7805 (5.0450)	grad_norm 0.4786 (0.4961)	mem 44912MB
Current slope: None 	
EPOCH 0 training takes 0:13:36
Test: [0/25]	Time 14.310 (14.310)	Loss 3.9751 (3.9751)	Acc@1 18.262 (18.262)	Acc@5 42.383 (42.383)	Mem 44912MB
 * Acc@1 15.848 Acc@5 36.186
Accuracy of the network on the 50000 test images: 15.85%
Max accuracy (after decay): 15.85%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [1/180][0/625]	eta 4:07:24 lr 0.799939	data 20.4899 (20.4899)	batch 23.7510 (23.7510)	loss 3.6166 (3.6166)	grad_norm 0.4825 (0.4825)	mem 44912MB
Train: [1/180][50/625]	eta 0:16:27 lr 0.799929	data 0.0013 (0.4026)	batch 1.2341 (1.7170)	loss 3.6656 (3.6143)	grad_norm 0.4873 (0.4839)	mem 44912MB
Train: [1/180][100/625]	eta 0:13:02 lr 0.799918	data 0.0007 (0.2036)	batch 1.2482 (1.4898)	loss 3.2566 (3.5509)	grad_norm 0.4546 (0.4805)	mem 44912MB
Train: [1/180][150/625]	eta 0:11:11 lr 0.799906	data 0.0006 (0.1365)	batch 1.2772 (1.4132)	loss 3.2321 (3.4769)	grad_norm 0.4810 (0.4808)	mem 44912MB
Train: [1/180][200/625]	eta 0:09:44 lr 0.799894	data 0.0005 (0.1027)	batch 1.2740 (1.3761)	loss 3.1760 (3.3998)	grad_norm 0.4854 (0.4788)	mem 44912MB
Train: [1/180][250/625]	eta 0:08:26 lr 0.799881	data 0.0007 (0.0824)	batch 1.2658 (1.3515)	loss 3.1402 (3.3215)	grad_norm 0.4891 (0.4778)	mem 44912MB
Train: [1/180][300/625]	eta 0:07:14 lr 0.799867	data 0.0006 (0.0688)	batch 1.2686 (1.3369)	loss 2.6859 (3.2423)	grad_norm 0.5063 (0.4755)	mem 44912MB
Train: [1/180][350/625]	eta 0:06:04 lr 0.799852	data 0.0006 (0.0591)	batch 1.2693 (1.3262)	loss 2.8100 (3.1709)	grad_norm 0.4559 (0.4738)	mem 44912MB
Train: [1/180][400/625]	eta 0:04:56 lr 0.799836	data 0.0007 (0.0519)	batch 1.2209 (1.3186)	loss 2.5904 (3.0979)	grad_norm 0.4464 (0.4726)	mem 44912MB
Train: [1/180][450/625]	eta 0:03:49 lr 0.799820	data 0.0006 (0.0462)	batch 1.2507 (1.3115)	loss 2.3672 (3.0256)	grad_norm 0.4461 (0.4720)	mem 44912MB
Train: [1/180][500/625]	eta 0:02:43 lr 0.799803	data 0.0005 (0.0416)	batch 1.2407 (1.3062)	loss 2.1496 (2.9544)	grad_norm 0.4278 (0.4705)	mem 44912MB
Train: [1/180][550/625]	eta 0:01:37 lr 0.799785	data 0.0004 (0.0379)	batch 1.2421 (1.3018)	loss 2.0387 (2.8839)	grad_norm 0.4640 (0.4688)	mem 44912MB
Train: [1/180][600/625]	eta 0:00:32 lr 0.799766	data 0.0005 (0.0348)	batch 1.2409 (1.2987)	loss 1.9202 (2.8132)	grad_norm 0.4403 (0.4683)	mem 44912MB
Current slope: None 	
EPOCH 1 training takes 0:13:32
Test: [0/25]	Time 14.222 (14.222)	Loss 3.4353 (3.4353)	Acc@1 29.834 (29.834)	Acc@5 57.080 (57.080)	Mem 44912MB
 * Acc@1 24.118 Acc@5 48.074
Accuracy of the network on the 50000 test images: 24.12%
Max accuracy (after decay): 24.12%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [2/180][0/625]	eta 4:00:43 lr 0.799756	data 21.0906 (21.0906)	batch 23.1098 (23.1098)	loss 1.8584 (1.8584)	grad_norm 0.4351 (0.4351)	mem 44912MB
Train: [2/180][50/625]	eta 0:16:13 lr 0.799736	data 0.0008 (0.4144)	batch 1.2595 (1.6933)	loss 1.8597 (1.8285)	grad_norm 0.4717 (0.4589)	mem 44912MB
Train: [2/180][100/625]	eta 0:12:57 lr 0.799716	data 0.0008 (0.2097)	batch 1.2986 (1.4808)	loss 1.6478 (1.7565)	grad_norm 0.4453 (0.4543)	mem 44912MB
Train: [2/180][150/625]	eta 0:11:08 lr 0.799694	data 0.0007 (0.1405)	batch 1.2575 (1.4065)	loss 1.4545 (1.6805)	grad_norm 0.4965 (0.4526)	mem 44912MB
Train: [2/180][200/625]	eta 0:09:42 lr 0.799672	data 0.0007 (0.1060)	batch 1.2587 (1.3707)	loss 1.3115 (1.6197)	grad_norm 0.4653 (0.4556)	mem 44912MB
Train: [2/180][250/625]	eta 0:08:25 lr 0.799649	data 0.0011 (0.0850)	batch 1.2487 (1.3491)	loss 1.1663 (1.5549)	grad_norm 0.4391 (0.4538)	mem 44912MB
Train: [2/180][300/625]	eta 0:07:13 lr 0.799625	data 0.0006 (0.0710)	batch 1.2405 (1.3349)	loss 1.1312 (1.4916)	grad_norm 0.4326 (0.4537)	mem 44912MB
Train: [2/180][350/625]	eta 0:06:04 lr 0.799601	data 0.0006 (0.0610)	batch 1.2517 (1.3248)	loss 1.0706 (1.4276)	grad_norm 0.4344 (0.4527)	mem 44912MB
Train: [2/180][400/625]	eta 0:04:56 lr 0.799575	data 0.0009 (0.0535)	batch 1.2286 (1.3171)	loss 0.6772 (1.3633)	grad_norm 0.4187 (0.4519)	mem 44912MB
Train: [2/180][450/625]	eta 0:03:49 lr 0.799549	data 0.0008 (0.0477)	batch 1.3879 (1.3113)	loss 0.7790 (1.2988)	grad_norm 0.4392 (0.4513)	mem 44912MB
Train: [2/180][500/625]	eta 0:02:43 lr 0.799522	data 0.0007 (0.0430)	batch 1.2745 (1.3065)	loss 0.5404 (1.2344)	grad_norm 0.4394 (0.4506)	mem 44912MB
Train: [2/180][550/625]	eta 0:01:37 lr 0.799495	data 0.0012 (0.0391)	batch 1.2656 (1.3019)	loss 0.5286 (1.1715)	grad_norm 0.4259 (0.4502)	mem 44912MB
Train: [2/180][600/625]	eta 0:00:32 lr 0.799466	data 0.0007 (0.0360)	batch 1.2490 (1.2984)	loss 0.4109 (1.1093)	grad_norm 0.4532 (0.4503)	mem 44912MB
Current slope: None 	
EPOCH 2 training takes 0:13:31
Test: [0/25]	Time 14.444 (14.444)	Loss 2.9232 (2.9232)	Acc@1 38.525 (38.525)	Acc@5 65.283 (65.283)	Mem 44912MB
 * Acc@1 29.344 Acc@5 54.494
Accuracy of the network on the 50000 test images: 29.34%
Max accuracy (after decay): 29.34%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [3/180][0/625]	eta 3:54:18 lr 0.799452	data 20.4166 (20.4166)	batch 22.4943 (22.4943)	loss 0.3605 (0.3605)	grad_norm 0.4349 (0.4349)	mem 44912MB
Train: [3/180][50/625]	eta 0:16:05 lr 0.799422	data 0.0008 (0.4011)	batch 1.2180 (1.6794)	loss 0.1602 (0.2224)	grad_norm 0.4430 (0.4492)	mem 44912MB
Train: [3/180][100/625]	eta 0:12:52 lr 0.799392	data 0.0006 (0.2030)	batch 1.2817 (1.4720)	loss -0.0077 (0.1640)	grad_norm 0.4524 (0.4468)	mem 44912MB
Train: [3/180][150/625]	eta 0:11:07 lr 0.799361	data 0.0013 (0.1362)	batch 1.2779 (1.4053)	loss -0.2246 (0.0993)	grad_norm 0.4322 (0.4459)	mem 44912MB
Train: [3/180][200/625]	eta 0:09:41 lr 0.799329	data 0.0008 (0.1025)	batch 1.2569 (1.3680)	loss -0.0839 (0.0479)	grad_norm 0.4197 (0.4433)	mem 44912MB
Train: [3/180][250/625]	eta 0:08:25 lr 0.799296	data 0.0016 (0.0823)	batch 1.2472 (1.3469)	loss -0.3284 (-0.0068)	grad_norm 0.4499 (0.4429)	mem 44912MB
Train: [3/180][300/625]	eta 0:07:13 lr 0.799262	data 0.0006 (0.0687)	batch 1.2560 (1.3325)	loss -0.5715 (-0.0678)	grad_norm 0.4441 (0.4432)	mem 44912MB
Train: [3/180][350/625]	eta 0:06:03 lr 0.799228	data 0.0011 (0.0591)	batch 1.2380 (1.3225)	loss -0.3961 (-0.1252)	grad_norm 0.4254 (0.4427)	mem 44912MB
Train: [3/180][400/625]	eta 0:04:55 lr 0.799193	data 0.0006 (0.0518)	batch 1.2765 (1.3142)	loss -0.5723 (-0.1847)	grad_norm 0.4344 (0.4424)	mem 44912MB
Train: [3/180][450/625]	eta 0:03:49 lr 0.799157	data 0.0008 (0.0462)	batch 1.2621 (1.3091)	loss -0.7302 (-0.2403)	grad_norm 0.4284 (0.4422)	mem 44912MB
Train: [3/180][500/625]	eta 0:02:43 lr 0.799121	data 0.0012 (0.0416)	batch 1.5063 (1.3047)	loss -0.8138 (-0.2999)	grad_norm 0.4290 (0.4417)	mem 44912MB
Train: [3/180][550/625]	eta 0:01:37 lr 0.799083	data 0.0008 (0.0379)	batch 1.3126 (1.3014)	loss -1.0658 (-0.3590)	grad_norm 0.4176 (0.4413)	mem 44912MB
Train: [3/180][600/625]	eta 0:00:32 lr 0.799045	data 0.0011 (0.0348)	batch 1.2837 (1.2975)	loss -0.9709 (-0.4148)	grad_norm 0.4196 (0.4405)	mem 44912MB
Current slope: None 	
EPOCH 3 training takes 0:13:31
Test: [0/25]	Time 14.224 (14.224)	Loss 2.6941 (2.6941)	Acc@1 40.283 (40.283)	Acc@5 68.359 (68.359)	Mem 44912MB
 * Acc@1 31.754 Acc@5 57.804
Accuracy of the network on the 50000 test images: 31.75%
Max accuracy (after decay): 31.75%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [4/180][0/625]	eta 4:00:11 lr 0.799026	data 20.3678 (20.3678)	batch 23.0582 (23.0582)	loss -1.3143 (-1.3143)	grad_norm 0.4367 (0.4367)	mem 44912MB
Train: [4/180][50/625]	eta 0:16:08 lr 0.798986	data 0.0007 (0.4002)	batch 1.2729 (1.6850)	loss -1.1429 (-1.2388)	grad_norm 0.4492 (0.4339)	mem 44912MB
Train: [4/180][100/625]	eta 0:12:53 lr 0.798946	data 0.0007 (0.2025)	batch 1.2468 (1.4735)	loss -1.4351 (-1.2904)	grad_norm 0.4199 (0.4362)	mem 44912MB
Train: [4/180][150/625]	eta 0:11:07 lr 0.798905	data 0.0009 (0.1357)	batch 1.2714 (1.4049)	loss -1.4585 (-1.3388)	grad_norm 0.4193 (0.4344)	mem 44912MB
Train: [4/180][200/625]	eta 0:09:41 lr 0.798864	data 0.0008 (0.1021)	batch 1.2755 (1.3691)	loss -1.5152 (-1.3947)	grad_norm 0.4282 (0.4348)	mem 44912MB
Train: [4/180][250/625]	eta 0:08:24 lr 0.798821	data 0.0009 (0.0820)	batch 1.2566 (1.3464)	loss -2.0108 (-1.4421)	grad_norm 0.4289 (0.4361)	mem 44912MB
Train: [4/180][300/625]	eta 0:07:12 lr 0.798778	data 0.0007 (0.0685)	batch 1.2319 (1.3322)	loss -1.9166 (-1.4911)	grad_norm 0.4223 (0.4350)	mem 44912MB
Train: [4/180][350/625]	eta 0:06:03 lr 0.798734	data 0.0008 (0.0588)	batch 1.2677 (1.3226)	loss -1.9690 (-1.5490)	grad_norm 0.4377 (0.4356)	mem 44912MB
Train: [4/180][400/625]	eta 0:04:55 lr 0.798689	data 0.0006 (0.0516)	batch 1.2665 (1.3151)	loss -1.9562 (-1.6046)	grad_norm 0.4411 (0.4346)	mem 44912MB
Train: [4/180][450/625]	eta 0:03:49 lr 0.798644	data 0.0007 (0.0460)	batch 1.2191 (1.3092)	loss -2.0164 (-1.6540)	grad_norm 0.4125 (0.4339)	mem 44912MB
Train: [4/180][500/625]	eta 0:02:43 lr 0.798597	data 0.0006 (0.0415)	batch 1.2541 (1.3044)	loss -2.3224 (-1.7090)	grad_norm 0.4203 (0.4337)	mem 44912MB
Train: [4/180][550/625]	eta 0:01:37 lr 0.798550	data 0.0011 (0.0378)	batch 1.2936 (1.3007)	loss -2.5465 (-1.7630)	grad_norm 0.4315 (0.4335)	mem 44912MB
Train: [4/180][600/625]	eta 0:00:32 lr 0.798502	data 0.0006 (0.0347)	batch 1.2414 (1.2976)	loss -2.4927 (-1.8157)	grad_norm 0.4247 (0.4329)	mem 44912MB
Current slope: None 	
EPOCH 4 training takes 0:13:31
Test: [0/25]	Time 14.482 (14.482)	Loss 2.5992 (2.5992)	Acc@1 45.752 (45.752)	Acc@5 70.605 (70.605)	Mem 44912MB
 * Acc@1 34.794 Acc@5 60.702
Accuracy of the network on the 50000 test images: 34.79%
Max accuracy (after decay): 34.79%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [5/180][0/625]	eta 4:02:22 lr 0.798478	data 21.1935 (21.1935)	batch 23.2675 (23.2675)	loss -2.4540 (-2.4540)	grad_norm 0.4429 (0.4429)	mem 44912MB
Train: [5/180][50/625]	eta 0:16:15 lr 0.798429	data 0.0009 (0.4165)	batch 1.2326 (1.6960)	loss -2.7219 (-2.5752)	grad_norm 0.4676 (0.4313)	mem 44912MB
Train: [5/180][100/625]	eta 0:12:58 lr 0.798379	data 0.0007 (0.2107)	batch 1.2401 (1.4822)	loss -2.7445 (-2.6354)	grad_norm 0.4230 (0.4330)	mem 44912MB
Train: [5/180][150/625]	eta 0:11:09 lr 0.798328	data 0.0004 (0.1412)	batch 1.2744 (1.4085)	loss -2.8464 (-2.6747)	grad_norm 0.4182 (0.4322)	mem 44912MB
Train: [5/180][200/625]	eta 0:09:43 lr 0.798277	data 0.0008 (0.1063)	batch 1.2295 (1.3729)	loss -2.8112 (-2.7234)	grad_norm 0.4385 (0.4316)	mem 44912MB
Train: [5/180][250/625]	eta 0:08:26 lr 0.798225	data 0.0008 (0.0853)	batch 1.2316 (1.3503)	loss -3.1108 (-2.7699)	grad_norm 0.4212 (0.4310)	mem 44912MB
Train: [5/180][300/625]	eta 0:07:13 lr 0.798172	data 0.0004 (0.0712)	batch 1.2408 (1.3351)	loss -3.0115 (-2.8196)	grad_norm 0.4241 (0.4313)	mem 44912MB
Train: [5/180][350/625]	eta 0:06:04 lr 0.798118	data 0.0006 (0.0612)	batch 1.2611 (1.3248)	loss -3.1535 (-2.8720)	grad_norm 0.4175 (0.4306)	mem 44912MB
Train: [5/180][400/625]	eta 0:04:56 lr 0.798064	data 0.0007 (0.0537)	batch 1.2749 (1.3176)	loss -3.2446 (-2.9251)	grad_norm 0.4379 (0.4301)	mem 44912MB
Train: [5/180][450/625]	eta 0:03:49 lr 0.798008	data 0.0007 (0.0478)	batch 1.2818 (1.3112)	loss -3.5552 (-2.9725)	grad_norm 0.4352 (0.4303)	mem 44912MB
Train: [5/180][500/625]	eta 0:02:43 lr 0.797952	data 0.0007 (0.0431)	batch 1.2569 (1.3059)	loss -3.7073 (-3.0234)	grad_norm 0.4209 (0.4299)	mem 44912MB
Train: [5/180][550/625]	eta 0:01:37 lr 0.797896	data 0.0005 (0.0392)	batch 1.2613 (1.3016)	loss -3.5212 (-3.0730)	grad_norm 0.4099 (0.4294)	mem 44912MB
Train: [5/180][600/625]	eta 0:00:32 lr 0.797838	data 0.0010 (0.0360)	batch 1.2362 (1.2985)	loss -3.5843 (-3.1251)	grad_norm 0.4134 (0.4289)	mem 44912MB
Current slope: None 	
EPOCH 5 training takes 0:13:31
Test: [0/25]	Time 14.107 (14.107)	Loss 2.3579 (2.3579)	Acc@1 48.340 (48.340)	Acc@5 74.170 (74.170)	Mem 44912MB
 * Acc@1 36.628 Acc@5 62.754
Accuracy of the network on the 50000 test images: 36.63%
Max accuracy (after decay): 36.63%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [6/180][0/625]	eta 3:58:57 lr 0.797809	data 21.3985 (21.3985)	batch 22.9396 (22.9396)	loss -3.6518 (-3.6518)	grad_norm 0.4540 (0.4540)	mem 44912MB
Train: [6/180][50/625]	eta 0:16:09 lr 0.797750	data 0.0008 (0.4204)	batch 1.2811 (1.6860)	loss -4.0310 (-3.8443)	grad_norm 0.4101 (0.4253)	mem 44912MB
Train: [6/180][100/625]	eta 0:12:54 lr 0.797691	data 0.0008 (0.2130)	batch 1.3092 (1.4754)	loss -3.9368 (-3.8793)	grad_norm 0.4560 (0.4282)	mem 44912MB
Train: [6/180][150/625]	eta 0:11:07 lr 0.797630	data 0.0006 (0.1428)	batch 1.2504 (1.4048)	loss -4.0171 (-3.9269)	grad_norm 0.4287 (0.4275)	mem 44912MB
Train: [6/180][200/625]	eta 0:09:41 lr 0.797569	data 0.0010 (0.1075)	batch 1.2304 (1.3684)	loss -4.0016 (-3.9664)	grad_norm 0.4402 (0.4269)	mem 44912MB
Train: [6/180][250/625]	eta 0:08:25 lr 0.797507	data 0.0005 (0.0862)	batch 1.3913 (1.3475)	loss -4.1581 (-4.0171)	grad_norm 0.4475 (0.4277)	mem 44912MB
Train: [6/180][300/625]	eta 0:07:13 lr 0.797445	data 0.0008 (0.0720)	batch 1.2458 (1.3327)	loss -4.3128 (-4.0652)	grad_norm 0.4293 (0.4271)	mem 44912MB
Train: [6/180][350/625]	eta 0:06:03 lr 0.797381	data 0.0015 (0.0619)	batch 1.2544 (1.3228)	loss -4.4851 (-4.1131)	grad_norm 0.4212 (0.4268)	mem 44912MB
Train: [6/180][400/625]	eta 0:04:55 lr 0.797317	data 0.0007 (0.0543)	batch 1.2321 (1.3153)	loss -4.4701 (-4.1604)	grad_norm 0.4201 (0.4264)	mem 44912MB
Train: [6/180][450/625]	eta 0:03:49 lr 0.797252	data 0.0009 (0.0484)	batch 1.2638 (1.3097)	loss -4.6240 (-4.2091)	grad_norm 0.4276 (0.4263)	mem 44912MB
Train: [6/180][500/625]	eta 0:02:43 lr 0.797186	data 0.0013 (0.0436)	batch 1.2651 (1.3050)	loss -4.6045 (-4.2559)	grad_norm 0.4143 (0.4258)	mem 44912MB
Train: [6/180][550/625]	eta 0:01:37 lr 0.797120	data 0.0007 (0.0397)	batch 1.2297 (1.3009)	loss -4.8483 (-4.3025)	grad_norm 0.4172 (0.4258)	mem 44912MB
Train: [6/180][600/625]	eta 0:00:32 lr 0.797053	data 0.0007 (0.0365)	batch 1.2583 (1.2977)	loss -5.0730 (-4.3497)	grad_norm 0.4283 (0.4258)	mem 44912MB
Current slope: None 	
EPOCH 6 training takes 0:13:31
Test: [0/25]	Time 14.694 (14.694)	Loss 2.2164 (2.2164)	Acc@1 50.098 (50.098)	Acc@5 76.416 (76.416)	Mem 44912MB
 * Acc@1 38.698 Acc@5 65.172
Accuracy of the network on the 50000 test images: 38.70%
Max accuracy (after decay): 38.70%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [7/180][0/625]	eta 3:59:46 lr 0.797019	data 20.9000 (20.9000)	batch 23.0179 (23.0179)	loss -4.9779 (-4.9779)	grad_norm 0.4147 (0.4147)	mem 44912MB
Train: [7/180][50/625]	eta 0:16:12 lr 0.796950	data 0.0006 (0.4105)	batch 1.2575 (1.6906)	loss -5.0456 (-5.0262)	grad_norm 0.4290 (0.4239)	mem 44912MB
Train: [7/180][100/625]	eta 0:12:57 lr 0.796881	data 0.0008 (0.2077)	batch 1.2334 (1.4806)	loss -5.0679 (-5.0575)	grad_norm 0.4207 (0.4243)	mem 44912MB
Train: [7/180][150/625]	eta 0:11:10 lr 0.796811	data 0.0007 (0.1392)	batch 1.2190 (1.4110)	loss -5.3085 (-5.1104)	grad_norm 0.4296 (0.4236)	mem 44912MB
Train: [7/180][200/625]	eta 0:09:43 lr 0.796740	data 0.0007 (0.1048)	batch 1.2323 (1.3732)	loss -5.3204 (-5.1581)	grad_norm 0.4223 (0.4237)	mem 44912MB
Train: [7/180][250/625]	eta 0:08:27 lr 0.796669	data 0.0007 (0.0842)	batch 1.3164 (1.3529)	loss -5.4658 (-5.2006)	grad_norm 0.4291 (0.4240)	mem 44912MB
Train: [7/180][300/625]	eta 0:07:15 lr 0.796596	data 0.0008 (0.0704)	batch 1.2491 (1.3390)	loss -5.5855 (-5.2454)	grad_norm 0.4072 (0.4235)	mem 44912MB
Train: [7/180][350/625]	eta 0:06:05 lr 0.796523	data 0.0008 (0.0605)	batch 1.2251 (1.3286)	loss -5.5803 (-5.2882)	grad_norm 0.4197 (0.4232)	mem 44912MB
Train: [7/180][400/625]	eta 0:04:57 lr 0.796449	data 0.0008 (0.0530)	batch 1.2677 (1.3206)	loss -5.6709 (-5.3307)	grad_norm 0.4178 (0.4234)	mem 44912MB
Train: [7/180][450/625]	eta 0:03:50 lr 0.796375	data 0.0006 (0.0472)	batch 1.3285 (1.3148)	loss -5.7648 (-5.3773)	grad_norm 0.4154 (0.4230)	mem 44912MB
Train: [7/180][500/625]	eta 0:02:43 lr 0.796299	data 0.0008 (0.0426)	batch 1.2531 (1.3097)	loss -5.9115 (-5.4223)	grad_norm 0.4194 (0.4229)	mem 44912MB
Train: [7/180][550/625]	eta 0:01:37 lr 0.796223	data 0.0005 (0.0388)	batch 1.2484 (1.3058)	loss -6.2004 (-5.4659)	grad_norm 0.4209 (0.4226)	mem 44912MB
Train: [7/180][600/625]	eta 0:00:32 lr 0.796146	data 0.0005 (0.0356)	batch 1.3234 (1.3027)	loss -6.0224 (-5.5099)	grad_norm 0.4431 (0.4225)	mem 44912MB
Current slope: None 	
EPOCH 7 training takes 0:13:34
Test: [0/25]	Time 14.522 (14.522)	Loss 2.3592 (2.3592)	Acc@1 48.242 (48.242)	Acc@5 74.268 (74.268)	Mem 44912MB
 * Acc@1 39.746 Acc@5 65.896
Accuracy of the network on the 50000 test images: 39.75%
Max accuracy (after decay): 39.75%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [8/180][0/625]	eta 3:59:09 lr 0.796107	data 20.5920 (20.5920)	batch 22.9588 (22.9588)	loss -5.9082 (-5.9082)	grad_norm 0.4323 (0.4323)	mem 44912MB
Train: [8/180][50/625]	eta 0:16:09 lr 0.796029	data 0.0006 (0.4049)	batch 1.2691 (1.6855)	loss -6.1314 (-6.0965)	grad_norm 0.4140 (0.4206)	mem 44912MB
Train: [8/180][100/625]	eta 0:12:54 lr 0.795950	data 0.0009 (0.2049)	batch 1.2481 (1.4754)	loss -6.1115 (-6.1553)	grad_norm 0.4307 (0.4228)	mem 44912MB
Train: [8/180][150/625]	eta 0:11:07 lr 0.795871	data 0.0010 (0.1373)	batch 1.2419 (1.4058)	loss -6.4206 (-6.2058)	grad_norm 0.4100 (0.4217)	mem 44912MB
Train: [8/180][200/625]	eta 0:09:42 lr 0.795790	data 0.0011 (0.1034)	batch 1.2540 (1.3712)	loss -6.5683 (-6.2545)	grad_norm 0.4148 (0.4215)	mem 44912MB
Train: [8/180][250/625]	eta 0:08:26 lr 0.795709	data 0.0006 (0.0829)	batch 1.3364 (1.3498)	loss -6.4009 (-6.2969)	grad_norm 0.4580 (0.4215)	mem 44912MB
Train: [8/180][300/625]	eta 0:07:13 lr 0.795627	data 0.0006 (0.0693)	batch 1.2786 (1.3352)	loss -6.5230 (-6.3386)	grad_norm 0.4354 (0.4223)	mem 44912MB
Train: [8/180][350/625]	eta 0:06:04 lr 0.795544	data 0.0007 (0.0595)	batch 1.3026 (1.3247)	loss -6.6765 (-6.3814)	grad_norm 0.4145 (0.4212)	mem 44912MB
Train: [8/180][400/625]	eta 0:04:56 lr 0.795461	data 0.0008 (0.0522)	batch 1.2292 (1.3172)	loss -6.5168 (-6.4238)	grad_norm 0.4207 (0.4208)	mem 44912MB
Train: [8/180][450/625]	eta 0:03:49 lr 0.795377	data 0.0012 (0.0465)	batch 1.2349 (1.3112)	loss -7.0980 (-6.4679)	grad_norm 0.4125 (0.4208)	mem 44912MB
Train: [8/180][500/625]	eta 0:02:43 lr 0.795292	data 0.0006 (0.0419)	batch 1.2391 (1.3064)	loss -6.8360 (-6.5086)	grad_norm 0.4120 (0.4206)	mem 44912MB
Train: [8/180][550/625]	eta 0:01:37 lr 0.795206	data 0.0006 (0.0382)	batch 1.2452 (1.3027)	loss -7.0055 (-6.5494)	grad_norm 0.4158 (0.4207)	mem 44912MB
Train: [8/180][600/625]	eta 0:00:32 lr 0.795119	data 0.0008 (0.0351)	batch 1.2763 (1.3002)	loss -6.9547 (-6.5924)	grad_norm 0.4194 (0.4203)	mem 44912MB
Current slope: None 	
EPOCH 8 training takes 0:13:32
Test: [0/25]	Time 14.551 (14.551)	Loss 2.0697 (2.0697)	Acc@1 52.490 (52.490)	Acc@5 78.076 (78.076)	Mem 44912MB
 * Acc@1 41.360 Acc@5 67.950
Accuracy of the network on the 50000 test images: 41.36%
Max accuracy (after decay): 41.36%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [9/180][0/625]	eta 4:03:38 lr 0.795076	data 21.4054 (21.4054)	batch 23.3894 (23.3894)	loss -7.1328 (-7.1328)	grad_norm 0.4198 (0.4198)	mem 44912MB
Train: [9/180][50/625]	eta 0:16:15 lr 0.794988	data 0.0006 (0.4206)	batch 1.2803 (1.6958)	loss -7.2371 (-7.1968)	grad_norm 0.4011 (0.4174)	mem 44912MB
Train: [9/180][100/625]	eta 0:12:58 lr 0.794899	data 0.0007 (0.2128)	batch 1.2478 (1.4829)	loss -7.1612 (-7.2413)	grad_norm 0.4259 (0.4179)	mem 44912MB
Train: [9/180][150/625]	eta 0:11:09 lr 0.794810	data 0.0007 (0.1426)	batch 1.2446 (1.4100)	loss -7.1079 (-7.2717)	grad_norm 0.4170 (0.4188)	mem 44912MB
Train: [9/180][200/625]	eta 0:09:44 lr 0.794720	data 0.0013 (0.1073)	batch 1.2904 (1.3742)	loss -7.5113 (-7.3098)	grad_norm 0.4069 (0.4188)	mem 44912MB
Train: [9/180][250/625]	eta 0:08:26 lr 0.794629	data 0.0005 (0.0861)	batch 1.2622 (1.3512)	loss -7.5397 (-7.3494)	grad_norm 0.4123 (0.4192)	mem 44912MB
Train: [9/180][300/625]	eta 0:07:14 lr 0.794538	data 0.0007 (0.0719)	batch 1.2951 (1.3367)	loss -7.6103 (-7.3896)	grad_norm 0.4048 (0.4193)	mem 44912MB
Train: [9/180][350/625]	eta 0:06:04 lr 0.794445	data 0.0007 (0.0618)	batch 1.2663 (1.3261)	loss -7.9607 (-7.4278)	grad_norm 0.4273 (0.4192)	mem 44912MB
Train: [9/180][400/625]	eta 0:04:56 lr 0.794352	data 0.0017 (0.0542)	batch 1.2814 (1.3189)	loss -7.7570 (-7.4648)	grad_norm 0.4523 (0.4193)	mem 44912MB
Train: [9/180][450/625]	eta 0:03:49 lr 0.794258	data 0.0007 (0.0483)	batch 1.2711 (1.3123)	loss -7.8384 (-7.5041)	grad_norm 0.4147 (0.4194)	mem 44912MB
Train: [9/180][500/625]	eta 0:02:43 lr 0.794163	data 0.0008 (0.0435)	batch 1.2886 (1.3081)	loss -8.0166 (-7.5444)	grad_norm 0.4166 (0.4194)	mem 44912MB
Train: [9/180][550/625]	eta 0:01:37 lr 0.794068	data 0.0005 (0.0397)	batch 1.2766 (1.3041)	loss -8.1839 (-7.5838)	grad_norm 0.4182 (0.4190)	mem 44912MB
Train: [9/180][600/625]	eta 0:00:32 lr 0.793972	data 0.0005 (0.0364)	batch 1.4693 (1.3015)	loss -8.3614 (-7.6224)	grad_norm 0.4095 (0.4189)	mem 44912MB
Current slope: None 	
EPOCH 9 training takes 0:13:33
Test: [0/25]	Time 14.388 (14.388)	Loss 2.1407 (2.1407)	Acc@1 53.613 (53.613)	Acc@5 78.174 (78.174)	Mem 44912MB
 * Acc@1 42.350 Acc@5 68.538
Accuracy of the network on the 50000 test images: 42.35%
Max accuracy (after decay): 42.35%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [10/180][0/625]	eta 3:54:53 lr 0.793923	data 20.7373 (20.7373)	batch 22.5503 (22.5503)	loss -8.1700 (-8.1700)	grad_norm 0.4057 (0.4057)	mem 44912MB
Train: [10/180][50/625]	eta 0:16:08 lr 0.793826	data 0.0006 (0.4074)	batch 1.2680 (1.6842)	loss -8.2928 (-8.1626)	grad_norm 0.4221 (0.4182)	mem 44912MB
Train: [10/180][100/625]	eta 0:12:55 lr 0.793728	data 0.0005 (0.2062)	batch 1.2764 (1.4765)	loss -8.4721 (-8.2111)	grad_norm 0.4246 (0.4195)	mem 44912MB
Train: [10/180][150/625]	eta 0:11:08 lr 0.793629	data 0.0007 (0.1382)	batch 1.2616 (1.4066)	loss -8.3830 (-8.2532)	grad_norm 0.4191 (0.4181)	mem 44912MB
Train: [10/180][200/625]	eta 0:09:42 lr 0.793529	data 0.0007 (0.1040)	batch 1.2596 (1.3706)	loss -8.4229 (-8.2893)	grad_norm 0.4103 (0.4178)	mem 44912MB
Train: [10/180][250/625]	eta 0:08:25 lr 0.793429	data 0.0011 (0.0835)	batch 1.2437 (1.3491)	loss -8.3677 (-8.3280)	grad_norm 0.4189 (0.4178)	mem 44912MB
Train: [10/180][300/625]	eta 0:07:13 lr 0.793328	data 0.0007 (0.0697)	batch 1.2201 (1.3348)	loss -8.5135 (-8.3743)	grad_norm 0.4150 (0.4172)	mem 44912MB
Train: [10/180][350/625]	eta 0:06:04 lr 0.793226	data 0.0013 (0.0599)	batch 1.2528 (1.3249)	loss -8.6934 (-8.4097)	grad_norm 0.4033 (0.4177)	mem 44912MB
Train: [10/180][400/625]	eta 0:04:56 lr 0.793123	data 0.0010 (0.0525)	batch 1.2517 (1.3173)	loss -8.9715 (-8.4493)	grad_norm 0.4061 (0.4178)	mem 44912MB
Train: [10/180][450/625]	eta 0:03:49 lr 0.793020	data 0.0011 (0.0468)	batch 1.2441 (1.3113)	loss -8.8335 (-8.4860)	grad_norm 0.4128 (0.4178)	mem 44912MB
Train: [10/180][500/625]	eta 0:02:43 lr 0.792915	data 0.0007 (0.0422)	batch 1.3215 (1.3067)	loss -8.9522 (-8.5199)	grad_norm 0.4255 (0.4178)	mem 44912MB
Train: [10/180][550/625]	eta 0:01:37 lr 0.792810	data 0.0006 (0.0384)	batch 1.3255 (1.3028)	loss -8.9765 (-8.5598)	grad_norm 0.4132 (0.4176)	mem 44912MB
Train: [10/180][600/625]	eta 0:00:32 lr 0.792704	data 0.0006 (0.0353)	batch 1.3030 (1.2997)	loss -9.0431 (-8.5980)	grad_norm 0.4213 (0.4179)	mem 44912MB
Current slope: None 	
EPOCH 10 training takes 0:13:32
Test: [0/25]	Time 14.691 (14.691)	Loss 2.0621 (2.0621)	Acc@1 54.395 (54.395)	Acc@5 78.613 (78.613)	Mem 44912MB
 * Acc@1 42.998 Acc@5 68.756
Accuracy of the network on the 50000 test images: 43.00%
Max accuracy (after decay): 43.00%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [11/180][0/625]	eta 3:55:42 lr 0.792651	data 20.9419 (20.9419)	batch 22.6279 (22.6279)	loss -8.9347 (-8.9347)	grad_norm 0.4082 (0.4082)	mem 44912MB
Train: [11/180][50/625]	eta 0:16:09 lr 0.792544	data 0.0007 (0.4117)	batch 1.2114 (1.6860)	loss -9.0845 (-9.1391)	grad_norm 0.4197 (0.4220)	mem 44912MB
Train: [11/180][100/625]	eta 0:12:54 lr 0.792437	data 0.0008 (0.2083)	batch 1.2310 (1.4757)	loss -9.2770 (-9.1665)	grad_norm 0.4786 (0.4211)	mem 44912MB
Train: [11/180][150/625]	eta 0:11:07 lr 0.792328	data 0.0006 (0.1396)	batch 1.2611 (1.4060)	loss -9.2191 (-9.2098)	grad_norm 0.4212 (0.4195)	mem 44912MB
Train: [11/180][200/625]	eta 0:09:42 lr 0.792219	data 0.0007 (0.1051)	batch 1.3244 (1.3703)	loss -9.3391 (-9.2391)	grad_norm 0.4193 (0.4182)	mem 44912MB
Train: [11/180][250/625]	eta 0:08:26 lr 0.792109	data 0.0005 (0.0843)	batch 1.2419 (1.3498)	loss -9.5051 (-9.2738)	grad_norm 0.4063 (0.4187)	mem 44912MB
Train: [11/180][300/625]	eta 0:07:14 lr 0.791998	data 0.0010 (0.0704)	batch 1.3128 (1.3355)	loss -9.4240 (-9.3083)	grad_norm 0.4027 (0.4179)	mem 44912MB
Train: [11/180][350/625]	eta 0:06:04 lr 0.791887	data 0.0009 (0.0606)	batch 1.2373 (1.3259)	loss -9.7309 (-9.3442)	grad_norm 0.4040 (0.4177)	mem 44912MB
Train: [11/180][400/625]	eta 0:04:56 lr 0.791774	data 0.0007 (0.0532)	batch 1.2459 (1.3176)	loss -9.7665 (-9.3812)	grad_norm 0.4005 (0.4176)	mem 44912MB
Train: [11/180][450/625]	eta 0:03:49 lr 0.791661	data 0.0005 (0.0474)	batch 1.2215 (1.3120)	loss -9.8458 (-9.4135)	grad_norm 0.4052 (0.4182)	mem 44912MB
Train: [11/180][500/625]	eta 0:02:43 lr 0.791547	data 0.0012 (0.0427)	batch 1.2941 (1.3072)	loss -9.8416 (-9.4506)	grad_norm 0.4138 (0.4180)	mem 44912MB
Train: [11/180][550/625]	eta 0:01:37 lr 0.791433	data 0.0006 (0.0389)	batch 1.2567 (1.3035)	loss -9.7180 (-9.4855)	grad_norm 0.4402 (0.4178)	mem 44912MB
Train: [11/180][600/625]	eta 0:00:32 lr 0.791317	data 0.0009 (0.0357)	batch 1.2579 (1.2997)	loss -9.8006 (-9.5216)	grad_norm 0.4192 (0.4175)	mem 44912MB
Current slope: None 	
EPOCH 11 training takes 0:13:32
Test: [0/25]	Time 14.715 (14.715)	Loss 2.0340 (2.0340)	Acc@1 52.930 (52.930)	Acc@5 80.469 (80.469)	Mem 44912MB
 * Acc@1 43.468 Acc@5 69.610
Accuracy of the network on the 50000 test images: 43.47%
Max accuracy (after decay): 43.47%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [12/180][0/625]	eta 3:55:16 lr 0.791259	data 20.8713 (20.8713)	batch 22.5867 (22.5867)	loss -9.9183 (-9.9183)	grad_norm 0.4125 (0.4125)	mem 44912MB
Train: [12/180][50/625]	eta 0:16:09 lr 0.791143	data 0.0004 (0.4101)	batch 1.3136 (1.6859)	loss -9.9221 (-10.0365)	grad_norm 0.4103 (0.4182)	mem 44912MB
Train: [12/180][100/625]	eta 0:12:56 lr 0.791026	data 0.0006 (0.2075)	batch 1.3023 (1.4793)	loss -10.2037 (-10.0629)	grad_norm 0.4150 (0.4192)	mem 44912MB
Train: [12/180][150/625]	eta 0:11:07 lr 0.790908	data 0.0007 (0.1390)	batch 1.2514 (1.4063)	loss -10.1170 (-10.0941)	grad_norm 0.4318 (0.4178)	mem 44912MB
Train: [12/180][200/625]	eta 0:09:42 lr 0.790789	data 0.0008 (0.1046)	batch 1.2585 (1.3703)	loss -10.3412 (-10.1301)	grad_norm 0.4217 (0.4181)	mem 44912MB
Train: [12/180][250/625]	eta 0:08:25 lr 0.790669	data 0.0007 (0.0840)	batch 1.2394 (1.3481)	loss -10.3183 (-10.1680)	grad_norm 0.4206 (0.4176)	mem 44912MB
Train: [12/180][300/625]	eta 0:07:13 lr 0.790549	data 0.0010 (0.0703)	batch 1.2846 (1.3344)	loss -10.1586 (-10.2000)	grad_norm 0.4064 (0.4177)	mem 44912MB
Train: [12/180][350/625]	eta 0:06:03 lr 0.790428	data 0.0006 (0.0603)	batch 1.2851 (1.3235)	loss -10.3542 (-10.2332)	grad_norm 0.4838 (0.4176)	mem 44912MB
Train: [12/180][400/625]	eta 0:04:56 lr 0.790306	data 0.0005 (0.0529)	batch 1.3279 (1.3168)	loss -10.4069 (-10.2669)	grad_norm 0.4184 (0.4172)	mem 44912MB
Train: [12/180][450/625]	eta 0:03:49 lr 0.790184	data 0.0006 (0.0471)	batch 1.2765 (1.3102)	loss -10.5727 (-10.2986)	grad_norm 0.4133 (0.4167)	mem 44912MB
Train: [12/180][500/625]	eta 0:02:43 lr 0.790060	data 0.0006 (0.0425)	batch 1.2303 (1.3056)	loss -10.7019 (-10.3313)	grad_norm 0.4290 (0.4166)	mem 44912MB
Train: [12/180][550/625]	eta 0:01:37 lr 0.789936	data 0.0006 (0.0387)	batch 1.2836 (1.3009)	loss -10.7580 (-10.3629)	grad_norm 0.4254 (0.4165)	mem 44912MB
Train: [12/180][600/625]	eta 0:00:32 lr 0.789811	data 0.0006 (0.0355)	batch 1.2248 (1.2977)	loss -10.6351 (-10.3950)	grad_norm 0.4068 (0.4164)	mem 44912MB
Current slope: None 	
EPOCH 12 training takes 0:13:31
Test: [0/25]	Time 14.622 (14.622)	Loss 2.0759 (2.0759)	Acc@1 54.346 (54.346)	Acc@5 79.785 (79.785)	Mem 44912MB
 * Acc@1 44.228 Acc@5 70.670
Accuracy of the network on the 50000 test images: 44.23%
Max accuracy (after decay): 44.23%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [13/180][0/625]	eta 4:00:10 lr 0.789749	data 21.3755 (21.3755)	batch 23.0575 (23.0575)	loss -10.8222 (-10.8222)	grad_norm 0.3982 (0.3982)	mem 44912MB
Train: [13/180][50/625]	eta 0:16:10 lr 0.789623	data 0.0008 (0.4203)	batch 1.2029 (1.6880)	loss -11.0399 (-10.8768)	grad_norm 0.4183 (0.4181)	mem 44912MB
Train: [13/180][100/625]	eta 0:12:56 lr 0.789496	data 0.0011 (0.2127)	batch 1.2235 (1.4783)	loss -10.9812 (-10.9151)	grad_norm 0.4045 (0.4168)	mem 44912MB
Train: [13/180][150/625]	eta 0:11:07 lr 0.789368	data 0.0006 (0.1425)	batch 1.2524 (1.4058)	loss -11.1706 (-10.9531)	grad_norm 0.4182 (0.4174)	mem 44912MB
Train: [13/180][200/625]	eta 0:09:42 lr 0.789240	data 0.0008 (0.1073)	batch 1.2244 (1.3713)	loss -11.0258 (-10.9902)	grad_norm 0.4128 (0.4173)	mem 44912MB
Train: [13/180][250/625]	eta 0:08:26 lr 0.789111	data 0.0007 (0.0861)	batch 1.2632 (1.3494)	loss -11.2744 (-11.0164)	grad_norm 0.4245 (0.4171)	mem 44912MB
Train: [13/180][300/625]	eta 0:07:14 lr 0.788981	data 0.0005 (0.0719)	batch 1.2657 (1.3355)	loss -11.0733 (-11.0480)	grad_norm 0.4118 (0.4167)	mem 44912MB
Train: [13/180][350/625]	eta 0:06:04 lr 0.788851	data 0.0012 (0.0618)	batch 1.2178 (1.3242)	loss -11.2432 (-11.0801)	grad_norm 0.4205 (0.4167)	mem 44912MB
Train: [13/180][400/625]	eta 0:04:56 lr 0.788719	data 0.0013 (0.0542)	batch 1.2338 (1.3174)	loss -11.2795 (-11.1090)	grad_norm 0.4116 (0.4165)	mem 44912MB
Train: [13/180][450/625]	eta 0:03:49 lr 0.788587	data 0.0007 (0.0483)	batch 1.2718 (1.3104)	loss -11.4112 (-11.1414)	grad_norm 0.4069 (0.4163)	mem 44912MB
Train: [13/180][500/625]	eta 0:02:43 lr 0.788454	data 0.0007 (0.0435)	batch 1.2156 (1.3056)	loss -11.4224 (-11.1734)	grad_norm 0.4128 (0.4163)	mem 44912MB
Train: [13/180][550/625]	eta 0:01:37 lr 0.788321	data 0.0008 (0.0397)	batch 1.2535 (1.3015)	loss -11.3563 (-11.1981)	grad_norm 0.4167 (0.4164)	mem 44912MB
Train: [13/180][600/625]	eta 0:00:32 lr 0.788186	data 0.0005 (0.0364)	batch 1.2686 (1.2982)	loss -11.7561 (-11.2289)	grad_norm 0.4158 (0.4163)	mem 44912MB
Current slope: None 	
EPOCH 13 training takes 0:13:31
Test: [0/25]	Time 14.335 (14.335)	Loss 1.7987 (1.7987)	Acc@1 58.252 (58.252)	Acc@5 82.666 (82.666)	Mem 44912MB
 * Acc@1 45.298 Acc@5 71.062
Accuracy of the network on the 50000 test images: 45.30%
Max accuracy (after decay): 45.30%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [14/180][0/625]	eta 3:54:20 lr 0.788119	data 20.7572 (20.7572)	batch 22.4967 (22.4967)	loss -11.8416 (-11.8416)	grad_norm 0.4158 (0.4158)	mem 44912MB
Train: [14/180][50/625]	eta 0:16:11 lr 0.787983	data 0.0016 (0.4078)	batch 1.2333 (1.6900)	loss -11.9435 (-11.6819)	grad_norm 0.3919 (0.4163)	mem 44912MB
Train: [14/180][100/625]	eta 0:12:55 lr 0.787847	data 0.0008 (0.2063)	batch 1.2510 (1.4765)	loss -11.8068 (-11.7346)	grad_norm 0.4224 (0.4167)	mem 44912MB
Train: [14/180][150/625]	eta 0:11:07 lr 0.787710	data 0.0007 (0.1383)	batch 1.2713 (1.4056)	loss -11.7401 (-11.7564)	grad_norm 0.4096 (0.4162)	mem 44912MB
Train: [14/180][200/625]	eta 0:09:42 lr 0.787572	data 0.0007 (0.1041)	batch 1.2773 (1.3700)	loss -12.1367 (-11.7871)	grad_norm 0.3957 (0.4162)	mem 44912MB
Train: [14/180][250/625]	eta 0:08:26 lr 0.787434	data 0.0007 (0.0835)	batch 1.2445 (1.3505)	loss -12.1460 (-11.8187)	grad_norm 0.4015 (0.4163)	mem 44912MB
Train: [14/180][300/625]	eta 0:07:14 lr 0.787295	data 0.0007 (0.0697)	batch 1.2337 (1.3357)	loss -12.0626 (-11.8480)	grad_norm 0.4204 (0.4161)	mem 44912MB
Train: [14/180][350/625]	eta 0:06:04 lr 0.787155	data 0.0008 (0.0599)	batch 1.2578 (1.3263)	loss -11.9636 (-11.8737)	grad_norm 0.4074 (0.4155)	mem 44912MB
Train: [14/180][400/625]	eta 0:04:56 lr 0.787014	data 0.0007 (0.0525)	batch 1.2217 (1.3181)	loss -12.2239 (-11.9014)	grad_norm 0.4146 (0.4160)	mem 44912MB
Train: [14/180][450/625]	eta 0:03:49 lr 0.786872	data 0.0009 (0.0468)	batch 1.2407 (1.3126)	loss -12.3016 (-11.9332)	grad_norm 0.4214 (0.4158)	mem 44912MB
Train: [14/180][500/625]	eta 0:02:43 lr 0.786730	data 0.0005 (0.0422)	batch 1.2735 (1.3070)	loss -12.3304 (-11.9653)	grad_norm 0.4118 (0.4156)	mem 44912MB
Train: [14/180][550/625]	eta 0:01:37 lr 0.786587	data 0.0006 (0.0384)	batch 1.2503 (1.3030)	loss -12.2855 (-11.9919)	grad_norm 0.3943 (0.4157)	mem 44912MB
Train: [14/180][600/625]	eta 0:00:32 lr 0.786443	data 0.0005 (0.0353)	batch 1.2702 (1.2990)	loss -12.3415 (-12.0213)	grad_norm 0.4099 (0.4155)	mem 44912MB
Current slope: None 	
EPOCH 14 training takes 0:13:32
Test: [0/25]	Time 14.515 (14.515)	Loss 1.9354 (1.9354)	Acc@1 56.592 (56.592)	Acc@5 80.957 (80.957)	Mem 44912MB
 * Acc@1 45.294 Acc@5 71.318
Accuracy of the network on the 50000 test images: 45.29%
Max accuracy (after decay): 45.30%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [15/180][0/625]	eta 3:56:32 lr 0.786371	data 21.2371 (21.2371)	batch 22.7085 (22.7085)	loss -12.4712 (-12.4712)	grad_norm 0.4079 (0.4079)	mem 44912MB
Train: [15/180][50/625]	eta 0:16:11 lr 0.786226	data 0.0008 (0.4173)	batch 1.2464 (1.6904)	loss -12.5277 (-12.4576)	grad_norm 0.4061 (0.4169)	mem 44912MB
Train: [15/180][100/625]	eta 0:12:56 lr 0.786080	data 0.0009 (0.2111)	batch 1.2695 (1.4799)	loss -12.5794 (-12.4838)	grad_norm 0.4193 (0.4170)	mem 44912MB
Train: [15/180][150/625]	eta 0:11:09 lr 0.785934	data 0.0007 (0.1415)	batch 1.2462 (1.4092)	loss -12.6697 (-12.5033)	grad_norm 0.4175 (0.4162)	mem 44912MB
Train: [15/180][200/625]	eta 0:09:43 lr 0.785787	data 0.0004 (0.1065)	batch 1.3107 (1.3719)	loss -12.5460 (-12.5289)	grad_norm 0.4061 (0.4167)	mem 44912MB
Train: [15/180][250/625]	eta 0:08:25 lr 0.785639	data 0.0004 (0.0854)	batch 1.2673 (1.3491)	loss -12.8030 (-12.5542)	grad_norm 0.4217 (0.4169)	mem 44912MB
Train: [15/180][300/625]	eta 0:07:13 lr 0.785490	data 0.0011 (0.0713)	batch 1.2194 (1.3348)	loss -12.8336 (-12.5876)	grad_norm 0.4085 (0.4165)	mem 44912MB
Train: [15/180][350/625]	eta 0:06:04 lr 0.785341	data 0.0006 (0.0613)	batch 1.2363 (1.3244)	loss -12.8920 (-12.6147)	grad_norm 0.3878 (0.4165)	mem 44912MB
Train: [15/180][400/625]	eta 0:04:56 lr 0.785191	data 0.0006 (0.0537)	batch 1.2951 (1.3158)	loss -12.7442 (-12.6420)	grad_norm 0.4179 (0.4168)	mem 44912MB
Train: [15/180][450/625]	eta 0:03:49 lr 0.785040	data 0.0006 (0.0478)	batch 1.2467 (1.3094)	loss -12.7442 (-12.6692)	grad_norm 0.4156 (0.4160)	mem 44912MB
Train: [15/180][500/625]	eta 0:02:43 lr 0.784888	data 0.0012 (0.0431)	batch 1.2464 (1.3044)	loss -12.7965 (-12.6980)	grad_norm 0.4100 (0.4159)	mem 44912MB
Train: [15/180][550/625]	eta 0:01:37 lr 0.784736	data 0.0006 (0.0393)	batch 1.2546 (1.3008)	loss -13.1873 (-12.7257)	grad_norm 0.4122 (0.4157)	mem 44912MB
Train: [15/180][600/625]	eta 0:00:32 lr 0.784582	data 0.0008 (0.0361)	batch 1.2577 (1.2975)	loss -13.0922 (-12.7551)	grad_norm 0.4158 (0.4155)	mem 44912MB
Current slope: None 	
EPOCH 15 training takes 0:13:31
Test: [0/25]	Time 14.690 (14.690)	Loss 1.8399 (1.8399)	Acc@1 58.350 (58.350)	Acc@5 82.520 (82.520)	Mem 44912MB
 * Acc@1 45.690 Acc@5 71.904
Accuracy of the network on the 50000 test images: 45.69%
Max accuracy (after decay): 45.69%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [16/180][0/625]	eta 3:54:57 lr 0.784505	data 20.8660 (20.8660)	batch 22.5552 (22.5552)	loss -13.1804 (-13.1804)	grad_norm 0.4184 (0.4184)	mem 44912MB
Train: [16/180][50/625]	eta 0:16:06 lr 0.784351	data 0.0010 (0.4099)	batch 1.2769 (1.6811)	loss -13.1496 (-13.1849)	grad_norm 0.4174 (0.4150)	mem 44912MB
Train: [16/180][100/625]	eta 0:12:56 lr 0.784196	data 0.0012 (0.2075)	batch 1.2637 (1.4783)	loss -13.0703 (-13.1939)	grad_norm 0.3983 (0.4153)	mem 44912MB
Train: [16/180][150/625]	eta 0:11:08 lr 0.784040	data 0.0005 (0.1390)	batch 1.2470 (1.4066)	loss -13.3872 (-13.2150)	grad_norm 0.4223 (0.4156)	mem 44912MB
Train: [16/180][200/625]	eta 0:09:42 lr 0.783884	data 0.0007 (0.1046)	batch 1.2058 (1.3717)	loss -13.2939 (-13.2346)	grad_norm 0.4291 (0.4153)	mem 44912MB
Train: [16/180][250/625]	eta 0:08:25 lr 0.783726	data 0.0006 (0.0839)	batch 1.2655 (1.3493)	loss -13.3774 (-13.2621)	grad_norm 0.4177 (0.4156)	mem 44912MB
Train: [16/180][300/625]	eta 0:07:13 lr 0.783568	data 0.0005 (0.0701)	batch 1.2371 (1.3346)	loss -13.6750 (-13.2916)	grad_norm 0.4326 (0.4156)	mem 44912MB
Train: [16/180][350/625]	eta 0:06:03 lr 0.783410	data 0.0006 (0.0602)	batch 1.2301 (1.3235)	loss -13.6047 (-13.3173)	grad_norm 0.3998 (0.4154)	mem 44912MB
Train: [16/180][400/625]	eta 0:04:56 lr 0.783250	data 0.0005 (0.0528)	batch 1.2681 (1.3166)	loss -13.6825 (-13.3457)	grad_norm 0.3948 (0.4153)	mem 44912MB
Train: [16/180][450/625]	eta 0:03:49 lr 0.783090	data 0.0005 (0.0470)	batch 1.2491 (1.3104)	loss -13.5667 (-13.3745)	grad_norm 0.4237 (0.4153)	mem 44912MB
Train: [16/180][500/625]	eta 0:02:43 lr 0.782929	data 0.0003 (0.0424)	batch 1.2552 (1.3058)	loss -13.8726 (-13.4028)	grad_norm 0.4104 (0.4156)	mem 44912MB
Train: [16/180][550/625]	eta 0:01:37 lr 0.782767	data 0.0007 (0.0387)	batch 1.3073 (1.3015)	loss -13.8367 (-13.4316)	grad_norm 0.4052 (0.4152)	mem 44912MB
Train: [16/180][600/625]	eta 0:00:32 lr 0.782604	data 0.0006 (0.0355)	batch 1.2600 (1.2981)	loss -13.9078 (-13.4584)	grad_norm 0.4002 (0.4151)	mem 44912MB
Current slope: None 	
EPOCH 16 training takes 0:13:31
Test: [0/25]	Time 14.488 (14.488)	Loss 1.8440 (1.8440)	Acc@1 59.277 (59.277)	Acc@5 81.396 (81.396)	Mem 44912MB
 * Acc@1 46.212 Acc@5 72.284
Accuracy of the network on the 50000 test images: 46.21%
Max accuracy (after decay): 46.21%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [17/180][0/625]	eta 3:57:32 lr 0.782523	data 20.9818 (20.9818)	batch 22.8042 (22.8042)	loss -13.7565 (-13.7565)	grad_norm 0.4079 (0.4079)	mem 44912MB
Train: [17/180][50/625]	eta 0:16:11 lr 0.782359	data 0.0008 (0.4122)	batch 1.3115 (1.6895)	loss -13.8374 (-13.8371)	grad_norm 0.4113 (0.4133)	mem 44912MB
Train: [17/180][100/625]	eta 0:12:57 lr 0.782195	data 0.0006 (0.2086)	batch 1.2756 (1.4803)	loss -13.8067 (-13.8662)	grad_norm 0.4195 (0.4154)	mem 44912MB
Train: [17/180][150/625]	eta 0:11:08 lr 0.782030	data 0.0013 (0.1400)	batch 1.2054 (1.4063)	loss -14.0418 (-13.9004)	grad_norm 0.4180 (0.4168)	mem 44912MB
Train: [17/180][200/625]	eta 0:09:42 lr 0.781864	data 0.0007 (0.1054)	batch 1.2116 (1.3704)	loss -13.9930 (-13.9220)	grad_norm 0.4061 (0.4170)	mem 44912MB
Train: [17/180][250/625]	eta 0:08:26 lr 0.781697	data 0.0009 (0.0845)	batch 1.2409 (1.3495)	loss -14.1951 (-13.9464)	grad_norm 0.4223 (0.4164)	mem 44912MB
Train: [17/180][300/625]	eta 0:07:13 lr 0.781530	data 0.0006 (0.0707)	batch 1.2362 (1.3353)	loss -14.0843 (-13.9718)	grad_norm 0.4292 (0.4162)	mem 44912MB
Train: [17/180][350/625]	eta 0:06:04 lr 0.781362	data 0.0006 (0.0608)	batch 1.2691 (1.3248)	loss -14.1960 (-13.9967)	grad_norm 0.4220 (0.4159)	mem 44912MB
Train: [17/180][400/625]	eta 0:04:56 lr 0.781193	data 0.0008 (0.0533)	batch 1.2410 (1.3167)	loss -14.1414 (-14.0240)	grad_norm 0.4245 (0.4161)	mem 44912MB
Train: [17/180][450/625]	eta 0:03:49 lr 0.781023	data 0.0005 (0.0474)	batch 1.2990 (1.3110)	loss -14.4347 (-14.0462)	grad_norm 0.4234 (0.4161)	mem 44912MB
Train: [17/180][500/625]	eta 0:02:43 lr 0.780853	data 0.0005 (0.0428)	batch 1.3282 (1.3064)	loss -14.2219 (-14.0737)	grad_norm 0.4150 (0.4157)	mem 44912MB
Train: [17/180][550/625]	eta 0:01:37 lr 0.780682	data 0.0011 (0.0390)	batch 1.2758 (1.3024)	loss -14.0722 (-14.0991)	grad_norm 0.4062 (0.4158)	mem 44912MB
Train: [17/180][600/625]	eta 0:00:32 lr 0.780510	data 0.0006 (0.0358)	batch 1.2573 (1.2992)	loss -14.5233 (-14.1258)	grad_norm 0.4055 (0.4156)	mem 44912MB
Current slope: None 	
EPOCH 17 training takes 0:13:32
Test: [0/25]	Time 14.360 (14.360)	Loss 1.7382 (1.7382)	Acc@1 59.668 (59.668)	Acc@5 84.277 (84.277)	Mem 44912MB
 * Acc@1 47.376 Acc@5 73.182
Accuracy of the network on the 50000 test images: 47.38%
Max accuracy (after decay): 47.38%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [18/180][0/625]	eta 4:10:48 lr 0.780424	data 22.8297 (22.8297)	batch 24.0778 (24.0778)	loss -14.2258 (-14.2258)	grad_norm 0.4122 (0.4122)	mem 44912MB
Train: [18/180][50/625]	eta 0:16:26 lr 0.780251	data 0.0009 (0.4482)	batch 1.3020 (1.7154)	loss -14.4056 (-14.4849)	grad_norm 0.4564 (0.4170)	mem 44912MB
Train: [18/180][100/625]	eta 0:13:02 lr 0.780077	data 0.0008 (0.2267)	batch 1.2267 (1.4896)	loss -14.7559 (-14.5205)	grad_norm 0.4061 (0.4154)	mem 44912MB
Train: [18/180][150/625]	eta 0:11:11 lr 0.779903	data 0.0005 (0.1518)	batch 1.2632 (1.4141)	loss -14.2992 (-14.5421)	grad_norm 0.4093 (0.4167)	mem 44912MB
Train: [18/180][200/625]	eta 0:09:44 lr 0.779727	data 0.0005 (0.1142)	batch 1.2566 (1.3757)	loss -14.9011 (-14.5718)	grad_norm 0.4180 (0.4164)	mem 44912MB
Train: [18/180][250/625]	eta 0:08:27 lr 0.779551	data 0.0004 (0.0916)	batch 1.2773 (1.3542)	loss -14.8625 (-14.5962)	grad_norm 0.4175 (0.4164)	mem 44912MB
Train: [18/180][300/625]	eta 0:07:15 lr 0.779375	data 0.0006 (0.0765)	batch 1.2841 (1.3385)	loss -14.6418 (-14.6196)	grad_norm 0.4203 (0.4164)	mem 44912MB
Train: [18/180][350/625]	eta 0:06:05 lr 0.779197	data 0.0004 (0.0657)	batch 1.2599 (1.3277)	loss -14.8606 (-14.6456)	grad_norm 0.4167 (0.4159)	mem 44912MB
Train: [18/180][400/625]	eta 0:04:56 lr 0.779019	data 0.0007 (0.0577)	batch 1.2470 (1.3192)	loss -14.7327 (-14.6685)	grad_norm 0.4289 (0.4155)	mem 44912MB
Train: [18/180][450/625]	eta 0:03:49 lr 0.778840	data 0.0014 (0.0514)	batch 1.2781 (1.3130)	loss -15.0517 (-14.6913)	grad_norm 0.3979 (0.4154)	mem 44912MB
Train: [18/180][500/625]	eta 0:02:43 lr 0.778661	data 0.0006 (0.0463)	batch 1.2633 (1.3077)	loss -15.0726 (-14.7142)	grad_norm 0.4068 (0.4151)	mem 44912MB
Train: [18/180][550/625]	eta 0:01:37 lr 0.778480	data 0.0006 (0.0421)	batch 1.2749 (1.3035)	loss -15.1108 (-14.7389)	grad_norm 0.4201 (0.4148)	mem 44912MB
Train: [18/180][600/625]	eta 0:00:32 lr 0.778299	data 0.0006 (0.0387)	batch 1.2329 (1.2997)	loss -15.0852 (-14.7639)	grad_norm 0.4160 (0.4147)	mem 44912MB
Current slope: None 	
EPOCH 18 training takes 0:13:32
Test: [0/25]	Time 14.495 (14.495)	Loss 1.8131 (1.8131)	Acc@1 59.180 (59.180)	Acc@5 82.715 (82.715)	Mem 44912MB
 * Acc@1 47.444 Acc@5 72.954
Accuracy of the network on the 50000 test images: 47.44%
Max accuracy (after decay): 47.44%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [19/180][0/625]	eta 3:59:30 lr 0.778209	data 21.5912 (21.5912)	batch 22.9920 (22.9920)	loss -15.1507 (-15.1507)	grad_norm 0.4109 (0.4109)	mem 44912MB
Train: [19/180][50/625]	eta 0:16:09 lr 0.778026	data 0.0009 (0.4242)	batch 1.2639 (1.6864)	loss -15.2583 (-15.1328)	grad_norm 0.4044 (0.4218)	mem 44912MB
Train: [19/180][100/625]	eta 0:12:55 lr 0.777843	data 0.0010 (0.2146)	batch 1.2426 (1.4771)	loss -15.1633 (-15.1557)	grad_norm 0.4069 (0.4171)	mem 44912MB
Train: [19/180][150/625]	eta 0:11:08 lr 0.777660	data 0.0006 (0.1438)	batch 1.3130 (1.4084)	loss -15.2309 (-15.1790)	grad_norm 0.4055 (0.4174)	mem 44912MB
Train: [19/180][200/625]	eta 0:09:43 lr 0.777475	data 0.0012 (0.1083)	batch 1.2737 (1.3723)	loss -15.1369 (-15.1964)	grad_norm 0.4137 (0.4170)	mem 44912MB
Train: [19/180][250/625]	eta 0:08:26 lr 0.777290	data 0.0006 (0.0869)	batch 1.2716 (1.3501)	loss -15.1674 (-15.2138)	grad_norm 0.4041 (0.4165)	mem 44912MB
Train: [19/180][300/625]	eta 0:07:14 lr 0.777104	data 0.0016 (0.0726)	batch 1.3751 (1.3356)	loss -15.5274 (-15.2380)	grad_norm 0.4151 (0.4167)	mem 44912MB
Train: [19/180][350/625]	eta 0:06:04 lr 0.776918	data 0.0013 (0.0624)	batch 1.2188 (1.3254)	loss -15.5084 (-15.2588)	grad_norm 0.4440 (0.4169)	mem 44912MB
Train: [19/180][400/625]	eta 0:04:56 lr 0.776730	data 0.0009 (0.0547)	batch 1.2608 (1.3179)	loss -15.6285 (-15.2819)	grad_norm 0.4067 (0.4168)	mem 44912MB
Train: [19/180][450/625]	eta 0:03:49 lr 0.776542	data 0.0006 (0.0487)	batch 1.2991 (1.3121)	loss -15.6087 (-15.3028)	grad_norm 0.4080 (0.4167)	mem 44912MB
Train: [19/180][500/625]	eta 0:02:43 lr 0.776353	data 0.0009 (0.0439)	batch 1.2604 (1.3070)	loss -15.4975 (-15.3237)	grad_norm 0.4294 (0.4166)	mem 44912MB
Train: [19/180][550/625]	eta 0:01:37 lr 0.776164	data 0.0008 (0.0400)	batch 1.2718 (1.3027)	loss -15.7612 (-15.3476)	grad_norm 0.4108 (0.4164)	mem 44912MB
Train: [19/180][600/625]	eta 0:00:32 lr 0.775974	data 0.0008 (0.0368)	batch 1.2786 (1.2998)	loss -15.4199 (-15.3713)	grad_norm 0.4109 (0.4161)	mem 44912MB
Current slope: None 	
EPOCH 19 training takes 0:13:32
Test: [0/25]	Time 14.833 (14.833)	Loss 1.6873 (1.6873)	Acc@1 60.986 (60.986)	Acc@5 84.229 (84.229)	Mem 44912MB
 * Acc@1 47.976 Acc@5 73.704
Accuracy of the network on the 50000 test images: 47.98%
Max accuracy (after decay): 47.98%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [20/180][0/625]	eta 3:59:59 lr 0.775878	data 21.5520 (21.5520)	batch 23.0386 (23.0386)	loss -15.6332 (-15.6332)	grad_norm 0.4260 (0.4260)	mem 44912MB
Train: [20/180][50/625]	eta 0:16:12 lr 0.775687	data 0.0005 (0.4235)	batch 1.2614 (1.6910)	loss -15.6849 (-15.6991)	grad_norm 0.4149 (0.4155)	mem 44912MB
Train: [20/180][100/625]	eta 0:12:59 lr 0.775495	data 0.0008 (0.2142)	batch 1.2605 (1.4839)	loss -15.6794 (-15.7277)	grad_norm 0.4030 (0.4154)	mem 44912MB
Train: [20/180][150/625]	eta 0:11:09 lr 0.775302	data 0.0006 (0.1435)	batch 1.3195 (1.4105)	loss -15.9195 (-15.7434)	grad_norm 0.4381 (0.4161)	mem 44912MB
Train: [20/180][200/625]	eta 0:09:44 lr 0.775108	data 0.0006 (0.1080)	batch 1.3382 (1.3745)	loss -15.8659 (-15.7613)	grad_norm 0.4013 (0.4161)	mem 44912MB
Train: [20/180][250/625]	eta 0:08:26 lr 0.774914	data 0.0005 (0.0866)	batch 1.2899 (1.3509)	loss -16.0026 (-15.7877)	grad_norm 0.4098 (0.4159)	mem 44912MB
Train: [20/180][300/625]	eta 0:07:14 lr 0.774719	data 0.0005 (0.0725)	batch 1.2911 (1.3374)	loss -16.1870 (-15.8067)	grad_norm 0.4048 (0.4157)	mem 44912MB
Train: [20/180][350/625]	eta 0:06:04 lr 0.774523	data 0.0007 (0.0623)	batch 1.2300 (1.3258)	loss -15.9128 (-15.8295)	grad_norm 0.4267 (0.4160)	mem 44912MB
Train: [20/180][400/625]	eta 0:04:56 lr 0.774327	data 0.0006 (0.0546)	batch 1.2483 (1.3178)	loss -16.1542 (-15.8530)	grad_norm 0.4405 (0.4165)	mem 44912MB
Train: [20/180][450/625]	eta 0:03:49 lr 0.774130	data 0.0006 (0.0486)	batch 1.2653 (1.3110)	loss -16.0929 (-15.8744)	grad_norm 0.4050 (0.4163)	mem 44912MB
Train: [20/180][500/625]	eta 0:02:43 lr 0.773932	data 0.0005 (0.0438)	batch 1.2301 (1.3067)	loss -16.0917 (-15.8985)	grad_norm 0.4306 (0.4160)	mem 44912MB
Train: [20/180][550/625]	eta 0:01:37 lr 0.773733	data 0.0008 (0.0399)	batch 1.2922 (1.3022)	loss -16.3015 (-15.9177)	grad_norm 0.4076 (0.4157)	mem 44912MB
Train: [20/180][600/625]	eta 0:00:32 lr 0.773533	data 0.0007 (0.0367)	batch 1.3062 (1.2985)	loss -16.3815 (-15.9384)	grad_norm 0.4066 (0.4156)	mem 44912MB
Current slope: None 	
EPOCH 20 training takes 0:13:31
Test: [0/25]	Time 14.563 (14.563)	Loss 1.8708 (1.8708)	Acc@1 58.984 (58.984)	Acc@5 82.666 (82.666)	Mem 44912MB
 * Acc@1 48.158 Acc@5 73.702
Accuracy of the network on the 50000 test images: 48.16%
Max accuracy (after decay): 48.16%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [21/180][0/625]	eta 4:05:10 lr 0.773433	data 21.5173 (21.5173)	batch 23.5369 (23.5369)	loss -16.2013 (-16.2013)	grad_norm 0.4045 (0.4045)	mem 44912MB
Train: [21/180][50/625]	eta 0:16:18 lr 0.773233	data 0.0008 (0.4228)	batch 1.2104 (1.7013)	loss -16.3009 (-16.2224)	grad_norm 0.4206 (0.4160)	mem 44912MB
Train: [21/180][100/625]	eta 0:12:59 lr 0.773032	data 0.0007 (0.2139)	batch 1.2687 (1.4850)	loss -16.2211 (-16.2581)	grad_norm 0.4049 (0.4145)	mem 44912MB
Train: [21/180][150/625]	eta 0:11:10 lr 0.772830	data 0.0008 (0.1433)	batch 1.3027 (1.4119)	loss -16.2633 (-16.2922)	grad_norm 0.4148 (0.4152)	mem 44912MB
Train: [21/180][200/625]	eta 0:09:44 lr 0.772627	data 0.0005 (0.1078)	batch 1.2545 (1.3745)	loss -16.5504 (-16.3203)	grad_norm 0.4036 (0.4161)	mem 44912MB
Train: [21/180][250/625]	eta 0:08:27 lr 0.772424	data 0.0006 (0.0865)	batch 1.2444 (1.3521)	loss -16.3371 (-16.3446)	grad_norm 0.4143 (0.4154)	mem 44912MB
Train: [21/180][300/625]	eta 0:07:14 lr 0.772220	data 0.0007 (0.0723)	batch 1.2937 (1.3376)	loss -16.4899 (-16.3645)	grad_norm 0.4061 (0.4153)	mem 44912MB
Train: [21/180][350/625]	eta 0:06:04 lr 0.772015	data 0.0005 (0.0621)	batch 1.2159 (1.3262)	loss -16.6693 (-16.3878)	grad_norm 0.4543 (0.4152)	mem 44912MB
Train: [21/180][400/625]	eta 0:04:56 lr 0.771809	data 0.0007 (0.0544)	batch 1.2533 (1.3186)	loss -16.7604 (-16.4085)	grad_norm 0.4096 (0.4152)	mem 44912MB
Train: [21/180][450/625]	eta 0:03:49 lr 0.771603	data 0.0008 (0.0485)	batch 1.3158 (1.3127)	loss -16.3006 (-16.4286)	grad_norm 0.4062 (0.4151)	mem 44912MB
Train: [21/180][500/625]	eta 0:02:43 lr 0.771396	data 0.0006 (0.0437)	batch 1.2300 (1.3077)	loss -16.6898 (-16.4502)	grad_norm 0.4207 (0.4151)	mem 44912MB
Train: [21/180][550/625]	eta 0:01:37 lr 0.771188	data 0.0005 (0.0398)	batch 1.2209 (1.3035)	loss -16.7335 (-16.4722)	grad_norm 0.4174 (0.4154)	mem 44912MB
Train: [21/180][600/625]	eta 0:00:32 lr 0.770980	data 0.0005 (0.0365)	batch 1.2583 (1.3003)	loss -16.8449 (-16.4924)	grad_norm 0.4104 (0.4152)	mem 44912MB
Current slope: None 	
EPOCH 21 training takes 0:13:33
Test: [0/25]	Time 14.733 (14.733)	Loss 1.6950 (1.6950)	Acc@1 61.572 (61.572)	Acc@5 84.375 (84.375)	Mem 44912MB
 * Acc@1 48.266 Acc@5 73.960
Accuracy of the network on the 50000 test images: 48.27%
Max accuracy (after decay): 48.27%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [22/180][0/625]	eta 4:05:05 lr 0.770875	data 20.8810 (20.8810)	batch 23.5280 (23.5280)	loss -16.7070 (-16.7070)	grad_norm 0.4178 (0.4178)	mem 44912MB
Train: [22/180][50/625]	eta 0:16:17 lr 0.770665	data 0.0004 (0.4105)	batch 1.2262 (1.7006)	loss -16.7952 (-16.7818)	grad_norm 0.4083 (0.4127)	mem 44912MB
Train: [22/180][100/625]	eta 0:12:58 lr 0.770455	data 0.0006 (0.2077)	batch 1.2635 (1.4822)	loss -16.9272 (-16.8003)	grad_norm 0.4123 (0.4143)	mem 44912MB
Train: [22/180][150/625]	eta 0:11:09 lr 0.770244	data 0.0008 (0.1391)	batch 1.2932 (1.4099)	loss -16.7994 (-16.8242)	grad_norm 0.4247 (0.4157)	mem 44912MB
Train: [22/180][200/625]	eta 0:09:43 lr 0.770032	data 0.0005 (0.1047)	batch 1.2555 (1.3727)	loss -16.6926 (-16.8437)	grad_norm 0.4119 (0.4164)	mem 44912MB
Train: [22/180][250/625]	eta 0:08:26 lr 0.769820	data 0.0011 (0.0840)	batch 1.2165 (1.3504)	loss -16.9297 (-16.8643)	grad_norm 0.4117 (0.4160)	mem 44912MB
Train: [22/180][300/625]	eta 0:07:14 lr 0.769607	data 0.0009 (0.0702)	batch 1.2717 (1.3357)	loss -16.9133 (-16.8807)	grad_norm 0.4137 (0.4165)	mem 44912MB
Train: [22/180][350/625]	eta 0:06:04 lr 0.769393	data 0.0010 (0.0603)	batch 1.2451 (1.3252)	loss -16.9876 (-16.9014)	grad_norm 0.4183 (0.4165)	mem 44912MB
Train: [22/180][400/625]	eta 0:04:56 lr 0.769178	data 0.0013 (0.0528)	batch 1.3484 (1.3179)	loss -17.1254 (-16.9202)	grad_norm 0.4134 (0.4161)	mem 44912MB
Train: [22/180][450/625]	eta 0:03:49 lr 0.768963	data 0.0005 (0.0471)	batch 1.2896 (1.3121)	loss -17.1272 (-16.9424)	grad_norm 0.4157 (0.4161)	mem 44912MB
Train: [22/180][500/625]	eta 0:02:43 lr 0.768747	data 0.0005 (0.0424)	batch 1.2890 (1.3074)	loss -17.1678 (-16.9615)	grad_norm 0.4372 (0.4163)	mem 44912MB
Train: [22/180][550/625]	eta 0:01:37 lr 0.768530	data 0.0006 (0.0386)	batch 1.2581 (1.3034)	loss -17.2746 (-16.9817)	grad_norm 0.4094 (0.4161)	mem 44912MB
Train: [22/180][600/625]	eta 0:00:32 lr 0.768313	data 0.0005 (0.0355)	batch 1.3045 (1.3002)	loss -17.1918 (-17.0003)	grad_norm 0.4139 (0.4159)	mem 44912MB
Current slope: None 	
EPOCH 22 training takes 0:13:32
Test: [0/25]	Time 14.892 (14.892)	Loss 1.8120 (1.8120)	Acc@1 60.010 (60.010)	Acc@5 82.861 (82.861)	Mem 44912MB
 * Acc@1 48.246 Acc@5 73.732
Accuracy of the network on the 50000 test images: 48.25%
Max accuracy (after decay): 48.27%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [23/180][0/625]	eta 4:07:44 lr 0.768204	data 21.0187 (21.0187)	batch 23.7832 (23.7832)	loss -17.3745 (-17.3745)	grad_norm 0.4055 (0.4055)	mem 44912MB
Train: [23/180][50/625]	eta 0:16:20 lr 0.767985	data 0.0006 (0.4129)	batch 1.2780 (1.7051)	loss -17.1442 (-17.3191)	grad_norm 0.4701 (0.4178)	mem 44912MB
Train: [23/180][100/625]	eta 0:12:59 lr 0.767766	data 0.0007 (0.2088)	batch 1.2435 (1.4856)	loss -17.4487 (-17.3175)	grad_norm 0.4411 (0.4182)	mem 44912MB
Train: [23/180][150/625]	eta 0:11:10 lr 0.767546	data 0.0010 (0.1400)	batch 1.3055 (1.4118)	loss -17.4055 (-17.3282)	grad_norm 0.4159 (0.4183)	mem 44912MB
Train: [23/180][200/625]	eta 0:09:44 lr 0.767325	data 0.0012 (0.1053)	batch 1.2604 (1.3760)	loss -17.6071 (-17.3497)	grad_norm 0.4314 (0.4182)	mem 44912MB
Train: [23/180][250/625]	eta 0:08:27 lr 0.767103	data 0.0006 (0.0847)	batch 1.2267 (1.3525)	loss -17.4455 (-17.3720)	grad_norm 0.3987 (0.4186)	mem 44912MB
Train: [23/180][300/625]	eta 0:07:14 lr 0.766881	data 0.0005 (0.0707)	batch 1.2287 (1.3375)	loss -17.4558 (-17.3910)	grad_norm 0.4207 (0.4181)	mem 44912MB
Train: [23/180][350/625]	eta 0:06:04 lr 0.766658	data 0.0006 (0.0608)	batch 1.2769 (1.3270)	loss -17.6076 (-17.4099)	grad_norm 0.4053 (0.4179)	mem 44912MB
Train: [23/180][400/625]	eta 0:04:57 lr 0.766435	data 0.0006 (0.0533)	batch 1.4423 (1.3204)	loss -17.6820 (-17.4245)	grad_norm 0.4001 (0.4176)	mem 44912MB
Train: [23/180][450/625]	eta 0:03:49 lr 0.766211	data 0.0010 (0.0475)	batch 1.2560 (1.3136)	loss -17.6630 (-17.4437)	grad_norm 0.4210 (0.4176)	mem 44912MB
Train: [23/180][500/625]	eta 0:02:43 lr 0.765986	data 0.0009 (0.0428)	batch 1.2361 (1.3085)	loss -17.8346 (-17.4611)	grad_norm 0.4065 (0.4175)	mem 44912MB
Train: [23/180][550/625]	eta 0:01:37 lr 0.765760	data 0.0012 (0.0390)	batch 1.2585 (1.3040)	loss -17.5408 (-17.4810)	grad_norm 0.3982 (0.4174)	mem 44912MB
Train: [23/180][600/625]	eta 0:00:32 lr 0.765533	data 0.0004 (0.0358)	batch 1.2818 (1.3014)	loss -17.5595 (-17.5000)	grad_norm 0.4171 (0.4170)	mem 44912MB
Current slope: None 	
EPOCH 23 training takes 0:13:33
Test: [0/25]	Time 14.590 (14.590)	Loss 1.6246 (1.6246)	Acc@1 61.426 (61.426)	Acc@5 85.400 (85.400)	Mem 44912MB
 * Acc@1 49.210 Acc@5 74.602
Accuracy of the network on the 50000 test images: 49.21%
Max accuracy (after decay): 49.21%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [24/180][0/625]	eta 4:02:48 lr 0.765420	data 20.9801 (20.9801)	batch 23.3104 (23.3104)	loss -17.8456 (-17.8456)	grad_norm 0.4313 (0.4313)	mem 44912MB
Train: [24/180][50/625]	eta 0:16:18 lr 0.765192	data 0.0006 (0.4122)	batch 1.2321 (1.7017)	loss -17.7926 (-17.7781)	grad_norm 0.4036 (0.4168)	mem 44912MB
Train: [24/180][100/625]	eta 0:13:00 lr 0.764964	data 0.0009 (0.2086)	batch 1.2507 (1.4868)	loss -18.0586 (-17.8033)	grad_norm 0.4157 (0.4172)	mem 44912MB
Train: [24/180][150/625]	eta 0:11:11 lr 0.764735	data 0.0009 (0.1398)	batch 1.2638 (1.4146)	loss -17.9905 (-17.8134)	grad_norm 0.4179 (0.4165)	mem 44912MB
Train: [24/180][200/625]	eta 0:09:45 lr 0.764506	data 0.0008 (0.1052)	batch 1.2573 (1.3773)	loss -17.5428 (-17.8229)	grad_norm 0.4158 (0.4170)	mem 44912MB
Train: [24/180][250/625]	eta 0:08:27 lr 0.764275	data 0.0007 (0.0844)	batch 1.2233 (1.3540)	loss -17.9695 (-17.8379)	grad_norm 0.4251 (0.4174)	mem 44912MB
Train: [24/180][300/625]	eta 0:07:15 lr 0.764044	data 0.0004 (0.0705)	batch 1.2638 (1.3391)	loss -18.1195 (-17.8591)	grad_norm 0.4186 (0.4175)	mem 44912MB
Train: [24/180][350/625]	eta 0:06:05 lr 0.763812	data 0.0007 (0.0606)	batch 1.3337 (1.3290)	loss -17.9921 (-17.8778)	grad_norm 0.4092 (0.4175)	mem 44912MB
Train: [24/180][400/625]	eta 0:04:57 lr 0.763580	data 0.0011 (0.0531)	batch 1.3147 (1.3207)	loss -17.9568 (-17.8917)	grad_norm 0.4133 (0.4170)	mem 44912MB
Train: [24/180][450/625]	eta 0:03:50 lr 0.763347	data 0.0010 (0.0473)	batch 1.4338 (1.3144)	loss -18.1848 (-17.9072)	grad_norm 0.4129 (0.4167)	mem 44912MB
Train: [24/180][500/625]	eta 0:02:43 lr 0.763113	data 0.0005 (0.0427)	batch 1.3170 (1.3091)	loss -18.1240 (-17.9234)	grad_norm 0.4165 (0.4166)	mem 44912MB
Train: [24/180][550/625]	eta 0:01:37 lr 0.762878	data 0.0006 (0.0389)	batch 1.3258 (1.3053)	loss -18.3019 (-17.9406)	grad_norm 0.4249 (0.4169)	mem 44912MB
Train: [24/180][600/625]	eta 0:00:32 lr 0.762643	data 0.0012 (0.0358)	batch 1.2577 (1.3019)	loss -18.1335 (-17.9574)	grad_norm 0.4161 (0.4168)	mem 44912MB
Current slope: None 	
EPOCH 24 training takes 0:13:34
Test: [0/25]	Time 14.447 (14.447)	Loss 1.7468 (1.7468)	Acc@1 60.059 (60.059)	Acc@5 83.350 (83.350)	Mem 44912MB
 * Acc@1 49.040 Acc@5 74.592
Accuracy of the network on the 50000 test images: 49.04%
Max accuracy (after decay): 49.21%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [25/180][0/625]	eta 3:58:35 lr 0.762525	data 21.6130 (21.6130)	batch 22.9044 (22.9044)	loss -18.1657 (-18.1657)	grad_norm 0.4053 (0.4053)	mem 44912MB
Train: [25/180][50/625]	eta 0:16:13 lr 0.762289	data 0.0008 (0.4247)	batch 1.2822 (1.6922)	loss -18.1373 (-18.2048)	grad_norm 0.4113 (0.4177)	mem 44912MB
Train: [25/180][100/625]	eta 0:12:55 lr 0.762052	data 0.0007 (0.2149)	batch 1.2851 (1.4768)	loss -18.2407 (-18.2338)	grad_norm 0.4175 (0.4166)	mem 44912MB
Train: [25/180][150/625]	eta 0:11:08 lr 0.761814	data 0.0006 (0.1440)	batch 1.2605 (1.4078)	loss -18.3731 (-18.2538)	grad_norm 0.4162 (0.4165)	mem 44912MB
Train: [25/180][200/625]	eta 0:09:42 lr 0.761575	data 0.0010 (0.1084)	batch 1.2465 (1.3708)	loss -18.4263 (-18.2682)	grad_norm 0.4122 (0.4168)	mem 44912MB
Train: [25/180][250/625]	eta 0:08:25 lr 0.761336	data 0.0008 (0.0869)	batch 1.3023 (1.3493)	loss -18.4007 (-18.2866)	grad_norm 0.4087 (0.4170)	mem 44912MB
Train: [25/180][300/625]	eta 0:07:13 lr 0.761096	data 0.0006 (0.0726)	batch 1.2714 (1.3340)	loss -18.4681 (-18.3069)	grad_norm 0.4058 (0.4172)	mem 44912MB
Train: [25/180][350/625]	eta 0:06:04 lr 0.760856	data 0.0005 (0.0624)	batch 1.2655 (1.3251)	loss -18.3633 (-18.3251)	grad_norm 0.4185 (0.4169)	mem 44912MB
Train: [25/180][400/625]	eta 0:04:56 lr 0.760614	data 0.0009 (0.0547)	batch 1.2135 (1.3164)	loss -18.4851 (-18.3411)	grad_norm 0.4029 (0.4169)	mem 44912MB
Train: [25/180][450/625]	eta 0:03:49 lr 0.760372	data 0.0010 (0.0487)	batch 1.2577 (1.3107)	loss -18.6266 (-18.3556)	grad_norm 0.4082 (0.4171)	mem 44912MB
Train: [25/180][500/625]	eta 0:02:43 lr 0.760130	data 0.0005 (0.0439)	batch 1.2482 (1.3058)	loss -18.4018 (-18.3699)	grad_norm 0.4237 (0.4172)	mem 44912MB
Train: [25/180][550/625]	eta 0:01:37 lr 0.759886	data 0.0006 (0.0400)	batch 1.2376 (1.3032)	loss -18.5351 (-18.3866)	grad_norm 0.4108 (0.4172)	mem 44912MB
Train: [25/180][600/625]	eta 0:00:32 lr 0.759642	data 0.0006 (0.0368)	batch 1.2321 (1.2997)	loss -18.5288 (-18.4015)	grad_norm 0.4277 (0.4174)	mem 44912MB
Current slope: None 	
EPOCH 25 training takes 0:13:32
Test: [0/25]	Time 14.776 (14.776)	Loss 1.7469 (1.7469)	Acc@1 61.230 (61.230)	Acc@5 84.277 (84.277)	Mem 44912MB
 * Acc@1 49.530 Acc@5 74.854
Accuracy of the network on the 50000 test images: 49.53%
Max accuracy (after decay): 49.53%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [26/180][0/625]	eta 3:58:40 lr 0.759520	data 21.6449 (21.6449)	batch 22.9123 (22.9123)	loss -18.4270 (-18.4270)	grad_norm 0.4116 (0.4116)	mem 44912MB
Train: [26/180][50/625]	eta 0:16:11 lr 0.759274	data 0.0007 (0.4252)	batch 1.2838 (1.6903)	loss -18.5943 (-18.6304)	grad_norm 0.4158 (0.4161)	mem 44912MB
Train: [26/180][100/625]	eta 0:12:58 lr 0.759029	data 0.0019 (0.2152)	batch 1.2510 (1.4823)	loss -18.4419 (-18.6597)	grad_norm 0.4161 (0.4173)	mem 44912MB
Train: [26/180][150/625]	eta 0:11:09 lr 0.758782	data 0.0007 (0.1442)	batch 1.2627 (1.4103)	loss -18.6761 (-18.6815)	grad_norm 0.4121 (0.4171)	mem 44912MB
Train: [26/180][200/625]	eta 0:09:44 lr 0.758535	data 0.0011 (0.1085)	batch 1.4845 (1.3751)	loss -18.7536 (-18.6929)	grad_norm 0.4144 (0.4171)	mem 44912MB
Train: [26/180][250/625]	eta 0:08:26 lr 0.758287	data 0.0014 (0.0871)	batch 1.3113 (1.3516)	loss -18.8398 (-18.7118)	grad_norm 0.4034 (0.4174)	mem 44912MB
Train: [26/180][300/625]	eta 0:07:14 lr 0.758038	data 0.0014 (0.0728)	batch 1.2780 (1.3376)	loss -18.9275 (-18.7304)	grad_norm 0.4239 (0.4175)	mem 44912MB
Train: [26/180][350/625]	eta 0:06:04 lr 0.757789	data 0.0008 (0.0625)	batch 1.2496 (1.3267)	loss -18.8113 (-18.7445)	grad_norm 0.4214 (0.4173)	mem 44912MB
Train: [26/180][400/625]	eta 0:04:56 lr 0.757539	data 0.0007 (0.0548)	batch 1.3083 (1.3194)	loss -19.0136 (-18.7630)	grad_norm 0.4564 (0.4175)	mem 44912MB
Train: [26/180][450/625]	eta 0:03:49 lr 0.757288	data 0.0008 (0.0488)	batch 1.2219 (1.3126)	loss -19.0266 (-18.7776)	grad_norm 0.4009 (0.4175)	mem 44912MB
Train: [26/180][500/625]	eta 0:02:43 lr 0.757036	data 0.0005 (0.0440)	batch 1.2697 (1.3087)	loss -18.7362 (-18.7911)	grad_norm 0.4146 (0.4175)	mem 44912MB
Train: [26/180][550/625]	eta 0:01:37 lr 0.756784	data 0.0007 (0.0401)	batch 1.2642 (1.3046)	loss -19.0400 (-18.8067)	grad_norm 0.4145 (0.4173)	mem 44912MB
Train: [26/180][600/625]	eta 0:00:32 lr 0.756531	data 0.0006 (0.0368)	batch 1.2474 (1.3009)	loss -19.0424 (-18.8237)	grad_norm 0.4139 (0.4171)	mem 44912MB
Current slope: None 	
EPOCH 26 training takes 0:13:33
Test: [0/25]	Time 15.084 (15.084)	Loss 1.7240 (1.7240)	Acc@1 60.352 (60.352)	Acc@5 84.375 (84.375)	Mem 44912MB
 * Acc@1 49.396 Acc@5 74.834
Accuracy of the network on the 50000 test images: 49.40%
Max accuracy (after decay): 49.53%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [27/180][0/625]	eta 4:00:59 lr 0.756405	data 21.1420 (21.1420)	batch 23.1355 (23.1355)	loss -19.0348 (-19.0348)	grad_norm 0.4202 (0.4202)	mem 44912MB
Train: [27/180][50/625]	eta 0:16:10 lr 0.756151	data 0.0009 (0.4154)	batch 1.2621 (1.6874)	loss -18.9033 (-19.0720)	grad_norm 0.4248 (0.4194)	mem 44912MB
Train: [27/180][100/625]	eta 0:12:57 lr 0.755896	data 0.0007 (0.2101)	batch 1.2590 (1.4804)	loss -19.2519 (-19.0805)	grad_norm 0.4232 (0.4187)	mem 44912MB
Train: [27/180][150/625]	eta 0:11:08 lr 0.755641	data 0.0006 (0.1408)	batch 1.2984 (1.4067)	loss -19.1234 (-19.0882)	grad_norm 0.4296 (0.4189)	mem 44912MB
Train: [27/180][200/625]	eta 0:09:42 lr 0.755385	data 0.0014 (0.1060)	batch 1.2214 (1.3715)	loss -19.1321 (-19.1052)	grad_norm 0.4081 (0.4180)	mem 44912MB
Train: [27/180][250/625]	eta 0:08:25 lr 0.755128	data 0.0006 (0.0851)	batch 1.2899 (1.3493)	loss -19.2077 (-19.1242)	grad_norm 0.4134 (0.4177)	mem 44912MB
Train: [27/180][300/625]	eta 0:07:13 lr 0.754871	data 0.0006 (0.0711)	batch 1.2516 (1.3352)	loss -19.3453 (-19.1400)	grad_norm 0.4137 (0.4177)	mem 44912MB
Train: [27/180][350/625]	eta 0:06:04 lr 0.754613	data 0.0010 (0.0611)	batch 1.3256 (1.3249)	loss -19.2633 (-19.1501)	grad_norm 0.4064 (0.4178)	mem 44912MB
Train: [27/180][400/625]	eta 0:04:56 lr 0.754354	data 0.0009 (0.0536)	batch 1.2391 (1.3177)	loss -19.5244 (-19.1657)	grad_norm 0.4079 (0.4178)	mem 44912MB
Train: [27/180][450/625]	eta 0:03:49 lr 0.754095	data 0.0010 (0.0478)	batch 1.2892 (1.3112)	loss -19.2688 (-19.1827)	grad_norm 0.4219 (0.4175)	mem 44912MB
Train: [27/180][500/625]	eta 0:02:43 lr 0.753835	data 0.0010 (0.0431)	batch 1.2482 (1.3082)	loss -19.5516 (-19.1991)	grad_norm 0.4132 (0.4177)	mem 44912MB
Train: [27/180][550/625]	eta 0:01:37 lr 0.753574	data 0.0007 (0.0393)	batch 1.2844 (1.3038)	loss -19.4126 (-19.2127)	grad_norm 0.4158 (0.4177)	mem 44912MB
Train: [27/180][600/625]	eta 0:00:32 lr 0.753312	data 0.0011 (0.0361)	batch 1.2816 (1.3011)	loss -19.2373 (-19.2261)	grad_norm 0.4184 (0.4177)	mem 44912MB
Current slope: None 	
EPOCH 27 training takes 0:13:33
Test: [0/25]	Time 14.604 (14.604)	Loss 1.7017 (1.7017)	Acc@1 61.719 (61.719)	Acc@5 84.961 (84.961)	Mem 44912MB
 * Acc@1 50.016 Acc@5 75.410
Accuracy of the network on the 50000 test images: 50.02%
Max accuracy (after decay): 50.02%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [28/180][0/625]	eta 4:01:43 lr 0.753181	data 21.2272 (21.2272)	batch 23.2056 (23.2056)	loss -19.3631 (-19.3631)	grad_norm 0.4072 (0.4072)	mem 44912MB
Train: [28/180][50/625]	eta 0:16:18 lr 0.752919	data 0.0009 (0.4169)	batch 1.2404 (1.7017)	loss -19.4282 (-19.4549)	grad_norm 0.4255 (0.4183)	mem 44912MB
Train: [28/180][100/625]	eta 0:12:59 lr 0.752656	data 0.0008 (0.2109)	batch 1.2518 (1.4841)	loss -19.5206 (-19.4628)	grad_norm 0.4181 (0.4175)	mem 44912MB
Train: [28/180][150/625]	eta 0:11:11 lr 0.752392	data 0.0006 (0.1414)	batch 1.2462 (1.4133)	loss -19.4563 (-19.4717)	grad_norm 0.4264 (0.4179)	mem 44912MB
Train: [28/180][200/625]	eta 0:09:44 lr 0.752127	data 0.0009 (0.1064)	batch 1.2167 (1.3753)	loss -19.7282 (-19.4819)	grad_norm 0.4013 (0.4179)	mem 44912MB
Train: [28/180][250/625]	eta 0:08:27 lr 0.751862	data 0.0007 (0.0854)	batch 1.2642 (1.3537)	loss -19.5593 (-19.4959)	grad_norm 0.4061 (0.4177)	mem 44912MB
Train: [28/180][300/625]	eta 0:07:15 lr 0.751596	data 0.0006 (0.0713)	batch 1.2789 (1.3391)	loss -19.5501 (-19.5093)	grad_norm 0.4237 (0.4182)	mem 44912MB
Train: [28/180][350/625]	eta 0:06:05 lr 0.751329	data 0.0006 (0.0613)	batch 1.3096 (1.3302)	loss -19.7017 (-19.5257)	grad_norm 0.4155 (0.4178)	mem 44912MB
Train: [28/180][400/625]	eta 0:04:57 lr 0.751062	data 0.0007 (0.0537)	batch 1.2585 (1.3218)	loss -19.6662 (-19.5394)	grad_norm 0.4227 (0.4182)	mem 44912MB
Train: [28/180][450/625]	eta 0:03:50 lr 0.750794	data 0.0007 (0.0479)	batch 1.2680 (1.3154)	loss -19.6674 (-19.5532)	grad_norm 0.4245 (0.4180)	mem 44912MB
Train: [28/180][500/625]	eta 0:02:43 lr 0.750525	data 0.0006 (0.0432)	batch 1.2277 (1.3108)	loss -19.6440 (-19.5690)	grad_norm 0.4171 (0.4183)	mem 44912MB
Train: [28/180][550/625]	eta 0:01:38 lr 0.750256	data 0.0009 (0.0394)	batch 1.2670 (1.3069)	loss -19.6364 (-19.5857)	grad_norm 0.4166 (0.4182)	mem 44912MB
Train: [28/180][600/625]	eta 0:00:32 lr 0.749986	data 0.0018 (0.0362)	batch 1.2349 (1.3032)	loss -19.7373 (-19.6001)	grad_norm 0.4118 (0.4179)	mem 44912MB
Current slope: None 	
EPOCH 28 training takes 0:13:34
Test: [0/25]	Time 14.709 (14.709)	Loss 1.6718 (1.6718)	Acc@1 62.402 (62.402)	Acc@5 85.010 (85.010)	Mem 44912MB
 * Acc@1 49.374 Acc@5 74.766
Accuracy of the network on the 50000 test images: 49.37%
Max accuracy (after decay): 50.02%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [29/180][0/625]	eta 4:01:17 lr 0.749850	data 21.1302 (21.1302)	batch 23.1635 (23.1635)	loss -19.8352 (-19.8352)	grad_norm 0.4187 (0.4187)	mem 44912MB
Train: [29/180][50/625]	eta 0:16:13 lr 0.749579	data 0.0010 (0.4152)	batch 1.2743 (1.6932)	loss -19.7348 (-19.8025)	grad_norm 0.4009 (0.4158)	mem 44912MB
Train: [29/180][100/625]	eta 0:12:56 lr 0.749308	data 0.0010 (0.2101)	batch 1.2397 (1.4781)	loss -19.8914 (-19.8193)	grad_norm 0.4520 (0.4183)	mem 44912MB
Train: [29/180][150/625]	eta 0:11:09 lr 0.749035	data 0.0008 (0.1410)	batch 1.2573 (1.4091)	loss -19.8752 (-19.8384)	grad_norm 0.4105 (0.4181)	mem 44912MB
Train: [29/180][200/625]	eta 0:09:43 lr 0.748762	data 0.0004 (0.1061)	batch 1.2720 (1.3735)	loss -19.9234 (-19.8468)	grad_norm 0.4276 (0.4182)	mem 44912MB
Train: [29/180][250/625]	eta 0:08:26 lr 0.748488	data 0.0012 (0.0851)	batch 1.2622 (1.3513)	loss -19.8032 (-19.8587)	grad_norm 0.4140 (0.4183)	mem 44912MB
Train: [29/180][300/625]	eta 0:07:14 lr 0.748214	data 0.0007 (0.0711)	batch 1.2395 (1.3365)	loss -20.1239 (-19.8744)	grad_norm 0.4106 (0.4180)	mem 44912MB
Train: [29/180][350/625]	eta 0:06:04 lr 0.747938	data 0.0010 (0.0611)	batch 1.2649 (1.3269)	loss -19.9176 (-19.8862)	grad_norm 0.4190 (0.4180)	mem 44912MB
Train: [29/180][400/625]	eta 0:04:56 lr 0.747663	data 0.0007 (0.0536)	batch 1.2051 (1.3197)	loss -20.1200 (-19.8999)	grad_norm 0.4195 (0.4178)	mem 44912MB
Train: [29/180][450/625]	eta 0:03:49 lr 0.747386	data 0.0005 (0.0477)	batch 1.2750 (1.3134)	loss -20.2259 (-19.9157)	grad_norm 0.4279 (0.4176)	mem 44912MB
Train: [29/180][500/625]	eta 0:02:43 lr 0.747109	data 0.0006 (0.0430)	batch 1.2534 (1.3080)	loss -19.9896 (-19.9294)	grad_norm 0.4217 (0.4174)	mem 44912MB
Train: [29/180][550/625]	eta 0:01:37 lr 0.746831	data 0.0012 (0.0392)	batch 1.2440 (1.3043)	loss -20.2284 (-19.9412)	grad_norm 0.4130 (0.4175)	mem 44912MB
Train: [29/180][600/625]	eta 0:00:32 lr 0.746552	data 0.0006 (0.0361)	batch 1.2396 (1.3014)	loss -20.1499 (-19.9532)	grad_norm 0.4338 (0.4175)	mem 44912MB
Current slope: None 	
EPOCH 29 training takes 0:13:33
Test: [0/25]	Time 14.658 (14.658)	Loss 1.5956 (1.5956)	Acc@1 63.232 (63.232)	Acc@5 85.596 (85.596)	Mem 44912MB
 * Acc@1 50.286 Acc@5 75.360
Accuracy of the network on the 50000 test images: 50.29%
Max accuracy (after decay): 50.29%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [30/180][0/625]	eta 3:55:30 lr 0.746413	data 20.3185 (20.3185)	batch 22.6087 (22.6087)	loss -20.2619 (-20.2619)	grad_norm 0.4134 (0.4134)	mem 44912MB
Train: [30/180][50/625]	eta 0:16:06 lr 0.746133	data 0.0010 (0.3992)	batch 1.2157 (1.6813)	loss -20.0908 (-20.1807)	grad_norm 0.4179 (0.4157)	mem 44912MB
Train: [30/180][100/625]	eta 0:12:57 lr 0.745853	data 0.0006 (0.2020)	batch 1.2788 (1.4807)	loss -20.2357 (-20.1859)	grad_norm 0.4158 (0.4194)	mem 44912MB
Train: [30/180][150/625]	eta 0:11:08 lr 0.745572	data 0.0008 (0.1356)	batch 1.2871 (1.4075)	loss -20.3089 (-20.1925)	grad_norm 0.4063 (0.4190)	mem 44912MB
Train: [30/180][200/625]	eta 0:09:43 lr 0.745290	data 0.0005 (0.1021)	batch 1.2924 (1.3722)	loss -20.3323 (-20.2049)	grad_norm 0.4261 (0.4197)	mem 44912MB
Train: [30/180][250/625]	eta 0:08:26 lr 0.745008	data 0.0006 (0.0819)	batch 1.2203 (1.3503)	loss -20.0874 (-20.2132)	grad_norm 0.4220 (0.4204)	mem 44912MB
Train: [30/180][300/625]	eta 0:07:14 lr 0.744725	data 0.0006 (0.0684)	batch 1.2605 (1.3369)	loss -20.3390 (-20.2270)	grad_norm 0.4109 (0.4203)	mem 44912MB
Train: [30/180][350/625]	eta 0:06:04 lr 0.744442	data 0.0008 (0.0588)	batch 1.2845 (1.3267)	loss -20.2392 (-20.2422)	grad_norm 0.4144 (0.4199)	mem 44912MB
Train: [30/180][400/625]	eta 0:04:56 lr 0.744157	data 0.0010 (0.0516)	batch 1.2753 (1.3184)	loss -20.2560 (-20.2498)	grad_norm 0.4163 (0.4196)	mem 44912MB
Train: [30/180][450/625]	eta 0:03:49 lr 0.743872	data 0.0004 (0.0459)	batch 1.2734 (1.3122)	loss -20.5338 (-20.2602)	grad_norm 0.4140 (0.4194)	mem 44912MB
Train: [30/180][500/625]	eta 0:02:43 lr 0.743587	data 0.0008 (0.0414)	batch 1.2461 (1.3084)	loss -20.4101 (-20.2756)	grad_norm 0.4153 (0.4194)	mem 44912MB
Train: [30/180][550/625]	eta 0:01:37 lr 0.743300	data 0.0006 (0.0377)	batch 1.2739 (1.3042)	loss -20.2346 (-20.2888)	grad_norm 0.4316 (0.4193)	mem 44912MB
Train: [30/180][600/625]	eta 0:00:32 lr 0.743014	data 0.0010 (0.0347)	batch 1.2287 (1.3006)	loss -20.4043 (-20.3009)	grad_norm 0.4095 (0.4189)	mem 44912MB
Current slope: None 	
EPOCH 30 training takes 0:13:33
Test: [0/25]	Time 15.192 (15.192)	Loss 1.7173 (1.7173)	Acc@1 61.816 (61.816)	Acc@5 84.521 (84.521)	Mem 44912MB
 * Acc@1 50.374 Acc@5 75.506
Accuracy of the network on the 50000 test images: 50.37%
Max accuracy (after decay): 50.37%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [31/180][0/625]	eta 4:01:58 lr 0.742870	data 20.3655 (20.3655)	batch 23.2293 (23.2293)	loss -20.4169 (-20.4169)	grad_norm 0.4152 (0.4152)	mem 44912MB
Train: [31/180][50/625]	eta 0:16:20 lr 0.742582	data 0.0010 (0.4003)	batch 1.3594 (1.7045)	loss -20.6828 (-20.5007)	grad_norm 0.4187 (0.4177)	mem 44912MB
Train: [31/180][100/625]	eta 0:13:00 lr 0.742293	data 0.0007 (0.2026)	batch 1.2516 (1.4859)	loss -20.4619 (-20.4872)	grad_norm 0.4093 (0.4192)	mem 44912MB
Train: [31/180][150/625]	eta 0:11:11 lr 0.742004	data 0.0006 (0.1358)	batch 1.2578 (1.4135)	loss -20.3807 (-20.4979)	grad_norm 0.4103 (0.4204)	mem 44912MB
Train: [31/180][200/625]	eta 0:09:44 lr 0.741714	data 0.0009 (0.1022)	batch 1.2833 (1.3763)	loss -20.6629 (-20.5153)	grad_norm 0.4071 (0.4197)	mem 44912MB
Train: [31/180][250/625]	eta 0:08:28 lr 0.741423	data 0.0004 (0.0820)	batch 1.2924 (1.3553)	loss -20.6323 (-20.5278)	grad_norm 0.4238 (0.4197)	mem 44912MB
Train: [31/180][300/625]	eta 0:07:15 lr 0.741132	data 0.0010 (0.0687)	batch 1.2215 (1.3402)	loss -20.6985 (-20.5403)	grad_norm 0.4178 (0.4196)	mem 44912MB
Train: [31/180][350/625]	eta 0:06:05 lr 0.740840	data 0.0009 (0.0590)	batch 1.2705 (1.3308)	loss -20.3748 (-20.5534)	grad_norm 0.4092 (0.4199)	mem 44912MB
Train: [31/180][400/625]	eta 0:04:57 lr 0.740547	data 0.0006 (0.0517)	batch 1.2649 (1.3229)	loss -20.6455 (-20.5647)	grad_norm 0.4177 (0.4195)	mem 44912MB
Train: [31/180][450/625]	eta 0:03:50 lr 0.740254	data 0.0008 (0.0461)	batch 1.2790 (1.3170)	loss -20.6137 (-20.5804)	grad_norm 0.4123 (0.4192)	mem 44912MB
Train: [31/180][500/625]	eta 0:02:43 lr 0.739960	data 0.0007 (0.0416)	batch 1.2572 (1.3117)	loss -20.5375 (-20.5899)	grad_norm 0.4265 (0.4193)	mem 44912MB
Train: [31/180][550/625]	eta 0:01:38 lr 0.739665	data 0.0011 (0.0379)	batch 1.2654 (1.3077)	loss -20.9763 (-20.6026)	grad_norm 0.4131 (0.4190)	mem 44912MB
Train: [31/180][600/625]	eta 0:00:32 lr 0.739370	data 0.0005 (0.0348)	batch 1.2511 (1.3042)	loss -20.8926 (-20.6161)	grad_norm 0.4138 (0.4192)	mem 44912MB
Current slope: None 	
EPOCH 31 training takes 0:13:35
Test: [0/25]	Time 14.586 (14.586)	Loss 1.6830 (1.6830)	Acc@1 63.428 (63.428)	Acc@5 85.400 (85.400)	Mem 44912MB
 * Acc@1 50.006 Acc@5 75.292
Accuracy of the network on the 50000 test images: 50.01%
Max accuracy (after decay): 50.37%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [32/180][0/625]	eta 4:00:00 lr 0.739222	data 20.2574 (20.2574)	batch 23.0405 (23.0405)	loss -20.9015 (-20.9015)	grad_norm 0.4194 (0.4194)	mem 44912MB
Train: [32/180][50/625]	eta 0:16:13 lr 0.738926	data 0.0007 (0.3988)	batch 1.2436 (1.6927)	loss -21.0176 (-20.8502)	grad_norm 0.4530 (0.4211)	mem 44912MB
Train: [32/180][100/625]	eta 0:12:59 lr 0.738629	data 0.0008 (0.2018)	batch 1.2871 (1.4841)	loss -20.7105 (-20.8438)	grad_norm 0.4226 (0.4201)	mem 44912MB
Train: [32/180][150/625]	eta 0:11:10 lr 0.738331	data 0.0009 (0.1352)	batch 1.2992 (1.4109)	loss -21.0626 (-20.8524)	grad_norm 0.4121 (0.4195)	mem 44912MB
Train: [32/180][200/625]	eta 0:09:44 lr 0.738033	data 0.0008 (0.1018)	batch 1.2543 (1.3742)	loss -20.9299 (-20.8615)	grad_norm 0.4478 (0.4190)	mem 44912MB
Train: [32/180][250/625]	eta 0:08:27 lr 0.737734	data 0.0008 (0.0818)	batch 1.2438 (1.3532)	loss -20.8854 (-20.8703)	grad_norm 0.4036 (0.4183)	mem 44912MB
Train: [32/180][300/625]	eta 0:07:15 lr 0.737435	data 0.0007 (0.0683)	batch 1.3002 (1.3391)	loss -20.9583 (-20.8796)	grad_norm 0.4216 (0.4189)	mem 44912MB
Train: [32/180][350/625]	eta 0:06:05 lr 0.737134	data 0.0006 (0.0587)	batch 1.2577 (1.3278)	loss -20.7614 (-20.8866)	grad_norm 0.4249 (0.4188)	mem 44912MB
Train: [32/180][400/625]	eta 0:04:56 lr 0.736834	data 0.0011 (0.0515)	batch 1.2977 (1.3198)	loss -21.1355 (-20.8963)	grad_norm 0.4384 (0.4185)	mem 44912MB
Train: [32/180][450/625]	eta 0:03:50 lr 0.736532	data 0.0007 (0.0459)	batch 1.2103 (1.3143)	loss -21.0906 (-20.9082)	grad_norm 0.4301 (0.4186)	mem 44912MB
Train: [32/180][500/625]	eta 0:02:43 lr 0.736230	data 0.0004 (0.0414)	batch 1.3053 (1.3094)	loss -21.1036 (-20.9164)	grad_norm 0.4224 (0.4185)	mem 44912MB
Train: [32/180][550/625]	eta 0:01:37 lr 0.735927	data 0.0006 (0.0377)	batch 1.4263 (1.3055)	loss -20.9731 (-20.9266)	grad_norm 0.4241 (0.4183)	mem 44912MB
Train: [32/180][600/625]	eta 0:00:32 lr 0.735623	data 0.0007 (0.0346)	batch 1.2745 (1.3018)	loss -21.1518 (-20.9367)	grad_norm 0.4171 (0.4183)	mem 44912MB
Current slope: None 	
EPOCH 32 training takes 0:13:34
Test: [0/25]	Time 14.970 (14.970)	Loss 1.6254 (1.6254)	Acc@1 62.793 (62.793)	Acc@5 85.400 (85.400)	Mem 44912MB
 * Acc@1 50.154 Acc@5 75.198
Accuracy of the network on the 50000 test images: 50.15%
Max accuracy (after decay): 50.37%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [33/180][0/625]	eta 4:00:50 lr 0.735471	data 21.1342 (21.1342)	batch 23.1207 (23.1207)	loss -20.7482 (-20.7482)	grad_norm 0.4480 (0.4480)	mem 44912MB
Train: [33/180][50/625]	eta 0:16:14 lr 0.735167	data 0.0007 (0.4154)	batch 1.2388 (1.6953)	loss -21.1024 (-21.0986)	grad_norm 0.4167 (0.4177)	mem 44912MB
Train: [33/180][100/625]	eta 0:12:58 lr 0.734862	data 0.0006 (0.2102)	batch 1.2310 (1.4821)	loss -20.9603 (-21.1125)	grad_norm 0.4213 (0.4186)	mem 44912MB
Train: [33/180][150/625]	eta 0:11:10 lr 0.734556	data 0.0008 (0.1409)	batch 1.2948 (1.4106)	loss -21.1595 (-21.1304)	grad_norm 0.4111 (0.4188)	mem 44912MB
Train: [33/180][200/625]	eta 0:09:43 lr 0.734250	data 0.0007 (0.1061)	batch 1.2760 (1.3740)	loss -21.2245 (-21.1459)	grad_norm 0.4118 (0.4189)	mem 44912MB
Train: [33/180][250/625]	eta 0:08:26 lr 0.733942	data 0.0006 (0.0851)	batch 1.2682 (1.3517)	loss -21.0325 (-21.1551)	grad_norm 0.4173 (0.4186)	mem 44912MB
Train: [33/180][300/625]	eta 0:07:14 lr 0.733635	data 0.0010 (0.0711)	batch 1.2610 (1.3378)	loss -21.4283 (-21.1659)	grad_norm 0.4275 (0.4185)	mem 44912MB
Train: [33/180][350/625]	eta 0:06:04 lr 0.733326	data 0.0006 (0.0611)	batch 1.2639 (1.3268)	loss -21.2248 (-21.1760)	grad_norm 0.4047 (0.4186)	mem 44912MB
Train: [33/180][400/625]	eta 0:04:56 lr 0.733017	data 0.0005 (0.0535)	batch 1.2900 (1.3190)	loss -21.3616 (-21.1859)	grad_norm 0.4226 (0.4185)	mem 44912MB
Train: [33/180][450/625]	eta 0:03:49 lr 0.732708	data 0.0006 (0.0478)	batch 1.2444 (1.3123)	loss -21.4450 (-21.1980)	grad_norm 0.4102 (0.4185)	mem 44912MB
Train: [33/180][500/625]	eta 0:02:43 lr 0.732397	data 0.0005 (0.0431)	batch 1.2949 (1.3084)	loss -21.2971 (-21.2074)	grad_norm 0.4133 (0.4183)	mem 44912MB
Train: [33/180][550/625]	eta 0:01:37 lr 0.732086	data 0.0006 (0.0392)	batch 1.2370 (1.3041)	loss -21.4902 (-21.2184)	grad_norm 0.4155 (0.4184)	mem 44912MB
Train: [33/180][600/625]	eta 0:00:32 lr 0.731775	data 0.0005 (0.0360)	batch 1.2703 (1.3011)	loss -21.3215 (-21.2287)	grad_norm 0.4208 (0.4184)	mem 44912MB
Current slope: None 	
EPOCH 33 training takes 0:13:33
Test: [0/25]	Time 14.627 (14.627)	Loss 1.7477 (1.7477)	Acc@1 60.205 (60.205)	Acc@5 83.545 (83.545)	Mem 44912MB
 * Acc@1 50.606 Acc@5 75.902
Accuracy of the network on the 50000 test images: 50.61%
Max accuracy (after decay): 50.61%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [34/180][0/625]	eta 4:07:02 lr 0.731618	data 21.8971 (21.8971)	batch 23.7160 (23.7160)	loss -21.3210 (-21.3210)	grad_norm 0.4139 (0.4139)	mem 44912MB
Train: [34/180][50/625]	eta 0:16:19 lr 0.731306	data 0.0006 (0.4301)	batch 1.2593 (1.7026)	loss -21.2932 (-21.3798)	grad_norm 0.4314 (0.4161)	mem 44912MB
Train: [34/180][100/625]	eta 0:13:00 lr 0.730993	data 0.0006 (0.2175)	batch 1.2635 (1.4866)	loss -21.4494 (-21.4064)	grad_norm 0.4188 (0.4180)	mem 44912MB
Train: [34/180][150/625]	eta 0:11:10 lr 0.730679	data 0.0005 (0.1457)	batch 1.2565 (1.4124)	loss -21.4971 (-21.4111)	grad_norm 0.4168 (0.4184)	mem 44912MB
Train: [34/180][200/625]	eta 0:09:44 lr 0.730364	data 0.0005 (0.1096)	batch 1.2493 (1.3748)	loss -21.4955 (-21.4122)	grad_norm 0.4373 (0.4190)	mem 44912MB
Train: [34/180][250/625]	eta 0:08:26 lr 0.730049	data 0.0007 (0.0879)	batch 1.2397 (1.3519)	loss -21.4613 (-21.4217)	grad_norm 0.4193 (0.4188)	mem 44912MB
Train: [34/180][300/625]	eta 0:07:14 lr 0.729733	data 0.0005 (0.0734)	batch 1.2628 (1.3376)	loss -21.3937 (-21.4342)	grad_norm 0.4254 (0.4188)	mem 44912MB
Train: [34/180][350/625]	eta 0:06:05 lr 0.729417	data 0.0006 (0.0630)	batch 1.2989 (1.3275)	loss -21.5867 (-21.4464)	grad_norm 0.4188 (0.4192)	mem 44912MB
Train: [34/180][400/625]	eta 0:04:56 lr 0.729099	data 0.0006 (0.0553)	batch 1.2539 (1.3196)	loss -21.6102 (-21.4594)	grad_norm 0.4151 (0.4194)	mem 44912MB
Train: [34/180][450/625]	eta 0:03:49 lr 0.728782	data 0.0010 (0.0492)	batch 1.2605 (1.3141)	loss -21.6467 (-21.4737)	grad_norm 0.4114 (0.4196)	mem 44912MB
Train: [34/180][500/625]	eta 0:02:43 lr 0.728463	data 0.0010 (0.0444)	batch 1.2815 (1.3092)	loss -21.6863 (-21.4854)	grad_norm 0.4191 (0.4195)	mem 44912MB
Train: [34/180][550/625]	eta 0:01:37 lr 0.728144	data 0.0010 (0.0404)	batch 1.2634 (1.3047)	loss -21.9063 (-21.4991)	grad_norm 0.4047 (0.4200)	mem 44912MB
Train: [34/180][600/625]	eta 0:00:32 lr 0.727825	data 0.0010 (0.0371)	batch 1.2688 (1.3014)	loss -21.5495 (-21.5111)	grad_norm 0.4253 (0.4200)	mem 44912MB
Current slope: None 	
EPOCH 34 training takes 0:13:33
Test: [0/25]	Time 15.281 (15.281)	Loss 1.5581 (1.5581)	Acc@1 64.941 (64.941)	Acc@5 86.621 (86.621)	Mem 44912MB
 * Acc@1 51.544 Acc@5 76.394
Accuracy of the network on the 50000 test images: 51.54%
Max accuracy (after decay): 51.54%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [35/180][0/625]	eta 4:00:54 lr 0.727664	data 21.4445 (21.4445)	batch 23.1266 (23.1266)	loss -21.6803 (-21.6803)	grad_norm 0.4152 (0.4152)	mem 44912MB
Train: [35/180][50/625]	eta 0:16:16 lr 0.727344	data 0.0006 (0.4216)	batch 1.2549 (1.6985)	loss -21.5490 (-21.6705)	grad_norm 0.4313 (0.4209)	mem 44912MB
Train: [35/180][100/625]	eta 0:12:58 lr 0.727022	data 0.0005 (0.2133)	batch 1.2575 (1.4832)	loss -21.8175 (-21.6930)	grad_norm 0.4018 (0.4203)	mem 44912MB
Train: [35/180][150/625]	eta 0:11:10 lr 0.726701	data 0.0006 (0.1429)	batch 1.3302 (1.4116)	loss -21.5620 (-21.6896)	grad_norm 0.4270 (0.4207)	mem 44912MB
Train: [35/180][200/625]	eta 0:09:44 lr 0.726378	data 0.0006 (0.1075)	batch 1.1879 (1.3749)	loss -21.6140 (-21.6987)	grad_norm 0.4313 (0.4208)	mem 44912MB
Train: [35/180][250/625]	eta 0:08:27 lr 0.726055	data 0.0005 (0.0862)	batch 1.2385 (1.3536)	loss -21.8647 (-21.7086)	grad_norm 0.4324 (0.4208)	mem 44912MB
Train: [35/180][300/625]	eta 0:07:15 lr 0.725731	data 0.0008 (0.0720)	batch 1.2930 (1.3386)	loss -21.8302 (-21.7210)	grad_norm 0.4356 (0.4205)	mem 44912MB
Train: [35/180][350/625]	eta 0:06:05 lr 0.725407	data 0.0007 (0.0619)	batch 1.2328 (1.3277)	loss -21.7743 (-21.7320)	grad_norm 0.4204 (0.4201)	mem 44912MB
Train: [35/180][400/625]	eta 0:04:56 lr 0.725081	data 0.0010 (0.0543)	batch 1.2714 (1.3195)	loss -21.6241 (-21.7385)	grad_norm 0.4456 (0.4206)	mem 44912MB
Train: [35/180][450/625]	eta 0:03:49 lr 0.724756	data 0.0007 (0.0483)	batch 1.2562 (1.3138)	loss -21.8690 (-21.7458)	grad_norm 0.4187 (0.4205)	mem 44912MB
Train: [35/180][500/625]	eta 0:02:43 lr 0.724429	data 0.0011 (0.0436)	batch 1.3168 (1.3088)	loss -21.7960 (-21.7537)	grad_norm 0.4152 (0.4202)	mem 44912MB
Train: [35/180][550/625]	eta 0:01:37 lr 0.724102	data 0.0007 (0.0397)	batch 1.2524 (1.3048)	loss -21.8374 (-21.7658)	grad_norm 0.4196 (0.4202)	mem 44912MB
Train: [35/180][600/625]	eta 0:00:32 lr 0.723775	data 0.0005 (0.0364)	batch 1.2399 (1.3018)	loss -21.8438 (-21.7743)	grad_norm 0.4152 (0.4203)	mem 44912MB
Current slope: None 	
EPOCH 35 training takes 0:13:34
Test: [0/25]	Time 14.414 (14.414)	Loss 1.6390 (1.6390)	Acc@1 64.014 (64.014)	Acc@5 84.814 (84.814)	Mem 44912MB
 * Acc@1 51.064 Acc@5 76.234
Accuracy of the network on the 50000 test images: 51.06%
Max accuracy (after decay): 51.54%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [36/180][0/625]	eta 3:58:34 lr 0.723611	data 20.1864 (20.1864)	batch 22.9036 (22.9036)	loss -21.7194 (-21.7194)	grad_norm 0.4147 (0.4147)	mem 44912MB
Train: [36/180][50/625]	eta 0:16:19 lr 0.723282	data 0.0007 (0.3967)	batch 1.2556 (1.7031)	loss -22.0784 (-21.9017)	grad_norm 0.4181 (0.4213)	mem 44912MB
Train: [36/180][100/625]	eta 0:12:58 lr 0.722953	data 0.0004 (0.2007)	batch 1.2773 (1.4822)	loss -22.0570 (-21.9354)	grad_norm 0.4197 (0.4208)	mem 44912MB
Train: [36/180][150/625]	eta 0:11:10 lr 0.722623	data 0.0011 (0.1345)	batch 1.2537 (1.4124)	loss -22.1740 (-21.9396)	grad_norm 0.4351 (0.4216)	mem 44912MB
Train: [36/180][200/625]	eta 0:09:44 lr 0.722293	data 0.0008 (0.1013)	batch 1.2806 (1.3755)	loss -22.2284 (-21.9452)	grad_norm 0.4170 (0.4205)	mem 44912MB
Train: [36/180][250/625]	eta 0:08:28 lr 0.721961	data 0.0006 (0.0812)	batch 1.3163 (1.3547)	loss -21.9010 (-21.9547)	grad_norm 0.4361 (0.4210)	mem 44912MB
Train: [36/180][300/625]	eta 0:07:15 lr 0.721630	data 0.0011 (0.0679)	batch 1.2283 (1.3386)	loss -22.0827 (-21.9603)	grad_norm 0.4119 (0.4211)	mem 44912MB
Train: [36/180][350/625]	eta 0:06:05 lr 0.721297	data 0.0014 (0.0583)	batch 1.2866 (1.3284)	loss -21.8899 (-21.9727)	grad_norm 0.4414 (0.4210)	mem 44912MB
Train: [36/180][400/625]	eta 0:04:56 lr 0.720964	data 0.0005 (0.0512)	batch 1.2808 (1.3197)	loss -22.1086 (-21.9835)	grad_norm 0.4071 (0.4211)	mem 44912MB
Train: [36/180][450/625]	eta 0:03:49 lr 0.720631	data 0.0008 (0.0456)	batch 1.2425 (1.3142)	loss -22.0821 (-21.9919)	grad_norm 0.4062 (0.4209)	mem 44912MB
Train: [36/180][500/625]	eta 0:02:43 lr 0.720297	data 0.0006 (0.0412)	batch 1.2670 (1.3090)	loss -22.0015 (-21.9991)	grad_norm 0.4222 (0.4210)	mem 44912MB
Train: [36/180][550/625]	eta 0:01:37 lr 0.719962	data 0.0007 (0.0375)	batch 1.2261 (1.3044)	loss -21.8894 (-22.0074)	grad_norm 0.4139 (0.4209)	mem 44912MB
Train: [36/180][600/625]	eta 0:00:32 lr 0.719626	data 0.0008 (0.0344)	batch 1.2510 (1.3012)	loss -22.3375 (-22.0171)	grad_norm 0.4172 (0.4205)	mem 44912MB
Current slope: None 	
EPOCH 36 training takes 0:13:33
Test: [0/25]	Time 14.876 (14.876)	Loss 1.5718 (1.5718)	Acc@1 63.232 (63.232)	Acc@5 86.768 (86.768)	Mem 44912MB
 * Acc@1 51.766 Acc@5 76.776
Accuracy of the network on the 50000 test images: 51.77%
Max accuracy (after decay): 51.77%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [37/180][0/625]	eta 4:03:57 lr 0.719458	data 21.2209 (21.2209)	batch 23.4195 (23.4195)	loss -22.0997 (-22.0997)	grad_norm 0.4284 (0.4284)	mem 44912MB
Train: [37/180][50/625]	eta 0:16:21 lr 0.719122	data 0.0005 (0.4170)	batch 1.2932 (1.7061)	loss -22.2235 (-22.1893)	grad_norm 0.4310 (0.4191)	mem 44912MB
Train: [37/180][100/625]	eta 0:13:01 lr 0.718785	data 0.0006 (0.2110)	batch 1.2759 (1.4882)	loss -22.1941 (-22.1996)	grad_norm 0.4269 (0.4190)	mem 44912MB
Train: [37/180][150/625]	eta 0:11:12 lr 0.718447	data 0.0015 (0.1414)	batch 1.3024 (1.4159)	loss -22.3333 (-22.2027)	grad_norm 0.4107 (0.4212)	mem 44912MB
Train: [37/180][200/625]	eta 0:09:46 lr 0.718109	data 0.0008 (0.1064)	batch 1.2539 (1.3789)	loss -22.1117 (-22.2050)	grad_norm 0.4101 (0.4216)	mem 44912MB
Train: [37/180][250/625]	eta 0:08:28 lr 0.717770	data 0.0005 (0.0854)	batch 1.2751 (1.3557)	loss -22.0040 (-22.2145)	grad_norm 0.4276 (0.4216)	mem 44912MB
Train: [37/180][300/625]	eta 0:07:16 lr 0.717430	data 0.0009 (0.0713)	batch 1.2700 (1.3416)	loss -22.1406 (-22.2175)	grad_norm 0.4122 (0.4216)	mem 44912MB
Train: [37/180][350/625]	eta 0:06:05 lr 0.717090	data 0.0006 (0.0613)	batch 1.2888 (1.3307)	loss -22.1297 (-22.2237)	grad_norm 0.4138 (0.4218)	mem 44912MB
Train: [37/180][400/625]	eta 0:04:57 lr 0.716750	data 0.0006 (0.0538)	batch 1.2720 (1.3227)	loss -22.3114 (-22.2328)	grad_norm 0.4147 (0.4215)	mem 44912MB
Train: [37/180][450/625]	eta 0:03:50 lr 0.716408	data 0.0005 (0.0479)	batch 1.2565 (1.3162)	loss -22.3977 (-22.2434)	grad_norm 0.4371 (0.4216)	mem 44912MB
Train: [37/180][500/625]	eta 0:02:43 lr 0.716066	data 0.0005 (0.0432)	batch 1.2496 (1.3109)	loss -22.3906 (-22.2506)	grad_norm 0.4098 (0.4217)	mem 44912MB
Train: [37/180][550/625]	eta 0:01:37 lr 0.715724	data 0.0006 (0.0393)	batch 1.2506 (1.3062)	loss -22.4031 (-22.2580)	grad_norm 0.4218 (0.4217)	mem 44912MB
Train: [37/180][600/625]	eta 0:00:32 lr 0.715380	data 0.0006 (0.0361)	batch 1.2446 (1.3025)	loss -22.4204 (-22.2662)	grad_norm 0.4290 (0.4216)	mem 44912MB
Current slope: None 	
EPOCH 37 training takes 0:13:34
Test: [0/25]	Time 14.539 (14.539)	Loss 1.6675 (1.6675)	Acc@1 62.012 (62.012)	Acc@5 84.570 (84.570)	Mem 44912MB
 * Acc@1 51.098 Acc@5 76.044
Accuracy of the network on the 50000 test images: 51.10%
Max accuracy (after decay): 51.77%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [38/180][0/625]	eta 4:00:24 lr 0.715209	data 20.2539 (20.2539)	batch 23.0799 (23.0799)	loss -22.3241 (-22.3241)	grad_norm 0.4252 (0.4252)	mem 44912MB
Train: [38/180][50/625]	eta 0:16:12 lr 0.714864	data 0.0010 (0.3979)	batch 1.2779 (1.6911)	loss -22.4629 (-22.3808)	grad_norm 0.4165 (0.4226)	mem 44912MB
Train: [38/180][100/625]	eta 0:12:57 lr 0.714520	data 0.0013 (0.2013)	batch 1.2742 (1.4813)	loss -22.1249 (-22.4034)	grad_norm 0.4181 (0.4215)	mem 44912MB
Train: [38/180][150/625]	eta 0:11:09 lr 0.714174	data 0.0009 (0.1349)	batch 1.2568 (1.4093)	loss -22.6906 (-22.4114)	grad_norm 0.4141 (0.4235)	mem 44912MB
Train: [38/180][200/625]	eta 0:09:43 lr 0.713828	data 0.0005 (0.1015)	batch 1.2943 (1.3740)	loss -22.0933 (-22.4245)	grad_norm 0.4337 (0.4228)	mem 44912MB
Train: [38/180][250/625]	eta 0:08:27 lr 0.713482	data 0.0007 (0.0815)	batch 1.2784 (1.3532)	loss -22.6560 (-22.4331)	grad_norm 0.4123 (0.4228)	mem 44912MB
Train: [38/180][300/625]	eta 0:07:14 lr 0.713135	data 0.0005 (0.0682)	batch 1.2364 (1.3382)	loss -22.5139 (-22.4413)	grad_norm 0.4288 (0.4232)	mem 44912MB
Train: [38/180][350/625]	eta 0:06:05 lr 0.712787	data 0.0007 (0.0587)	batch 1.2320 (1.3275)	loss -22.2611 (-22.4499)	grad_norm 0.4261 (0.4228)	mem 44912MB
Train: [38/180][400/625]	eta 0:04:57 lr 0.712438	data 0.0005 (0.0514)	batch 1.3155 (1.3205)	loss -22.5673 (-22.4541)	grad_norm 0.4129 (0.4226)	mem 44912MB
Train: [38/180][450/625]	eta 0:03:50 lr 0.712089	data 0.0007 (0.0459)	batch 1.2237 (1.3144)	loss -22.4635 (-22.4633)	grad_norm 0.4237 (0.4223)	mem 44912MB
Train: [38/180][500/625]	eta 0:02:43 lr 0.711740	data 0.0005 (0.0414)	batch 1.2603 (1.3091)	loss -22.6361 (-22.4714)	grad_norm 0.4158 (0.4223)	mem 44912MB
Train: [38/180][550/625]	eta 0:01:37 lr 0.711389	data 0.0007 (0.0377)	batch 1.2560 (1.3052)	loss -22.5355 (-22.4788)	grad_norm 0.4221 (0.4221)	mem 44912MB
Train: [38/180][600/625]	eta 0:00:32 lr 0.711038	data 0.0007 (0.0346)	batch 1.2416 (1.3021)	loss -22.5702 (-22.4870)	grad_norm 0.4138 (0.4222)	mem 44912MB
Current slope: None 	
EPOCH 38 training takes 0:13:34
Test: [0/25]	Time 14.954 (14.954)	Loss 1.6818 (1.6818)	Acc@1 63.281 (63.281)	Acc@5 84.766 (84.766)	Mem 44912MB
 * Acc@1 51.954 Acc@5 76.702
Accuracy of the network on the 50000 test images: 51.95%
Max accuracy (after decay): 51.95%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [39/180][0/625]	eta 3:57:49 lr 0.710863	data 20.6996 (20.6996)	batch 22.8309 (22.8309)	loss -22.7711 (-22.7711)	grad_norm 0.4099 (0.4099)	mem 44912MB
Train: [39/180][50/625]	eta 0:16:13 lr 0.710511	data 0.0007 (0.4068)	batch 1.2623 (1.6939)	loss -22.4660 (-22.6184)	grad_norm 0.4194 (0.4232)	mem 44912MB
Train: [39/180][100/625]	eta 0:12:56 lr 0.710159	data 0.0008 (0.2058)	batch 1.2434 (1.4794)	loss -22.6730 (-22.6148)	grad_norm 0.4139 (0.4217)	mem 44912MB
Train: [39/180][150/625]	eta 0:11:09 lr 0.709806	data 0.0006 (0.1379)	batch 1.2243 (1.4094)	loss -22.8684 (-22.6355)	grad_norm 0.4363 (0.4232)	mem 44912MB
Train: [39/180][200/625]	eta 0:09:43 lr 0.709452	data 0.0006 (0.1038)	batch 1.3142 (1.3724)	loss -22.7117 (-22.6497)	grad_norm 0.4249 (0.4228)	mem 44912MB
Train: [39/180][250/625]	eta 0:08:26 lr 0.709098	data 0.0012 (0.0833)	batch 1.2515 (1.3514)	loss -22.4758 (-22.6551)	grad_norm 0.4288 (0.4230)	mem 44912MB
Train: [39/180][300/625]	eta 0:07:14 lr 0.708743	data 0.0008 (0.0696)	batch 1.3033 (1.3368)	loss -22.6055 (-22.6648)	grad_norm 0.4410 (0.4231)	mem 44912MB
Train: [39/180][350/625]	eta 0:06:04 lr 0.708388	data 0.0006 (0.0598)	batch 1.2512 (1.3267)	loss -22.7462 (-22.6677)	grad_norm 0.4244 (0.4236)	mem 44912MB
Train: [39/180][400/625]	eta 0:04:56 lr 0.708032	data 0.0009 (0.0524)	batch 1.4045 (1.3195)	loss -22.7397 (-22.6746)	grad_norm 0.4235 (0.4234)	mem 44912MB
Train: [39/180][450/625]	eta 0:03:49 lr 0.707675	data 0.0006 (0.0467)	batch 1.2251 (1.3139)	loss -22.6966 (-22.6790)	grad_norm 0.4102 (0.4232)	mem 44912MB
Train: [39/180][500/625]	eta 0:02:43 lr 0.707318	data 0.0006 (0.0421)	batch 1.2494 (1.3092)	loss -22.6757 (-22.6879)	grad_norm 0.4205 (0.4231)	mem 44912MB
Train: [39/180][550/625]	eta 0:01:37 lr 0.706960	data 0.0007 (0.0384)	batch 1.2501 (1.3055)	loss -22.7331 (-22.6936)	grad_norm 0.4417 (0.4233)	mem 44912MB
Train: [39/180][600/625]	eta 0:00:32 lr 0.706602	data 0.0005 (0.0353)	batch 1.2669 (1.3021)	loss -22.8403 (-22.7040)	grad_norm 0.4264 (0.4233)	mem 44912MB
Current slope: None 	
EPOCH 39 training takes 0:13:34
Test: [0/25]	Time 14.448 (14.448)	Loss 1.6913 (1.6913)	Acc@1 62.207 (62.207)	Acc@5 84.424 (84.424)	Mem 44912MB
 * Acc@1 50.844 Acc@5 75.996
Accuracy of the network on the 50000 test images: 50.84%
Max accuracy (after decay): 51.95%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [40/180][0/625]	eta 3:58:06 lr 0.706422	data 21.1994 (21.1994)	batch 22.8578 (22.8578)	loss -22.7627 (-22.7627)	grad_norm 0.4162 (0.4162)	mem 44912MB
Train: [40/180][50/625]	eta 0:16:12 lr 0.706063	data 0.0010 (0.4168)	batch 1.2627 (1.6913)	loss -22.8567 (-22.8306)	grad_norm 0.4221 (0.4229)	mem 44912MB
Train: [40/180][100/625]	eta 0:12:57 lr 0.705703	data 0.0006 (0.2109)	batch 1.2351 (1.4801)	loss -22.9334 (-22.8401)	grad_norm 0.4349 (0.4232)	mem 44912MB
Train: [40/180][150/625]	eta 0:11:10 lr 0.705343	data 0.0013 (0.1413)	batch 1.2707 (1.4110)	loss -22.7379 (-22.8436)	grad_norm 0.4154 (0.4234)	mem 44912MB
Train: [40/180][200/625]	eta 0:09:43 lr 0.704982	data 0.0008 (0.1064)	batch 1.2261 (1.3734)	loss -22.9854 (-22.8514)	grad_norm 0.4186 (0.4230)	mem 44912MB
Train: [40/180][250/625]	eta 0:08:26 lr 0.704620	data 0.0007 (0.0853)	batch 1.2228 (1.3512)	loss -23.0716 (-22.8597)	grad_norm 0.4254 (0.4233)	mem 44912MB
Train: [40/180][300/625]	eta 0:07:14 lr 0.704258	data 0.0009 (0.0713)	batch 1.2744 (1.3370)	loss -22.8389 (-22.8688)	grad_norm 0.4246 (0.4233)	mem 44912MB
Train: [40/180][350/625]	eta 0:06:04 lr 0.703895	data 0.0007 (0.0612)	batch 1.2698 (1.3264)	loss -22.6848 (-22.8769)	grad_norm 0.4505 (0.4235)	mem 44912MB
Train: [40/180][400/625]	eta 0:04:56 lr 0.703532	data 0.0006 (0.0537)	batch 1.2489 (1.3184)	loss -22.9285 (-22.8842)	grad_norm 0.4222 (0.4232)	mem 44912MB
Train: [40/180][450/625]	eta 0:03:49 lr 0.703168	data 0.0008 (0.0478)	batch 1.2318 (1.3128)	loss -23.0675 (-22.8903)	grad_norm 0.4097 (0.4235)	mem 44912MB
Train: [40/180][500/625]	eta 0:02:43 lr 0.702803	data 0.0005 (0.0431)	batch 1.2870 (1.3081)	loss -23.0336 (-22.8985)	grad_norm 0.4202 (0.4234)	mem 44912MB
Train: [40/180][550/625]	eta 0:01:37 lr 0.702438	data 0.0011 (0.0393)	batch 1.2531 (1.3045)	loss -22.7824 (-22.9027)	grad_norm 0.4268 (0.4232)	mem 44912MB
Train: [40/180][600/625]	eta 0:00:32 lr 0.702072	data 0.0006 (0.0361)	batch 1.2313 (1.3011)	loss -23.0044 (-22.9076)	grad_norm 0.4256 (0.4232)	mem 44912MB
Current slope: None 	
EPOCH 40 training takes 0:13:33
Test: [0/25]	Time 14.825 (14.825)	Loss 1.5713 (1.5713)	Acc@1 64.014 (64.014)	Acc@5 85.596 (85.596)	Mem 44912MB
 * Acc@1 51.656 Acc@5 76.734
Accuracy of the network on the 50000 test images: 51.66%
Max accuracy (after decay): 51.95%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [41/180][0/625]	eta 4:02:56 lr 0.701889	data 21.3312 (21.3312)	batch 23.3227 (23.3227)	loss -23.0803 (-23.0803)	grad_norm 0.4271 (0.4271)	mem 44912MB
Train: [41/180][50/625]	eta 0:16:16 lr 0.701522	data 0.0006 (0.4191)	batch 1.3153 (1.6977)	loss -23.1018 (-23.0513)	grad_norm 0.4258 (0.4220)	mem 44912MB
Train: [41/180][100/625]	eta 0:12:58 lr 0.701155	data 0.0010 (0.2121)	batch 1.2386 (1.4836)	loss -23.0345 (-23.0628)	grad_norm 0.4301 (0.4235)	mem 44912MB
Train: [41/180][150/625]	eta 0:11:10 lr 0.700787	data 0.0012 (0.1421)	batch 1.2673 (1.4122)	loss -23.1560 (-23.0626)	grad_norm 0.4085 (0.4230)	mem 44912MB
Train: [41/180][200/625]	eta 0:09:44 lr 0.700418	data 0.0015 (0.1070)	batch 1.2612 (1.3757)	loss -23.0862 (-23.0674)	grad_norm 0.4304 (0.4227)	mem 44912MB
Train: [41/180][250/625]	eta 0:08:27 lr 0.700049	data 0.0007 (0.0859)	batch 1.3115 (1.3539)	loss -23.0424 (-23.0732)	grad_norm 0.4350 (0.4240)	mem 44912MB
Train: [41/180][300/625]	eta 0:07:15 lr 0.699680	data 0.0006 (0.0717)	batch 1.2920 (1.3392)	loss -23.0447 (-23.0790)	grad_norm 0.4237 (0.4235)	mem 44912MB
Train: [41/180][350/625]	eta 0:06:05 lr 0.699310	data 0.0008 (0.0616)	batch 1.2360 (1.3285)	loss -23.1895 (-23.0851)	grad_norm 0.4313 (0.4240)	mem 44912MB
Train: [41/180][400/625]	eta 0:04:57 lr 0.698939	data 0.0009 (0.0541)	batch 1.3153 (1.3207)	loss -23.0233 (-23.0877)	grad_norm 0.4184 (0.4240)	mem 44912MB
Train: [41/180][450/625]	eta 0:03:49 lr 0.698567	data 0.0007 (0.0482)	batch 1.3455 (1.3142)	loss -23.1044 (-23.0948)	grad_norm 0.4495 (0.4238)	mem 44912MB
Train: [41/180][500/625]	eta 0:02:43 lr 0.698195	data 0.0012 (0.0434)	batch 1.2705 (1.3091)	loss -23.1237 (-23.0996)	grad_norm 0.4159 (0.4238)	mem 44912MB
Train: [41/180][550/625]	eta 0:01:37 lr 0.697823	data 0.0006 (0.0396)	batch 1.2535 (1.3050)	loss -23.1746 (-23.1049)	grad_norm 0.4212 (0.4237)	mem 44912MB
Train: [41/180][600/625]	eta 0:00:32 lr 0.697450	data 0.0006 (0.0363)	batch 1.2535 (1.3019)	loss -23.1945 (-23.1103)	grad_norm 0.4183 (0.4236)	mem 44912MB
Current slope: None 	
EPOCH 41 training takes 0:13:34
Test: [0/25]	Time 14.387 (14.387)	Loss 1.6478 (1.6478)	Acc@1 62.012 (62.012)	Acc@5 84.521 (84.521)	Mem 44912MB
 * Acc@1 51.570 Acc@5 76.366
Accuracy of the network on the 50000 test images: 51.57%
Max accuracy (after decay): 51.95%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [42/180][0/625]	eta 4:02:26 lr 0.697263	data 20.9725 (20.9725)	batch 23.2752 (23.2752)	loss -23.2348 (-23.2348)	grad_norm 0.4279 (0.4279)	mem 44912MB
Train: [42/180][50/625]	eta 0:16:17 lr 0.696889	data 0.0017 (0.4127)	batch 1.4010 (1.6996)	loss -23.5122 (-23.2171)	grad_norm 0.4140 (0.4247)	mem 44912MB
Train: [42/180][100/625]	eta 0:12:58 lr 0.696515	data 0.0008 (0.2088)	batch 1.2414 (1.4836)	loss -23.3450 (-23.2328)	grad_norm 0.3968 (0.4247)	mem 44912MB
Train: [42/180][150/625]	eta 0:11:10 lr 0.696139	data 0.0006 (0.1399)	batch 1.2568 (1.4107)	loss -23.1301 (-23.2379)	grad_norm 0.4326 (0.4262)	mem 44912MB
Train: [42/180][200/625]	eta 0:09:44 lr 0.695764	data 0.0014 (0.1053)	batch 1.2462 (1.3753)	loss -23.2110 (-23.2476)	grad_norm 0.4290 (0.4257)	mem 44912MB
Train: [42/180][250/625]	eta 0:08:27 lr 0.695387	data 0.0006 (0.0845)	batch 1.2635 (1.3528)	loss -23.3207 (-23.2546)	grad_norm 0.4058 (0.4260)	mem 44912MB
Train: [42/180][300/625]	eta 0:07:14 lr 0.695010	data 0.0007 (0.0707)	batch 1.3107 (1.3378)	loss -23.3517 (-23.2575)	grad_norm 0.4176 (0.4254)	mem 44912MB
Train: [42/180][350/625]	eta 0:06:05 lr 0.694633	data 0.0005 (0.0608)	batch 1.2564 (1.3277)	loss -23.3927 (-23.2633)	grad_norm 0.4305 (0.4254)	mem 44912MB
Train: [42/180][400/625]	eta 0:04:57 lr 0.694255	data 0.0007 (0.0533)	batch 1.2306 (1.3205)	loss -23.5289 (-23.2692)	grad_norm 0.4180 (0.4255)	mem 44912MB
Train: [42/180][450/625]	eta 0:03:50 lr 0.693876	data 0.0009 (0.0475)	batch 1.2662 (1.3148)	loss -23.2844 (-23.2782)	grad_norm 0.4328 (0.4252)	mem 44912MB
Train: [42/180][500/625]	eta 0:02:43 lr 0.693497	data 0.0010 (0.0428)	batch 1.3114 (1.3094)	loss -23.2152 (-23.2850)	grad_norm 0.4176 (0.4250)	mem 44912MB
Train: [42/180][550/625]	eta 0:01:37 lr 0.693118	data 0.0007 (0.0390)	batch 1.2760 (1.3051)	loss -23.3888 (-23.2932)	grad_norm 0.4234 (0.4249)	mem 44912MB
Train: [42/180][600/625]	eta 0:00:32 lr 0.692737	data 0.0008 (0.0359)	batch 1.2663 (1.3018)	loss -23.4548 (-23.2975)	grad_norm 0.4186 (0.4249)	mem 44912MB
Current slope: None 	
EPOCH 42 training takes 0:13:33
Test: [0/25]	Time 14.679 (14.679)	Loss 1.7234 (1.7234)	Acc@1 61.865 (61.865)	Acc@5 82.764 (82.764)	Mem 44912MB
 * Acc@1 51.630 Acc@5 76.706
Accuracy of the network on the 50000 test images: 51.63%
Max accuracy (after decay): 51.95%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [43/180][0/625]	eta 4:01:19 lr 0.692547	data 21.7824 (21.7824)	batch 23.1665 (23.1665)	loss -23.4678 (-23.4678)	grad_norm 0.4132 (0.4132)	mem 44912MB
Train: [43/180][50/625]	eta 0:16:20 lr 0.692166	data 0.0006 (0.4279)	batch 1.2610 (1.7060)	loss -23.6522 (-23.4066)	grad_norm 0.4180 (0.4258)	mem 44912MB
Train: [43/180][100/625]	eta 0:12:59 lr 0.691784	data 0.0009 (0.2165)	batch 1.2810 (1.4856)	loss -23.2894 (-23.3968)	grad_norm 0.4392 (0.4273)	mem 44912MB
Train: [43/180][150/625]	eta 0:11:11 lr 0.691402	data 0.0008 (0.1451)	batch 1.2217 (1.4132)	loss -23.3518 (-23.4016)	grad_norm 0.4239 (0.4270)	mem 44912MB
Train: [43/180][200/625]	eta 0:09:44 lr 0.691019	data 0.0011 (0.1092)	batch 1.2841 (1.3751)	loss -23.4594 (-23.4095)	grad_norm 0.4275 (0.4274)	mem 44912MB
Train: [43/180][250/625]	eta 0:08:27 lr 0.690635	data 0.0004 (0.0876)	batch 1.2249 (1.3534)	loss -23.5087 (-23.4177)	grad_norm 0.4160 (0.4268)	mem 44912MB
Train: [43/180][300/625]	eta 0:07:15 lr 0.690251	data 0.0006 (0.0732)	batch 1.2598 (1.3389)	loss -23.3370 (-23.4285)	grad_norm 0.4354 (0.4274)	mem 44912MB
Train: [43/180][350/625]	eta 0:06:05 lr 0.689867	data 0.0009 (0.0629)	batch 1.2529 (1.3291)	loss -23.3119 (-23.4337)	grad_norm 0.4373 (0.4267)	mem 44912MB
Train: [43/180][400/625]	eta 0:04:57 lr 0.689482	data 0.0008 (0.0551)	batch 1.2820 (1.3214)	loss -23.5334 (-23.4422)	grad_norm 0.4143 (0.4264)	mem 44912MB
Train: [43/180][450/625]	eta 0:03:50 lr 0.689096	data 0.0007 (0.0491)	batch 1.2258 (1.3158)	loss -23.6671 (-23.4528)	grad_norm 0.4113 (0.4264)	mem 44912MB
Train: [43/180][500/625]	eta 0:02:43 lr 0.688710	data 0.0006 (0.0443)	batch 1.2949 (1.3108)	loss -23.3184 (-23.4586)	grad_norm 0.4151 (0.4264)	mem 44912MB
Train: [43/180][550/625]	eta 0:01:38 lr 0.688323	data 0.0006 (0.0403)	batch 1.2499 (1.3068)	loss -23.6617 (-23.4656)	grad_norm 0.4145 (0.4261)	mem 44912MB
Train: [43/180][600/625]	eta 0:00:32 lr 0.687935	data 0.0006 (0.0370)	batch 1.3013 (1.3028)	loss -23.4141 (-23.4717)	grad_norm 0.4180 (0.4259)	mem 44912MB
Current slope: None 	
EPOCH 43 training takes 0:13:34
Test: [0/25]	Time 14.677 (14.677)	Loss 1.5472 (1.5472)	Acc@1 65.723 (65.723)	Acc@5 85.791 (85.791)	Mem 44912MB
 * Acc@1 52.198 Acc@5 76.962
Accuracy of the network on the 50000 test images: 52.20%
Max accuracy (after decay): 52.20%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [44/180][0/625]	eta 4:02:59 lr 0.687742	data 21.9027 (21.9027)	batch 23.3270 (23.3270)	loss -23.6962 (-23.6962)	grad_norm 0.4291 (0.4291)	mem 44912MB
Train: [44/180][50/625]	eta 0:16:19 lr 0.687353	data 0.0008 (0.4304)	batch 1.4330 (1.7039)	loss -23.6182 (-23.6209)	grad_norm 0.4093 (0.4254)	mem 44912MB
Train: [44/180][100/625]	eta 0:13:01 lr 0.686965	data 0.0015 (0.2177)	batch 1.2906 (1.4890)	loss -23.8308 (-23.5999)	grad_norm 0.4045 (0.4264)	mem 44912MB
Train: [44/180][150/625]	eta 0:11:12 lr 0.686575	data 0.0006 (0.1459)	batch 1.2416 (1.4153)	loss -23.7388 (-23.6095)	grad_norm 0.4379 (0.4262)	mem 44912MB
Train: [44/180][200/625]	eta 0:09:45 lr 0.686185	data 0.0006 (0.1098)	batch 1.2928 (1.3784)	loss -23.6845 (-23.6078)	grad_norm 0.4264 (0.4263)	mem 44912MB
Train: [44/180][250/625]	eta 0:08:28 lr 0.685795	data 0.0012 (0.0881)	batch 1.3510 (1.3548)	loss -23.5626 (-23.6102)	grad_norm 0.4391 (0.4272)	mem 44912MB
Train: [44/180][300/625]	eta 0:07:15 lr 0.685404	data 0.0010 (0.0736)	batch 1.2895 (1.3413)	loss -23.5519 (-23.6155)	grad_norm 0.4170 (0.4269)	mem 44912MB
Train: [44/180][350/625]	eta 0:06:05 lr 0.685012	data 0.0008 (0.0632)	batch 1.2200 (1.3298)	loss -23.6141 (-23.6177)	grad_norm 0.4206 (0.4269)	mem 44912MB
Train: [44/180][400/625]	eta 0:04:57 lr 0.684620	data 0.0008 (0.0554)	batch 1.2640 (1.3216)	loss -23.5837 (-23.6269)	grad_norm 0.4267 (0.4267)	mem 44912MB
Train: [44/180][450/625]	eta 0:03:50 lr 0.684227	data 0.0008 (0.0494)	batch 1.2709 (1.3147)	loss -23.6009 (-23.6323)	grad_norm 0.4400 (0.4267)	mem 44912MB
Train: [44/180][500/625]	eta 0:02:43 lr 0.683834	data 0.0009 (0.0445)	batch 1.2937 (1.3098)	loss -23.6751 (-23.6385)	grad_norm 0.4240 (0.4267)	mem 44912MB
Train: [44/180][550/625]	eta 0:01:37 lr 0.683440	data 0.0005 (0.0406)	batch 1.2601 (1.3055)	loss -23.9589 (-23.6418)	grad_norm 0.4265 (0.4265)	mem 44912MB
Train: [44/180][600/625]	eta 0:00:32 lr 0.683046	data 0.0006 (0.0372)	batch 1.2535 (1.3019)	loss -23.6599 (-23.6491)	grad_norm 0.4254 (0.4265)	mem 44912MB
Current slope: None 	
EPOCH 44 training takes 0:13:34
Test: [0/25]	Time 14.391 (14.391)	Loss 1.5630 (1.5630)	Acc@1 66.504 (66.504)	Acc@5 86.523 (86.523)	Mem 44912MB
 * Acc@1 52.484 Acc@5 77.290
Accuracy of the network on the 50000 test images: 52.48%
Max accuracy (after decay): 52.48%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [45/180][0/625]	eta 3:56:25 lr 0.682849	data 19.1555 (19.1555)	batch 22.6964 (22.6964)	loss -23.6602 (-23.6602)	grad_norm 0.4292 (0.4292)	mem 44912MB
Train: [45/180][50/625]	eta 0:16:12 lr 0.682453	data 0.0014 (0.3764)	batch 1.2350 (1.6916)	loss -23.7759 (-23.7388)	grad_norm 0.4517 (0.4270)	mem 44912MB
Train: [45/180][100/625]	eta 0:12:58 lr 0.682058	data 0.0007 (0.1905)	batch 1.2302 (1.4832)	loss -23.7695 (-23.7392)	grad_norm 0.4162 (0.4271)	mem 44912MB
Train: [45/180][150/625]	eta 0:11:09 lr 0.681661	data 0.0006 (0.1277)	batch 1.2638 (1.4105)	loss -23.8437 (-23.7509)	grad_norm 0.4362 (0.4264)	mem 44912MB
Train: [45/180][200/625]	eta 0:09:44 lr 0.681265	data 0.0006 (0.0961)	batch 1.2570 (1.3765)	loss -23.8437 (-23.7602)	grad_norm 0.4272 (0.4263)	mem 44912MB
Train: [45/180][250/625]	eta 0:08:27 lr 0.680867	data 0.0006 (0.0771)	batch 1.2651 (1.3534)	loss -23.5767 (-23.7627)	grad_norm 0.4668 (0.4272)	mem 44912MB
Train: [45/180][300/625]	eta 0:07:15 lr 0.680469	data 0.0007 (0.0645)	batch 1.2288 (1.3387)	loss -23.8571 (-23.7700)	grad_norm 0.4279 (0.4269)	mem 44912MB
Train: [45/180][350/625]	eta 0:06:04 lr 0.680071	data 0.0013 (0.0554)	batch 1.2622 (1.3272)	loss -23.6798 (-23.7752)	grad_norm 0.4164 (0.4264)	mem 44912MB
Train: [45/180][400/625]	eta 0:04:56 lr 0.679672	data 0.0007 (0.0486)	batch 1.2512 (1.3194)	loss -23.9720 (-23.7811)	grad_norm 0.4214 (0.4266)	mem 44912MB
Train: [45/180][450/625]	eta 0:03:49 lr 0.679272	data 0.0010 (0.0433)	batch 1.2792 (1.3137)	loss -23.7704 (-23.7849)	grad_norm 0.4264 (0.4265)	mem 44912MB
Train: [45/180][500/625]	eta 0:02:43 lr 0.678872	data 0.0006 (0.0390)	batch 1.2494 (1.3086)	loss -23.8177 (-23.7904)	grad_norm 0.4292 (0.4267)	mem 44912MB
Train: [45/180][550/625]	eta 0:01:37 lr 0.678471	data 0.0007 (0.0355)	batch 1.2418 (1.3043)	loss -23.7868 (-23.7961)	grad_norm 0.4209 (0.4266)	mem 44912MB
Train: [45/180][600/625]	eta 0:00:32 lr 0.678070	data 0.0006 (0.0326)	batch 1.2295 (1.3010)	loss -23.8823 (-23.8029)	grad_norm 0.4453 (0.4264)	mem 44912MB
Current slope: None 	
EPOCH 45 training takes 0:13:33
Test: [0/25]	Time 14.892 (14.892)	Loss 1.5287 (1.5287)	Acc@1 64.941 (64.941)	Acc@5 86.035 (86.035)	Mem 44912MB
 * Acc@1 52.354 Acc@5 77.458
Accuracy of the network on the 50000 test images: 52.35%
Max accuracy (after decay): 52.48%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [46/180][0/625]	eta 4:05:46 lr 0.677869	data 22.1774 (22.1774)	batch 23.5951 (23.5951)	loss -23.8549 (-23.8549)	grad_norm 0.4183 (0.4183)	mem 44912MB
Train: [46/180][50/625]	eta 0:16:22 lr 0.677467	data 0.0008 (0.4355)	batch 1.3566 (1.7079)	loss -23.8605 (-23.8787)	grad_norm 0.4248 (0.4311)	mem 44912MB
Train: [46/180][100/625]	eta 0:13:03 lr 0.677065	data 0.0007 (0.2203)	batch 1.2896 (1.4918)	loss -23.9543 (-23.8923)	grad_norm 0.4418 (0.4299)	mem 44912MB
Train: [46/180][150/625]	eta 0:11:12 lr 0.676662	data 0.0012 (0.1476)	batch 1.2488 (1.4160)	loss -23.9237 (-23.8968)	grad_norm 0.4249 (0.4288)	mem 44912MB
Train: [46/180][200/625]	eta 0:09:45 lr 0.676258	data 0.0007 (0.1111)	batch 1.2484 (1.3777)	loss -23.7280 (-23.9026)	grad_norm 0.4319 (0.4290)	mem 44912MB
Train: [46/180][250/625]	eta 0:08:28 lr 0.675854	data 0.0008 (0.0891)	batch 1.2683 (1.3560)	loss -24.0977 (-23.9058)	grad_norm 0.4186 (0.4290)	mem 44912MB
Train: [46/180][300/625]	eta 0:07:15 lr 0.675449	data 0.0010 (0.0744)	batch 1.2301 (1.3412)	loss -23.9742 (-23.9147)	grad_norm 0.4209 (0.4283)	mem 44912MB
Train: [46/180][350/625]	eta 0:06:05 lr 0.675044	data 0.0006 (0.0639)	batch 1.2391 (1.3304)	loss -24.0993 (-23.9228)	grad_norm 0.4044 (0.4284)	mem 44912MB
Train: [46/180][400/625]	eta 0:04:57 lr 0.674638	data 0.0007 (0.0561)	batch 1.2773 (1.3221)	loss -24.0627 (-23.9276)	grad_norm 0.4347 (0.4282)	mem 44912MB
Train: [46/180][450/625]	eta 0:03:50 lr 0.674232	data 0.0006 (0.0499)	batch 1.2631 (1.3164)	loss -23.8124 (-23.9318)	grad_norm 0.4108 (0.4277)	mem 44912MB
Train: [46/180][500/625]	eta 0:02:43 lr 0.673825	data 0.0006 (0.0450)	batch 1.2529 (1.3113)	loss -23.9975 (-23.9364)	grad_norm 0.4363 (0.4279)	mem 44912MB
Train: [46/180][550/625]	eta 0:01:38 lr 0.673418	data 0.0011 (0.0410)	batch 1.2836 (1.3071)	loss -24.1754 (-23.9396)	grad_norm 0.4170 (0.4275)	mem 44912MB
Train: [46/180][600/625]	eta 0:00:32 lr 0.673010	data 0.0011 (0.0377)	batch 1.2580 (1.3028)	loss -23.9725 (-23.9436)	grad_norm 0.4162 (0.4281)	mem 44912MB
Current slope: None 	
EPOCH 46 training takes 0:13:34
Test: [0/25]	Time 14.606 (14.606)	Loss 1.4914 (1.4914)	Acc@1 65.771 (65.771)	Acc@5 87.354 (87.354)	Mem 44912MB
 * Acc@1 52.800 Acc@5 77.846
Accuracy of the network on the 50000 test images: 52.80%
Max accuracy (after decay): 52.80%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [47/180][0/625]	eta 3:53:14 lr 0.672806	data 20.2757 (20.2757)	batch 22.3908 (22.3908)	loss -24.1269 (-24.1269)	grad_norm 0.4159 (0.4159)	mem 44912MB
Train: [47/180][50/625]	eta 0:16:07 lr 0.672397	data 0.0009 (0.3983)	batch 1.2097 (1.6828)	loss -23.9203 (-24.0545)	grad_norm 0.4222 (0.4238)	mem 44912MB
Train: [47/180][100/625]	eta 0:12:57 lr 0.671988	data 0.0008 (0.2016)	batch 1.2509 (1.4804)	loss -24.0826 (-24.0618)	grad_norm 0.4448 (0.4265)	mem 44912MB
Train: [47/180][150/625]	eta 0:11:09 lr 0.671578	data 0.0007 (0.1351)	batch 1.2488 (1.4102)	loss -24.1579 (-24.0658)	grad_norm 0.4265 (0.4271)	mem 44912MB
Train: [47/180][200/625]	eta 0:09:43 lr 0.671168	data 0.0010 (0.1017)	batch 1.2572 (1.3736)	loss -24.1274 (-24.0685)	grad_norm 0.4223 (0.4268)	mem 44912MB
Train: [47/180][250/625]	eta 0:08:27 lr 0.670757	data 0.0008 (0.0816)	batch 1.2944 (1.3533)	loss -24.1484 (-24.0717)	grad_norm 0.4275 (0.4267)	mem 44912MB
Train: [47/180][300/625]	eta 0:07:15 lr 0.670345	data 0.0007 (0.0682)	batch 1.2575 (1.3393)	loss -24.0973 (-24.0704)	grad_norm 0.4337 (0.4270)	mem 44912MB
Train: [47/180][350/625]	eta 0:06:05 lr 0.669934	data 0.0007 (0.0586)	batch 1.2358 (1.3288)	loss -24.1815 (-24.0736)	grad_norm 0.4284 (0.4269)	mem 44912MB
Train: [47/180][400/625]	eta 0:04:57 lr 0.669521	data 0.0007 (0.0514)	batch 1.3617 (1.3211)	loss -24.0722 (-24.0761)	grad_norm 0.4274 (0.4274)	mem 44912MB
Train: [47/180][450/625]	eta 0:03:50 lr 0.669108	data 0.0005 (0.0458)	batch 1.2725 (1.3151)	loss -24.0437 (-24.0822)	grad_norm 0.4187 (0.4278)	mem 44912MB
Train: [47/180][500/625]	eta 0:02:43 lr 0.668695	data 0.0006 (0.0413)	batch 1.3013 (1.3102)	loss -23.9890 (-24.0858)	grad_norm 0.4330 (0.4278)	mem 44912MB
Train: [47/180][550/625]	eta 0:01:37 lr 0.668281	data 0.0007 (0.0376)	batch 1.2868 (1.3060)	loss -24.3263 (-24.0916)	grad_norm 0.4305 (0.4281)	mem 44912MB
Train: [47/180][600/625]	eta 0:00:32 lr 0.667866	data 0.0007 (0.0345)	batch 1.3092 (1.3023)	loss -24.1667 (-24.0989)	grad_norm 0.4338 (0.4279)	mem 44912MB
Current slope: None 	
EPOCH 47 training takes 0:13:34
Test: [0/25]	Time 14.948 (14.948)	Loss 1.5717 (1.5717)	Acc@1 64.502 (64.502)	Acc@5 85.889 (85.889)	Mem 44912MB
 * Acc@1 52.648 Acc@5 77.782
Accuracy of the network on the 50000 test images: 52.65%
Max accuracy (after decay): 52.80%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [48/180][0/625]	eta 3:56:20 lr 0.667659	data 20.6479 (20.6479)	batch 22.6884 (22.6884)	loss -24.0805 (-24.0805)	grad_norm 0.4219 (0.4219)	mem 44912MB
Train: [48/180][50/625]	eta 0:16:08 lr 0.667244	data 0.0007 (0.4058)	batch 1.2504 (1.6851)	loss -24.2479 (-24.1870)	grad_norm 0.4656 (0.4278)	mem 44912MB
Train: [48/180][100/625]	eta 0:12:55 lr 0.666828	data 0.0006 (0.2054)	batch 1.2727 (1.4768)	loss -24.1961 (-24.1897)	grad_norm 0.4368 (0.4297)	mem 44912MB
Train: [48/180][150/625]	eta 0:11:08 lr 0.666411	data 0.0006 (0.1376)	batch 1.2686 (1.4067)	loss -24.3370 (-24.2039)	grad_norm 0.4205 (0.4308)	mem 44912MB
Train: [48/180][200/625]	eta 0:09:43 lr 0.665995	data 0.0007 (0.1036)	batch 1.2398 (1.3731)	loss -24.3549 (-24.2098)	grad_norm 0.4303 (0.4301)	mem 44912MB
Train: [48/180][250/625]	eta 0:08:26 lr 0.665577	data 0.0007 (0.0831)	batch 1.2699 (1.3514)	loss -24.1992 (-24.2182)	grad_norm 0.4189 (0.4297)	mem 44912MB
Train: [48/180][300/625]	eta 0:07:14 lr 0.665159	data 0.0006 (0.0695)	batch 1.2573 (1.3366)	loss -24.1656 (-24.2229)	grad_norm 0.4239 (0.4300)	mem 44912MB
Train: [48/180][350/625]	eta 0:06:04 lr 0.664741	data 0.0015 (0.0597)	batch 1.2797 (1.3260)	loss -24.1629 (-24.2245)	grad_norm 0.4360 (0.4298)	mem 44912MB
Train: [48/180][400/625]	eta 0:04:56 lr 0.664322	data 0.0010 (0.0523)	batch 1.2596 (1.3189)	loss -24.2391 (-24.2243)	grad_norm 0.4287 (0.4295)	mem 44912MB
Train: [48/180][450/625]	eta 0:03:49 lr 0.663903	data 0.0009 (0.0466)	batch 1.2532 (1.3130)	loss -24.3450 (-24.2289)	grad_norm 0.4336 (0.4293)	mem 44912MB
Train: [48/180][500/625]	eta 0:02:43 lr 0.663483	data 0.0009 (0.0420)	batch 1.2417 (1.3080)	loss -24.2731 (-24.2348)	grad_norm 0.4282 (0.4289)	mem 44912MB
Train: [48/180][550/625]	eta 0:01:37 lr 0.663062	data 0.0006 (0.0384)	batch 1.2555 (1.3042)	loss -24.1679 (-24.2366)	grad_norm 0.4395 (0.4292)	mem 44912MB
Train: [48/180][600/625]	eta 0:00:32 lr 0.662641	data 0.0004 (0.0352)	batch 1.3370 (1.3017)	loss -24.2640 (-24.2417)	grad_norm 0.4197 (0.4292)	mem 44912MB
Current slope: None 	
EPOCH 48 training takes 0:13:33
Test: [0/25]	Time 14.552 (14.552)	Loss 1.4881 (1.4881)	Acc@1 65.918 (65.918)	Acc@5 88.037 (88.037)	Mem 44912MB
 * Acc@1 52.876 Acc@5 77.790
Accuracy of the network on the 50000 test images: 52.88%
Max accuracy (after decay): 52.88%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [49/180][0/625]	eta 4:01:34 lr 0.662430	data 20.5726 (20.5726)	batch 23.1909 (23.1909)	loss -24.5816 (-24.5816)	grad_norm 0.4116 (0.4116)	mem 44912MB
Train: [49/180][50/625]	eta 0:16:16 lr 0.662009	data 0.0008 (0.4051)	batch 1.2473 (1.6984)	loss -24.4693 (-24.3301)	grad_norm 0.4257 (0.4317)	mem 44912MB
Train: [49/180][100/625]	eta 0:12:59 lr 0.661586	data 0.0007 (0.2050)	batch 1.2691 (1.4848)	loss -24.3959 (-24.3431)	grad_norm 0.4447 (0.4301)	mem 44912MB
Train: [49/180][150/625]	eta 0:11:11 lr 0.661164	data 0.0008 (0.1374)	batch 1.2977 (1.4134)	loss -24.5672 (-24.3301)	grad_norm 0.4234 (0.4320)	mem 44912MB
Train: [49/180][200/625]	eta 0:09:45 lr 0.660740	data 0.0006 (0.1034)	batch 1.6115 (1.3778)	loss -24.5487 (-24.3365)	grad_norm 0.4198 (0.4309)	mem 44912MB
Train: [49/180][250/625]	eta 0:08:28 lr 0.660317	data 0.0007 (0.0830)	batch 1.2689 (1.3558)	loss -24.3799 (-24.3385)	grad_norm 0.4161 (0.4305)	mem 44912MB
Train: [49/180][300/625]	eta 0:07:15 lr 0.659892	data 0.0009 (0.0693)	batch 1.2444 (1.3403)	loss -24.3860 (-24.3401)	grad_norm 0.4278 (0.4304)	mem 44912MB
Train: [49/180][350/625]	eta 0:06:05 lr 0.659468	data 0.0005 (0.0595)	batch 1.2967 (1.3300)	loss -24.4868 (-24.3485)	grad_norm 0.4306 (0.4301)	mem 44912MB
Train: [49/180][400/625]	eta 0:04:57 lr 0.659042	data 0.0007 (0.0522)	batch 1.2738 (1.3219)	loss -24.4361 (-24.3523)	grad_norm 0.4209 (0.4301)	mem 44912MB
Train: [49/180][450/625]	eta 0:03:50 lr 0.658616	data 0.0007 (0.0465)	batch 1.4222 (1.3160)	loss -24.3504 (-24.3563)	grad_norm 0.4366 (0.4298)	mem 44912MB
Train: [49/180][500/625]	eta 0:02:43 lr 0.658190	data 0.0008 (0.0420)	batch 1.2180 (1.3111)	loss -24.3443 (-24.3577)	grad_norm 0.4216 (0.4297)	mem 44912MB
Train: [49/180][550/625]	eta 0:01:38 lr 0.657763	data 0.0007 (0.0382)	batch 1.2749 (1.3078)	loss -24.4385 (-24.3642)	grad_norm 0.4304 (0.4298)	mem 44912MB
Train: [49/180][600/625]	eta 0:00:32 lr 0.657336	data 0.0007 (0.0351)	batch 1.2737 (1.3046)	loss -24.5248 (-24.3694)	grad_norm 0.4274 (0.4296)	mem 44912MB
Current slope: None 	
EPOCH 49 training takes 0:13:35
Test: [0/25]	Time 14.523 (14.523)	Loss 1.5634 (1.5634)	Acc@1 64.990 (64.990)	Acc@5 86.377 (86.377)	Mem 44912MB
 * Acc@1 53.188 Acc@5 77.916
Accuracy of the network on the 50000 test images: 53.19%
Max accuracy (after decay): 53.19%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [50/180][0/625]	eta 3:58:55 lr 0.657122	data 21.5779 (21.5779)	batch 22.9364 (22.9364)	loss -24.6466 (-24.6466)	grad_norm 0.4203 (0.4203)	mem 44912MB
Train: [50/180][50/625]	eta 0:16:11 lr 0.656694	data 0.0011 (0.4240)	batch 1.2625 (1.6899)	loss -24.6269 (-24.4802)	grad_norm 0.4160 (0.4303)	mem 44912MB
Train: [50/180][100/625]	eta 0:12:57 lr 0.656266	data 0.0011 (0.2145)	batch 1.2586 (1.4807)	loss -24.6269 (-24.4624)	grad_norm 0.4303 (0.4316)	mem 44912MB
Train: [50/180][150/625]	eta 0:11:10 lr 0.655836	data 0.0006 (0.1438)	batch 1.2564 (1.4113)	loss -24.4485 (-24.4626)	grad_norm 0.4246 (0.4315)	mem 44912MB
Train: [50/180][200/625]	eta 0:09:43 lr 0.655407	data 0.0009 (0.1082)	batch 1.2576 (1.3740)	loss -24.6697 (-24.4688)	grad_norm 0.4305 (0.4313)	mem 44912MB
Train: [50/180][250/625]	eta 0:08:27 lr 0.654977	data 0.0005 (0.0868)	batch 1.2729 (1.3521)	loss -24.3117 (-24.4756)	grad_norm 0.4256 (0.4312)	mem 44912MB
Train: [50/180][300/625]	eta 0:07:14 lr 0.654546	data 0.0010 (0.0725)	batch 1.2203 (1.3369)	loss -24.5347 (-24.4812)	grad_norm 0.4524 (0.4310)	mem 44912MB
Train: [50/180][350/625]	eta 0:06:04 lr 0.654115	data 0.0005 (0.0623)	batch 1.3132 (1.3269)	loss -24.5410 (-24.4838)	grad_norm 0.4204 (0.4315)	mem 44912MB
Train: [50/180][400/625]	eta 0:04:56 lr 0.653684	data 0.0011 (0.0546)	batch 1.2620 (1.3188)	loss -24.6626 (-24.4853)	grad_norm 0.4283 (0.4312)	mem 44912MB
Train: [50/180][450/625]	eta 0:03:49 lr 0.653252	data 0.0005 (0.0486)	batch 1.2930 (1.3126)	loss -24.7333 (-24.4889)	grad_norm 0.4287 (0.4314)	mem 44912MB
Train: [50/180][500/625]	eta 0:02:43 lr 0.652819	data 0.0009 (0.0439)	batch 1.3954 (1.3083)	loss -24.3443 (-24.4934)	grad_norm 0.4311 (0.4312)	mem 44912MB
Train: [50/180][550/625]	eta 0:01:37 lr 0.652386	data 0.0006 (0.0399)	batch 1.2415 (1.3042)	loss -24.4176 (-24.4995)	grad_norm 0.4271 (0.4310)	mem 44912MB
Train: [50/180][600/625]	eta 0:00:32 lr 0.651953	data 0.0005 (0.0367)	batch 1.2392 (1.3010)	loss -24.5457 (-24.5001)	grad_norm 0.4567 (0.4312)	mem 44912MB
Current slope: None 	
EPOCH 50 training takes 0:13:33
Test: [0/25]	Time 14.606 (14.606)	Loss 1.5499 (1.5499)	Acc@1 64.209 (64.209)	Acc@5 86.621 (86.621)	Mem 44912MB
 * Acc@1 53.010 Acc@5 77.772
Accuracy of the network on the 50000 test images: 53.01%
Max accuracy (after decay): 53.19%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [51/180][0/625]	eta 4:01:04 lr 0.651736	data 20.7160 (20.7160)	batch 23.1435 (23.1435)	loss -24.6777 (-24.6777)	grad_norm 0.4438 (0.4438)	mem 44912MB
Train: [51/180][50/625]	eta 0:16:17 lr 0.651301	data 0.0011 (0.4071)	batch 1.2315 (1.6992)	loss -24.8290 (-24.5974)	grad_norm 0.4250 (0.4282)	mem 44912MB
Train: [51/180][100/625]	eta 0:12:58 lr 0.650867	data 0.0008 (0.2060)	batch 1.2494 (1.4829)	loss -24.6655 (-24.5742)	grad_norm 0.4319 (0.4309)	mem 44912MB
Train: [51/180][150/625]	eta 0:11:10 lr 0.650431	data 0.0008 (0.1381)	batch 1.2190 (1.4121)	loss -24.6137 (-24.5769)	grad_norm 0.4229 (0.4332)	mem 44912MB
Train: [51/180][200/625]	eta 0:09:44 lr 0.649996	data 0.0006 (0.1040)	batch 1.2545 (1.3757)	loss -24.5332 (-24.5789)	grad_norm 0.4344 (0.4325)	mem 44912MB
Train: [51/180][250/625]	eta 0:08:27 lr 0.649559	data 0.0005 (0.0834)	batch 1.2631 (1.3541)	loss -24.6513 (-24.5784)	grad_norm 0.4209 (0.4324)	mem 44912MB
Train: [51/180][300/625]	eta 0:07:15 lr 0.649123	data 0.0008 (0.0697)	batch 1.2807 (1.3387)	loss -24.4570 (-24.5811)	grad_norm 0.4289 (0.4319)	mem 44912MB
Train: [51/180][350/625]	eta 0:06:05 lr 0.648685	data 0.0004 (0.0599)	batch 1.2484 (1.3280)	loss -24.3264 (-24.5850)	grad_norm 0.4375 (0.4317)	mem 44912MB
Train: [51/180][400/625]	eta 0:04:57 lr 0.648248	data 0.0010 (0.0525)	batch 1.2775 (1.3201)	loss -24.7396 (-24.5933)	grad_norm 0.4366 (0.4315)	mem 44912MB
Train: [51/180][450/625]	eta 0:03:49 lr 0.647810	data 0.0011 (0.0468)	batch 1.2660 (1.3139)	loss -24.7164 (-24.5994)	grad_norm 0.4323 (0.4314)	mem 44912MB
Train: [51/180][500/625]	eta 0:02:43 lr 0.647371	data 0.0005 (0.0422)	batch 1.2485 (1.3088)	loss -24.7807 (-24.6066)	grad_norm 0.4261 (0.4310)	mem 44912MB
Train: [51/180][550/625]	eta 0:01:37 lr 0.646932	data 0.0008 (0.0384)	batch 1.2424 (1.3051)	loss -24.7651 (-24.6137)	grad_norm 0.4219 (0.4315)	mem 44912MB
Train: [51/180][600/625]	eta 0:00:32 lr 0.646492	data 0.0006 (0.0353)	batch 1.2450 (1.3016)	loss -24.6514 (-24.6187)	grad_norm 0.4328 (0.4313)	mem 44912MB
Current slope: None 	
EPOCH 51 training takes 0:13:34
Test: [0/25]	Time 14.632 (14.632)	Loss 1.5589 (1.5589)	Acc@1 64.160 (64.160)	Acc@5 85.938 (85.938)	Mem 44912MB
 * Acc@1 53.416 Acc@5 78.394
Accuracy of the network on the 50000 test images: 53.42%
Max accuracy (after decay): 53.42%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [52/180][0/625]	eta 4:02:32 lr 0.646272	data 20.6426 (20.6426)	batch 23.2840 (23.2840)	loss -24.7444 (-24.7444)	grad_norm 0.4207 (0.4207)	mem 44912MB
Train: [52/180][50/625]	eta 0:16:20 lr 0.645832	data 0.0006 (0.4055)	batch 1.2696 (1.7055)	loss -24.9102 (-24.7110)	grad_norm 0.4320 (0.4334)	mem 44912MB
Train: [52/180][100/625]	eta 0:13:00 lr 0.645391	data 0.0019 (0.2052)	batch 1.2298 (1.4858)	loss -24.8806 (-24.6946)	grad_norm 0.4267 (0.4336)	mem 44912MB
Train: [52/180][150/625]	eta 0:11:10 lr 0.644950	data 0.0007 (0.1375)	batch 1.2242 (1.4113)	loss -24.7410 (-24.7005)	grad_norm 0.4266 (0.4328)	mem 44912MB
Train: [52/180][200/625]	eta 0:09:44 lr 0.644508	data 0.0006 (0.1035)	batch 1.2433 (1.3756)	loss -24.8014 (-24.7073)	grad_norm 0.4210 (0.4327)	mem 44912MB
Train: [52/180][250/625]	eta 0:08:28 lr 0.644066	data 0.0006 (0.0831)	batch 1.2635 (1.3549)	loss -24.7414 (-24.7057)	grad_norm 0.4230 (0.4325)	mem 44912MB
Train: [52/180][300/625]	eta 0:07:15 lr 0.643623	data 0.0007 (0.0696)	batch 1.2660 (1.3400)	loss -24.8329 (-24.7018)	grad_norm 0.4227 (0.4330)	mem 44912MB
Train: [52/180][350/625]	eta 0:06:05 lr 0.643180	data 0.0007 (0.0599)	batch 1.3074 (1.3296)	loss -24.9317 (-24.7057)	grad_norm 0.4096 (0.4324)	mem 44912MB
Train: [52/180][400/625]	eta 0:04:57 lr 0.642736	data 0.0006 (0.0525)	batch 1.2428 (1.3216)	loss -24.6612 (-24.7122)	grad_norm 0.4373 (0.4329)	mem 44912MB
Train: [52/180][450/625]	eta 0:03:50 lr 0.642292	data 0.0006 (0.0468)	batch 1.2684 (1.3158)	loss -24.9476 (-24.7193)	grad_norm 0.4284 (0.4326)	mem 44912MB
Train: [52/180][500/625]	eta 0:02:43 lr 0.641848	data 0.0005 (0.0422)	batch 1.2449 (1.3109)	loss -24.7509 (-24.7244)	grad_norm 0.4365 (0.4326)	mem 44912MB
Train: [52/180][550/625]	eta 0:01:37 lr 0.641402	data 0.0005 (0.0384)	batch 1.2696 (1.3066)	loss -24.9690 (-24.7280)	grad_norm 0.4217 (0.4328)	mem 44912MB
Train: [52/180][600/625]	eta 0:00:32 lr 0.640957	data 0.0006 (0.0353)	batch 1.2972 (1.3033)	loss -24.7989 (-24.7325)	grad_norm 0.4300 (0.4326)	mem 44912MB
Current slope: None 	
EPOCH 52 training takes 0:13:35
Test: [0/25]	Time 14.669 (14.669)	Loss 1.5206 (1.5206)	Acc@1 66.309 (66.309)	Acc@5 86.816 (86.816)	Mem 44912MB
 * Acc@1 53.848 Acc@5 78.480
Accuracy of the network on the 50000 test images: 53.85%
Max accuracy (after decay): 53.85%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [53/180][0/625]	eta 3:59:36 lr 0.640734	data 21.0201 (21.0201)	batch 23.0031 (23.0031)	loss -24.6847 (-24.6847)	grad_norm 0.4314 (0.4314)	mem 44912MB
Train: [53/180][50/625]	eta 0:16:13 lr 0.640288	data 0.0008 (0.4132)	batch 1.3177 (1.6932)	loss -24.8716 (-24.7994)	grad_norm 0.4341 (0.4384)	mem 44912MB
Train: [53/180][100/625]	eta 0:12:58 lr 0.639841	data 0.0012 (0.2091)	batch 1.2923 (1.4831)	loss -25.1409 (-24.7989)	grad_norm 0.4262 (0.4350)	mem 44912MB
Train: [53/180][150/625]	eta 0:11:10 lr 0.639394	data 0.0007 (0.1401)	batch 1.2420 (1.4125)	loss -24.9583 (-24.8010)	grad_norm 0.4170 (0.4352)	mem 44912MB
Train: [53/180][200/625]	eta 0:09:44 lr 0.638946	data 0.0006 (0.1055)	batch 1.2338 (1.3761)	loss -25.0335 (-24.8043)	grad_norm 0.4302 (0.4345)	mem 44912MB
Train: [53/180][250/625]	eta 0:08:27 lr 0.638498	data 0.0007 (0.0846)	batch 1.2595 (1.3538)	loss -24.8495 (-24.8119)	grad_norm 0.4360 (0.4348)	mem 44912MB
Train: [53/180][300/625]	eta 0:07:15 lr 0.638049	data 0.0007 (0.0707)	batch 1.2254 (1.3391)	loss -25.0632 (-24.8157)	grad_norm 0.4215 (0.4350)	mem 44912MB
Train: [53/180][350/625]	eta 0:06:05 lr 0.637600	data 0.0006 (0.0607)	batch 1.2187 (1.3284)	loss -24.9805 (-24.8209)	grad_norm 0.4449 (0.4345)	mem 44912MB
Train: [53/180][400/625]	eta 0:04:57 lr 0.637151	data 0.0006 (0.0532)	batch 1.2768 (1.3211)	loss -24.9052 (-24.8205)	grad_norm 0.4219 (0.4343)	mem 44912MB
Train: [53/180][450/625]	eta 0:03:50 lr 0.636701	data 0.0005 (0.0474)	batch 1.2816 (1.3146)	loss -24.9432 (-24.8284)	grad_norm 0.4346 (0.4342)	mem 44912MB
Train: [53/180][500/625]	eta 0:02:43 lr 0.636250	data 0.0005 (0.0427)	batch 1.2602 (1.3101)	loss -24.9421 (-24.8359)	grad_norm 0.4335 (0.4338)	mem 44912MB
Train: [53/180][550/625]	eta 0:01:38 lr 0.635800	data 0.0006 (0.0389)	batch 1.4959 (1.3067)	loss -24.9561 (-24.8390)	grad_norm 0.4263 (0.4338)	mem 44912MB
Train: [53/180][600/625]	eta 0:00:32 lr 0.635348	data 0.0005 (0.0358)	batch 1.2542 (1.3036)	loss -24.5749 (-24.8417)	grad_norm 0.4318 (0.4339)	mem 44912MB
Current slope: None 	
EPOCH 53 training takes 0:13:34
Test: [0/25]	Time 14.593 (14.593)	Loss 1.5642 (1.5642)	Acc@1 65.137 (65.137)	Acc@5 86.426 (86.426)	Mem 44912MB
 * Acc@1 53.844 Acc@5 78.524
Accuracy of the network on the 50000 test images: 53.84%
Max accuracy (after decay): 53.85%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [54/180][0/625]	eta 3:57:57 lr 0.635122	data 21.4490 (21.4490)	batch 22.8437 (22.8437)	loss -24.6695 (-24.6695)	grad_norm 0.4271 (0.4271)	mem 44912MB
Train: [54/180][50/625]	eta 0:16:12 lr 0.634670	data 0.0007 (0.4213)	batch 1.2646 (1.6918)	loss -24.9066 (-24.9254)	grad_norm 0.4430 (0.4350)	mem 44912MB
Train: [54/180][100/625]	eta 0:12:57 lr 0.634218	data 0.0017 (0.2132)	batch 1.2488 (1.4811)	loss -25.1877 (-24.9334)	grad_norm 0.4237 (0.4344)	mem 44912MB
Train: [54/180][150/625]	eta 0:11:10 lr 0.633765	data 0.0007 (0.1429)	batch 1.2641 (1.4122)	loss -24.9892 (-24.9356)	grad_norm 0.4526 (0.4348)	mem 44912MB
Train: [54/180][200/625]	eta 0:09:44 lr 0.633311	data 0.0007 (0.1075)	batch 1.2331 (1.3763)	loss -24.9930 (-24.9289)	grad_norm 0.4352 (0.4351)	mem 44912MB
Train: [54/180][250/625]	eta 0:08:27 lr 0.632858	data 0.0009 (0.0863)	batch 1.2963 (1.3545)	loss -25.0324 (-24.9294)	grad_norm 0.4279 (0.4348)	mem 44912MB
Train: [54/180][300/625]	eta 0:07:15 lr 0.632403	data 0.0006 (0.0721)	batch 1.2494 (1.3387)	loss -25.0481 (-24.9337)	grad_norm 0.4304 (0.4347)	mem 44912MB
Train: [54/180][350/625]	eta 0:06:05 lr 0.631948	data 0.0009 (0.0619)	batch 1.2624 (1.3292)	loss -24.8224 (-24.9346)	grad_norm 0.4255 (0.4347)	mem 44912MB
Train: [54/180][400/625]	eta 0:04:57 lr 0.631493	data 0.0007 (0.0543)	batch 1.2689 (1.3209)	loss -24.7735 (-24.9365)	grad_norm 0.4331 (0.4348)	mem 44912MB
Train: [54/180][450/625]	eta 0:03:50 lr 0.631038	data 0.0010 (0.0484)	batch 1.2626 (1.3153)	loss -24.9174 (-24.9405)	grad_norm 0.4326 (0.4348)	mem 44912MB
Train: [54/180][500/625]	eta 0:02:43 lr 0.630581	data 0.0007 (0.0437)	batch 1.2357 (1.3104)	loss -25.0338 (-24.9437)	grad_norm 0.4283 (0.4348)	mem 44912MB
Train: [54/180][550/625]	eta 0:01:37 lr 0.630125	data 0.0007 (0.0398)	batch 1.2381 (1.3067)	loss -24.9773 (-24.9478)	grad_norm 0.4381 (0.4349)	mem 44912MB
Train: [54/180][600/625]	eta 0:00:32 lr 0.629668	data 0.0007 (0.0365)	batch 1.2340 (1.3037)	loss -25.1154 (-24.9506)	grad_norm 0.4274 (0.4346)	mem 44912MB
Current slope: None 	
EPOCH 54 training takes 0:13:35
Test: [0/25]	Time 14.533 (14.533)	Loss 1.5904 (1.5904)	Acc@1 64.062 (64.062)	Acc@5 84.961 (84.961)	Mem 44912MB
 * Acc@1 53.348 Acc@5 78.132
Accuracy of the network on the 50000 test images: 53.35%
Max accuracy (after decay): 53.85%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [55/180][0/625]	eta 4:01:13 lr 0.629439	data 20.7639 (20.7639)	batch 23.1570 (23.1570)	loss -24.7740 (-24.7740)	grad_norm 0.4327 (0.4327)	mem 44912MB
Train: [55/180][50/625]	eta 0:16:13 lr 0.628981	data 0.0011 (0.4079)	batch 1.1969 (1.6923)	loss -25.1227 (-25.0069)	grad_norm 0.4452 (0.4377)	mem 44912MB
Train: [55/180][100/625]	eta 0:12:58 lr 0.628523	data 0.0016 (0.2064)	batch 1.2910 (1.4825)	loss -25.0774 (-25.0086)	grad_norm 0.4292 (0.4365)	mem 44912MB
Train: [55/180][150/625]	eta 0:11:09 lr 0.628065	data 0.0006 (0.1383)	batch 1.2479 (1.4097)	loss -25.0567 (-25.0110)	grad_norm 0.4614 (0.4360)	mem 44912MB
Train: [55/180][200/625]	eta 0:09:44 lr 0.627606	data 0.0013 (0.1041)	batch 1.2674 (1.3745)	loss -25.0166 (-25.0204)	grad_norm 0.4329 (0.4365)	mem 44912MB
Train: [55/180][250/625]	eta 0:08:27 lr 0.627146	data 0.0009 (0.0835)	batch 1.3118 (1.3527)	loss -25.0122 (-25.0248)	grad_norm 0.4338 (0.4361)	mem 44912MB
Train: [55/180][300/625]	eta 0:07:15 lr 0.626686	data 0.0007 (0.0698)	batch 1.1771 (1.3392)	loss -24.8454 (-25.0270)	grad_norm 0.4473 (0.4357)	mem 44912MB
Train: [55/180][350/625]	eta 0:06:05 lr 0.626226	data 0.0007 (0.0599)	batch 1.2605 (1.3290)	loss -25.2587 (-25.0345)	grad_norm 0.4119 (0.4356)	mem 44912MB
Train: [55/180][400/625]	eta 0:04:57 lr 0.625765	data 0.0009 (0.0526)	batch 1.3040 (1.3210)	loss -25.2201 (-25.0375)	grad_norm 0.4318 (0.4357)	mem 44912MB
Train: [55/180][450/625]	eta 0:03:50 lr 0.625304	data 0.0006 (0.0468)	batch 1.2400 (1.3144)	loss -24.9938 (-25.0416)	grad_norm 0.4348 (0.4356)	mem 44912MB
Train: [55/180][500/625]	eta 0:02:43 lr 0.624842	data 0.0005 (0.0422)	batch 1.3302 (1.3100)	loss -25.0970 (-25.0431)	grad_norm 0.4242 (0.4354)	mem 44912MB
Train: [55/180][550/625]	eta 0:01:37 lr 0.624380	data 0.0007 (0.0385)	batch 1.2364 (1.3059)	loss -24.9626 (-25.0480)	grad_norm 0.4219 (0.4355)	mem 44912MB
Train: [55/180][600/625]	eta 0:00:32 lr 0.623917	data 0.0011 (0.0353)	batch 1.2810 (1.3025)	loss -25.0612 (-25.0510)	grad_norm 0.4429 (0.4352)	mem 44912MB
Current slope: None 	
EPOCH 55 training takes 0:13:34
Test: [0/25]	Time 14.309 (14.309)	Loss 1.5812 (1.5812)	Acc@1 64.893 (64.893)	Acc@5 85.254 (85.254)	Mem 44912MB
 * Acc@1 53.668 Acc@5 78.196
Accuracy of the network on the 50000 test images: 53.67%
Max accuracy (after decay): 53.85%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [56/180][0/625]	eta 3:58:30 lr 0.623686	data 21.6634 (21.6634)	batch 22.8974 (22.8974)	loss -25.1107 (-25.1107)	grad_norm 0.4247 (0.4247)	mem 44912MB
Train: [56/180][50/625]	eta 0:16:10 lr 0.623223	data 0.0007 (0.4256)	batch 1.2337 (1.6874)	loss -25.0846 (-25.1059)	grad_norm 0.4245 (0.4351)	mem 44912MB
Train: [56/180][100/625]	eta 0:12:57 lr 0.622759	data 0.0009 (0.2154)	batch 1.2708 (1.4815)	loss -25.1463 (-25.0994)	grad_norm 0.4435 (0.4360)	mem 44912MB
Train: [56/180][150/625]	eta 0:11:10 lr 0.622295	data 0.0009 (0.1443)	batch 1.2859 (1.4110)	loss -25.0275 (-25.1082)	grad_norm 0.4382 (0.4353)	mem 44912MB
Train: [56/180][200/625]	eta 0:09:45 lr 0.621831	data 0.0008 (0.1086)	batch 1.2473 (1.3766)	loss -25.2047 (-25.1146)	grad_norm 0.4241 (0.4357)	mem 44912MB
Train: [56/180][250/625]	eta 0:08:27 lr 0.621366	data 0.0006 (0.0872)	batch 1.2274 (1.3534)	loss -25.0739 (-25.1208)	grad_norm 0.4428 (0.4358)	mem 44912MB
Train: [56/180][300/625]	eta 0:07:15 lr 0.620900	data 0.0008 (0.0728)	batch 1.2497 (1.3399)	loss -24.9004 (-25.1294)	grad_norm 0.4421 (0.4362)	mem 44912MB
Train: [56/180][350/625]	eta 0:06:05 lr 0.620434	data 0.0005 (0.0626)	batch 1.2463 (1.3294)	loss -25.1649 (-25.1363)	grad_norm 0.4263 (0.4361)	mem 44912MB
Train: [56/180][400/625]	eta 0:04:57 lr 0.619968	data 0.0007 (0.0549)	batch 1.3148 (1.3213)	loss -24.9918 (-25.1382)	grad_norm 0.4432 (0.4364)	mem 44912MB
Train: [56/180][450/625]	eta 0:03:50 lr 0.619501	data 0.0007 (0.0489)	batch 1.2424 (1.3149)	loss -25.2063 (-25.1447)	grad_norm 0.4334 (0.4361)	mem 44912MB
Train: [56/180][500/625]	eta 0:02:43 lr 0.619034	data 0.0005 (0.0441)	batch 1.2642 (1.3108)	loss -25.2630 (-25.1449)	grad_norm 0.4334 (0.4361)	mem 44912MB
Train: [56/180][550/625]	eta 0:01:37 lr 0.618567	data 0.0005 (0.0401)	batch 1.2797 (1.3065)	loss -25.1359 (-25.1448)	grad_norm 0.4508 (0.4361)	mem 44912MB
Train: [56/180][600/625]	eta 0:00:32 lr 0.618099	data 0.0009 (0.0369)	batch 1.2196 (1.3028)	loss -25.1233 (-25.1452)	grad_norm 0.4415 (0.4362)	mem 44912MB
Current slope: None 	
EPOCH 56 training takes 0:13:34
Test: [0/25]	Time 14.722 (14.722)	Loss 1.4739 (1.4739)	Acc@1 67.480 (67.480)	Acc@5 87.744 (87.744)	Mem 44912MB
 * Acc@1 54.052 Acc@5 78.616
Accuracy of the network on the 50000 test images: 54.05%
Max accuracy (after decay): 54.05%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [57/180][0/625]	eta 3:58:42 lr 0.617865	data 20.8068 (20.8068)	batch 22.9161 (22.9161)	loss -25.2836 (-25.2836)	grad_norm 0.4280 (0.4280)	mem 44912MB
Train: [57/180][50/625]	eta 0:16:16 lr 0.617396	data 0.0006 (0.4096)	batch 1.2775 (1.6982)	loss -25.2256 (-25.1736)	grad_norm 0.4327 (0.4356)	mem 44912MB
Train: [57/180][100/625]	eta 0:12:59 lr 0.616927	data 0.0011 (0.2073)	batch 1.3317 (1.4839)	loss -25.3733 (-25.1937)	grad_norm 0.4340 (0.4388)	mem 44912MB
Train: [57/180][150/625]	eta 0:11:10 lr 0.616458	data 0.0007 (0.1389)	batch 1.2573 (1.4113)	loss -25.3761 (-25.2063)	grad_norm 0.4403 (0.4376)	mem 44912MB
Train: [57/180][200/625]	eta 0:09:44 lr 0.615988	data 0.0012 (0.1046)	batch 1.2581 (1.3757)	loss -25.1286 (-25.2062)	grad_norm 0.4473 (0.4372)	mem 44912MB
Train: [57/180][250/625]	eta 0:08:27 lr 0.615518	data 0.0008 (0.0839)	batch 1.2713 (1.3544)	loss -25.2558 (-25.2121)	grad_norm 0.4353 (0.4366)	mem 44912MB
Train: [57/180][300/625]	eta 0:07:15 lr 0.615047	data 0.0007 (0.0701)	batch 1.2407 (1.3400)	loss -25.2604 (-25.2119)	grad_norm 0.4216 (0.4363)	mem 44912MB
Train: [57/180][350/625]	eta 0:06:05 lr 0.614576	data 0.0006 (0.0602)	batch 1.3342 (1.3294)	loss -25.2235 (-25.2135)	grad_norm 0.4374 (0.4365)	mem 44912MB
Train: [57/180][400/625]	eta 0:04:57 lr 0.614104	data 0.0009 (0.0528)	batch 1.1990 (1.3219)	loss -25.3462 (-25.2206)	grad_norm 0.4225 (0.4368)	mem 44912MB
Train: [57/180][450/625]	eta 0:03:50 lr 0.613632	data 0.0007 (0.0470)	batch 1.2532 (1.3163)	loss -25.3442 (-25.2239)	grad_norm 0.4275 (0.4366)	mem 44912MB
Train: [57/180][500/625]	eta 0:02:43 lr 0.613160	data 0.0006 (0.0424)	batch 1.2602 (1.3109)	loss -25.1941 (-25.2265)	grad_norm 0.4335 (0.4366)	mem 44912MB
Train: [57/180][550/625]	eta 0:01:38 lr 0.612687	data 0.0010 (0.0386)	batch 1.2602 (1.3074)	loss -25.1722 (-25.2281)	grad_norm 0.4438 (0.4367)	mem 44912MB
Train: [57/180][600/625]	eta 0:00:32 lr 0.612214	data 0.0007 (0.0355)	batch 1.2634 (1.3040)	loss -25.3615 (-25.2298)	grad_norm 0.4383 (0.4371)	mem 44912MB
Current slope: None 	
EPOCH 57 training takes 0:13:35
Test: [0/25]	Time 14.945 (14.945)	Loss 1.5583 (1.5583)	Acc@1 64.746 (64.746)	Acc@5 86.279 (86.279)	Mem 44912MB
 * Acc@1 54.024 Acc@5 78.338
Accuracy of the network on the 50000 test images: 54.02%
Max accuracy (after decay): 54.05%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [58/180][0/625]	eta 3:59:05 lr 0.611977	data 20.6858 (20.6858)	batch 22.9533 (22.9533)	loss -25.4075 (-25.4075)	grad_norm 0.4308 (0.4308)	mem 44912MB
Train: [58/180][50/625]	eta 0:16:13 lr 0.611503	data 0.0011 (0.4066)	batch 1.2481 (1.6923)	loss -25.2093 (-25.2676)	grad_norm 0.4543 (0.4366)	mem 44912MB
Train: [58/180][100/625]	eta 0:12:57 lr 0.611029	data 0.0006 (0.2058)	batch 1.2623 (1.4801)	loss -25.1819 (-25.2800)	grad_norm 0.4349 (0.4365)	mem 44912MB
Train: [58/180][150/625]	eta 0:11:08 lr 0.610554	data 0.0008 (0.1379)	batch 1.2801 (1.4082)	loss -25.1368 (-25.2793)	grad_norm 0.4369 (0.4367)	mem 44912MB
Train: [58/180][200/625]	eta 0:09:43 lr 0.610079	data 0.0005 (0.1038)	batch 1.2559 (1.3741)	loss -25.4081 (-25.2835)	grad_norm 0.4383 (0.4368)	mem 44912MB
Train: [58/180][250/625]	eta 0:08:27 lr 0.609604	data 0.0005 (0.0833)	batch 1.2437 (1.3528)	loss -25.2463 (-25.2848)	grad_norm 0.4425 (0.4375)	mem 44912MB
Train: [58/180][300/625]	eta 0:07:14 lr 0.609128	data 0.0004 (0.0696)	batch 1.2705 (1.3378)	loss -25.4166 (-25.2852)	grad_norm 0.4288 (0.4381)	mem 44912MB
Train: [58/180][350/625]	eta 0:06:04 lr 0.608652	data 0.0011 (0.0598)	batch 1.2459 (1.3270)	loss -25.3864 (-25.2909)	grad_norm 0.4272 (0.4381)	mem 44912MB
Train: [58/180][400/625]	eta 0:04:56 lr 0.608175	data 0.0014 (0.0524)	batch 1.2581 (1.3195)	loss -25.2958 (-25.2967)	grad_norm 0.4359 (0.4383)	mem 44912MB
Train: [58/180][450/625]	eta 0:03:49 lr 0.607698	data 0.0012 (0.0467)	batch 1.2691 (1.3133)	loss -25.3923 (-25.3000)	grad_norm 0.4476 (0.4382)	mem 44912MB
Train: [58/180][500/625]	eta 0:02:43 lr 0.607220	data 0.0478 (0.0422)	batch 1.2834 (1.3083)	loss -25.4630 (-25.3056)	grad_norm 0.4309 (0.4383)	mem 44912MB
Train: [58/180][550/625]	eta 0:01:37 lr 0.606743	data 0.0007 (0.0385)	batch 1.2986 (1.3046)	loss -25.5013 (-25.3109)	grad_norm 0.4459 (0.4385)	mem 44912MB
Train: [58/180][600/625]	eta 0:00:32 lr 0.606264	data 0.0005 (0.0353)	batch 1.2735 (1.3013)	loss -25.3687 (-25.3134)	grad_norm 0.4306 (0.4384)	mem 44912MB
Current slope: None 	
EPOCH 58 training takes 0:13:33
Test: [0/25]	Time 14.613 (14.613)	Loss 1.5448 (1.5448)	Acc@1 65.820 (65.820)	Acc@5 86.670 (86.670)	Mem 44912MB
 * Acc@1 53.888 Acc@5 78.396
Accuracy of the network on the 50000 test images: 53.89%
Max accuracy (after decay): 54.05%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [59/180][0/625]	eta 4:00:33 lr 0.606025	data 20.6060 (20.6060)	batch 23.0942 (23.0942)	loss -25.1871 (-25.1871)	grad_norm 0.4663 (0.4663)	mem 44912MB
Train: [59/180][50/625]	eta 0:16:11 lr 0.605546	data 0.0006 (0.4048)	batch 1.2813 (1.6893)	loss -25.4074 (-25.3617)	grad_norm 0.4444 (0.4404)	mem 44912MB
Train: [59/180][100/625]	eta 0:12:57 lr 0.605067	data 0.0010 (0.2051)	batch 1.2598 (1.4809)	loss -25.4110 (-25.3702)	grad_norm 0.4512 (0.4390)	mem 44912MB
Train: [59/180][150/625]	eta 0:11:09 lr 0.604587	data 0.0006 (0.1377)	batch 1.2640 (1.4095)	loss -25.4722 (-25.3740)	grad_norm 0.4489 (0.4405)	mem 44912MB
Train: [59/180][200/625]	eta 0:09:44 lr 0.604107	data 0.0007 (0.1037)	batch 1.2536 (1.3744)	loss -25.6852 (-25.3860)	grad_norm 0.4363 (0.4392)	mem 44912MB
Train: [59/180][250/625]	eta 0:08:26 lr 0.603626	data 0.0008 (0.0832)	batch 1.2276 (1.3516)	loss -25.4877 (-25.3866)	grad_norm 0.4454 (0.4395)	mem 44912MB
Train: [59/180][300/625]	eta 0:07:14 lr 0.603145	data 0.0007 (0.0695)	batch 1.2537 (1.3376)	loss -25.2687 (-25.3904)	grad_norm 0.4306 (0.4391)	mem 44912MB
Train: [59/180][350/625]	eta 0:06:05 lr 0.602664	data 0.0006 (0.0597)	batch 1.2698 (1.3274)	loss -25.4835 (-25.3918)	grad_norm 0.4380 (0.4391)	mem 44912MB
Train: [59/180][400/625]	eta 0:04:57 lr 0.602182	data 0.0008 (0.0524)	batch 1.3558 (1.3201)	loss -25.2597 (-25.3932)	grad_norm 0.4394 (0.4390)	mem 44912MB
Train: [59/180][450/625]	eta 0:03:49 lr 0.601700	data 0.0010 (0.0467)	batch 1.3152 (1.3137)	loss -25.2260 (-25.3916)	grad_norm 0.4341 (0.4389)	mem 44912MB
Train: [59/180][500/625]	eta 0:02:43 lr 0.601218	data 0.0007 (0.0421)	batch 1.2326 (1.3094)	loss -25.3934 (-25.3967)	grad_norm 0.4379 (0.4386)	mem 44912MB
Train: [59/180][550/625]	eta 0:01:37 lr 0.600735	data 0.0007 (0.0383)	batch 1.3126 (1.3050)	loss -25.4260 (-25.4002)	grad_norm 0.4325 (0.4385)	mem 44912MB
Train: [59/180][600/625]	eta 0:00:32 lr 0.600252	data 0.0005 (0.0352)	batch 1.2328 (1.3016)	loss -25.5948 (-25.4042)	grad_norm 0.4169 (0.4386)	mem 44912MB
Current slope: None 	
EPOCH 59 training takes 0:13:33
Test: [0/25]	Time 14.991 (14.991)	Loss 1.5396 (1.5396)	Acc@1 66.113 (66.113)	Acc@5 86.133 (86.133)	Mem 44912MB
 * Acc@1 54.226 Acc@5 78.696
Accuracy of the network on the 50000 test images: 54.23%
Max accuracy (after decay): 54.23%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [60/180][0/625]	eta 3:59:07 lr 0.600010	data 20.5331 (20.5331)	batch 22.9559 (22.9559)	loss -25.5248 (-25.5248)	grad_norm 0.4408 (0.4408)	mem 44912MB
Train: [60/180][50/625]	eta 0:16:19 lr 0.599526	data 0.0012 (0.4035)	batch 1.2494 (1.7040)	loss -25.4098 (-25.4603)	grad_norm 0.4607 (0.4392)	mem 44912MB
Train: [60/180][100/625]	eta 0:13:00 lr 0.599042	data 0.0009 (0.2042)	batch 1.2406 (1.4871)	loss -25.6378 (-25.4579)	grad_norm 0.4380 (0.4394)	mem 44912MB
Train: [60/180][150/625]	eta 0:11:11 lr 0.598557	data 0.0007 (0.1368)	batch 1.2344 (1.4139)	loss -25.2873 (-25.4583)	grad_norm 0.4391 (0.4393)	mem 44912MB
Train: [60/180][200/625]	eta 0:09:44 lr 0.598072	data 0.0013 (0.1030)	batch 1.2776 (1.3763)	loss -25.5278 (-25.4615)	grad_norm 0.4436 (0.4410)	mem 44912MB
Train: [60/180][250/625]	eta 0:08:28 lr 0.597587	data 0.0007 (0.0828)	batch 1.3004 (1.3554)	loss -25.3585 (-25.4618)	grad_norm 0.4413 (0.4411)	mem 44912MB
Train: [60/180][300/625]	eta 0:07:15 lr 0.597101	data 0.0006 (0.0692)	batch 1.2543 (1.3400)	loss -25.5128 (-25.4638)	grad_norm 0.4461 (0.4408)	mem 44912MB
Train: [60/180][350/625]	eta 0:06:05 lr 0.596615	data 0.0006 (0.0594)	batch 1.2478 (1.3296)	loss -25.5138 (-25.4660)	grad_norm 0.4298 (0.4410)	mem 44912MB
Train: [60/180][400/625]	eta 0:04:57 lr 0.596128	data 0.0007 (0.0521)	batch 1.2433 (1.3216)	loss -25.5828 (-25.4702)	grad_norm 0.4434 (0.4407)	mem 44912MB
Train: [60/180][450/625]	eta 0:03:50 lr 0.595641	data 0.0008 (0.0464)	batch 1.2524 (1.3160)	loss -25.5861 (-25.4717)	grad_norm 0.4479 (0.4407)	mem 44912MB
Train: [60/180][500/625]	eta 0:02:43 lr 0.595154	data 0.0007 (0.0419)	batch 1.3220 (1.3112)	loss -25.6356 (-25.4722)	grad_norm 0.4255 (0.4409)	mem 44912MB
Train: [60/180][550/625]	eta 0:01:38 lr 0.594666	data 0.0007 (0.0381)	batch 1.2715 (1.3069)	loss -25.3531 (-25.4730)	grad_norm 0.4299 (0.4404)	mem 44912MB
Train: [60/180][600/625]	eta 0:00:32 lr 0.594178	data 0.0005 (0.0350)	batch 1.2742 (1.3033)	loss -25.5366 (-25.4762)	grad_norm 0.4395 (0.4404)	mem 44912MB
Current slope: None 	
EPOCH 60 training takes 0:13:35
Test: [0/25]	Time 14.862 (14.862)	Loss 1.5266 (1.5266)	Acc@1 67.627 (67.627)	Acc@5 86.621 (86.621)	Mem 44912MB
 * Acc@1 54.280 Acc@5 78.712
Accuracy of the network on the 50000 test images: 54.28%
Max accuracy (after decay): 54.28%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [61/180][0/625]	eta 4:02:50 lr 0.593934	data 21.9639 (21.9639)	batch 23.3126 (23.3126)	loss -25.4565 (-25.4565)	grad_norm 0.4440 (0.4440)	mem 44912MB
Train: [61/180][50/625]	eta 0:16:22 lr 0.593446	data 0.0005 (0.4316)	batch 1.3238 (1.7079)	loss -25.5460 (-25.5497)	grad_norm 0.4410 (0.4409)	mem 44912MB
Train: [61/180][100/625]	eta 0:13:02 lr 0.592956	data 0.0007 (0.2184)	batch 1.2316 (1.4901)	loss -25.4782 (-25.5240)	grad_norm 0.4474 (0.4411)	mem 44912MB
Train: [61/180][150/625]	eta 0:11:12 lr 0.592467	data 0.0008 (0.1463)	batch 1.2770 (1.4167)	loss -25.4646 (-25.5330)	grad_norm 0.4554 (0.4403)	mem 44912MB
Train: [61/180][200/625]	eta 0:09:46 lr 0.591977	data 0.0016 (0.1101)	batch 1.2570 (1.3792)	loss -25.4947 (-25.5324)	grad_norm 0.4477 (0.4411)	mem 44912MB
Train: [61/180][250/625]	eta 0:08:29 lr 0.591487	data 0.0008 (0.0884)	batch 1.2428 (1.3585)	loss -25.6537 (-25.5331)	grad_norm 0.4369 (0.4402)	mem 44912MB
Train: [61/180][300/625]	eta 0:07:16 lr 0.590997	data 0.0012 (0.0738)	batch 1.4032 (1.3440)	loss -25.6429 (-25.5390)	grad_norm 0.4391 (0.4402)	mem 44912MB
Train: [61/180][350/625]	eta 0:06:06 lr 0.590506	data 0.0006 (0.0636)	batch 1.2728 (1.3328)	loss -25.5521 (-25.5372)	grad_norm 0.4444 (0.4406)	mem 44912MB
Train: [61/180][400/625]	eta 0:04:57 lr 0.590014	data 0.0006 (0.0557)	batch 1.2751 (1.3240)	loss -25.4257 (-25.5403)	grad_norm 0.4453 (0.4411)	mem 44912MB
Train: [61/180][450/625]	eta 0:03:50 lr 0.589523	data 0.0007 (0.0496)	batch 1.3004 (1.3177)	loss -25.4729 (-25.5454)	grad_norm 0.4720 (0.4410)	mem 44912MB
Train: [61/180][500/625]	eta 0:02:44 lr 0.589031	data 0.0008 (0.0448)	batch 1.3412 (1.3131)	loss -25.4464 (-25.5444)	grad_norm 0.4374 (0.4411)	mem 44912MB
Train: [61/180][550/625]	eta 0:01:38 lr 0.588538	data 0.0011 (0.0408)	batch 1.2353 (1.3088)	loss -25.4942 (-25.5470)	grad_norm 0.4325 (0.4411)	mem 44912MB
Train: [61/180][600/625]	eta 0:00:32 lr 0.588046	data 0.0007 (0.0374)	batch 1.2515 (1.3048)	loss -25.6402 (-25.5508)	grad_norm 0.4280 (0.4407)	mem 44912MB
Current slope: None 	
EPOCH 61 training takes 0:13:35
Test: [0/25]	Time 14.633 (14.633)	Loss 1.5099 (1.5099)	Acc@1 66.357 (66.357)	Acc@5 87.500 (87.500)	Mem 44912MB
 * Acc@1 54.446 Acc@5 79.032
Accuracy of the network on the 50000 test images: 54.45%
Max accuracy (after decay): 54.45%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [62/180][0/625]	eta 3:59:26 lr 0.587799	data 21.5281 (21.5281)	batch 22.9866 (22.9866)	loss -25.6115 (-25.6115)	grad_norm 0.4596 (0.4596)	mem 44912MB
Train: [62/180][50/625]	eta 0:16:15 lr 0.587306	data 0.0006 (0.4229)	batch 1.3116 (1.6962)	loss -25.4609 (-25.6151)	grad_norm 0.4312 (0.4445)	mem 44912MB
Train: [62/180][100/625]	eta 0:12:57 lr 0.586812	data 0.0008 (0.2140)	batch 1.2274 (1.4807)	loss -25.6516 (-25.6152)	grad_norm 0.4496 (0.4423)	mem 44912MB
Train: [62/180][150/625]	eta 0:11:09 lr 0.586318	data 0.0007 (0.1434)	batch 1.2595 (1.4092)	loss -25.6567 (-25.6143)	grad_norm 0.4452 (0.4423)	mem 44912MB
Train: [62/180][200/625]	eta 0:09:44 lr 0.585824	data 0.0007 (0.1079)	batch 1.2923 (1.3749)	loss -25.6919 (-25.6097)	grad_norm 0.4391 (0.4419)	mem 44912MB
Train: [62/180][250/625]	eta 0:08:26 lr 0.585329	data 0.0006 (0.0866)	batch 1.2880 (1.3519)	loss -25.6611 (-25.6132)	grad_norm 0.4458 (0.4419)	mem 44912MB
Train: [62/180][300/625]	eta 0:07:14 lr 0.584834	data 0.0007 (0.0723)	batch 1.2578 (1.3374)	loss -25.6154 (-25.6141)	grad_norm 0.4320 (0.4418)	mem 44912MB
Train: [62/180][350/625]	eta 0:06:04 lr 0.584339	data 0.0006 (0.0622)	batch 1.2303 (1.3273)	loss -25.5045 (-25.6165)	grad_norm 0.4456 (0.4417)	mem 44912MB
Train: [62/180][400/625]	eta 0:04:57 lr 0.583843	data 0.0007 (0.0545)	batch 1.2650 (1.3204)	loss -25.7568 (-25.6195)	grad_norm 0.4387 (0.4416)	mem 44912MB
Train: [62/180][450/625]	eta 0:03:50 lr 0.583347	data 0.0007 (0.0486)	batch 1.2396 (1.3146)	loss -25.7016 (-25.6243)	grad_norm 0.4474 (0.4417)	mem 44912MB
Train: [62/180][500/625]	eta 0:02:43 lr 0.582850	data 0.0007 (0.0438)	batch 1.2343 (1.3094)	loss -25.6113 (-25.6274)	grad_norm 0.4415 (0.4420)	mem 44912MB
Train: [62/180][550/625]	eta 0:01:37 lr 0.582353	data 0.0007 (0.0399)	batch 1.2480 (1.3054)	loss -25.5190 (-25.6278)	grad_norm 0.4460 (0.4420)	mem 44912MB
Train: [62/180][600/625]	eta 0:00:32 lr 0.581856	data 0.0010 (0.0366)	batch 1.2801 (1.3025)	loss -25.7678 (-25.6300)	grad_norm 0.4433 (0.4421)	mem 44912MB
Current slope: None 	
EPOCH 62 training takes 0:13:34
Test: [0/25]	Time 14.589 (14.589)	Loss 1.5311 (1.5311)	Acc@1 67.480 (67.480)	Acc@5 86.523 (86.523)	Mem 44912MB
 * Acc@1 54.288 Acc@5 78.734
Accuracy of the network on the 50000 test images: 54.29%
Max accuracy (after decay): 54.45%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [63/180][0/625]	eta 3:58:34 lr 0.581607	data 20.5665 (20.5665)	batch 22.9030 (22.9030)	loss -25.6737 (-25.6737)	grad_norm 0.4524 (0.4524)	mem 44912MB
Train: [63/180][50/625]	eta 0:16:13 lr 0.581109	data 0.0015 (0.4041)	batch 1.2852 (1.6928)	loss -25.6670 (-25.6789)	grad_norm 0.4542 (0.4451)	mem 44912MB
Train: [63/180][100/625]	eta 0:12:57 lr 0.580611	data 0.0008 (0.2045)	batch 1.2284 (1.4813)	loss -25.8745 (-25.6684)	grad_norm 0.4360 (0.4441)	mem 44912MB
Train: [63/180][150/625]	eta 0:11:09 lr 0.580113	data 0.0009 (0.1371)	batch 1.2703 (1.4089)	loss -25.6712 (-25.6789)	grad_norm 0.4393 (0.4437)	mem 44912MB
Train: [63/180][200/625]	eta 0:09:43 lr 0.579614	data 0.0009 (0.1032)	batch 1.2414 (1.3740)	loss -25.6212 (-25.6801)	grad_norm 0.4427 (0.4435)	mem 44912MB
Train: [63/180][250/625]	eta 0:08:27 lr 0.579115	data 0.0007 (0.0828)	batch 1.2447 (1.3531)	loss -25.6803 (-25.6867)	grad_norm 0.4449 (0.4437)	mem 44912MB
Train: [63/180][300/625]	eta 0:07:15 lr 0.578615	data 0.0006 (0.0692)	batch 1.2466 (1.3390)	loss -25.8388 (-25.6851)	grad_norm 0.4403 (0.4434)	mem 44912MB
Train: [63/180][350/625]	eta 0:06:05 lr 0.578115	data 0.0006 (0.0595)	batch 1.3181 (1.3285)	loss -25.8016 (-25.6887)	grad_norm 0.4464 (0.4434)	mem 44912MB
Train: [63/180][400/625]	eta 0:04:57 lr 0.577615	data 0.0009 (0.0521)	batch 1.2730 (1.3209)	loss -25.6637 (-25.6917)	grad_norm 0.4443 (0.4433)	mem 44912MB
Train: [63/180][450/625]	eta 0:03:50 lr 0.577114	data 0.0006 (0.0464)	batch 1.2400 (1.3150)	loss -25.7708 (-25.6927)	grad_norm 0.4404 (0.4432)	mem 44912MB
Train: [63/180][500/625]	eta 0:02:43 lr 0.576614	data 0.0006 (0.0419)	batch 1.2587 (1.3094)	loss -25.6564 (-25.6976)	grad_norm 0.4482 (0.4431)	mem 44912MB
Train: [63/180][550/625]	eta 0:01:37 lr 0.576112	data 0.0006 (0.0381)	batch 1.2842 (1.3054)	loss -25.6926 (-25.6992)	grad_norm 0.4400 (0.4430)	mem 44912MB
Train: [63/180][600/625]	eta 0:00:32 lr 0.575611	data 0.0007 (0.0350)	batch 1.2604 (1.3020)	loss -25.8061 (-25.7018)	grad_norm 0.4449 (0.4430)	mem 44912MB
Current slope: None 	
EPOCH 63 training takes 0:13:34
Test: [0/25]	Time 14.535 (14.535)	Loss 1.4275 (1.4275)	Acc@1 67.773 (67.773)	Acc@5 87.012 (87.012)	Mem 44912MB
 * Acc@1 54.348 Acc@5 78.750
Accuracy of the network on the 50000 test images: 54.35%
Max accuracy (after decay): 54.45%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [64/180][0/625]	eta 3:59:14 lr 0.575360	data 21.0501 (21.0501)	batch 22.9676 (22.9676)	loss -25.8695 (-25.8695)	grad_norm 0.4372 (0.4372)	mem 44912MB
Train: [64/180][50/625]	eta 0:16:15 lr 0.574858	data 0.0012 (0.4138)	batch 1.2384 (1.6971)	loss -25.7344 (-25.7163)	grad_norm 0.4339 (0.4433)	mem 44912MB
Train: [64/180][100/625]	eta 0:12:58 lr 0.574355	data 0.0007 (0.2094)	batch 1.2596 (1.4829)	loss -25.7096 (-25.7274)	grad_norm 0.4389 (0.4438)	mem 44912MB
Train: [64/180][150/625]	eta 0:11:11 lr 0.573852	data 0.0010 (0.1404)	batch 1.2424 (1.4134)	loss -25.8001 (-25.7373)	grad_norm 0.4485 (0.4451)	mem 44912MB
Train: [64/180][200/625]	eta 0:09:45 lr 0.573349	data 0.0007 (0.1057)	batch 1.2433 (1.3771)	loss -25.8597 (-25.7351)	grad_norm 0.4289 (0.4450)	mem 44912MB
Train: [64/180][250/625]	eta 0:08:28 lr 0.572846	data 0.0009 (0.0848)	batch 1.2540 (1.3550)	loss -25.7570 (-25.7393)	grad_norm 0.4553 (0.4452)	mem 44912MB
Train: [64/180][300/625]	eta 0:07:15 lr 0.572342	data 0.0008 (0.0708)	batch 1.2392 (1.3406)	loss -25.6713 (-25.7416)	grad_norm 0.4579 (0.4451)	mem 44912MB
Train: [64/180][350/625]	eta 0:06:05 lr 0.571838	data 0.0009 (0.0609)	batch 1.2781 (1.3304)	loss -25.6193 (-25.7439)	grad_norm 0.4574 (0.4449)	mem 44912MB
Train: [64/180][400/625]	eta 0:04:57 lr 0.571333	data 0.0007 (0.0534)	batch 1.2501 (1.3222)	loss -25.8618 (-25.7466)	grad_norm 0.4909 (0.4451)	mem 44912MB
Train: [64/180][450/625]	eta 0:03:50 lr 0.570828	data 0.0008 (0.0476)	batch 1.2457 (1.3161)	loss -25.9033 (-25.7505)	grad_norm 0.4254 (0.4447)	mem 44912MB
Train: [64/180][500/625]	eta 0:02:43 lr 0.570323	data 0.0009 (0.0429)	batch 1.2367 (1.3107)	loss -25.9209 (-25.7562)	grad_norm 0.4441 (0.4448)	mem 44912MB
Train: [64/180][550/625]	eta 0:01:38 lr 0.569818	data 0.0012 (0.0391)	batch 1.2586 (1.3067)	loss -25.8936 (-25.7590)	grad_norm 0.4264 (0.4446)	mem 44912MB
Train: [64/180][600/625]	eta 0:00:32 lr 0.569312	data 0.0005 (0.0359)	batch 1.2432 (1.3033)	loss -25.7537 (-25.7609)	grad_norm 0.4356 (0.4447)	mem 44912MB
Current slope: None 	
EPOCH 64 training takes 0:13:34
Test: [0/25]	Time 14.842 (14.842)	Loss 1.5010 (1.5010)	Acc@1 67.285 (67.285)	Acc@5 87.549 (87.549)	Mem 44912MB
 * Acc@1 54.650 Acc@5 79.080
Accuracy of the network on the 50000 test images: 54.65%
Max accuracy (after decay): 54.65%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [65/180][0/625]	eta 3:57:48 lr 0.569059	data 20.3177 (20.3177)	batch 22.8297 (22.8297)	loss -26.0303 (-26.0303)	grad_norm 0.4277 (0.4277)	mem 44912MB
Train: [65/180][50/625]	eta 0:16:14 lr 0.568553	data 0.0007 (0.3992)	batch 1.2522 (1.6952)	loss -25.9324 (-25.8081)	grad_norm 0.4321 (0.4473)	mem 44912MB
Train: [65/180][100/625]	eta 0:12:58 lr 0.568046	data 0.0022 (0.2023)	batch 1.3167 (1.4819)	loss -25.8740 (-25.8099)	grad_norm 0.4456 (0.4476)	mem 44912MB
Train: [65/180][150/625]	eta 0:11:10 lr 0.567539	data 0.0006 (0.1356)	batch 1.3363 (1.4118)	loss -25.7214 (-25.8064)	grad_norm 0.4476 (0.4466)	mem 44912MB
Train: [65/180][200/625]	eta 0:09:44 lr 0.567032	data 0.0011 (0.1023)	batch 1.2733 (1.3751)	loss -26.0413 (-25.8054)	grad_norm 0.4512 (0.4459)	mem 44912MB
Train: [65/180][250/625]	eta 0:08:27 lr 0.566524	data 0.0007 (0.0821)	batch 1.2425 (1.3543)	loss -25.9323 (-25.8101)	grad_norm 0.4470 (0.4466)	mem 44912MB
Train: [65/180][300/625]	eta 0:07:15 lr 0.566016	data 0.0009 (0.0686)	batch 1.2751 (1.3404)	loss -25.9315 (-25.8163)	grad_norm 0.4457 (0.4467)	mem 44912MB
Train: [65/180][350/625]	eta 0:06:05 lr 0.565508	data 0.0003 (0.0589)	batch 1.2683 (1.3302)	loss -26.0586 (-25.8189)	grad_norm 0.4466 (0.4471)	mem 44912MB
Train: [65/180][400/625]	eta 0:04:57 lr 0.564999	data 0.0011 (0.0517)	batch 1.2491 (1.3227)	loss -25.8627 (-25.8242)	grad_norm 0.4328 (0.4468)	mem 44912MB
Train: [65/180][450/625]	eta 0:03:50 lr 0.564490	data 0.0009 (0.0460)	batch 1.2305 (1.3171)	loss -25.7963 (-25.8242)	grad_norm 0.4425 (0.4467)	mem 44912MB
Train: [65/180][500/625]	eta 0:02:44 lr 0.563981	data 0.0006 (0.0415)	batch 1.2821 (1.3123)	loss -25.9009 (-25.8243)	grad_norm 0.4955 (0.4465)	mem 44912MB
Train: [65/180][550/625]	eta 0:01:38 lr 0.563471	data 0.0005 (0.0378)	batch 1.2220 (1.3083)	loss -25.7888 (-25.8228)	grad_norm 0.4556 (0.4465)	mem 44912MB
Train: [65/180][600/625]	eta 0:00:32 lr 0.562962	data 0.0006 (0.0347)	batch 1.3535 (1.3046)	loss -25.7913 (-25.8226)	grad_norm 0.4364 (0.4463)	mem 44912MB
Current slope: None 	
EPOCH 65 training takes 0:13:35
Test: [0/25]	Time 14.439 (14.439)	Loss 1.5982 (1.5982)	Acc@1 64.404 (64.404)	Acc@5 85.840 (85.840)	Mem 44912MB
 * Acc@1 54.426 Acc@5 79.018
Accuracy of the network on the 50000 test images: 54.43%
Max accuracy (after decay): 54.65%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [66/180][0/625]	eta 4:01:02 lr 0.562707	data 20.7276 (20.7276)	batch 23.1400 (23.1400)	loss -25.8841 (-25.8841)	grad_norm 0.4408 (0.4408)	mem 44912MB
Train: [66/180][50/625]	eta 0:16:13 lr 0.562196	data 0.0009 (0.4073)	batch 1.2732 (1.6927)	loss -25.8089 (-25.8580)	grad_norm 0.4503 (0.4471)	mem 44912MB
Train: [66/180][100/625]	eta 0:12:57 lr 0.561686	data 0.0008 (0.2060)	batch 1.2363 (1.4816)	loss -25.8596 (-25.8626)	grad_norm 0.4369 (0.4475)	mem 44912MB
Train: [66/180][150/625]	eta 0:11:09 lr 0.561175	data 0.0005 (0.1380)	batch 1.2650 (1.4093)	loss -25.8452 (-25.8681)	grad_norm 0.4519 (0.4484)	mem 44912MB
Train: [66/180][200/625]	eta 0:09:44 lr 0.560663	data 0.0005 (0.1039)	batch 1.2705 (1.3743)	loss -25.9742 (-25.8687)	grad_norm 0.4623 (0.4475)	mem 44912MB
Train: [66/180][250/625]	eta 0:08:26 lr 0.560152	data 0.0005 (0.0833)	batch 1.2604 (1.3512)	loss -25.8429 (-25.8727)	grad_norm 0.4446 (0.4479)	mem 44912MB
Train: [66/180][300/625]	eta 0:07:14 lr 0.559640	data 0.0004 (0.0696)	batch 1.2585 (1.3375)	loss -25.6622 (-25.8707)	grad_norm 0.4492 (0.4476)	mem 44912MB
Train: [66/180][350/625]	eta 0:06:05 lr 0.559127	data 0.0004 (0.0598)	batch 1.2799 (1.3273)	loss -25.9114 (-25.8735)	grad_norm 0.4417 (0.4469)	mem 44912MB
Train: [66/180][400/625]	eta 0:04:57 lr 0.558615	data 0.0008 (0.0524)	batch 1.2702 (1.3213)	loss -25.8336 (-25.8753)	grad_norm 0.4382 (0.4473)	mem 44912MB
Train: [66/180][450/625]	eta 0:03:50 lr 0.558102	data 0.0005 (0.0468)	batch 1.2932 (1.3149)	loss -25.9573 (-25.8778)	grad_norm 0.4375 (0.4468)	mem 44912MB
Train: [66/180][500/625]	eta 0:02:43 lr 0.557589	data 0.0008 (0.0422)	batch 1.2720 (1.3100)	loss -26.0504 (-25.8802)	grad_norm 0.4501 (0.4466)	mem 44912MB
Train: [66/180][550/625]	eta 0:01:37 lr 0.557075	data 0.0008 (0.0385)	batch 1.2606 (1.3059)	loss -26.0597 (-25.8836)	grad_norm 0.4428 (0.4465)	mem 44912MB
Train: [66/180][600/625]	eta 0:00:32 lr 0.556562	data 0.0005 (0.0354)	batch 1.2692 (1.3027)	loss -25.9225 (-25.8856)	grad_norm 0.4438 (0.4470)	mem 44912MB
Current slope: None 	
EPOCH 66 training takes 0:13:34
Test: [0/25]	Time 14.618 (14.618)	Loss 1.4376 (1.4376)	Acc@1 66.846 (66.846)	Acc@5 87.988 (87.988)	Mem 44912MB
 * Acc@1 54.706 Acc@5 79.136
Accuracy of the network on the 50000 test images: 54.71%
Max accuracy (after decay): 54.71%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [67/180][0/625]	eta 3:56:29 lr 0.556305	data 21.0071 (21.0071)	batch 22.7028 (22.7028)	loss -25.8906 (-25.8906)	grad_norm 0.4389 (0.4389)	mem 44912MB
Train: [67/180][50/625]	eta 0:16:09 lr 0.555790	data 0.0012 (0.4130)	batch 1.2395 (1.6864)	loss -25.7748 (-25.9325)	grad_norm 0.4463 (0.4459)	mem 44912MB
Train: [67/180][100/625]	eta 0:12:57 lr 0.555276	data 0.0010 (0.2090)	batch 1.2389 (1.4801)	loss -25.8431 (-25.9307)	grad_norm 0.4364 (0.4479)	mem 44912MB
Train: [67/180][150/625]	eta 0:11:08 lr 0.554761	data 0.0007 (0.1401)	batch 1.2199 (1.4084)	loss -25.9917 (-25.9346)	grad_norm 0.4518 (0.4488)	mem 44912MB
Train: [67/180][200/625]	eta 0:09:43 lr 0.554246	data 0.0007 (0.1054)	batch 1.3097 (1.3737)	loss -25.9667 (-25.9372)	grad_norm 0.4407 (0.4485)	mem 44912MB
Train: [67/180][250/625]	eta 0:08:26 lr 0.553730	data 0.0008 (0.0846)	batch 1.2732 (1.3511)	loss -25.9444 (-25.9416)	grad_norm 0.4503 (0.4491)	mem 44912MB
Train: [67/180][300/625]	eta 0:07:14 lr 0.553215	data 0.0009 (0.0706)	batch 1.2784 (1.3379)	loss -25.8724 (-25.9450)	grad_norm 0.4545 (0.4486)	mem 44912MB
Train: [67/180][350/625]	eta 0:06:05 lr 0.552699	data 0.0006 (0.0607)	batch 1.2618 (1.3274)	loss -26.0489 (-25.9443)	grad_norm 0.4458 (0.4484)	mem 44912MB
Train: [67/180][400/625]	eta 0:04:56 lr 0.552182	data 0.0012 (0.0532)	batch 1.2354 (1.3194)	loss -26.0679 (-25.9428)	grad_norm 0.4453 (0.4482)	mem 44912MB
Train: [67/180][450/625]	eta 0:03:49 lr 0.551666	data 0.0006 (0.0474)	batch 1.2809 (1.3138)	loss -25.9482 (-25.9419)	grad_norm 0.4618 (0.4481)	mem 44912MB
Train: [67/180][500/625]	eta 0:02:43 lr 0.551149	data 0.0006 (0.0428)	batch 1.2719 (1.3092)	loss -25.9936 (-25.9394)	grad_norm 0.4550 (0.4481)	mem 44912MB
Train: [67/180][550/625]	eta 0:01:37 lr 0.550632	data 0.0006 (0.0389)	batch 1.3390 (1.3053)	loss -25.9171 (-25.9366)	grad_norm 0.4412 (0.4480)	mem 44912MB
Train: [67/180][600/625]	eta 0:00:32 lr 0.550114	data 0.0015 (0.0358)	batch 1.2534 (1.3022)	loss -25.8377 (-25.9390)	grad_norm 0.4472 (0.4480)	mem 44912MB
Current slope: None 	
EPOCH 67 training takes 0:13:34
Test: [0/25]	Time 15.139 (15.139)	Loss 1.4816 (1.4816)	Acc@1 65.283 (65.283)	Acc@5 87.988 (87.988)	Mem 44912MB
 * Acc@1 54.588 Acc@5 79.008
Accuracy of the network on the 50000 test images: 54.59%
Max accuracy (after decay): 54.71%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [68/180][0/625]	eta 3:57:08 lr 0.549855	data 20.7456 (20.7456)	batch 22.7651 (22.7651)	loss -26.1203 (-26.1203)	grad_norm 0.4267 (0.4267)	mem 44912MB
Train: [68/180][50/625]	eta 0:16:13 lr 0.549337	data 0.0006 (0.4077)	batch 1.2624 (1.6922)	loss -25.9762 (-25.9978)	grad_norm 0.4476 (0.4490)	mem 44912MB
Train: [68/180][100/625]	eta 0:12:58 lr 0.548819	data 0.0012 (0.2063)	batch 1.2890 (1.4820)	loss -25.9517 (-25.9921)	grad_norm 0.4396 (0.4488)	mem 44912MB
Train: [68/180][150/625]	eta 0:11:10 lr 0.548300	data 0.0007 (0.1386)	batch 1.2696 (1.4107)	loss -25.9880 (-25.9959)	grad_norm 0.4379 (0.4485)	mem 44912MB
Train: [68/180][200/625]	eta 0:09:44 lr 0.547782	data 0.0011 (0.1043)	batch 1.2506 (1.3748)	loss -26.1346 (-25.9909)	grad_norm 0.4572 (0.4489)	mem 44912MB
Train: [68/180][250/625]	eta 0:08:27 lr 0.547262	data 0.0006 (0.0837)	batch 1.2557 (1.3535)	loss -25.8326 (-25.9884)	grad_norm 0.4539 (0.4486)	mem 44912MB
Train: [68/180][300/625]	eta 0:07:15 lr 0.546743	data 0.0008 (0.0699)	batch 1.2903 (1.3392)	loss -26.1471 (-25.9911)	grad_norm 0.4421 (0.4491)	mem 44912MB
Train: [68/180][350/625]	eta 0:06:05 lr 0.546223	data 0.0009 (0.0601)	batch 1.2847 (1.3290)	loss -25.9955 (-25.9882)	grad_norm 0.4413 (0.4493)	mem 44912MB
Train: [68/180][400/625]	eta 0:04:57 lr 0.545703	data 0.0007 (0.0527)	batch 1.2432 (1.3213)	loss -25.8773 (-25.9891)	grad_norm 0.4450 (0.4491)	mem 44912MB
Train: [68/180][450/625]	eta 0:03:50 lr 0.545183	data 0.0006 (0.0469)	batch 1.2606 (1.3160)	loss -25.7759 (-25.9877)	grad_norm 0.4602 (0.4491)	mem 44912MB
Train: [68/180][500/625]	eta 0:02:43 lr 0.544663	data 0.0006 (0.0423)	batch 1.2263 (1.3106)	loss -26.0533 (-25.9898)	grad_norm 0.4390 (0.4493)	mem 44912MB
Train: [68/180][550/625]	eta 0:01:37 lr 0.544142	data 0.0005 (0.0386)	batch 1.2475 (1.3066)	loss -26.0017 (-25.9905)	grad_norm 0.4815 (0.4493)	mem 44912MB
Train: [68/180][600/625]	eta 0:00:32 lr 0.543621	data 0.0005 (0.0354)	batch 1.2876 (1.3036)	loss -26.0303 (-25.9917)	grad_norm 0.4380 (0.4492)	mem 44912MB
Current slope: None 	
EPOCH 68 training takes 0:13:35
Test: [0/25]	Time 14.679 (14.679)	Loss 1.4197 (1.4197)	Acc@1 67.725 (67.725)	Acc@5 87.598 (87.598)	Mem 44912MB
 * Acc@1 54.714 Acc@5 79.080
Accuracy of the network on the 50000 test images: 54.71%
Max accuracy (after decay): 54.71%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [69/180][0/625]	eta 4:00:34 lr 0.543360	data 20.8441 (20.8441)	batch 23.0946 (23.0946)	loss -26.1253 (-26.1253)	grad_norm 0.4460 (0.4460)	mem 44912MB
Train: [69/180][50/625]	eta 0:16:18 lr 0.542838	data 0.0011 (0.4104)	batch 1.2534 (1.7014)	loss -25.9523 (-26.0345)	grad_norm 0.4471 (0.4511)	mem 44912MB
Train: [69/180][100/625]	eta 0:12:59 lr 0.542317	data 0.0007 (0.2077)	batch 1.2542 (1.4850)	loss -26.0035 (-26.0396)	grad_norm 0.4348 (0.4518)	mem 44912MB
Train: [69/180][150/625]	eta 0:11:11 lr 0.541795	data 0.0021 (0.1392)	batch 1.2805 (1.4131)	loss -26.1616 (-26.0455)	grad_norm 0.4326 (0.4514)	mem 44912MB
Train: [69/180][200/625]	eta 0:09:44 lr 0.541272	data 0.0009 (0.1048)	batch 1.2477 (1.3764)	loss -26.0189 (-26.0470)	grad_norm 0.4467 (0.4513)	mem 44912MB
Train: [69/180][250/625]	eta 0:08:28 lr 0.540750	data 0.0007 (0.0840)	batch 1.2710 (1.3552)	loss -25.9947 (-26.0523)	grad_norm 0.4492 (0.4515)	mem 44912MB
Train: [69/180][300/625]	eta 0:07:15 lr 0.540227	data 0.0006 (0.0702)	batch 1.3038 (1.3400)	loss -26.1344 (-26.0523)	grad_norm 0.4555 (0.4510)	mem 44912MB
Train: [69/180][350/625]	eta 0:06:05 lr 0.539704	data 0.0006 (0.0603)	batch 1.2530 (1.3293)	loss -26.2623 (-26.0521)	grad_norm 0.4373 (0.4507)	mem 44912MB
Train: [69/180][400/625]	eta 0:04:57 lr 0.539180	data 0.0006 (0.0529)	batch 1.2645 (1.3213)	loss -26.1900 (-26.0532)	grad_norm 0.4508 (0.4507)	mem 44912MB
Train: [69/180][450/625]	eta 0:03:50 lr 0.538656	data 0.0006 (0.0471)	batch 1.2195 (1.3153)	loss -26.1737 (-26.0508)	grad_norm 0.4499 (0.4505)	mem 44912MB
Train: [69/180][500/625]	eta 0:02:43 lr 0.538132	data 0.0007 (0.0424)	batch 1.3016 (1.3100)	loss -25.9986 (-26.0516)	grad_norm 0.4631 (0.4505)	mem 44912MB
Train: [69/180][550/625]	eta 0:01:37 lr 0.537608	data 0.0003 (0.0387)	batch 1.2816 (1.3059)	loss -26.0549 (-26.0517)	grad_norm 0.4431 (0.4504)	mem 44912MB
Train: [69/180][600/625]	eta 0:00:32 lr 0.537084	data 0.0007 (0.0355)	batch 1.2489 (1.3029)	loss -26.0308 (-26.0518)	grad_norm 0.4564 (0.4507)	mem 44912MB
Current slope: None 	
EPOCH 69 training takes 0:13:34
Test: [0/25]	Time 14.512 (14.512)	Loss 1.4668 (1.4668)	Acc@1 68.750 (68.750)	Acc@5 87.793 (87.793)	Mem 44912MB
 * Acc@1 55.034 Acc@5 79.196
Accuracy of the network on the 50000 test images: 55.03%
Max accuracy (after decay): 55.03%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [70/180][0/625]	eta 3:56:43 lr 0.536821	data 20.4880 (20.4880)	batch 22.7260 (22.7260)	loss -26.0537 (-26.0537)	grad_norm 0.4330 (0.4330)	mem 44912MB
Train: [70/180][50/625]	eta 0:16:12 lr 0.536296	data 0.0012 (0.4026)	batch 1.2911 (1.6921)	loss -25.9470 (-26.0786)	grad_norm 0.4559 (0.4511)	mem 44912MB
Train: [70/180][100/625]	eta 0:12:57 lr 0.535771	data 0.0008 (0.2037)	batch 1.2788 (1.4818)	loss -26.2458 (-26.0807)	grad_norm 0.4424 (0.4509)	mem 44912MB
Train: [70/180][150/625]	eta 0:11:09 lr 0.535246	data 0.0006 (0.1365)	batch 1.2408 (1.4085)	loss -26.1901 (-26.0818)	grad_norm 0.4512 (0.4515)	mem 44912MB
Train: [70/180][200/625]	eta 0:09:43 lr 0.534720	data 0.0005 (0.1028)	batch 1.2300 (1.3726)	loss -25.9486 (-26.0879)	grad_norm 0.4480 (0.4519)	mem 44912MB
Train: [70/180][250/625]	eta 0:08:26 lr 0.534194	data 0.0008 (0.0825)	batch 1.2992 (1.3509)	loss -26.1978 (-26.0870)	grad_norm 0.4607 (0.4515)	mem 44912MB
Train: [70/180][300/625]	eta 0:07:14 lr 0.533668	data 0.0007 (0.0689)	batch 1.2409 (1.3378)	loss -26.2293 (-26.0935)	grad_norm 0.4374 (0.4511)	mem 44912MB
Train: [70/180][350/625]	eta 0:06:05 lr 0.533141	data 0.0007 (0.0592)	batch 1.2888 (1.3278)	loss -26.1566 (-26.0916)	grad_norm 0.4495 (0.4513)	mem 44912MB
Train: [70/180][400/625]	eta 0:04:57 lr 0.532614	data 0.0008 (0.0519)	batch 1.2881 (1.3205)	loss -26.1242 (-26.0926)	grad_norm 0.4406 (0.4516)	mem 44912MB
Train: [70/180][450/625]	eta 0:03:50 lr 0.532087	data 0.0009 (0.0462)	batch 1.2472 (1.3147)	loss -26.2900 (-26.0949)	grad_norm 0.4598 (0.4515)	mem 44912MB
Train: [70/180][500/625]	eta 0:02:43 lr 0.531560	data 0.0005 (0.0417)	batch 1.2808 (1.3104)	loss -26.3008 (-26.0981)	grad_norm 0.4425 (0.4511)	mem 44912MB
Train: [70/180][550/625]	eta 0:01:37 lr 0.531033	data 0.0005 (0.0380)	batch 1.2481 (1.3064)	loss -26.1891 (-26.0986)	grad_norm 0.4640 (0.4511)	mem 44912MB
Train: [70/180][600/625]	eta 0:00:32 lr 0.530505	data 0.0009 (0.0349)	batch 1.2765 (1.3030)	loss -26.1619 (-26.1010)	grad_norm 0.4733 (0.4512)	mem 44912MB
Current slope: None 	
EPOCH 70 training takes 0:13:35
Test: [0/25]	Time 14.922 (14.922)	Loss 1.5180 (1.5180)	Acc@1 66.455 (66.455)	Acc@5 87.109 (87.109)	Mem 44912MB
 * Acc@1 54.968 Acc@5 79.352
Accuracy of the network on the 50000 test images: 54.97%
Max accuracy (after decay): 55.03%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [71/180][0/625]	eta 4:01:57 lr 0.530241	data 21.2902 (21.2902)	batch 23.2280 (23.2280)	loss -26.1304 (-26.1304)	grad_norm 0.4434 (0.4434)	mem 44912MB
Train: [71/180][50/625]	eta 0:16:15 lr 0.529713	data 0.0012 (0.4183)	batch 1.2668 (1.6967)	loss -26.1138 (-26.1756)	grad_norm 0.4442 (0.4486)	mem 44912MB
Train: [71/180][100/625]	eta 0:12:59 lr 0.529184	data 0.0012 (0.2116)	batch 1.2343 (1.4849)	loss -26.3329 (-26.1657)	grad_norm 0.4446 (0.4503)	mem 44912MB
Train: [71/180][150/625]	eta 0:11:10 lr 0.528655	data 0.0006 (0.1418)	batch 1.2653 (1.4108)	loss -25.8996 (-26.1618)	grad_norm 0.4822 (0.4513)	mem 44912MB
Train: [71/180][200/625]	eta 0:09:44 lr 0.528127	data 0.0006 (0.1067)	batch 1.2282 (1.3760)	loss -26.1545 (-26.1538)	grad_norm 0.4372 (0.4513)	mem 44912MB
Train: [71/180][250/625]	eta 0:08:27 lr 0.527597	data 0.0017 (0.0856)	batch 1.2671 (1.3540)	loss -26.2234 (-26.1541)	grad_norm 0.4392 (0.4512)	mem 44912MB
Train: [71/180][300/625]	eta 0:07:15 lr 0.527068	data 0.0008 (0.0715)	batch 1.2221 (1.3389)	loss -26.1715 (-26.1532)	grad_norm 0.4509 (0.4516)	mem 44912MB
Train: [71/180][350/625]	eta 0:06:05 lr 0.526538	data 0.0007 (0.0615)	batch 1.2970 (1.3273)	loss -26.1784 (-26.1510)	grad_norm 0.4486 (0.4520)	mem 44912MB
Train: [71/180][400/625]	eta 0:04:57 lr 0.526008	data 0.0008 (0.0539)	batch 1.2707 (1.3209)	loss -26.1477 (-26.1534)	grad_norm 0.4721 (0.4520)	mem 44912MB
Train: [71/180][450/625]	eta 0:03:50 lr 0.525478	data 0.0006 (0.0480)	batch 1.2728 (1.3147)	loss -26.1392 (-26.1530)	grad_norm 0.4430 (0.4521)	mem 44912MB
Train: [71/180][500/625]	eta 0:02:43 lr 0.524948	data 0.0007 (0.0433)	batch 1.2370 (1.3099)	loss -26.2186 (-26.1550)	grad_norm 0.4472 (0.4521)	mem 44912MB
Train: [71/180][550/625]	eta 0:01:37 lr 0.524417	data 0.0007 (0.0394)	batch 1.2870 (1.3061)	loss -26.1848 (-26.1571)	grad_norm 0.4503 (0.4524)	mem 44912MB
Train: [71/180][600/625]	eta 0:00:32 lr 0.523886	data 0.0013 (0.0362)	batch 1.2817 (1.3028)	loss -25.9983 (-26.1573)	grad_norm 0.4593 (0.4522)	mem 44912MB
Current slope: None 	
EPOCH 71 training takes 0:13:34
Test: [0/25]	Time 14.690 (14.690)	Loss 1.4987 (1.4987)	Acc@1 66.846 (66.846)	Acc@5 88.135 (88.135)	Mem 44912MB
 * Acc@1 54.924 Acc@5 79.480
Accuracy of the network on the 50000 test images: 54.92%
Max accuracy (after decay): 55.03%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [72/180][0/625]	eta 3:57:07 lr 0.523621	data 21.1996 (21.1996)	batch 22.7637 (22.7637)	loss -26.2087 (-26.2087)	grad_norm 0.4752 (0.4752)	mem 44912MB
Train: [72/180][50/625]	eta 0:16:17 lr 0.523089	data 0.0006 (0.4165)	batch 1.2427 (1.7001)	loss -26.4763 (-26.2020)	grad_norm 0.4386 (0.4556)	mem 44912MB
Train: [72/180][100/625]	eta 0:12:58 lr 0.522558	data 0.0010 (0.2107)	batch 1.2890 (1.4838)	loss -26.1855 (-26.2026)	grad_norm 0.4490 (0.4546)	mem 44912MB
Train: [72/180][150/625]	eta 0:11:10 lr 0.522026	data 0.0011 (0.1412)	batch 1.2485 (1.4107)	loss -26.1678 (-26.2083)	grad_norm 0.4799 (0.4545)	mem 44912MB
Train: [72/180][200/625]	eta 0:09:44 lr 0.521494	data 0.0011 (0.1063)	batch 1.2602 (1.3742)	loss -26.1925 (-26.2077)	grad_norm 0.4548 (0.4540)	mem 44912MB
Train: [72/180][250/625]	eta 0:08:28 lr 0.520962	data 0.0008 (0.0853)	batch 1.2364 (1.3547)	loss -26.2618 (-26.2006)	grad_norm 0.4446 (0.4540)	mem 44912MB
Train: [72/180][300/625]	eta 0:07:15 lr 0.520429	data 0.0007 (0.0713)	batch 1.2649 (1.3388)	loss -26.0299 (-26.1984)	grad_norm 0.4508 (0.4538)	mem 44912MB
Train: [72/180][350/625]	eta 0:06:05 lr 0.519897	data 0.0008 (0.0612)	batch 1.3274 (1.3285)	loss -26.3641 (-26.1954)	grad_norm 0.4429 (0.4537)	mem 44912MB
Train: [72/180][400/625]	eta 0:04:57 lr 0.519364	data 0.0006 (0.0537)	batch 1.2301 (1.3210)	loss -26.2972 (-26.1961)	grad_norm 0.4601 (0.4542)	mem 44912MB
Train: [72/180][450/625]	eta 0:03:50 lr 0.518831	data 0.0008 (0.0478)	batch 1.2787 (1.3153)	loss -26.2471 (-26.1970)	grad_norm 0.4640 (0.4542)	mem 44912MB
Train: [72/180][500/625]	eta 0:02:43 lr 0.518297	data 0.0009 (0.0432)	batch 1.2326 (1.3101)	loss -26.2994 (-26.1978)	grad_norm 0.4779 (0.4543)	mem 44912MB
Train: [72/180][550/625]	eta 0:01:37 lr 0.517764	data 0.0004 (0.0394)	batch 1.2552 (1.3058)	loss -26.0559 (-26.1972)	grad_norm 0.4733 (0.4543)	mem 44912MB
Train: [72/180][600/625]	eta 0:00:32 lr 0.517230	data 0.0007 (0.0361)	batch 1.2630 (1.3022)	loss -26.2756 (-26.1984)	grad_norm 0.4386 (0.4539)	mem 44912MB
Current slope: None 	
EPOCH 72 training takes 0:13:34
Test: [0/25]	Time 15.015 (15.015)	Loss 1.4997 (1.4997)	Acc@1 66.650 (66.650)	Acc@5 86.182 (86.182)	Mem 44912MB
 * Acc@1 55.460 Acc@5 79.718
Accuracy of the network on the 50000 test images: 55.46%
Max accuracy (after decay): 55.46%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [73/180][0/625]	eta 4:04:15 lr 0.516963	data 21.4175 (21.4175)	batch 23.4489 (23.4489)	loss -26.0738 (-26.0738)	grad_norm 0.4502 (0.4502)	mem 44912MB
Train: [73/180][50/625]	eta 0:16:17 lr 0.516429	data 0.0007 (0.4209)	batch 1.2635 (1.7001)	loss -26.1054 (-26.2508)	grad_norm 0.4592 (0.4521)	mem 44912MB
Train: [73/180][100/625]	eta 0:13:00 lr 0.515894	data 0.0011 (0.2130)	batch 1.2328 (1.4872)	loss -26.3257 (-26.2373)	grad_norm 0.4528 (0.4532)	mem 44912MB
Train: [73/180][150/625]	eta 0:11:11 lr 0.515360	data 0.0013 (0.1427)	batch 1.2597 (1.4132)	loss -26.2755 (-26.2334)	grad_norm 0.4514 (0.4546)	mem 44912MB
Train: [73/180][200/625]	eta 0:09:44 lr 0.514825	data 0.0006 (0.1074)	batch 1.2916 (1.3757)	loss -26.1620 (-26.2361)	grad_norm 0.4555 (0.4548)	mem 44912MB
Train: [73/180][250/625]	eta 0:08:27 lr 0.514290	data 0.0009 (0.0862)	batch 1.2564 (1.3531)	loss -26.2605 (-26.2315)	grad_norm 0.4600 (0.4551)	mem 44912MB
Train: [73/180][300/625]	eta 0:07:15 lr 0.513754	data 0.0009 (0.0720)	batch 1.2404 (1.3385)	loss -26.2098 (-26.2348)	grad_norm 0.4431 (0.4550)	mem 44912MB
Train: [73/180][350/625]	eta 0:06:05 lr 0.513219	data 0.0015 (0.0619)	batch 1.3143 (1.3280)	loss -26.3504 (-26.2338)	grad_norm 0.4520 (0.4553)	mem 44912MB
Train: [73/180][400/625]	eta 0:04:56 lr 0.512683	data 0.0007 (0.0543)	batch 1.2563 (1.3198)	loss -26.0909 (-26.2336)	grad_norm 0.4473 (0.4553)	mem 44912MB
Train: [73/180][450/625]	eta 0:03:49 lr 0.512147	data 0.0006 (0.0483)	batch 1.3082 (1.3139)	loss -26.2609 (-26.2361)	grad_norm 0.4593 (0.4555)	mem 44912MB
Train: [73/180][500/625]	eta 0:02:43 lr 0.511611	data 0.0005 (0.0436)	batch 1.2359 (1.3094)	loss -26.3243 (-26.2393)	grad_norm 0.4671 (0.4554)	mem 44912MB
Train: [73/180][550/625]	eta 0:01:37 lr 0.511074	data 0.0011 (0.0397)	batch 1.2709 (1.3051)	loss -26.2471 (-26.2408)	grad_norm 0.4509 (0.4556)	mem 44912MB
Train: [73/180][600/625]	eta 0:00:32 lr 0.510538	data 0.0011 (0.0365)	batch 1.2732 (1.3015)	loss -26.1671 (-26.2419)	grad_norm 0.4527 (0.4558)	mem 44912MB
Current slope: None 	
EPOCH 73 training takes 0:13:33
Test: [0/25]	Time 14.645 (14.645)	Loss 1.4639 (1.4639)	Acc@1 66.553 (66.553)	Acc@5 87.354 (87.354)	Mem 44912MB
 * Acc@1 55.140 Acc@5 79.332
Accuracy of the network on the 50000 test images: 55.14%
Max accuracy (after decay): 55.46%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [74/180][0/625]	eta 4:04:08 lr 0.510269	data 21.9408 (21.9408)	batch 23.4382 (23.4382)	loss -26.2821 (-26.2821)	grad_norm 0.4686 (0.4686)	mem 44912MB
Train: [74/180][50/625]	eta 0:16:16 lr 0.509732	data 0.0009 (0.4310)	batch 1.2449 (1.6988)	loss -26.3270 (-26.2625)	grad_norm 0.4496 (0.4571)	mem 44912MB
Train: [74/180][100/625]	eta 0:13:01 lr 0.509195	data 0.0012 (0.2181)	batch 1.4698 (1.4888)	loss -26.1552 (-26.2415)	grad_norm 0.4530 (0.4575)	mem 44912MB
Train: [74/180][150/625]	eta 0:11:11 lr 0.508658	data 0.0006 (0.1461)	batch 1.2471 (1.4143)	loss -26.2969 (-26.2628)	grad_norm 0.4686 (0.4578)	mem 44912MB
Train: [74/180][200/625]	eta 0:09:45 lr 0.508120	data 0.0010 (0.1100)	batch 1.2991 (1.3785)	loss -26.3539 (-26.2642)	grad_norm 0.4439 (0.4574)	mem 44912MB
Train: [74/180][250/625]	eta 0:08:28 lr 0.507583	data 0.0012 (0.0882)	batch 1.2615 (1.3559)	loss -26.0863 (-26.2603)	grad_norm 0.4716 (0.4578)	mem 44912MB
Train: [74/180][300/625]	eta 0:07:15 lr 0.507045	data 0.0005 (0.0737)	batch 1.2732 (1.3408)	loss -26.2768 (-26.2647)	grad_norm 0.4673 (0.4573)	mem 44912MB
Train: [74/180][350/625]	eta 0:06:05 lr 0.506506	data 0.0006 (0.0633)	batch 1.2469 (1.3296)	loss -26.1392 (-26.2674)	grad_norm 0.4592 (0.4576)	mem 44912MB
Train: [74/180][400/625]	eta 0:04:57 lr 0.505968	data 0.0006 (0.0555)	batch 1.2915 (1.3217)	loss -26.4085 (-26.2694)	grad_norm 0.4297 (0.4575)	mem 44912MB
Train: [74/180][450/625]	eta 0:03:50 lr 0.505429	data 0.0006 (0.0494)	batch 1.2678 (1.3152)	loss -26.2291 (-26.2731)	grad_norm 0.4537 (0.4577)	mem 44912MB
Train: [74/180][500/625]	eta 0:02:43 lr 0.504890	data 0.0006 (0.0446)	batch 1.2086 (1.3104)	loss -26.2220 (-26.2746)	grad_norm 0.4481 (0.4572)	mem 44912MB
Train: [74/180][550/625]	eta 0:01:37 lr 0.504351	data 0.0005 (0.0406)	batch 1.3984 (1.3060)	loss -26.3352 (-26.2775)	grad_norm 0.4654 (0.4572)	mem 44912MB
Train: [74/180][600/625]	eta 0:00:32 lr 0.503812	data 0.0004 (0.0373)	batch 1.2595 (1.3022)	loss -26.1122 (-26.2791)	grad_norm 0.4612 (0.4571)	mem 44912MB
Current slope: None 	
EPOCH 74 training takes 0:13:34
Test: [0/25]	Time 14.548 (14.548)	Loss 1.3950 (1.3950)	Acc@1 67.188 (67.188)	Acc@5 89.258 (89.258)	Mem 44912MB
 * Acc@1 55.246 Acc@5 79.798
Accuracy of the network on the 50000 test images: 55.25%
Max accuracy (after decay): 55.46%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [75/180][0/625]	eta 3:57:10 lr 0.503542	data 21.0215 (21.0215)	batch 22.7694 (22.7694)	loss -26.4989 (-26.4989)	grad_norm 0.4448 (0.4448)	mem 44912MB
Train: [75/180][50/625]	eta 0:16:17 lr 0.503003	data 0.0007 (0.4129)	batch 1.2362 (1.7003)	loss -26.3239 (-26.3285)	grad_norm 0.4539 (0.4580)	mem 44912MB
Train: [75/180][100/625]	eta 0:12:59 lr 0.502463	data 0.0006 (0.2089)	batch 1.3114 (1.4846)	loss -26.3454 (-26.3327)	grad_norm 0.4588 (0.4605)	mem 44912MB
Train: [75/180][150/625]	eta 0:11:10 lr 0.501923	data 0.0006 (0.1400)	batch 1.2704 (1.4123)	loss -26.4698 (-26.3309)	grad_norm 0.4682 (0.4602)	mem 44912MB
Train: [75/180][200/625]	eta 0:09:44 lr 0.501383	data 0.0008 (0.1055)	batch 1.2621 (1.3760)	loss -26.2193 (-26.3289)	grad_norm 0.4724 (0.4591)	mem 44912MB
Train: [75/180][250/625]	eta 0:08:28 lr 0.500843	data 0.0007 (0.0846)	batch 1.2276 (1.3551)	loss -26.2902 (-26.3231)	grad_norm 0.4803 (0.4588)	mem 44912MB
Train: [75/180][300/625]	eta 0:07:15 lr 0.500302	data 0.0011 (0.0707)	batch 1.2928 (1.3397)	loss -26.3840 (-26.3266)	grad_norm 0.4469 (0.4586)	mem 44912MB
Train: [75/180][350/625]	eta 0:06:05 lr 0.499761	data 0.0010 (0.0608)	batch 1.2311 (1.3287)	loss -26.3749 (-26.3294)	grad_norm 0.4670 (0.4583)	mem 44912MB
Train: [75/180][400/625]	eta 0:04:57 lr 0.499220	data 0.0006 (0.0533)	batch 1.2408 (1.3206)	loss -26.4606 (-26.3306)	grad_norm 0.4510 (0.4581)	mem 44912MB
Train: [75/180][450/625]	eta 0:03:50 lr 0.498679	data 0.0007 (0.0474)	batch 1.2814 (1.3150)	loss -26.6127 (-26.3324)	grad_norm 0.4645 (0.4580)	mem 44912MB
Train: [75/180][500/625]	eta 0:02:43 lr 0.498138	data 0.0006 (0.0428)	batch 1.2526 (1.3093)	loss -26.5178 (-26.3328)	grad_norm 0.4582 (0.4581)	mem 44912MB
Train: [75/180][550/625]	eta 0:01:37 lr 0.497597	data 0.0005 (0.0390)	batch 1.2585 (1.3050)	loss -26.4444 (-26.3295)	grad_norm 0.4665 (0.4581)	mem 44912MB
Train: [75/180][600/625]	eta 0:00:32 lr 0.497055	data 0.0008 (0.0358)	batch 1.2621 (1.3017)	loss -26.5416 (-26.3303)	grad_norm 0.4508 (0.4577)	mem 44912MB
Current slope: None 	
EPOCH 75 training takes 0:13:33
Test: [0/25]	Time 15.045 (15.045)	Loss 1.5001 (1.5001)	Acc@1 67.090 (67.090)	Acc@5 86.865 (86.865)	Mem 44912MB
 * Acc@1 55.526 Acc@5 79.732
Accuracy of the network on the 50000 test images: 55.53%
Max accuracy (after decay): 55.53%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [76/180][0/625]	eta 3:57:40 lr 0.496784	data 20.2890 (20.2890)	batch 22.8176 (22.8176)	loss -26.2543 (-26.2543)	grad_norm 0.4765 (0.4765)	mem 44912MB
Train: [76/180][50/625]	eta 0:16:11 lr 0.496242	data 0.0011 (0.3989)	batch 1.2363 (1.6897)	loss -26.3654 (-26.3484)	grad_norm 0.4694 (0.4596)	mem 44912MB
Train: [76/180][100/625]	eta 0:12:56 lr 0.495700	data 0.0007 (0.2019)	batch 1.2511 (1.4784)	loss -26.4518 (-26.3473)	grad_norm 0.4439 (0.4585)	mem 44912MB
Train: [76/180][150/625]	eta 0:11:09 lr 0.495157	data 0.0010 (0.1356)	batch 1.2493 (1.4093)	loss -26.2178 (-26.3542)	grad_norm 0.4534 (0.4586)	mem 44912MB
Train: [76/180][200/625]	eta 0:09:43 lr 0.494615	data 0.0009 (0.1020)	batch 1.2684 (1.3734)	loss -26.3650 (-26.3577)	grad_norm 0.4533 (0.4586)	mem 44912MB
Train: [76/180][250/625]	eta 0:08:27 lr 0.494072	data 0.0007 (0.0819)	batch 1.2045 (1.3538)	loss -26.4881 (-26.3558)	grad_norm 0.4575 (0.4592)	mem 44912MB
Train: [76/180][300/625]	eta 0:07:15 lr 0.493529	data 0.0009 (0.0684)	batch 1.2674 (1.3389)	loss -26.3709 (-26.3587)	grad_norm 0.4609 (0.4590)	mem 44912MB
Train: [76/180][350/625]	eta 0:06:05 lr 0.492986	data 0.0007 (0.0588)	batch 1.2476 (1.3281)	loss -26.4643 (-26.3607)	grad_norm 0.4442 (0.4597)	mem 44912MB
Train: [76/180][400/625]	eta 0:04:56 lr 0.492443	data 0.0005 (0.0516)	batch 1.2421 (1.3197)	loss -26.5942 (-26.3606)	grad_norm 0.4540 (0.4597)	mem 44912MB
Train: [76/180][450/625]	eta 0:03:49 lr 0.491899	data 0.0010 (0.0459)	batch 1.2249 (1.3141)	loss -26.3751 (-26.3576)	grad_norm 0.4613 (0.4597)	mem 44912MB
Train: [76/180][500/625]	eta 0:02:43 lr 0.491356	data 0.0010 (0.0415)	batch 1.3011 (1.3095)	loss -26.1999 (-26.3585)	grad_norm 0.4530 (0.4595)	mem 44912MB
Train: [76/180][550/625]	eta 0:01:37 lr 0.490812	data 0.0007 (0.0378)	batch 1.2683 (1.3058)	loss -26.6146 (-26.3583)	grad_norm 0.4535 (0.4593)	mem 44912MB
Train: [76/180][600/625]	eta 0:00:32 lr 0.490268	data 0.0007 (0.0347)	batch 1.3970 (1.3022)	loss -26.3536 (-26.3596)	grad_norm 0.4959 (0.4594)	mem 44912MB
Current slope: None 	
EPOCH 76 training takes 0:13:34
Test: [0/25]	Time 14.914 (14.914)	Loss 1.4073 (1.4073)	Acc@1 69.287 (69.287)	Acc@5 87.549 (87.549)	Mem 44912MB
 * Acc@1 55.892 Acc@5 79.744
Accuracy of the network on the 50000 test images: 55.89%
Max accuracy (after decay): 55.89%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [77/180][0/625]	eta 3:57:12 lr 0.489996	data 21.3090 (21.3090)	batch 22.7726 (22.7726)	loss -26.5781 (-26.5781)	grad_norm 0.4645 (0.4645)	mem 44912MB
Train: [77/180][50/625]	eta 0:16:09 lr 0.489452	data 0.0007 (0.4186)	batch 1.2237 (1.6861)	loss -26.2023 (-26.3807)	grad_norm 0.4579 (0.4612)	mem 44912MB
Train: [77/180][100/625]	eta 0:12:55 lr 0.488907	data 0.0006 (0.2118)	batch 1.2439 (1.4776)	loss -26.1861 (-26.3880)	grad_norm 0.4528 (0.4597)	mem 44912MB
Train: [77/180][150/625]	eta 0:11:07 lr 0.488363	data 0.0006 (0.1419)	batch 1.2260 (1.4061)	loss -26.2189 (-26.3904)	grad_norm 0.4514 (0.4604)	mem 44912MB
Train: [77/180][200/625]	eta 0:09:43 lr 0.487818	data 0.0008 (0.1068)	batch 1.2946 (1.3720)	loss -26.4006 (-26.3921)	grad_norm 0.4542 (0.4596)	mem 44912MB
Train: [77/180][250/625]	eta 0:08:26 lr 0.487273	data 0.0008 (0.0857)	batch 1.2777 (1.3494)	loss -26.2534 (-26.3934)	grad_norm 0.4491 (0.4597)	mem 44912MB
Train: [77/180][300/625]	eta 0:07:13 lr 0.486728	data 0.0008 (0.0716)	batch 1.2578 (1.3354)	loss -26.3812 (-26.3968)	grad_norm 0.4669 (0.4598)	mem 44912MB
Train: [77/180][350/625]	eta 0:06:04 lr 0.486183	data 0.0010 (0.0615)	batch 1.2348 (1.3259)	loss -26.4173 (-26.3993)	grad_norm 0.5025 (0.4601)	mem 44912MB
Train: [77/180][400/625]	eta 0:04:56 lr 0.485637	data 0.0008 (0.0539)	batch 1.2917 (1.3194)	loss -26.4233 (-26.4041)	grad_norm 0.4639 (0.4600)	mem 44912MB
Train: [77/180][450/625]	eta 0:03:49 lr 0.485091	data 0.0010 (0.0480)	batch 1.2410 (1.3128)	loss -26.1986 (-26.4049)	grad_norm 0.4533 (0.4601)	mem 44912MB
Train: [77/180][500/625]	eta 0:02:43 lr 0.484546	data 0.0008 (0.0433)	batch 1.2578 (1.3079)	loss -26.5049 (-26.4065)	grad_norm 0.4578 (0.4603)	mem 44912MB
Train: [77/180][550/625]	eta 0:01:37 lr 0.484000	data 0.0012 (0.0395)	batch 1.2429 (1.3043)	loss -26.3357 (-26.4042)	grad_norm 0.4547 (0.4605)	mem 44912MB
Train: [77/180][600/625]	eta 0:00:32 lr 0.483454	data 0.0006 (0.0363)	batch 1.2693 (1.3013)	loss -26.3172 (-26.4040)	grad_norm 0.4543 (0.4607)	mem 44912MB
Current slope: None 	
EPOCH 77 training takes 0:13:33
Test: [0/25]	Time 14.677 (14.677)	Loss 1.4305 (1.4305)	Acc@1 66.504 (66.504)	Acc@5 87.256 (87.256)	Mem 44912MB
 * Acc@1 55.764 Acc@5 79.790
Accuracy of the network on the 50000 test images: 55.76%
Max accuracy (after decay): 55.89%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [78/180][0/625]	eta 4:04:05 lr 0.483181	data 21.5081 (21.5081)	batch 23.4333 (23.4333)	loss -26.4012 (-26.4012)	grad_norm 0.4654 (0.4654)	mem 44912MB
Train: [78/180][50/625]	eta 0:16:15 lr 0.482634	data 0.0012 (0.4226)	batch 1.2481 (1.6974)	loss -26.4500 (-26.4548)	grad_norm 0.4455 (0.4585)	mem 44912MB
Train: [78/180][100/625]	eta 0:12:58 lr 0.482088	data 0.0006 (0.2138)	batch 1.2541 (1.4828)	loss -26.6043 (-26.4425)	grad_norm 0.4637 (0.4602)	mem 44912MB
Train: [78/180][150/625]	eta 0:11:10 lr 0.481541	data 0.0006 (0.1433)	batch 1.3364 (1.4117)	loss -26.3773 (-26.4378)	grad_norm 0.4611 (0.4616)	mem 44912MB
Train: [78/180][200/625]	eta 0:09:44 lr 0.480994	data 0.0014 (0.1078)	batch 1.4005 (1.3742)	loss -26.4962 (-26.4330)	grad_norm 0.4910 (0.4625)	mem 44912MB
Train: [78/180][250/625]	eta 0:08:27 lr 0.480447	data 0.0007 (0.0865)	batch 1.2496 (1.3523)	loss -26.6818 (-26.4308)	grad_norm 0.4641 (0.4623)	mem 44912MB
Train: [78/180][300/625]	eta 0:07:15 lr 0.479900	data 0.0011 (0.0723)	batch 1.2644 (1.3386)	loss -26.3164 (-26.4319)	grad_norm 0.4664 (0.4627)	mem 44912MB
Train: [78/180][350/625]	eta 0:06:05 lr 0.479353	data 0.0008 (0.0621)	batch 1.2617 (1.3279)	loss -26.7163 (-26.4326)	grad_norm 0.4665 (0.4626)	mem 44912MB
Train: [78/180][400/625]	eta 0:04:57 lr 0.478805	data 0.0005 (0.0545)	batch 1.2632 (1.3201)	loss -26.4384 (-26.4343)	grad_norm 0.4590 (0.4626)	mem 44912MB
Train: [78/180][450/625]	eta 0:03:49 lr 0.478258	data 0.0005 (0.0485)	batch 1.2405 (1.3137)	loss -26.2378 (-26.4351)	grad_norm 0.4643 (0.4627)	mem 44912MB
Train: [78/180][500/625]	eta 0:02:43 lr 0.477710	data 0.0011 (0.0438)	batch 1.2462 (1.3094)	loss -26.4455 (-26.4357)	grad_norm 0.4535 (0.4626)	mem 44912MB
Train: [78/180][550/625]	eta 0:01:37 lr 0.477162	data 0.0006 (0.0399)	batch 1.2466 (1.3056)	loss -26.4896 (-26.4380)	grad_norm 0.4668 (0.4625)	mem 44912MB
Train: [78/180][600/625]	eta 0:00:32 lr 0.476614	data 0.0006 (0.0366)	batch 1.2530 (1.3020)	loss -26.5958 (-26.4375)	grad_norm 0.4735 (0.4623)	mem 44912MB
Current slope: None 	
EPOCH 78 training takes 0:13:34
Test: [0/25]	Time 14.764 (14.764)	Loss 1.4207 (1.4207)	Acc@1 67.383 (67.383)	Acc@5 87.451 (87.451)	Mem 44912MB
 * Acc@1 54.974 Acc@5 79.356
Accuracy of the network on the 50000 test images: 54.97%
Max accuracy (after decay): 55.89%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [79/180][0/625]	eta 4:01:20 lr 0.476340	data 20.9746 (20.9746)	batch 23.1691 (23.1691)	loss -26.4591 (-26.4591)	grad_norm 0.4602 (0.4602)	mem 44912MB
Train: [79/180][50/625]	eta 0:16:15 lr 0.475791	data 0.0010 (0.4121)	batch 1.2790 (1.6962)	loss -26.5450 (-26.4777)	grad_norm 0.4809 (0.4642)	mem 44912MB
Train: [79/180][100/625]	eta 0:12:59 lr 0.475243	data 0.0004 (0.2085)	batch 1.2629 (1.4849)	loss -26.4840 (-26.4747)	grad_norm 0.4492 (0.4639)	mem 44912MB
Train: [79/180][150/625]	eta 0:11:11 lr 0.474694	data 0.0013 (0.1397)	batch 1.2414 (1.4136)	loss -26.5488 (-26.4726)	grad_norm 0.4819 (0.4643)	mem 44912MB
Train: [79/180][200/625]	eta 0:09:44 lr 0.474146	data 0.0007 (0.1052)	batch 1.2168 (1.3756)	loss -26.4783 (-26.4724)	grad_norm 0.4771 (0.4646)	mem 44912MB
Train: [79/180][250/625]	eta 0:08:27 lr 0.473597	data 0.0009 (0.0844)	batch 1.3244 (1.3541)	loss -26.3011 (-26.4702)	grad_norm 0.4564 (0.4647)	mem 44912MB
Train: [79/180][300/625]	eta 0:07:15 lr 0.473048	data 0.0005 (0.0705)	batch 1.2567 (1.3402)	loss -26.5690 (-26.4664)	grad_norm 0.4672 (0.4643)	mem 44912MB
Train: [79/180][350/625]	eta 0:06:05 lr 0.472499	data 0.0010 (0.0605)	batch 1.2420 (1.3297)	loss -26.4474 (-26.4684)	grad_norm 0.4649 (0.4642)	mem 44912MB
Train: [79/180][400/625]	eta 0:04:57 lr 0.471949	data 0.0004 (0.0531)	batch 1.2686 (1.3211)	loss -26.5054 (-26.4697)	grad_norm 0.4778 (0.4642)	mem 44912MB
Train: [79/180][450/625]	eta 0:03:50 lr 0.471400	data 0.0006 (0.0473)	batch 1.2615 (1.3146)	loss -26.4514 (-26.4721)	grad_norm 0.4731 (0.4641)	mem 44912MB
Train: [79/180][500/625]	eta 0:02:43 lr 0.470850	data 0.0005 (0.0426)	batch 1.2649 (1.3096)	loss -26.4672 (-26.4742)	grad_norm 0.4624 (0.4640)	mem 44912MB
Train: [79/180][550/625]	eta 0:01:37 lr 0.470301	data 0.0009 (0.0388)	batch 1.3106 (1.3060)	loss -26.4809 (-26.4731)	grad_norm 0.4926 (0.4641)	mem 44912MB
Train: [79/180][600/625]	eta 0:00:32 lr 0.469751	data 0.0006 (0.0356)	batch 1.2536 (1.3027)	loss -26.2766 (-26.4746)	grad_norm 0.4698 (0.4640)	mem 44912MB
Current slope: None 	
EPOCH 79 training takes 0:13:34
Test: [0/25]	Time 14.967 (14.967)	Loss 1.4315 (1.4315)	Acc@1 68.896 (68.896)	Acc@5 87.646 (87.646)	Mem 44912MB
 * Acc@1 56.020 Acc@5 80.032
Accuracy of the network on the 50000 test images: 56.02%
Max accuracy (after decay): 56.02%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [80/180][0/625]	eta 3:56:55 lr 0.469476	data 20.2768 (20.2768)	batch 22.7452 (22.7452)	loss -26.5476 (-26.5476)	grad_norm 0.4737 (0.4737)	mem 44912MB
Train: [80/180][50/625]	eta 0:16:13 lr 0.468926	data 0.0008 (0.3984)	batch 1.2488 (1.6938)	loss -26.5053 (-26.5319)	grad_norm 0.4871 (0.4659)	mem 44912MB
Train: [80/180][100/625]	eta 0:12:57 lr 0.468376	data 0.0007 (0.2016)	batch 1.3129 (1.4810)	loss -26.5300 (-26.5215)	grad_norm 0.4602 (0.4642)	mem 44912MB
Train: [80/180][150/625]	eta 0:11:09 lr 0.467825	data 0.0009 (0.1351)	batch 1.2535 (1.4089)	loss -26.5309 (-26.5201)	grad_norm 0.4667 (0.4640)	mem 44912MB
Train: [80/180][200/625]	eta 0:09:43 lr 0.467275	data 0.0011 (0.1017)	batch 1.2781 (1.3728)	loss -26.4680 (-26.5161)	grad_norm 0.4630 (0.4643)	mem 44912MB
Train: [80/180][250/625]	eta 0:08:27 lr 0.466724	data 0.0005 (0.0816)	batch 1.3022 (1.3532)	loss -26.5483 (-26.5197)	grad_norm 0.4641 (0.4642)	mem 44912MB
Train: [80/180][300/625]	eta 0:07:14 lr 0.466173	data 0.0008 (0.0682)	batch 1.2512 (1.3380)	loss -26.4649 (-26.5226)	grad_norm 0.4619 (0.4643)	mem 44912MB
Train: [80/180][350/625]	eta 0:06:04 lr 0.465623	data 0.0007 (0.0586)	batch 1.2429 (1.3267)	loss -26.4618 (-26.5212)	grad_norm 0.5054 (0.4647)	mem 44912MB
Train: [80/180][400/625]	eta 0:04:56 lr 0.465072	data 0.0007 (0.0514)	batch 1.3666 (1.3192)	loss -26.4383 (-26.5162)	grad_norm 0.4570 (0.4649)	mem 44912MB
Train: [80/180][450/625]	eta 0:03:49 lr 0.464521	data 0.0007 (0.0458)	batch 1.2744 (1.3143)	loss -26.4879 (-26.5140)	grad_norm 0.4649 (0.4649)	mem 44912MB
Train: [80/180][500/625]	eta 0:02:43 lr 0.463969	data 0.0006 (0.0413)	batch 1.2595 (1.3093)	loss -26.5932 (-26.5154)	grad_norm 0.4507 (0.4651)	mem 44912MB
Train: [80/180][550/625]	eta 0:01:37 lr 0.463418	data 0.0007 (0.0376)	batch 1.2629 (1.3055)	loss -26.5832 (-26.5164)	grad_norm 0.4596 (0.4654)	mem 44912MB
Train: [80/180][600/625]	eta 0:00:32 lr 0.462866	data 0.0012 (0.0345)	batch 1.2598 (1.3022)	loss -26.4779 (-26.5160)	grad_norm 0.4657 (0.4655)	mem 44912MB
Current slope: None 	
EPOCH 80 training takes 0:13:34
Test: [0/25]	Time 14.451 (14.451)	Loss 1.4205 (1.4205)	Acc@1 68.945 (68.945)	Acc@5 88.281 (88.281)	Mem 44912MB
 * Acc@1 55.844 Acc@5 80.028
Accuracy of the network on the 50000 test images: 55.84%
Max accuracy (after decay): 56.02%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [81/180][0/625]	eta 3:52:23 lr 0.462591	data 20.2377 (20.2377)	batch 22.3098 (22.3098)	loss -26.3497 (-26.3497)	grad_norm 0.4566 (0.4566)	mem 44912MB
Train: [81/180][50/625]	eta 0:16:05 lr 0.462039	data 0.0008 (0.3976)	batch 1.3194 (1.6797)	loss -26.3136 (-26.5009)	grad_norm 0.4724 (0.4664)	mem 44912MB
Train: [81/180][100/625]	eta 0:12:55 lr 0.461487	data 0.0008 (0.2012)	batch 1.2419 (1.4762)	loss -26.6602 (-26.5271)	grad_norm 0.4674 (0.4659)	mem 44912MB
Train: [81/180][150/625]	eta 0:11:08 lr 0.460935	data 0.0007 (0.1349)	batch 1.2516 (1.4066)	loss -26.5869 (-26.5345)	grad_norm 0.4424 (0.4663)	mem 44912MB
Train: [81/180][200/625]	eta 0:09:43 lr 0.460383	data 0.0005 (0.1015)	batch 1.2220 (1.3721)	loss -26.5968 (-26.5337)	grad_norm 0.4682 (0.4658)	mem 44912MB
Train: [81/180][250/625]	eta 0:08:26 lr 0.459831	data 0.0006 (0.0815)	batch 1.2164 (1.3502)	loss -26.3776 (-26.5309)	grad_norm 0.4866 (0.4664)	mem 44912MB
Train: [81/180][300/625]	eta 0:07:14 lr 0.459279	data 0.0012 (0.0680)	batch 1.2857 (1.3366)	loss -26.5331 (-26.5308)	grad_norm 0.4533 (0.4664)	mem 44912MB
Train: [81/180][350/625]	eta 0:06:04 lr 0.458727	data 0.0009 (0.0585)	batch 1.2310 (1.3255)	loss -26.4634 (-26.5301)	grad_norm 0.5824 (0.4674)	mem 44912MB
Train: [81/180][400/625]	eta 0:04:56 lr 0.458174	data 0.0007 (0.0513)	batch 1.2498 (1.3187)	loss -26.5299 (-26.5354)	grad_norm 0.4644 (0.4674)	mem 44912MB
Train: [81/180][450/625]	eta 0:03:49 lr 0.457621	data 0.0006 (0.0457)	batch 1.2895 (1.3132)	loss -26.4592 (-26.5358)	grad_norm 0.4641 (0.4676)	mem 44912MB
Train: [81/180][500/625]	eta 0:02:43 lr 0.457069	data 0.0003 (0.0412)	batch 1.5602 (1.3088)	loss -26.5265 (-26.5364)	grad_norm 0.4641 (0.4675)	mem 44912MB
Train: [81/180][550/625]	eta 0:01:37 lr 0.456516	data 0.0007 (0.0375)	batch 1.3148 (1.3043)	loss -26.6036 (-26.5381)	grad_norm 0.4780 (0.4673)	mem 44912MB
Train: [81/180][600/625]	eta 0:00:32 lr 0.455963	data 0.0006 (0.0344)	batch 1.2852 (1.3016)	loss -26.7033 (-26.5383)	grad_norm 0.4729 (0.4672)	mem 44912MB
Current slope: None 	
EPOCH 81 training takes 0:13:33
Test: [0/25]	Time 14.785 (14.785)	Loss 1.4979 (1.4979)	Acc@1 67.627 (67.627)	Acc@5 86.963 (86.963)	Mem 44912MB
 * Acc@1 55.722 Acc@5 79.862
Accuracy of the network on the 50000 test images: 55.72%
Max accuracy (after decay): 56.02%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [82/180][0/625]	eta 3:57:31 lr 0.455686	data 20.5797 (20.5797)	batch 22.8030 (22.8030)	loss -26.4766 (-26.4766)	grad_norm 0.4670 (0.4670)	mem 44912MB
Train: [82/180][50/625]	eta 0:16:12 lr 0.455133	data 0.0012 (0.4044)	batch 1.2385 (1.6908)	loss -26.7033 (-26.5670)	grad_norm 0.4821 (0.4655)	mem 44912MB
Train: [82/180][100/625]	eta 0:12:55 lr 0.454580	data 0.0010 (0.2046)	batch 1.2291 (1.4777)	loss -26.4714 (-26.5738)	grad_norm 0.4749 (0.4661)	mem 44912MB
Train: [82/180][150/625]	eta 0:11:08 lr 0.454027	data 0.0007 (0.1371)	batch 1.2334 (1.4065)	loss -26.7116 (-26.5857)	grad_norm 0.4513 (0.4670)	mem 44912MB
Train: [82/180][200/625]	eta 0:09:42 lr 0.453473	data 0.0006 (0.1032)	batch 1.3005 (1.3710)	loss -26.6305 (-26.5801)	grad_norm 0.4671 (0.4675)	mem 44912MB
Train: [82/180][250/625]	eta 0:08:26 lr 0.452920	data 0.0007 (0.0827)	batch 1.2615 (1.3495)	loss -26.7515 (-26.5735)	grad_norm 0.4782 (0.4676)	mem 44912MB
Train: [82/180][300/625]	eta 0:07:14 lr 0.452366	data 0.0006 (0.0691)	batch 1.2810 (1.3354)	loss -26.5529 (-26.5741)	grad_norm 0.4564 (0.4679)	mem 44912MB
Train: [82/180][350/625]	eta 0:06:04 lr 0.451813	data 0.0005 (0.0594)	batch 1.2898 (1.3249)	loss -26.4323 (-26.5704)	grad_norm 0.4713 (0.4678)	mem 44912MB
Train: [82/180][400/625]	eta 0:04:56 lr 0.451259	data 0.0005 (0.0521)	batch 1.2983 (1.3176)	loss -26.7106 (-26.5712)	grad_norm 0.4783 (0.4677)	mem 44912MB
Train: [82/180][450/625]	eta 0:03:49 lr 0.450705	data 0.0011 (0.0464)	batch 1.2139 (1.3119)	loss -26.5952 (-26.5676)	grad_norm 0.4699 (0.4679)	mem 44912MB
Train: [82/180][500/625]	eta 0:02:43 lr 0.450151	data 0.0005 (0.0418)	batch 1.2791 (1.3069)	loss -26.5440 (-26.5706)	grad_norm 0.4652 (0.4681)	mem 44912MB
Train: [82/180][550/625]	eta 0:01:37 lr 0.449597	data 0.0011 (0.0381)	batch 1.2800 (1.3029)	loss -26.7256 (-26.5724)	grad_norm 0.4615 (0.4680)	mem 44912MB
Train: [82/180][600/625]	eta 0:00:32 lr 0.449042	data 0.0007 (0.0351)	batch 1.2518 (1.3000)	loss -26.4974 (-26.5703)	grad_norm 0.4703 (0.4681)	mem 44912MB
Current slope: None 	
EPOCH 82 training takes 0:13:32
Test: [0/25]	Time 14.742 (14.742)	Loss 1.3543 (1.3543)	Acc@1 68.457 (68.457)	Acc@5 89.209 (89.209)	Mem 44912MB
 * Acc@1 56.032 Acc@5 80.076
Accuracy of the network on the 50000 test images: 56.03%
Max accuracy (after decay): 56.03%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [83/180][0/625]	eta 3:56:30 lr 0.448765	data 20.9285 (20.9285)	batch 22.7053 (22.7053)	loss -26.5946 (-26.5946)	grad_norm 0.4723 (0.4723)	mem 44912MB
Train: [83/180][50/625]	eta 0:16:19 lr 0.448211	data 0.0006 (0.4112)	batch 1.2687 (1.7032)	loss -26.5759 (-26.5670)	grad_norm 0.4607 (0.4698)	mem 44912MB
Train: [83/180][100/625]	eta 0:13:00 lr 0.447656	data 0.0006 (0.2080)	batch 1.2536 (1.4860)	loss -26.6069 (-26.5825)	grad_norm 0.4728 (0.4696)	mem 44912MB
Train: [83/180][150/625]	eta 0:11:12 lr 0.447102	data 0.0009 (0.1394)	batch 1.2693 (1.4163)	loss -26.6603 (-26.5881)	grad_norm 0.4713 (0.4697)	mem 44912MB
Train: [83/180][200/625]	eta 0:09:45 lr 0.446547	data 0.0006 (0.1049)	batch 1.2499 (1.3781)	loss -26.5770 (-26.5841)	grad_norm 0.4589 (0.4704)	mem 44912MB
Train: [83/180][250/625]	eta 0:08:29 lr 0.445993	data 0.0005 (0.0842)	batch 1.2574 (1.3574)	loss -26.7655 (-26.5912)	grad_norm 0.4760 (0.4701)	mem 44912MB
Train: [83/180][300/625]	eta 0:07:15 lr 0.445438	data 0.0006 (0.0703)	batch 1.3324 (1.3407)	loss -26.4879 (-26.5889)	grad_norm 0.4601 (0.4698)	mem 44912MB
Train: [83/180][350/625]	eta 0:06:05 lr 0.444883	data 0.0020 (0.0604)	batch 1.2879 (1.3299)	loss -26.5168 (-26.5907)	grad_norm 0.4559 (0.4699)	mem 44912MB
Train: [83/180][400/625]	eta 0:04:57 lr 0.444328	data 0.0005 (0.0530)	batch 1.2758 (1.3215)	loss -26.6411 (-26.5901)	grad_norm 0.4766 (0.4699)	mem 44912MB
Train: [83/180][450/625]	eta 0:03:50 lr 0.443773	data 0.0006 (0.0472)	batch 1.3138 (1.3162)	loss -26.7448 (-26.5923)	grad_norm 0.4627 (0.4697)	mem 44912MB
Train: [83/180][500/625]	eta 0:02:43 lr 0.443218	data 0.0006 (0.0425)	batch 1.2365 (1.3104)	loss -26.7224 (-26.5935)	grad_norm 0.4593 (0.4700)	mem 44912MB
Train: [83/180][550/625]	eta 0:01:37 lr 0.442662	data 0.0004 (0.0387)	batch 1.3151 (1.3065)	loss -26.6680 (-26.5944)	grad_norm 0.4645 (0.4698)	mem 44912MB
Train: [83/180][600/625]	eta 0:00:32 lr 0.442107	data 0.0007 (0.0356)	batch 1.2717 (1.3026)	loss -26.7074 (-26.5944)	grad_norm 0.4693 (0.4701)	mem 44912MB
Current slope: None 	
EPOCH 83 training takes 0:13:34
Test: [0/25]	Time 14.340 (14.340)	Loss 1.4138 (1.4138)	Acc@1 69.287 (69.287)	Acc@5 87.305 (87.305)	Mem 44912MB
 * Acc@1 55.928 Acc@5 80.020
Accuracy of the network on the 50000 test images: 55.93%
Max accuracy (after decay): 56.03%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [84/180][0/625]	eta 3:59:54 lr 0.441829	data 20.1887 (20.1887)	batch 23.0311 (23.0311)	loss -26.5453 (-26.5453)	grad_norm 0.4723 (0.4723)	mem 44912MB
Train: [84/180][50/625]	eta 0:16:14 lr 0.441274	data 0.0007 (0.3968)	batch 1.2646 (1.6943)	loss -26.8088 (-26.6164)	grad_norm 0.4710 (0.4720)	mem 44912MB
Train: [84/180][100/625]	eta 0:13:00 lr 0.440718	data 0.0384 (0.2012)	batch 1.2459 (1.4865)	loss -26.7192 (-26.6208)	grad_norm 0.4708 (0.4718)	mem 44912MB
Train: [84/180][150/625]	eta 0:11:11 lr 0.440163	data 0.0008 (0.1349)	batch 1.2685 (1.4132)	loss -26.4990 (-26.6183)	grad_norm 0.4731 (0.4711)	mem 44912MB
Train: [84/180][200/625]	eta 0:09:44 lr 0.439607	data 0.0008 (0.1015)	batch 1.3508 (1.3762)	loss -26.5444 (-26.6314)	grad_norm 0.4628 (0.4716)	mem 44912MB
Train: [84/180][250/625]	eta 0:08:27 lr 0.439051	data 0.0006 (0.0814)	batch 1.2575 (1.3545)	loss -26.6448 (-26.6317)	grad_norm 0.4629 (0.4718)	mem 44912MB
Train: [84/180][300/625]	eta 0:07:15 lr 0.438495	data 0.0013 (0.0680)	batch 1.2953 (1.3403)	loss -26.6360 (-26.6330)	grad_norm 0.4623 (0.4719)	mem 44912MB
Train: [84/180][350/625]	eta 0:06:05 lr 0.437939	data 0.0006 (0.0585)	batch 1.2847 (1.3304)	loss -26.5532 (-26.6295)	grad_norm 0.4777 (0.4718)	mem 44912MB
Train: [84/180][400/625]	eta 0:04:57 lr 0.437383	data 0.0009 (0.0513)	batch 1.2859 (1.3225)	loss -26.6547 (-26.6299)	grad_norm 0.4651 (0.4721)	mem 44912MB
Train: [84/180][450/625]	eta 0:03:50 lr 0.436827	data 0.0008 (0.0456)	batch 1.2505 (1.3159)	loss -26.6284 (-26.6265)	grad_norm 0.4626 (0.4720)	mem 44912MB
Train: [84/180][500/625]	eta 0:02:43 lr 0.436271	data 0.0010 (0.0412)	batch 1.3176 (1.3111)	loss -26.6362 (-26.6282)	grad_norm 0.4663 (0.4719)	mem 44912MB
Train: [84/180][550/625]	eta 0:01:37 lr 0.435715	data 0.0005 (0.0376)	batch 1.2239 (1.3064)	loss -26.6224 (-26.6297)	grad_norm 0.4787 (0.4719)	mem 44912MB
Train: [84/180][600/625]	eta 0:00:32 lr 0.435159	data 0.0005 (0.0345)	batch 1.2387 (1.3029)	loss -26.7088 (-26.6279)	grad_norm 0.4634 (0.4719)	mem 44912MB
Current slope: None 	
EPOCH 84 training takes 0:13:34
Test: [0/25]	Time 14.726 (14.726)	Loss 1.4469 (1.4469)	Acc@1 66.992 (66.992)	Acc@5 87.744 (87.744)	Mem 44912MB
 * Acc@1 55.964 Acc@5 79.930
Accuracy of the network on the 50000 test images: 55.96%
Max accuracy (after decay): 56.03%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [85/180][0/625]	eta 4:00:10 lr 0.434881	data 20.4518 (20.4518)	batch 23.0570 (23.0570)	loss -26.7631 (-26.7631)	grad_norm 0.4623 (0.4623)	mem 44912MB
Train: [85/180][50/625]	eta 0:16:13 lr 0.434324	data 0.0013 (0.4028)	batch 1.2636 (1.6936)	loss -26.7291 (-26.6706)	grad_norm 0.4714 (0.4711)	mem 44912MB
Train: [85/180][100/625]	eta 0:12:59 lr 0.433768	data 0.0010 (0.2038)	batch 1.2926 (1.4843)	loss -26.3932 (-26.6628)	grad_norm 0.5547 (0.4717)	mem 44912MB
Train: [85/180][150/625]	eta 0:11:11 lr 0.433211	data 0.0012 (0.1367)	batch 1.2544 (1.4132)	loss -26.8602 (-26.6637)	grad_norm 0.4637 (0.4720)	mem 44912MB
Train: [85/180][200/625]	eta 0:09:45 lr 0.432655	data 0.0007 (0.1029)	batch 1.2668 (1.3768)	loss -26.7729 (-26.6727)	grad_norm 0.4706 (0.4718)	mem 44912MB
Train: [85/180][250/625]	eta 0:08:27 lr 0.432098	data 0.0006 (0.0825)	batch 1.2708 (1.3542)	loss -26.7494 (-26.6648)	grad_norm 0.4902 (0.4718)	mem 44912MB
Train: [85/180][300/625]	eta 0:07:15 lr 0.431541	data 0.0008 (0.0690)	batch 1.2509 (1.3393)	loss -26.7374 (-26.6619)	grad_norm 0.4616 (0.4716)	mem 44912MB
Train: [85/180][350/625]	eta 0:06:05 lr 0.430984	data 0.0005 (0.0593)	batch 1.2520 (1.3289)	loss -26.6805 (-26.6582)	grad_norm 0.4597 (0.4722)	mem 44912MB
Train: [85/180][400/625]	eta 0:04:57 lr 0.430428	data 0.0005 (0.0519)	batch 1.2386 (1.3207)	loss -26.5672 (-26.6626)	grad_norm 0.4839 (0.4723)	mem 44912MB
Train: [85/180][450/625]	eta 0:03:49 lr 0.429871	data 0.0006 (0.0463)	batch 1.2711 (1.3140)	loss -26.5677 (-26.6616)	grad_norm 0.4630 (0.4719)	mem 44912MB
Train: [85/180][500/625]	eta 0:02:43 lr 0.429314	data 0.0006 (0.0418)	batch 1.2590 (1.3090)	loss -26.4198 (-26.6601)	grad_norm 0.4678 (0.4719)	mem 44912MB
Train: [85/180][550/625]	eta 0:01:37 lr 0.428757	data 0.0006 (0.0380)	batch 1.2286 (1.3053)	loss -26.7139 (-26.6617)	grad_norm 0.4707 (0.4724)	mem 44912MB
Train: [85/180][600/625]	eta 0:00:32 lr 0.428200	data 0.0011 (0.0349)	batch 1.2349 (1.3024)	loss -26.4537 (-26.6635)	grad_norm 0.4632 (0.4723)	mem 44912MB
Current slope: None 	
EPOCH 85 training takes 0:13:34
Test: [0/25]	Time 14.607 (14.607)	Loss 1.4086 (1.4086)	Acc@1 68.457 (68.457)	Acc@5 88.184 (88.184)	Mem 44912MB
 * Acc@1 56.604 Acc@5 80.666
Accuracy of the network on the 50000 test images: 56.60%
Max accuracy (after decay): 56.60%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [86/180][0/625]	eta 3:55:42 lr 0.427921	data 20.6726 (20.6726)	batch 22.6278 (22.6278)	loss -26.8328 (-26.8328)	grad_norm 0.4716 (0.4716)	mem 44912MB
Train: [86/180][50/625]	eta 0:16:06 lr 0.427364	data 0.0007 (0.4064)	batch 1.2694 (1.6813)	loss -26.7250 (-26.6627)	grad_norm 0.4659 (0.4740)	mem 44912MB
Train: [86/180][100/625]	eta 0:12:55 lr 0.426807	data 0.0013 (0.2056)	batch 1.2580 (1.4762)	loss -26.6738 (-26.6659)	grad_norm 0.4790 (0.4743)	mem 44912MB
Train: [86/180][150/625]	eta 0:11:08 lr 0.426250	data 0.0005 (0.1378)	batch 1.2515 (1.4070)	loss -26.7233 (-26.6594)	grad_norm 0.4841 (0.4749)	mem 44912MB
Train: [86/180][200/625]	eta 0:09:43 lr 0.425692	data 0.0010 (0.1037)	batch 1.2430 (1.3718)	loss -26.5281 (-26.6656)	grad_norm 0.4686 (0.4751)	mem 44912MB
Train: [86/180][250/625]	eta 0:08:26 lr 0.425135	data 0.0006 (0.0832)	batch 1.2687 (1.3512)	loss -26.6671 (-26.6679)	grad_norm 0.4676 (0.4750)	mem 44912MB
Train: [86/180][300/625]	eta 0:07:14 lr 0.424578	data 0.0006 (0.0695)	batch 1.2872 (1.3371)	loss -26.7607 (-26.6692)	grad_norm 0.4635 (0.4752)	mem 44912MB
Train: [86/180][350/625]	eta 0:06:05 lr 0.424020	data 0.0011 (0.0597)	batch 1.3290 (1.3277)	loss -26.7744 (-26.6712)	grad_norm 0.4834 (0.4750)	mem 44912MB
Train: [86/180][400/625]	eta 0:04:56 lr 0.423463	data 0.0007 (0.0524)	batch 1.2034 (1.3199)	loss -26.8064 (-26.6712)	grad_norm 0.4606 (0.4750)	mem 44912MB
Train: [86/180][450/625]	eta 0:03:49 lr 0.422905	data 0.0007 (0.0466)	batch 1.2365 (1.3140)	loss -26.5588 (-26.6729)	grad_norm 0.4669 (0.4750)	mem 44912MB
Train: [86/180][500/625]	eta 0:02:43 lr 0.422347	data 0.0006 (0.0420)	batch 1.1968 (1.3089)	loss -26.6277 (-26.6746)	grad_norm 0.4814 (0.4751)	mem 44912MB
Train: [86/180][550/625]	eta 0:01:37 lr 0.421790	data 0.0006 (0.0383)	batch 1.3044 (1.3051)	loss -26.7774 (-26.6768)	grad_norm 0.4712 (0.4750)	mem 44912MB
Train: [86/180][600/625]	eta 0:00:32 lr 0.421232	data 0.0007 (0.0352)	batch 1.2487 (1.3016)	loss -26.7196 (-26.6761)	grad_norm 0.4702 (0.4748)	mem 44912MB
Current slope: None 	
EPOCH 86 training takes 0:13:34
Test: [0/25]	Time 14.680 (14.680)	Loss 1.4116 (1.4116)	Acc@1 68.652 (68.652)	Acc@5 88.281 (88.281)	Mem 44912MB
 * Acc@1 56.076 Acc@5 80.242
Accuracy of the network on the 50000 test images: 56.08%
Max accuracy (after decay): 56.60%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [87/180][0/625]	eta 3:59:07 lr 0.420953	data 20.4845 (20.4845)	batch 22.9561 (22.9561)	loss -26.9533 (-26.9533)	grad_norm 0.4683 (0.4683)	mem 44912MB
Train: [87/180][50/625]	eta 0:16:15 lr 0.420396	data 0.0011 (0.4025)	batch 1.2337 (1.6966)	loss -26.7152 (-26.7371)	grad_norm 0.4880 (0.4754)	mem 44912MB
Train: [87/180][100/625]	eta 0:13:00 lr 0.419838	data 0.0006 (0.2037)	batch 1.2168 (1.4861)	loss -26.5538 (-26.7281)	grad_norm 0.4762 (0.4757)	mem 44912MB
Train: [87/180][150/625]	eta 0:11:11 lr 0.419280	data 0.0006 (0.1365)	batch 1.2409 (1.4138)	loss -26.5379 (-26.7221)	grad_norm 0.4871 (0.4754)	mem 44912MB
Train: [87/180][200/625]	eta 0:09:44 lr 0.418722	data 0.0008 (0.1028)	batch 1.2550 (1.3763)	loss -26.7277 (-26.7208)	grad_norm 0.4729 (0.4760)	mem 44912MB
Train: [87/180][250/625]	eta 0:08:28 lr 0.418164	data 0.0006 (0.0824)	batch 1.2630 (1.3547)	loss -26.7933 (-26.7207)	grad_norm 0.4703 (0.4755)	mem 44912MB
Train: [87/180][300/625]	eta 0:07:15 lr 0.417606	data 0.0008 (0.0689)	batch 1.2950 (1.3400)	loss -26.4292 (-26.7185)	grad_norm 0.4766 (0.4753)	mem 44912MB
Train: [87/180][350/625]	eta 0:06:05 lr 0.417048	data 0.0010 (0.0592)	batch 1.2522 (1.3297)	loss -26.6650 (-26.7180)	grad_norm 0.4722 (0.4754)	mem 44912MB
Train: [87/180][400/625]	eta 0:04:57 lr 0.416490	data 0.0008 (0.0519)	batch 1.2781 (1.3219)	loss -26.6898 (-26.7205)	grad_norm 0.4766 (0.4760)	mem 44912MB
Train: [87/180][450/625]	eta 0:03:50 lr 0.415932	data 0.0010 (0.0462)	batch 1.2251 (1.3160)	loss -26.6310 (-26.7217)	grad_norm 0.4805 (0.4759)	mem 44912MB
Train: [87/180][500/625]	eta 0:02:43 lr 0.415374	data 0.0006 (0.0417)	batch 1.2511 (1.3111)	loss -26.8049 (-26.7214)	grad_norm 0.4840 (0.4759)	mem 44912MB
Train: [87/180][550/625]	eta 0:01:38 lr 0.414816	data 0.0011 (0.0380)	batch 1.2806 (1.3072)	loss -26.9155 (-26.7218)	grad_norm 0.4707 (0.4761)	mem 44912MB
Train: [87/180][600/625]	eta 0:00:32 lr 0.414258	data 0.0006 (0.0349)	batch 1.4329 (1.3036)	loss -26.6410 (-26.7209)	grad_norm 0.4676 (0.4758)	mem 44912MB
Current slope: None 	
EPOCH 87 training takes 0:13:35
Test: [0/25]	Time 14.749 (14.749)	Loss 1.3816 (1.3816)	Acc@1 68.848 (68.848)	Acc@5 88.818 (88.818)	Mem 44912MB
 * Acc@1 56.182 Acc@5 80.368
Accuracy of the network on the 50000 test images: 56.18%
Max accuracy (after decay): 56.60%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [88/180][0/625]	eta 4:01:50 lr 0.413979	data 21.4021 (21.4021)	batch 23.2162 (23.2162)	loss -26.6734 (-26.6734)	grad_norm 0.4675 (0.4675)	mem 44912MB
Train: [88/180][50/625]	eta 0:16:20 lr 0.413421	data 0.0016 (0.4206)	batch 1.2837 (1.7044)	loss -26.7490 (-26.7762)	grad_norm 0.4786 (0.4782)	mem 44912MB
Train: [88/180][100/625]	eta 0:13:01 lr 0.412863	data 0.0006 (0.2128)	batch 1.2678 (1.4881)	loss -26.7098 (-26.7484)	grad_norm 0.4727 (0.4784)	mem 44912MB
Train: [88/180][150/625]	eta 0:11:10 lr 0.412305	data 0.0009 (0.1426)	batch 1.2367 (1.4119)	loss -26.6510 (-26.7329)	grad_norm 0.4823 (0.4775)	mem 44912MB
Train: [88/180][200/625]	eta 0:09:44 lr 0.411746	data 0.0008 (0.1073)	batch 1.2460 (1.3753)	loss -26.6940 (-26.7277)	grad_norm 0.4821 (0.4773)	mem 44912MB
Train: [88/180][250/625]	eta 0:08:27 lr 0.411188	data 0.0008 (0.0861)	batch 1.2892 (1.3535)	loss -26.7117 (-26.7270)	grad_norm 0.4785 (0.4778)	mem 44912MB
Train: [88/180][300/625]	eta 0:07:15 lr 0.410630	data 0.0007 (0.0719)	batch 1.2701 (1.3391)	loss -26.7360 (-26.7281)	grad_norm 0.5011 (0.4783)	mem 44912MB
Train: [88/180][350/625]	eta 0:06:05 lr 0.410072	data 0.0005 (0.0618)	batch 1.2434 (1.3277)	loss -26.7322 (-26.7304)	grad_norm 0.4783 (0.4785)	mem 44912MB
Train: [88/180][400/625]	eta 0:04:57 lr 0.409513	data 0.0006 (0.0542)	batch 1.2641 (1.3203)	loss -26.5834 (-26.7316)	grad_norm 0.4987 (0.4785)	mem 44912MB
Train: [88/180][450/625]	eta 0:03:50 lr 0.408955	data 0.0005 (0.0483)	batch 1.2384 (1.3149)	loss -26.7268 (-26.7289)	grad_norm 0.4689 (0.4785)	mem 44912MB
Train: [88/180][500/625]	eta 0:02:43 lr 0.408397	data 0.0007 (0.0435)	batch 1.2175 (1.3102)	loss -26.9330 (-26.7315)	grad_norm 0.4652 (0.4789)	mem 44912MB
Train: [88/180][550/625]	eta 0:01:37 lr 0.407838	data 0.0008 (0.0396)	batch 1.2280 (1.3061)	loss -26.8402 (-26.7321)	grad_norm 0.4730 (0.4787)	mem 44912MB
Train: [88/180][600/625]	eta 0:00:32 lr 0.407280	data 0.0010 (0.0364)	batch 1.2739 (1.3029)	loss -26.5846 (-26.7325)	grad_norm 0.4797 (0.4790)	mem 44912MB
Current slope: None 	
EPOCH 88 training takes 0:13:34
Test: [0/25]	Time 14.702 (14.702)	Loss 1.4457 (1.4457)	Acc@1 68.115 (68.115)	Acc@5 87.451 (87.451)	Mem 44912MB
 * Acc@1 56.000 Acc@5 80.110
Accuracy of the network on the 50000 test images: 56.00%
Max accuracy (after decay): 56.60%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [89/180][0/625]	eta 3:58:36 lr 0.407001	data 20.8002 (20.8002)	batch 22.9062 (22.9062)	loss -26.7858 (-26.7858)	grad_norm 0.4750 (0.4750)	mem 44912MB
Train: [89/180][50/625]	eta 0:16:10 lr 0.406442	data 0.0008 (0.4087)	batch 1.2548 (1.6876)	loss -26.8765 (-26.7640)	grad_norm 0.4748 (0.4757)	mem 44912MB
Train: [89/180][100/625]	eta 0:12:57 lr 0.405884	data 0.0007 (0.2068)	batch 1.2641 (1.4816)	loss -26.6463 (-26.7552)	grad_norm 0.4742 (0.4789)	mem 44912MB
Train: [89/180][150/625]	eta 0:11:10 lr 0.405325	data 0.0009 (0.1385)	batch 1.2482 (1.4113)	loss -27.0088 (-26.7595)	grad_norm 0.4842 (0.4785)	mem 44912MB
Train: [89/180][200/625]	eta 0:09:44 lr 0.404767	data 0.0006 (0.1043)	batch 1.2312 (1.3753)	loss -26.6820 (-26.7555)	grad_norm 0.4693 (0.4787)	mem 44912MB
Train: [89/180][250/625]	eta 0:08:27 lr 0.404209	data 0.0007 (0.0836)	batch 1.2694 (1.3531)	loss -26.6883 (-26.7517)	grad_norm 0.4959 (0.4788)	mem 44912MB
Train: [89/180][300/625]	eta 0:07:14 lr 0.403650	data 0.0006 (0.0699)	batch 1.2315 (1.3381)	loss -26.7734 (-26.7512)	grad_norm 0.4998 (0.4793)	mem 44912MB
Train: [89/180][350/625]	eta 0:06:05 lr 0.403092	data 0.0010 (0.0600)	batch 1.2391 (1.3276)	loss -26.7726 (-26.7562)	grad_norm 0.4834 (0.4792)	mem 44912MB
Train: [89/180][400/625]	eta 0:04:56 lr 0.402533	data 0.0005 (0.0526)	batch 1.2984 (1.3199)	loss -26.8152 (-26.7554)	grad_norm 0.4712 (0.4794)	mem 44912MB
Train: [89/180][450/625]	eta 0:03:49 lr 0.401975	data 0.0007 (0.0468)	batch 1.2548 (1.3135)	loss -26.8417 (-26.7551)	grad_norm 0.4684 (0.4792)	mem 44912MB
Train: [89/180][500/625]	eta 0:02:43 lr 0.401416	data 0.0007 (0.0422)	batch 1.2860 (1.3094)	loss -26.7603 (-26.7565)	grad_norm 0.4630 (0.4792)	mem 44912MB
Train: [89/180][550/625]	eta 0:01:37 lr 0.400858	data 0.0005 (0.0385)	batch 1.3375 (1.3058)	loss -26.3934 (-26.7558)	grad_norm 0.4807 (0.4793)	mem 44912MB
Train: [89/180][600/625]	eta 0:00:32 lr 0.400299	data 0.0006 (0.0353)	batch 1.2572 (1.3025)	loss -26.6686 (-26.7547)	grad_norm 0.5129 (0.4795)	mem 44912MB
Current slope: None 	
EPOCH 89 training takes 0:13:34
Test: [0/25]	Time 15.107 (15.107)	Loss 1.3837 (1.3837)	Acc@1 68.506 (68.506)	Acc@5 88.232 (88.232)	Mem 44912MB
 * Acc@1 56.854 Acc@5 80.768
Accuracy of the network on the 50000 test images: 56.85%
Max accuracy (after decay): 56.85%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [90/180][0/625]	eta 4:03:11 lr 0.400020	data 20.6981 (20.6981)	batch 23.3464 (23.3464)	loss -26.5282 (-26.5282)	grad_norm 0.4698 (0.4698)	mem 44912MB
Train: [90/180][50/625]	eta 0:16:23 lr 0.399462	data 0.0009 (0.4067)	batch 1.2614 (1.7105)	loss -26.6714 (-26.7867)	grad_norm 0.4861 (0.4795)	mem 44912MB
Train: [90/180][100/625]	eta 0:13:02 lr 0.398903	data 0.0007 (0.2058)	batch 1.2618 (1.4910)	loss -26.8772 (-26.7777)	grad_norm 0.4720 (0.4801)	mem 44912MB
Train: [90/180][150/625]	eta 0:11:13 lr 0.398345	data 0.0011 (0.1382)	batch 1.2495 (1.4174)	loss -26.7023 (-26.7804)	grad_norm 0.5008 (0.4812)	mem 44912MB
Train: [90/180][200/625]	eta 0:09:46 lr 0.397786	data 0.0006 (0.1040)	batch 1.2968 (1.3796)	loss -26.9096 (-26.7814)	grad_norm 0.4841 (0.4814)	mem 44912MB
Train: [90/180][250/625]	eta 0:08:29 lr 0.397228	data 0.0008 (0.0835)	batch 1.2338 (1.3582)	loss -26.7720 (-26.7759)	grad_norm 0.4949 (0.4822)	mem 44912MB
Train: [90/180][300/625]	eta 0:07:16 lr 0.396669	data 0.0009 (0.0698)	batch 1.2647 (1.3423)	loss -26.5721 (-26.7750)	grad_norm 0.4718 (0.4818)	mem 44912MB
Train: [90/180][350/625]	eta 0:06:06 lr 0.396111	data 0.0006 (0.0599)	batch 1.3044 (1.3330)	loss -26.9660 (-26.7731)	grad_norm 0.4708 (0.4815)	mem 44912MB
Train: [90/180][400/625]	eta 0:04:57 lr 0.395552	data 0.0005 (0.0526)	batch 1.2877 (1.3243)	loss -26.8737 (-26.7752)	grad_norm 0.4715 (0.4820)	mem 44912MB
Train: [90/180][450/625]	eta 0:03:50 lr 0.394994	data 0.0008 (0.0468)	batch 1.2457 (1.3181)	loss -26.6298 (-26.7756)	grad_norm 0.4743 (0.4817)	mem 44912MB
Train: [90/180][500/625]	eta 0:02:44 lr 0.394435	data 0.0008 (0.0422)	batch 1.2419 (1.3125)	loss -26.6934 (-26.7766)	grad_norm 0.4740 (0.4813)	mem 44912MB
Train: [90/180][550/625]	eta 0:01:38 lr 0.393877	data 0.0009 (0.0384)	batch 1.2640 (1.3081)	loss -26.9043 (-26.7762)	grad_norm 0.4697 (0.4814)	mem 44912MB
Train: [90/180][600/625]	eta 0:00:32 lr 0.393319	data 0.0008 (0.0353)	batch 1.2333 (1.3041)	loss -26.5514 (-26.7749)	grad_norm 0.5001 (0.4815)	mem 44912MB
Current slope: None 	
EPOCH 90 training takes 0:13:35
Test: [0/25]	Time 14.738 (14.738)	Loss 1.3736 (1.3736)	Acc@1 68.701 (68.701)	Acc@5 87.695 (87.695)	Mem 44912MB
 * Acc@1 56.588 Acc@5 80.504
Accuracy of the network on the 50000 test images: 56.59%
Max accuracy (after decay): 56.85%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [91/180][0/625]	eta 3:58:40 lr 0.393039	data 20.7260 (20.7260)	batch 22.9131 (22.9131)	loss -26.6365 (-26.6365)	grad_norm 0.4873 (0.4873)	mem 44912MB
Train: [91/180][50/625]	eta 0:16:18 lr 0.392481	data 0.0007 (0.4075)	batch 1.2789 (1.7019)	loss -26.8926 (-26.8004)	grad_norm 0.4712 (0.4814)	mem 44912MB
Train: [91/180][100/625]	eta 0:13:01 lr 0.391923	data 0.0007 (0.2062)	batch 1.2868 (1.4880)	loss -26.8750 (-26.8095)	grad_norm 0.4653 (0.4842)	mem 44912MB
Train: [91/180][150/625]	eta 0:11:12 lr 0.391364	data 0.0010 (0.1382)	batch 1.2662 (1.4160)	loss -26.7258 (-26.8049)	grad_norm 0.4843 (0.4848)	mem 44912MB
Train: [91/180][200/625]	eta 0:09:46 lr 0.390806	data 0.0008 (0.1040)	batch 1.2363 (1.3789)	loss -26.9572 (-26.8064)	grad_norm 0.4828 (0.4833)	mem 44912MB
Train: [91/180][250/625]	eta 0:08:28 lr 0.390248	data 0.0006 (0.0835)	batch 1.2391 (1.3570)	loss -26.8872 (-26.8056)	grad_norm 0.4833 (0.4841)	mem 44912MB
Train: [91/180][300/625]	eta 0:07:16 lr 0.389689	data 0.0006 (0.0697)	batch 1.2508 (1.3417)	loss -26.7426 (-26.8063)	grad_norm 0.4763 (0.4837)	mem 44912MB
Train: [91/180][350/625]	eta 0:06:06 lr 0.389131	data 0.0006 (0.0599)	batch 1.2541 (1.3310)	loss -26.6803 (-26.8043)	grad_norm 0.4920 (0.4837)	mem 44912MB
Train: [91/180][400/625]	eta 0:04:57 lr 0.388573	data 0.0007 (0.0525)	batch 1.2977 (1.3235)	loss -27.0485 (-26.8037)	grad_norm 0.4795 (0.4838)	mem 44912MB
Train: [91/180][450/625]	eta 0:03:50 lr 0.388015	data 0.0006 (0.0468)	batch 1.2485 (1.3174)	loss -26.9552 (-26.8017)	grad_norm 0.4849 (0.4838)	mem 44912MB
Train: [91/180][500/625]	eta 0:02:44 lr 0.387456	data 0.0006 (0.0422)	batch 1.2709 (1.3122)	loss -26.7365 (-26.8027)	grad_norm 0.4797 (0.4840)	mem 44912MB
Train: [91/180][550/625]	eta 0:01:38 lr 0.386898	data 0.0014 (0.0384)	batch 1.2596 (1.3079)	loss -26.8725 (-26.8038)	grad_norm 0.4892 (0.4840)	mem 44912MB
Train: [91/180][600/625]	eta 0:00:32 lr 0.386340	data 0.0005 (0.0354)	batch 1.4874 (1.3046)	loss -26.8905 (-26.8041)	grad_norm 0.4610 (0.4838)	mem 44912MB
Current slope: None 	
EPOCH 91 training takes 0:13:35
Test: [0/25]	Time 14.764 (14.764)	Loss 1.3690 (1.3690)	Acc@1 69.189 (69.189)	Acc@5 88.672 (88.672)	Mem 44912MB
 * Acc@1 57.048 Acc@5 80.736
Accuracy of the network on the 50000 test images: 57.05%
Max accuracy (after decay): 57.05%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [92/180][0/625]	eta 4:00:12 lr 0.386061	data 21.7263 (21.7263)	batch 23.0602 (23.0602)	loss -26.7280 (-26.7280)	grad_norm 0.5092 (0.5092)	mem 44912MB
Train: [92/180][50/625]	eta 0:16:12 lr 0.385503	data 0.0008 (0.4268)	batch 1.2498 (1.6905)	loss -26.7083 (-26.8108)	grad_norm 0.4935 (0.4840)	mem 44912MB
Train: [92/180][100/625]	eta 0:12:57 lr 0.384945	data 0.0007 (0.2159)	batch 1.2380 (1.4811)	loss -26.9234 (-26.8148)	grad_norm 0.4818 (0.4849)	mem 44912MB
Train: [92/180][150/625]	eta 0:11:10 lr 0.384387	data 0.0005 (0.1447)	batch 1.3750 (1.4113)	loss -26.7907 (-26.8182)	grad_norm 0.4872 (0.4846)	mem 44912MB
Train: [92/180][200/625]	eta 0:09:44 lr 0.383829	data 0.0013 (0.1089)	batch 1.2432 (1.3762)	loss -26.9377 (-26.8248)	grad_norm 0.4851 (0.4844)	mem 44912MB
Train: [92/180][250/625]	eta 0:08:27 lr 0.383271	data 0.0005 (0.0874)	batch 1.2728 (1.3535)	loss -26.8273 (-26.8188)	grad_norm 0.4742 (0.4850)	mem 44912MB
Train: [92/180][300/625]	eta 0:07:15 lr 0.382713	data 0.0006 (0.0730)	batch 1.2665 (1.3392)	loss -26.6297 (-26.8111)	grad_norm 0.4838 (0.4851)	mem 44912MB
Train: [92/180][350/625]	eta 0:06:05 lr 0.382155	data 0.0006 (0.0627)	batch 1.2871 (1.3288)	loss -26.8155 (-26.8141)	grad_norm 0.4844 (0.4851)	mem 44912MB
Train: [92/180][400/625]	eta 0:04:57 lr 0.381597	data 0.0005 (0.0550)	batch 1.2569 (1.3214)	loss -26.8966 (-26.8112)	grad_norm 0.4911 (0.4851)	mem 44912MB
Train: [92/180][450/625]	eta 0:03:50 lr 0.381039	data 0.0012 (0.0490)	batch 1.2588 (1.3145)	loss -26.7453 (-26.8122)	grad_norm 0.4828 (0.4854)	mem 44912MB
Train: [92/180][500/625]	eta 0:02:43 lr 0.380481	data 0.0004 (0.0441)	batch 1.2602 (1.3099)	loss -26.9625 (-26.8126)	grad_norm 0.4758 (0.4856)	mem 44912MB
Train: [92/180][550/625]	eta 0:01:37 lr 0.379923	data 0.0007 (0.0402)	batch 1.2563 (1.3061)	loss -27.0386 (-26.8150)	grad_norm 0.5019 (0.4855)	mem 44912MB
Train: [92/180][600/625]	eta 0:00:32 lr 0.379366	data 0.0009 (0.0369)	batch 1.2410 (1.3029)	loss -26.7971 (-26.8163)	grad_norm 0.4829 (0.4853)	mem 44912MB
Current slope: None 	
EPOCH 92 training takes 0:13:34
Test: [0/25]	Time 14.640 (14.640)	Loss 1.3686 (1.3686)	Acc@1 69.287 (69.287)	Acc@5 88.281 (88.281)	Mem 44912MB
 * Acc@1 56.992 Acc@5 80.774
Accuracy of the network on the 50000 test images: 56.99%
Max accuracy (after decay): 57.05%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [93/180][0/625]	eta 3:57:52 lr 0.379087	data 21.2504 (21.2504)	batch 22.8362 (22.8362)	loss -26.7642 (-26.7642)	grad_norm 0.4876 (0.4876)	mem 44912MB
Train: [93/180][50/625]	eta 0:16:11 lr 0.378529	data 0.0010 (0.4175)	batch 1.3209 (1.6902)	loss -26.9950 (-26.8697)	grad_norm 0.4772 (0.4867)	mem 44912MB
Train: [93/180][100/625]	eta 0:12:57 lr 0.377971	data 0.0007 (0.2112)	batch 1.2341 (1.4814)	loss -26.7877 (-26.8543)	grad_norm 0.4746 (0.4878)	mem 44912MB
Train: [93/180][150/625]	eta 0:11:11 lr 0.377414	data 0.0008 (0.1421)	batch 1.2710 (1.4141)	loss -26.8614 (-26.8534)	grad_norm 0.4789 (0.4877)	mem 44912MB
Train: [93/180][200/625]	eta 0:09:44 lr 0.376856	data 0.0007 (0.1069)	batch 1.2694 (1.3760)	loss -26.7596 (-26.8459)	grad_norm 0.4934 (0.4880)	mem 44912MB
Train: [93/180][250/625]	eta 0:08:27 lr 0.376299	data 0.0006 (0.0858)	batch 1.2527 (1.3534)	loss -27.0648 (-26.8474)	grad_norm 0.4933 (0.4882)	mem 44912MB
Train: [93/180][300/625]	eta 0:07:14 lr 0.375741	data 0.0006 (0.0717)	batch 1.2865 (1.3383)	loss -26.8900 (-26.8538)	grad_norm 0.4778 (0.4878)	mem 44912MB
Train: [93/180][350/625]	eta 0:06:05 lr 0.375184	data 0.0008 (0.0615)	batch 1.2848 (1.3299)	loss -26.8081 (-26.8529)	grad_norm 0.4741 (0.4877)	mem 44912MB
Train: [93/180][400/625]	eta 0:04:57 lr 0.374626	data 0.0012 (0.0540)	batch 1.2514 (1.3222)	loss -26.6794 (-26.8546)	grad_norm 0.4778 (0.4878)	mem 44912MB
Train: [93/180][450/625]	eta 0:03:50 lr 0.374069	data 0.0007 (0.0481)	batch 1.2612 (1.3159)	loss -26.7214 (-26.8531)	grad_norm 0.5007 (0.4878)	mem 44912MB
Train: [93/180][500/625]	eta 0:02:43 lr 0.373512	data 0.0006 (0.0434)	batch 1.3657 (1.3113)	loss -26.6542 (-26.8512)	grad_norm 0.4780 (0.4878)	mem 44912MB
Train: [93/180][550/625]	eta 0:01:38 lr 0.372955	data 0.0006 (0.0395)	batch 1.2889 (1.3079)	loss -26.8412 (-26.8495)	grad_norm 0.4709 (0.4876)	mem 44912MB
Train: [93/180][600/625]	eta 0:00:32 lr 0.372397	data 0.0005 (0.0363)	batch 1.3096 (1.3045)	loss -26.8705 (-26.8485)	grad_norm 0.4879 (0.4876)	mem 44912MB
Current slope: None 	
EPOCH 93 training takes 0:13:35
Test: [0/25]	Time 14.450 (14.450)	Loss 1.4374 (1.4374)	Acc@1 68.750 (68.750)	Acc@5 87.549 (87.549)	Mem 44912MB
 * Acc@1 56.472 Acc@5 80.374
Accuracy of the network on the 50000 test images: 56.47%
Max accuracy (after decay): 57.05%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [94/180][0/625]	eta 3:58:42 lr 0.372119	data 21.0420 (21.0420)	batch 22.9159 (22.9159)	loss -26.7963 (-26.7963)	grad_norm 0.4865 (0.4865)	mem 44912MB
Train: [94/180][50/625]	eta 0:16:15 lr 0.371562	data 0.0006 (0.4135)	batch 1.2560 (1.6959)	loss -27.0306 (-26.8904)	grad_norm 0.4842 (0.4923)	mem 44912MB
Train: [94/180][100/625]	eta 0:12:58 lr 0.371005	data 0.0010 (0.2092)	batch 1.2651 (1.4820)	loss -26.9104 (-26.8828)	grad_norm 0.4732 (0.4906)	mem 44912MB
Train: [94/180][150/625]	eta 0:11:10 lr 0.370448	data 0.0006 (0.1403)	batch 1.2235 (1.4118)	loss -26.8430 (-26.8739)	grad_norm 0.4913 (0.4905)	mem 44912MB
Train: [94/180][200/625]	eta 0:09:44 lr 0.369891	data 0.0008 (0.1056)	batch 1.2476 (1.3745)	loss -26.8887 (-26.8727)	grad_norm 0.4827 (0.4901)	mem 44912MB
Train: [94/180][250/625]	eta 0:08:27 lr 0.369334	data 0.0005 (0.0847)	batch 1.2614 (1.3527)	loss -26.8557 (-26.8736)	grad_norm 0.4943 (0.4899)	mem 44912MB
Train: [94/180][300/625]	eta 0:07:14 lr 0.368777	data 0.0007 (0.0708)	batch 1.2687 (1.3380)	loss -26.7056 (-26.8735)	grad_norm 0.4885 (0.4902)	mem 44912MB
Train: [94/180][350/625]	eta 0:06:05 lr 0.368220	data 0.0013 (0.0608)	batch 1.2344 (1.3286)	loss -26.9882 (-26.8737)	grad_norm 0.4797 (0.4897)	mem 44912MB
Train: [94/180][400/625]	eta 0:04:57 lr 0.367664	data 0.0006 (0.0533)	batch 1.2363 (1.3205)	loss -26.8931 (-26.8728)	grad_norm 0.4760 (0.4898)	mem 44912MB
Train: [94/180][450/625]	eta 0:03:49 lr 0.367107	data 0.0006 (0.0475)	batch 1.3292 (1.3142)	loss -26.9548 (-26.8722)	grad_norm 0.4832 (0.4902)	mem 44912MB
Train: [94/180][500/625]	eta 0:02:43 lr 0.366551	data 0.0007 (0.0428)	batch 1.2702 (1.3092)	loss -26.9753 (-26.8679)	grad_norm 0.4931 (0.4899)	mem 44912MB
Train: [94/180][550/625]	eta 0:01:37 lr 0.365994	data 0.0006 (0.0390)	batch 1.2683 (1.3055)	loss -26.6592 (-26.8664)	grad_norm 0.4889 (0.4899)	mem 44912MB
Train: [94/180][600/625]	eta 0:00:32 lr 0.365438	data 0.0010 (0.0358)	batch 1.2654 (1.3020)	loss -26.7275 (-26.8655)	grad_norm 0.4777 (0.4899)	mem 44912MB
Current slope: None 	
EPOCH 94 training takes 0:13:34
Test: [0/25]	Time 14.472 (14.472)	Loss 1.3586 (1.3586)	Acc@1 69.824 (69.824)	Acc@5 88.184 (88.184)	Mem 44912MB
 * Acc@1 57.014 Acc@5 80.690
Accuracy of the network on the 50000 test images: 57.01%
Max accuracy (after decay): 57.05%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [95/180][0/625]	eta 3:59:39 lr 0.365159	data 21.4878 (21.4878)	batch 23.0070 (23.0070)	loss -27.0707 (-27.0707)	grad_norm 0.4874 (0.4874)	mem 44912MB
Train: [95/180][50/625]	eta 0:16:12 lr 0.364603	data 0.0012 (0.4224)	batch 1.2418 (1.6911)	loss -26.8970 (-26.8909)	grad_norm 0.4950 (0.4909)	mem 44912MB
Train: [95/180][100/625]	eta 0:12:58 lr 0.364047	data 0.0006 (0.2137)	batch 1.2637 (1.4837)	loss -26.9138 (-26.8837)	grad_norm 0.5008 (0.4907)	mem 44912MB
Train: [95/180][150/625]	eta 0:11:09 lr 0.363491	data 0.0008 (0.1432)	batch 1.2269 (1.4095)	loss -27.0151 (-26.8834)	grad_norm 0.5062 (0.4913)	mem 44912MB
Train: [95/180][200/625]	eta 0:09:43 lr 0.362935	data 0.0008 (0.1078)	batch 1.2756 (1.3726)	loss -26.7416 (-26.8851)	grad_norm 0.5007 (0.4905)	mem 44912MB
Train: [95/180][250/625]	eta 0:08:27 lr 0.362379	data 0.0006 (0.0866)	batch 1.3079 (1.3520)	loss -26.7457 (-26.8779)	grad_norm 0.4859 (0.4905)	mem 44912MB
Train: [95/180][300/625]	eta 0:07:15 lr 0.361823	data 0.0008 (0.0724)	batch 1.2458 (1.3388)	loss -27.0026 (-26.8819)	grad_norm 0.4987 (0.4905)	mem 44912MB
Train: [95/180][350/625]	eta 0:06:05 lr 0.361267	data 0.0007 (0.0622)	batch 1.2545 (1.3281)	loss -26.8914 (-26.8833)	grad_norm 0.4960 (0.4905)	mem 44912MB
Train: [95/180][400/625]	eta 0:04:56 lr 0.360711	data 0.0007 (0.0545)	batch 1.2678 (1.3197)	loss -26.9184 (-26.8805)	grad_norm 0.4926 (0.4907)	mem 44912MB
Train: [95/180][450/625]	eta 0:03:49 lr 0.360155	data 0.0011 (0.0485)	batch 1.2433 (1.3133)	loss -26.7112 (-26.8805)	grad_norm 0.4859 (0.4908)	mem 44912MB
Train: [95/180][500/625]	eta 0:02:43 lr 0.359600	data 0.0006 (0.0438)	batch 1.2605 (1.3093)	loss -27.0226 (-26.8814)	grad_norm 0.4883 (0.4908)	mem 44912MB
Train: [95/180][550/625]	eta 0:01:37 lr 0.359044	data 0.0006 (0.0399)	batch 1.2442 (1.3051)	loss -26.8469 (-26.8793)	grad_norm 0.4805 (0.4909)	mem 44912MB
Train: [95/180][600/625]	eta 0:00:32 lr 0.358488	data 0.0007 (0.0366)	batch 1.2793 (1.3016)	loss -27.0666 (-26.8803)	grad_norm 0.4815 (0.4905)	mem 44912MB
Current slope: None 	
EPOCH 95 training takes 0:13:33
Test: [0/25]	Time 14.850 (14.850)	Loss 1.3067 (1.3067)	Acc@1 69.336 (69.336)	Acc@5 89.502 (89.502)	Mem 44912MB
 * Acc@1 57.060 Acc@5 80.864
Accuracy of the network on the 50000 test images: 57.06%
Max accuracy (after decay): 57.06%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [96/180][0/625]	eta 3:56:32 lr 0.358211	data 20.0346 (20.0346)	batch 22.7077 (22.7077)	loss -26.7499 (-26.7499)	grad_norm 0.4911 (0.4911)	mem 44912MB
Train: [96/180][50/625]	eta 0:16:14 lr 0.357655	data 0.0005 (0.3939)	batch 1.2970 (1.6956)	loss -26.8703 (-26.8973)	grad_norm 0.5155 (0.4919)	mem 44912MB
Train: [96/180][100/625]	eta 0:12:59 lr 0.357100	data 0.0005 (0.1993)	batch 1.2631 (1.4842)	loss -26.8816 (-26.9024)	grad_norm 0.4927 (0.4926)	mem 44912MB
Train: [96/180][150/625]	eta 0:11:11 lr 0.356545	data 0.0005 (0.1336)	batch 1.2544 (1.4127)	loss -26.9991 (-26.8937)	grad_norm 0.4923 (0.4932)	mem 44912MB
Train: [96/180][200/625]	eta 0:09:44 lr 0.355990	data 0.0008 (0.1006)	batch 1.2528 (1.3753)	loss -26.7776 (-26.8958)	grad_norm 0.4995 (0.4928)	mem 44912MB
Train: [96/180][250/625]	eta 0:08:27 lr 0.355435	data 0.0006 (0.0807)	batch 1.2506 (1.3528)	loss -26.9721 (-26.8923)	grad_norm 0.4785 (0.4930)	mem 44912MB
Train: [96/180][300/625]	eta 0:07:15 lr 0.354880	data 0.0012 (0.0674)	batch 1.2133 (1.3388)	loss -26.8787 (-26.8971)	grad_norm 0.4954 (0.4928)	mem 44912MB
Train: [96/180][350/625]	eta 0:06:05 lr 0.354325	data 0.0011 (0.0579)	batch 1.2384 (1.3283)	loss -26.8391 (-26.8966)	grad_norm 0.5042 (0.4929)	mem 44912MB
Train: [96/180][400/625]	eta 0:04:56 lr 0.353770	data 0.0006 (0.0508)	batch 1.2642 (1.3197)	loss -26.9891 (-26.8998)	grad_norm 0.5128 (0.4929)	mem 44912MB
Train: [96/180][450/625]	eta 0:03:49 lr 0.353215	data 0.0007 (0.0452)	batch 1.2608 (1.3139)	loss -26.8035 (-26.8999)	grad_norm 0.4991 (0.4928)	mem 44912MB
Train: [96/180][500/625]	eta 0:02:43 lr 0.352661	data 0.0005 (0.0408)	batch 1.2629 (1.3094)	loss -26.8342 (-26.9025)	grad_norm 0.4772 (0.4926)	mem 44912MB
Train: [96/180][550/625]	eta 0:01:37 lr 0.352106	data 0.0011 (0.0372)	batch 1.2298 (1.3050)	loss -27.0287 (-26.9007)	grad_norm 0.5052 (0.4928)	mem 44912MB
Train: [96/180][600/625]	eta 0:00:32 lr 0.351552	data 0.0005 (0.0341)	batch 1.2861 (1.3017)	loss -27.0191 (-26.8988)	grad_norm 0.5003 (0.4927)	mem 44912MB
Current slope: None 	
EPOCH 96 training takes 0:13:33
Test: [0/25]	Time 14.773 (14.773)	Loss 1.3399 (1.3399)	Acc@1 69.727 (69.727)	Acc@5 89.111 (89.111)	Mem 44912MB
 * Acc@1 56.854 Acc@5 80.826
Accuracy of the network on the 50000 test images: 56.85%
Max accuracy (after decay): 57.06%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [97/180][0/625]	eta 3:56:45 lr 0.351275	data 21.1438 (21.1438)	batch 22.7285 (22.7285)	loss -26.9925 (-26.9925)	grad_norm 0.4865 (0.4865)	mem 44912MB
Train: [97/180][50/625]	eta 0:16:11 lr 0.350720	data 0.0008 (0.4153)	batch 1.2490 (1.6892)	loss -26.9569 (-26.9218)	grad_norm 0.5359 (0.4933)	mem 44912MB
Train: [97/180][100/625]	eta 0:12:56 lr 0.350166	data 0.0007 (0.2101)	batch 1.2770 (1.4791)	loss -26.8815 (-26.9260)	grad_norm 0.4869 (0.4940)	mem 44912MB
Train: [97/180][150/625]	eta 0:11:08 lr 0.349612	data 0.0007 (0.1410)	batch 1.2658 (1.4077)	loss -26.9156 (-26.9195)	grad_norm 0.5087 (0.4953)	mem 44912MB
Train: [97/180][200/625]	eta 0:09:43 lr 0.349058	data 0.0004 (0.1061)	batch 1.3046 (1.3728)	loss -26.8767 (-26.9151)	grad_norm 0.4940 (0.4951)	mem 44912MB
Train: [97/180][250/625]	eta 0:08:27 lr 0.348504	data 0.0005 (0.0851)	batch 1.2849 (1.3530)	loss -26.7643 (-26.9168)	grad_norm 0.4964 (0.4950)	mem 44912MB
Train: [97/180][300/625]	eta 0:07:15 lr 0.347951	data 0.0004 (0.0711)	batch 1.2882 (1.3392)	loss -26.9639 (-26.9171)	grad_norm 0.4978 (0.4947)	mem 44912MB
Train: [97/180][350/625]	eta 0:06:05 lr 0.347397	data 0.0005 (0.0611)	batch 1.2407 (1.3281)	loss -26.7832 (-26.9156)	grad_norm 0.4842 (0.4951)	mem 44912MB
Train: [97/180][400/625]	eta 0:04:57 lr 0.346843	data 0.0010 (0.0536)	batch 1.2472 (1.3200)	loss -26.8893 (-26.9149)	grad_norm 0.4911 (0.4950)	mem 44912MB
Train: [97/180][450/625]	eta 0:03:50 lr 0.346290	data 0.0010 (0.0477)	batch 1.2775 (1.3146)	loss -26.8656 (-26.9160)	grad_norm 0.4928 (0.4950)	mem 44912MB
Train: [97/180][500/625]	eta 0:02:43 lr 0.345736	data 0.0012 (0.0431)	batch 1.2824 (1.3099)	loss -26.6465 (-26.9127)	grad_norm 0.4820 (0.4951)	mem 44912MB
Train: [97/180][550/625]	eta 0:01:37 lr 0.345183	data 0.0009 (0.0393)	batch 1.2590 (1.3056)	loss -27.0869 (-26.9144)	grad_norm 0.4865 (0.4951)	mem 44912MB
Train: [97/180][600/625]	eta 0:00:32 lr 0.344630	data 0.0008 (0.0361)	batch 1.3214 (1.3024)	loss -26.9508 (-26.9140)	grad_norm 0.4903 (0.4949)	mem 44912MB
Current slope: None 	
EPOCH 97 training takes 0:13:34
Test: [0/25]	Time 14.872 (14.872)	Loss 1.3851 (1.3851)	Acc@1 68.652 (68.652)	Acc@5 88.477 (88.477)	Mem 44912MB
 * Acc@1 57.214 Acc@5 81.174
Accuracy of the network on the 50000 test images: 57.21%
Max accuracy (after decay): 57.21%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [98/180][0/625]	eta 3:58:29 lr 0.344354	data 20.5256 (20.5256)	batch 22.8959 (22.8959)	loss -27.1833 (-27.1833)	grad_norm 0.4893 (0.4893)	mem 44912MB
Train: [98/180][50/625]	eta 0:16:12 lr 0.343801	data 0.0006 (0.4039)	batch 1.2590 (1.6917)	loss -26.9823 (-26.9220)	grad_norm 0.5419 (0.4947)	mem 44912MB
Train: [98/180][100/625]	eta 0:12:57 lr 0.343248	data 0.0010 (0.2044)	batch 1.2549 (1.4804)	loss -27.0933 (-26.9274)	grad_norm 0.5075 (0.4951)	mem 44912MB
Train: [98/180][150/625]	eta 0:11:09 lr 0.342695	data 0.0005 (0.1370)	batch 1.2677 (1.4096)	loss -26.8030 (-26.9330)	grad_norm 0.4953 (0.4963)	mem 44912MB
Train: [98/180][200/625]	eta 0:09:44 lr 0.342142	data 0.0008 (0.1031)	batch 1.2349 (1.3745)	loss -26.8734 (-26.9323)	grad_norm 0.4985 (0.4964)	mem 44912MB
Train: [98/180][250/625]	eta 0:08:27 lr 0.341590	data 0.0006 (0.0827)	batch 1.2698 (1.3529)	loss -26.8770 (-26.9329)	grad_norm 0.4839 (0.4960)	mem 44912MB
Train: [98/180][300/625]	eta 0:07:14 lr 0.341037	data 0.0010 (0.0691)	batch 1.2206 (1.3375)	loss -27.1268 (-26.9344)	grad_norm 0.5090 (0.4965)	mem 44912MB
Train: [98/180][350/625]	eta 0:06:05 lr 0.340485	data 0.0006 (0.0595)	batch 1.2865 (1.3274)	loss -26.9881 (-26.9380)	grad_norm 0.4976 (0.4967)	mem 44912MB
Train: [98/180][400/625]	eta 0:04:56 lr 0.339933	data 0.0004 (0.0522)	batch 1.2873 (1.3199)	loss -26.9876 (-26.9417)	grad_norm 0.4807 (0.4967)	mem 44912MB
Train: [98/180][450/625]	eta 0:03:50 lr 0.339381	data 0.0007 (0.0465)	batch 1.2989 (1.3145)	loss -26.9520 (-26.9408)	grad_norm 0.5071 (0.4969)	mem 44912MB
Train: [98/180][500/625]	eta 0:02:43 lr 0.338829	data 0.0008 (0.0419)	batch 1.2704 (1.3094)	loss -27.0166 (-26.9404)	grad_norm 0.4827 (0.4969)	mem 44912MB
Train: [98/180][550/625]	eta 0:01:37 lr 0.338277	data 0.0005 (0.0382)	batch 1.3987 (1.3055)	loss -26.7560 (-26.9424)	grad_norm 0.5111 (0.4970)	mem 44912MB
Train: [98/180][600/625]	eta 0:00:32 lr 0.337725	data 0.0007 (0.0351)	batch 1.2444 (1.3018)	loss -27.0252 (-26.9404)	grad_norm 0.4877 (0.4970)	mem 44912MB
Current slope: None 	
EPOCH 98 training takes 0:13:34
Test: [0/25]	Time 14.536 (14.536)	Loss 1.3832 (1.3832)	Acc@1 68.555 (68.555)	Acc@5 88.232 (88.232)	Mem 44912MB
 * Acc@1 57.036 Acc@5 80.836
Accuracy of the network on the 50000 test images: 57.04%
Max accuracy (after decay): 57.21%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [99/180][0/625]	eta 4:03:00 lr 0.337449	data 20.5770 (20.5770)	batch 23.3293 (23.3293)	loss -27.0783 (-27.0783)	grad_norm 0.4851 (0.4851)	mem 44912MB
Train: [99/180][50/625]	eta 0:16:19 lr 0.336898	data 0.0009 (0.4043)	batch 1.2800 (1.7034)	loss -27.0265 (-26.9827)	grad_norm 0.5148 (0.5000)	mem 44912MB
Train: [99/180][100/625]	eta 0:12:58 lr 0.336346	data 0.0006 (0.2045)	batch 1.2445 (1.4836)	loss -26.9862 (-26.9659)	grad_norm 0.4909 (0.5012)	mem 44912MB
Train: [99/180][150/625]	eta 0:11:09 lr 0.335795	data 0.0006 (0.1371)	batch 1.2806 (1.4103)	loss -26.8797 (-26.9580)	grad_norm 0.4969 (0.5002)	mem 44912MB
Train: [99/180][200/625]	eta 0:09:44 lr 0.335244	data 0.0005 (0.1031)	batch 1.2527 (1.3746)	loss -27.0222 (-26.9556)	grad_norm 0.5036 (0.5001)	mem 44912MB
Train: [99/180][250/625]	eta 0:08:27 lr 0.334693	data 0.0006 (0.0827)	batch 1.2676 (1.3539)	loss -26.9844 (-26.9547)	grad_norm 0.4993 (0.5002)	mem 44912MB
Train: [99/180][300/625]	eta 0:07:15 lr 0.334142	data 0.0004 (0.0691)	batch 1.2694 (1.3387)	loss -27.1256 (-26.9528)	grad_norm 0.4957 (0.5005)	mem 44912MB
Train: [99/180][350/625]	eta 0:06:05 lr 0.333591	data 0.0009 (0.0594)	batch 1.2861 (1.3283)	loss -26.8334 (-26.9489)	grad_norm 0.4952 (0.5006)	mem 44912MB
Train: [99/180][400/625]	eta 0:04:57 lr 0.333041	data 0.0010 (0.0521)	batch 1.2207 (1.3211)	loss -27.0108 (-26.9498)	grad_norm 0.4896 (0.5001)	mem 44912MB
Train: [99/180][450/625]	eta 0:03:50 lr 0.332490	data 0.0007 (0.0464)	batch 1.2344 (1.3156)	loss -26.9638 (-26.9520)	grad_norm 0.4909 (0.5000)	mem 44912MB
Train: [99/180][500/625]	eta 0:02:43 lr 0.331940	data 0.0006 (0.0418)	batch 1.3017 (1.3104)	loss -26.9711 (-26.9513)	grad_norm 0.4987 (0.4999)	mem 44912MB
Train: [99/180][550/625]	eta 0:01:37 lr 0.331389	data 0.0005 (0.0381)	batch 1.3452 (1.3062)	loss -26.9522 (-26.9524)	grad_norm 0.4996 (0.4997)	mem 44912MB
Train: [99/180][600/625]	eta 0:00:32 lr 0.330839	data 0.0006 (0.0350)	batch 1.2691 (1.3027)	loss -26.9155 (-26.9524)	grad_norm 0.5058 (0.4995)	mem 44912MB
Current slope: None 	
EPOCH 99 training takes 0:13:34
Test: [0/25]	Time 14.518 (14.518)	Loss 1.3351 (1.3351)	Acc@1 71.045 (71.045)	Acc@5 88.965 (88.965)	Mem 44912MB
 * Acc@1 57.084 Acc@5 80.902
Accuracy of the network on the 50000 test images: 57.08%
Max accuracy (after decay): 57.21%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [100/180][0/625]	eta 4:02:25 lr 0.330564	data 21.8632 (21.8632)	batch 23.2734 (23.2734)	loss -27.0804 (-27.0804)	grad_norm 0.4914 (0.4914)	mem 44912MB
Train: [100/180][50/625]	eta 0:16:17 lr 0.330014	data 0.0006 (0.4295)	batch 1.2786 (1.7006)	loss -26.8263 (-26.9975)	grad_norm 0.5136 (0.4993)	mem 44912MB
Train: [100/180][100/625]	eta 0:13:00 lr 0.329464	data 0.0007 (0.2172)	batch 1.2667 (1.4863)	loss -27.0184 (-26.9845)	grad_norm 0.5111 (0.5016)	mem 44912MB
Train: [100/180][150/625]	eta 0:11:10 lr 0.328915	data 0.0005 (0.1455)	batch 1.2483 (1.4111)	loss -27.0288 (-26.9797)	grad_norm 0.4937 (0.5015)	mem 44912MB
Train: [100/180][200/625]	eta 0:09:44 lr 0.328365	data 0.0012 (0.1095)	batch 1.3214 (1.3751)	loss -27.1498 (-26.9884)	grad_norm 0.4944 (0.5008)	mem 44912MB
Train: [100/180][250/625]	eta 0:08:27 lr 0.327816	data 0.0006 (0.0879)	batch 1.2883 (1.3526)	loss -26.9307 (-26.9850)	grad_norm 0.5110 (0.5010)	mem 44912MB
Train: [100/180][300/625]	eta 0:07:14 lr 0.327267	data 0.0007 (0.0734)	batch 1.3023 (1.3374)	loss -27.0534 (-26.9809)	grad_norm 0.5070 (0.5012)	mem 44912MB
Train: [100/180][350/625]	eta 0:06:04 lr 0.326718	data 0.0006 (0.0630)	batch 1.2500 (1.3266)	loss -27.0407 (-26.9788)	grad_norm 0.4911 (0.5009)	mem 44912MB
Train: [100/180][400/625]	eta 0:04:56 lr 0.326169	data 0.0005 (0.0553)	batch 1.2785 (1.3198)	loss -27.0498 (-26.9781)	grad_norm 0.4990 (0.5007)	mem 44912MB
Train: [100/180][450/625]	eta 0:03:49 lr 0.325620	data 0.0009 (0.0492)	batch 1.2310 (1.3134)	loss -27.0324 (-26.9731)	grad_norm 0.5077 (0.5011)	mem 44912MB
Train: [100/180][500/625]	eta 0:02:43 lr 0.325071	data 0.0007 (0.0444)	batch 1.2379 (1.3097)	loss -27.1205 (-26.9725)	grad_norm 0.4766 (0.5013)	mem 44912MB
Train: [100/180][550/625]	eta 0:01:37 lr 0.324523	data 0.0010 (0.0404)	batch 1.2813 (1.3055)	loss -26.9525 (-26.9699)	grad_norm 0.5163 (0.5014)	mem 44912MB
Train: [100/180][600/625]	eta 0:00:32 lr 0.323974	data 0.0005 (0.0371)	batch 1.2724 (1.3022)	loss -27.1468 (-26.9724)	grad_norm 0.5112 (0.5017)	mem 44912MB
Current slope: None 	
EPOCH 100 training takes 0:13:34
Test: [0/25]	Time 14.597 (14.597)	Loss 1.3598 (1.3598)	Acc@1 69.678 (69.678)	Acc@5 88.867 (88.867)	Mem 44912MB
 * Acc@1 57.534 Acc@5 81.246
Accuracy of the network on the 50000 test images: 57.53%
Max accuracy (after decay): 57.53%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [101/180][0/625]	eta 4:02:08 lr 0.323700	data 20.8244 (20.8244)	batch 23.2462 (23.2462)	loss -27.1360 (-27.1360)	grad_norm 0.4889 (0.4889)	mem 44912MB
Train: [101/180][50/625]	eta 0:16:17 lr 0.323152	data 0.0005 (0.4090)	batch 1.2831 (1.6995)	loss -26.9280 (-26.9788)	grad_norm 0.4893 (0.4999)	mem 44912MB
Train: [101/180][100/625]	eta 0:12:57 lr 0.322604	data 0.0008 (0.2069)	batch 1.2641 (1.4819)	loss -26.9294 (-26.9908)	grad_norm 0.5080 (0.5015)	mem 44912MB
Train: [101/180][150/625]	eta 0:11:09 lr 0.322056	data 0.0007 (0.1386)	batch 1.2772 (1.4103)	loss -27.1822 (-26.9894)	grad_norm 0.4948 (0.5016)	mem 44912MB
Train: [101/180][200/625]	eta 0:09:44 lr 0.321509	data 0.0007 (0.1043)	batch 1.2685 (1.3745)	loss -26.9529 (-26.9988)	grad_norm 0.5117 (0.5011)	mem 44912MB
Train: [101/180][250/625]	eta 0:08:27 lr 0.320961	data 0.0006 (0.0837)	batch 1.2749 (1.3545)	loss -27.0669 (-26.9976)	grad_norm 0.4935 (0.5014)	mem 44912MB
Train: [101/180][300/625]	eta 0:07:15 lr 0.320414	data 0.0006 (0.0699)	batch 1.2682 (1.3389)	loss -26.9380 (-26.9972)	grad_norm 0.5002 (0.5016)	mem 44912MB
Train: [101/180][350/625]	eta 0:06:05 lr 0.319866	data 0.0005 (0.0600)	batch 1.2366 (1.3294)	loss -27.0632 (-26.9946)	grad_norm 0.5278 (0.5019)	mem 44912MB
Train: [101/180][400/625]	eta 0:04:57 lr 0.319319	data 0.0006 (0.0526)	batch 1.2516 (1.3218)	loss -27.0202 (-26.9913)	grad_norm 0.5081 (0.5023)	mem 44912MB
Train: [101/180][450/625]	eta 0:03:50 lr 0.318772	data 0.0006 (0.0468)	batch 1.2571 (1.3166)	loss -27.0861 (-26.9907)	grad_norm 0.5047 (0.5026)	mem 44912MB
Train: [101/180][500/625]	eta 0:02:43 lr 0.318226	data 0.0005 (0.0422)	batch 1.2844 (1.3112)	loss -27.1696 (-26.9877)	grad_norm 0.5034 (0.5026)	mem 44912MB
Train: [101/180][550/625]	eta 0:01:38 lr 0.317679	data 0.0006 (0.0384)	batch 1.2782 (1.3075)	loss -26.9999 (-26.9890)	grad_norm 0.5016 (0.5025)	mem 44912MB
Train: [101/180][600/625]	eta 0:00:32 lr 0.317133	data 0.0005 (0.0353)	batch 1.2680 (1.3035)	loss -26.9303 (-26.9893)	grad_norm 0.5131 (0.5026)	mem 44912MB
Current slope: None 	
EPOCH 101 training takes 0:13:35
Test: [0/25]	Time 14.818 (14.818)	Loss 1.2904 (1.2904)	Acc@1 70.361 (70.361)	Acc@5 89.795 (89.795)	Mem 44912MB
 * Acc@1 57.318 Acc@5 81.094
Accuracy of the network on the 50000 test images: 57.32%
Max accuracy (after decay): 57.53%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [102/180][0/625]	eta 4:03:14 lr 0.316859	data 21.0108 (21.0108)	batch 23.3506 (23.3506)	loss -27.1037 (-27.1037)	grad_norm 0.4980 (0.4980)	mem 44912MB
Train: [102/180][50/625]	eta 0:16:20 lr 0.316313	data 0.0008 (0.4126)	batch 1.2845 (1.7053)	loss -26.9403 (-27.0383)	grad_norm 0.5071 (0.5030)	mem 44912MB
Train: [102/180][100/625]	eta 0:13:02 lr 0.315767	data 0.0005 (0.2086)	batch 1.2531 (1.4914)	loss -26.9687 (-27.0191)	grad_norm 0.5009 (0.5036)	mem 44912MB
Train: [102/180][150/625]	eta 0:11:12 lr 0.315221	data 0.0005 (0.1398)	batch 1.2533 (1.4156)	loss -27.0943 (-27.0163)	grad_norm 0.5262 (0.5049)	mem 44912MB
Train: [102/180][200/625]	eta 0:09:45 lr 0.314676	data 0.0005 (0.1051)	batch 1.2499 (1.3775)	loss -26.7234 (-27.0098)	grad_norm 0.5308 (0.5043)	mem 44912MB
Train: [102/180][250/625]	eta 0:08:28 lr 0.314130	data 0.0005 (0.0843)	batch 1.3005 (1.3563)	loss -26.8027 (-27.0065)	grad_norm 0.5025 (0.5047)	mem 44912MB
Train: [102/180][300/625]	eta 0:07:15 lr 0.313585	data 0.0006 (0.0704)	batch 1.2680 (1.3415)	loss -26.9653 (-27.0082)	grad_norm 0.5000 (0.5048)	mem 44912MB
Train: [102/180][350/625]	eta 0:06:05 lr 0.313040	data 0.0005 (0.0604)	batch 1.2583 (1.3298)	loss -27.0818 (-27.0063)	grad_norm 0.5056 (0.5045)	mem 44912MB
Train: [102/180][400/625]	eta 0:04:57 lr 0.312495	data 0.0005 (0.0530)	batch 1.2367 (1.3216)	loss -27.1848 (-27.0031)	grad_norm 0.4952 (0.5049)	mem 44912MB
Train: [102/180][450/625]	eta 0:03:50 lr 0.311950	data 0.0007 (0.0472)	batch 1.2753 (1.3154)	loss -26.8661 (-27.0004)	grad_norm 0.5129 (0.5049)	mem 44912MB
Train: [102/180][500/625]	eta 0:02:43 lr 0.311405	data 0.0005 (0.0425)	batch 1.2722 (1.3116)	loss -26.8320 (-27.0010)	grad_norm 0.5130 (0.5051)	mem 44912MB
Train: [102/180][550/625]	eta 0:01:38 lr 0.310861	data 0.0008 (0.0387)	batch 1.2240 (1.3069)	loss -26.7741 (-27.0001)	grad_norm 0.5090 (0.5051)	mem 44912MB
Train: [102/180][600/625]	eta 0:00:32 lr 0.310316	data 0.0005 (0.0355)	batch 1.2578 (1.3030)	loss -27.0766 (-27.0023)	grad_norm 0.5021 (0.5052)	mem 44912MB
Current slope: None 	
EPOCH 102 training takes 0:13:35
Test: [0/25]	Time 14.600 (14.600)	Loss 1.3173 (1.3173)	Acc@1 70.312 (70.312)	Acc@5 88.770 (88.770)	Mem 44912MB
 * Acc@1 57.652 Acc@5 81.308
Accuracy of the network on the 50000 test images: 57.65%
Max accuracy (after decay): 57.65%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [103/180][0/625]	eta 4:08:08 lr 0.310044	data 21.4800 (21.4800)	batch 23.8209 (23.8209)	loss -27.0563 (-27.0563)	grad_norm 0.5358 (0.5358)	mem 44912MB
Train: [103/180][50/625]	eta 0:16:23 lr 0.309500	data 0.0006 (0.4217)	batch 1.2521 (1.7108)	loss -27.1461 (-27.0365)	grad_norm 0.5510 (0.5109)	mem 44912MB
Train: [103/180][100/625]	eta 0:13:02 lr 0.308956	data 0.0006 (0.2136)	batch 1.2503 (1.4907)	loss -26.9533 (-27.0320)	grad_norm 0.4981 (0.5082)	mem 44912MB
Train: [103/180][150/625]	eta 0:11:12 lr 0.308412	data 0.0005 (0.1431)	batch 1.2344 (1.4158)	loss -26.9499 (-27.0243)	grad_norm 0.5055 (0.5080)	mem 44912MB
Train: [103/180][200/625]	eta 0:09:45 lr 0.307869	data 0.0005 (0.1076)	batch 1.2338 (1.3784)	loss -27.1022 (-27.0207)	grad_norm 0.5099 (0.5081)	mem 44912MB
Train: [103/180][250/625]	eta 0:08:28 lr 0.307325	data 0.0003 (0.0863)	batch 1.2615 (1.3565)	loss -27.1133 (-27.0161)	grad_norm 0.5053 (0.5082)	mem 44912MB
Train: [103/180][300/625]	eta 0:07:15 lr 0.306782	data 0.0007 (0.0720)	batch 1.2299 (1.3413)	loss -26.9684 (-27.0116)	grad_norm 0.5009 (0.5087)	mem 44912MB
Train: [103/180][350/625]	eta 0:06:05 lr 0.306239	data 0.0005 (0.0619)	batch 1.2656 (1.3303)	loss -27.1712 (-27.0121)	grad_norm 0.5182 (0.5083)	mem 44912MB
Train: [103/180][400/625]	eta 0:04:57 lr 0.305696	data 0.0005 (0.0542)	batch 1.3040 (1.3218)	loss -26.9454 (-27.0129)	grad_norm 0.5136 (0.5079)	mem 44912MB
Train: [103/180][450/625]	eta 0:03:50 lr 0.305154	data 0.0007 (0.0483)	batch 1.2617 (1.3155)	loss -27.1511 (-27.0141)	grad_norm 0.4978 (0.5078)	mem 44912MB
Train: [103/180][500/625]	eta 0:02:43 lr 0.304611	data 0.0010 (0.0435)	batch 1.2594 (1.3101)	loss -27.0614 (-27.0126)	grad_norm 0.5173 (0.5080)	mem 44912MB
Train: [103/180][550/625]	eta 0:01:37 lr 0.304069	data 0.0005 (0.0396)	batch 1.2435 (1.3061)	loss -27.0435 (-27.0133)	grad_norm 0.5042 (0.5078)	mem 44912MB
Train: [103/180][600/625]	eta 0:00:32 lr 0.303527	data 0.0005 (0.0364)	batch 1.2341 (1.3026)	loss -27.1557 (-27.0151)	grad_norm 0.5025 (0.5080)	mem 44912MB
Current slope: None 	
EPOCH 103 training takes 0:13:34
Test: [0/25]	Time 14.852 (14.852)	Loss 1.2974 (1.2974)	Acc@1 70.605 (70.605)	Acc@5 88.916 (88.916)	Mem 44912MB
 * Acc@1 57.710 Acc@5 81.310
Accuracy of the network on the 50000 test images: 57.71%
Max accuracy (after decay): 57.71%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [104/180][0/625]	eta 4:01:41 lr 0.303256	data 21.7127 (21.7127)	batch 23.2031 (23.2031)	loss -26.7084 (-26.7084)	grad_norm 0.5261 (0.5261)	mem 44912MB
Train: [104/180][50/625]	eta 0:16:16 lr 0.302714	data 0.0006 (0.4266)	batch 1.2365 (1.6980)	loss -27.0243 (-27.0337)	grad_norm 0.5152 (0.5102)	mem 44912MB
Train: [104/180][100/625]	eta 0:12:58 lr 0.302173	data 0.0006 (0.2157)	batch 1.2999 (1.4825)	loss -26.7164 (-27.0330)	grad_norm 0.5063 (0.5098)	mem 44912MB
Train: [104/180][150/625]	eta 0:11:10 lr 0.301631	data 0.0006 (0.1444)	batch 1.2601 (1.4119)	loss -26.8576 (-27.0357)	grad_norm 0.5200 (0.5090)	mem 44912MB
Train: [104/180][200/625]	eta 0:09:45 lr 0.301090	data 0.0005 (0.1087)	batch 1.2506 (1.3765)	loss -27.1951 (-27.0388)	grad_norm 0.5097 (0.5094)	mem 44912MB
Train: [104/180][250/625]	eta 0:08:28 lr 0.300549	data 0.0006 (0.0871)	batch 1.2204 (1.3563)	loss -27.2503 (-27.0416)	grad_norm 0.5115 (0.5091)	mem 44912MB
Train: [104/180][300/625]	eta 0:07:15 lr 0.300008	data 0.0006 (0.0727)	batch 1.2431 (1.3406)	loss -27.1198 (-27.0388)	grad_norm 0.5142 (0.5092)	mem 44912MB
Train: [104/180][350/625]	eta 0:06:05 lr 0.299468	data 0.0004 (0.0625)	batch 1.2494 (1.3295)	loss -27.0946 (-27.0369)	grad_norm 0.5379 (0.5092)	mem 44912MB
Train: [104/180][400/625]	eta 0:04:57 lr 0.298927	data 0.0005 (0.0548)	batch 1.2588 (1.3214)	loss -27.0908 (-27.0324)	grad_norm 0.4918 (0.5094)	mem 44912MB
Train: [104/180][450/625]	eta 0:03:50 lr 0.298387	data 0.0006 (0.0488)	batch 1.2583 (1.3157)	loss -27.0390 (-27.0285)	grad_norm 0.5144 (0.5097)	mem 44912MB
Train: [104/180][500/625]	eta 0:02:43 lr 0.297847	data 0.0006 (0.0440)	batch 1.3007 (1.3105)	loss -27.0639 (-27.0257)	grad_norm 0.5260 (0.5097)	mem 44912MB
Train: [104/180][550/625]	eta 0:01:37 lr 0.297307	data 0.0006 (0.0400)	batch 1.2337 (1.3066)	loss -26.9693 (-27.0267)	grad_norm 0.5113 (0.5096)	mem 44912MB
Train: [104/180][600/625]	eta 0:00:32 lr 0.296767	data 0.0005 (0.0367)	batch 1.2784 (1.3035)	loss -27.0843 (-27.0273)	grad_norm 0.4941 (0.5097)	mem 44912MB
Current slope: None 	
EPOCH 104 training takes 0:13:35
Test: [0/25]	Time 14.960 (14.960)	Loss 1.4393 (1.4393)	Acc@1 69.092 (69.092)	Acc@5 87.744 (87.744)	Mem 44912MB
 * Acc@1 57.246 Acc@5 81.080
Accuracy of the network on the 50000 test images: 57.25%
Max accuracy (after decay): 57.71%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [105/180][0/625]	eta 3:56:32 lr 0.296498	data 21.2961 (21.2961)	batch 22.7076 (22.7076)	loss -27.1092 (-27.1092)	grad_norm 0.5251 (0.5251)	mem 44912MB
Train: [105/180][50/625]	eta 0:16:13 lr 0.295958	data 0.0006 (0.4183)	batch 1.3040 (1.6928)	loss -27.0303 (-27.0306)	grad_norm 0.5127 (0.5070)	mem 44912MB
Train: [105/180][100/625]	eta 0:12:58 lr 0.295419	data 0.0004 (0.2115)	batch 1.3213 (1.4825)	loss -26.9661 (-27.0436)	grad_norm 0.4998 (0.5094)	mem 44912MB
Train: [105/180][150/625]	eta 0:11:09 lr 0.294880	data 0.0004 (0.1416)	batch 1.2640 (1.4103)	loss -27.0065 (-27.0452)	grad_norm 0.5101 (0.5104)	mem 44912MB
Train: [105/180][200/625]	eta 0:09:43 lr 0.294341	data 0.0004 (0.1065)	batch 1.2556 (1.3736)	loss -26.9585 (-27.0402)	grad_norm 0.4840 (0.5108)	mem 44912MB
Train: [105/180][250/625]	eta 0:08:27 lr 0.293803	data 0.0006 (0.0854)	batch 1.2585 (1.3523)	loss -27.1492 (-27.0410)	grad_norm 0.5271 (0.5122)	mem 44912MB
Train: [105/180][300/625]	eta 0:07:15 lr 0.293265	data 0.0005 (0.0713)	batch 1.2351 (1.3387)	loss -27.0640 (-27.0388)	grad_norm 0.5237 (0.5124)	mem 44912MB
Train: [105/180][350/625]	eta 0:06:05 lr 0.292726	data 0.0005 (0.0612)	batch 1.2771 (1.3282)	loss -27.0627 (-27.0418)	grad_norm 0.5281 (0.5118)	mem 44912MB
Train: [105/180][400/625]	eta 0:04:57 lr 0.292189	data 0.0004 (0.0538)	batch 1.2056 (1.3203)	loss -27.0771 (-27.0423)	grad_norm 0.5058 (0.5118)	mem 44912MB
Train: [105/180][450/625]	eta 0:03:49 lr 0.291651	data 0.0005 (0.0479)	batch 1.2360 (1.3140)	loss -26.8962 (-27.0407)	grad_norm 0.5077 (0.5120)	mem 44912MB
Train: [105/180][500/625]	eta 0:02:43 lr 0.291113	data 0.0005 (0.0432)	batch 1.2968 (1.3096)	loss -27.0514 (-27.0419)	grad_norm 0.5355 (0.5119)	mem 44912MB
Train: [105/180][550/625]	eta 0:01:37 lr 0.290576	data 0.0005 (0.0393)	batch 1.2316 (1.3057)	loss -27.1160 (-27.0430)	grad_norm 0.5394 (0.5123)	mem 44912MB
Train: [105/180][600/625]	eta 0:00:32 lr 0.290039	data 0.0005 (0.0361)	batch 1.2476 (1.3022)	loss -27.0118 (-27.0436)	grad_norm 0.5140 (0.5122)	mem 44912MB
Current slope: None 	
EPOCH 105 training takes 0:13:34
Test: [0/25]	Time 14.951 (14.951)	Loss 1.2977 (1.2977)	Acc@1 70.557 (70.557)	Acc@5 89.307 (89.307)	Mem 44912MB
 * Acc@1 58.056 Acc@5 81.680
Accuracy of the network on the 50000 test images: 58.06%
Max accuracy (after decay): 58.06%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [106/180][0/625]	eta 4:02:06 lr 0.289771	data 19.5435 (19.5435)	batch 23.2430 (23.2430)	loss -27.2332 (-27.2332)	grad_norm 0.4911 (0.4911)	mem 44912MB
Train: [106/180][50/625]	eta 0:16:17 lr 0.289234	data 0.0006 (0.3838)	batch 1.2255 (1.6997)	loss -26.9499 (-27.0634)	grad_norm 0.5284 (0.5138)	mem 44912MB
Train: [106/180][100/625]	eta 0:12:59 lr 0.288697	data 0.0006 (0.1941)	batch 1.2710 (1.4856)	loss -27.0570 (-27.0599)	grad_norm 0.5061 (0.5135)	mem 44912MB
Train: [106/180][150/625]	eta 0:11:10 lr 0.288161	data 0.0005 (0.1300)	batch 1.2867 (1.4121)	loss -27.1007 (-27.0551)	grad_norm 0.5236 (0.5145)	mem 44912MB
Train: [106/180][200/625]	eta 0:09:44 lr 0.287625	data 0.0005 (0.0980)	batch 1.2669 (1.3764)	loss -26.8883 (-27.0592)	grad_norm 0.5116 (0.5148)	mem 44912MB
Train: [106/180][250/625]	eta 0:08:27 lr 0.287089	data 0.0005 (0.0786)	batch 1.2822 (1.3543)	loss -27.0971 (-27.0617)	grad_norm 0.5488 (0.5155)	mem 44912MB
Train: [106/180][300/625]	eta 0:07:15 lr 0.286553	data 0.0005 (0.0656)	batch 1.2609 (1.3397)	loss -27.2069 (-27.0646)	grad_norm 0.5142 (0.5152)	mem 44912MB
Train: [106/180][350/625]	eta 0:06:05 lr 0.286018	data 0.0006 (0.0563)	batch 1.2646 (1.3289)	loss -27.1726 (-27.0693)	grad_norm 0.5162 (0.5153)	mem 44912MB
Train: [106/180][400/625]	eta 0:04:57 lr 0.285483	data 0.0005 (0.0494)	batch 1.2398 (1.3212)	loss -27.1192 (-27.0676)	grad_norm 0.5130 (0.5153)	mem 44912MB
Train: [106/180][450/625]	eta 0:03:50 lr 0.284948	data 0.0006 (0.0440)	batch 1.2202 (1.3152)	loss -26.9289 (-27.0670)	grad_norm 0.5286 (0.5149)	mem 44912MB
Train: [106/180][500/625]	eta 0:02:43 lr 0.284413	data 0.0005 (0.0396)	batch 1.2313 (1.3095)	loss -26.9170 (-27.0651)	grad_norm 0.5053 (0.5149)	mem 44912MB
Train: [106/180][550/625]	eta 0:01:37 lr 0.283879	data 0.0006 (0.0361)	batch 1.2760 (1.3055)	loss -26.9989 (-27.0632)	grad_norm 0.5240 (0.5148)	mem 44912MB
Train: [106/180][600/625]	eta 0:00:32 lr 0.283344	data 0.0004 (0.0331)	batch 1.2302 (1.3023)	loss -27.0746 (-27.0640)	grad_norm 0.5142 (0.5148)	mem 44912MB
Current slope: None 	
EPOCH 106 training takes 0:13:34
Test: [0/25]	Time 14.673 (14.673)	Loss 1.3311 (1.3311)	Acc@1 69.775 (69.775)	Acc@5 88.867 (88.867)	Mem 44912MB
 * Acc@1 57.586 Acc@5 81.298
Accuracy of the network on the 50000 test images: 57.59%
Max accuracy (after decay): 58.06%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [107/180][0/625]	eta 3:59:04 lr 0.283077	data 21.6274 (21.6274)	batch 22.9518 (22.9518)	loss -27.0289 (-27.0289)	grad_norm 0.5243 (0.5243)	mem 44912MB
Train: [107/180][50/625]	eta 0:16:10 lr 0.282543	data 0.0008 (0.4249)	batch 1.2860 (1.6886)	loss -27.1750 (-27.0664)	grad_norm 0.5066 (0.5139)	mem 44912MB
Train: [107/180][100/625]	eta 0:12:55 lr 0.282009	data 0.0018 (0.2150)	batch 1.2451 (1.4776)	loss -27.2400 (-27.0633)	grad_norm 0.5286 (0.5132)	mem 44912MB
Train: [107/180][150/625]	eta 0:11:09 lr 0.281476	data 0.0011 (0.1441)	batch 1.3230 (1.4100)	loss -26.9604 (-27.0709)	grad_norm 0.5008 (0.5141)	mem 44912MB
Train: [107/180][200/625]	eta 0:09:44 lr 0.280943	data 0.0005 (0.1086)	batch 1.2847 (1.3744)	loss -27.2050 (-27.0654)	grad_norm 0.5096 (0.5147)	mem 44912MB
Train: [107/180][250/625]	eta 0:08:27 lr 0.280410	data 0.0005 (0.0871)	batch 1.2327 (1.3527)	loss -27.0653 (-27.0651)	grad_norm 0.5204 (0.5149)	mem 44912MB
Train: [107/180][300/625]	eta 0:07:15 lr 0.279877	data 0.0005 (0.0728)	batch 1.2609 (1.3385)	loss -27.1004 (-27.0656)	grad_norm 0.4913 (0.5154)	mem 44912MB
Train: [107/180][350/625]	eta 0:06:05 lr 0.279344	data 0.0004 (0.0626)	batch 1.2583 (1.3281)	loss -26.8765 (-27.0649)	grad_norm 0.5085 (0.5154)	mem 44912MB
Train: [107/180][400/625]	eta 0:04:56 lr 0.278812	data 0.0004 (0.0548)	batch 1.2547 (1.3197)	loss -27.2307 (-27.0676)	grad_norm 0.5149 (0.5155)	mem 44912MB
Train: [107/180][450/625]	eta 0:03:49 lr 0.278280	data 0.0004 (0.0488)	batch 1.2607 (1.3133)	loss -27.0656 (-27.0657)	grad_norm 0.5312 (0.5166)	mem 44912MB
Train: [107/180][500/625]	eta 0:02:43 lr 0.277748	data 0.0004 (0.0440)	batch 1.2443 (1.3087)	loss -26.8393 (-27.0644)	grad_norm 0.5081 (0.5165)	mem 44912MB
Train: [107/180][550/625]	eta 0:01:37 lr 0.277216	data 0.0005 (0.0400)	batch 1.2535 (1.3049)	loss -27.1233 (-27.0655)	grad_norm 0.5178 (0.5169)	mem 44912MB
Train: [107/180][600/625]	eta 0:00:32 lr 0.276685	data 0.0004 (0.0368)	batch 1.2712 (1.3015)	loss -27.1082 (-27.0704)	grad_norm 0.5067 (0.5168)	mem 44912MB
Current slope: None 	
EPOCH 107 training takes 0:13:33
Test: [0/25]	Time 14.733 (14.733)	Loss 1.2957 (1.2957)	Acc@1 70.361 (70.361)	Acc@5 89.795 (89.795)	Mem 44912MB
 * Acc@1 57.892 Acc@5 81.508
Accuracy of the network on the 50000 test images: 57.89%
Max accuracy (after decay): 58.06%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [108/180][0/625]	eta 3:59:39 lr 0.276419	data 21.2063 (21.2063)	batch 23.0066 (23.0066)	loss -27.0243 (-27.0243)	grad_norm 0.5093 (0.5093)	mem 44912MB
Train: [108/180][50/625]	eta 0:16:15 lr 0.275888	data 0.0006 (0.4164)	batch 1.4516 (1.6970)	loss -27.1311 (-27.0836)	grad_norm 0.5151 (0.5168)	mem 44912MB
Train: [108/180][100/625]	eta 0:12:58 lr 0.275358	data 0.0006 (0.2106)	batch 1.2613 (1.4837)	loss -27.0290 (-27.0854)	grad_norm 0.5213 (0.5174)	mem 44912MB
Train: [108/180][150/625]	eta 0:11:11 lr 0.274827	data 0.0005 (0.1410)	batch 1.2629 (1.4132)	loss -27.0987 (-27.0885)	grad_norm 0.5093 (0.5181)	mem 44912MB
Train: [108/180][200/625]	eta 0:09:45 lr 0.274297	data 0.0006 (0.1061)	batch 1.2701 (1.3771)	loss -27.1264 (-27.0816)	grad_norm 0.5301 (0.5185)	mem 44912MB
Train: [108/180][250/625]	eta 0:08:28 lr 0.273767	data 0.0005 (0.0851)	batch 1.2804 (1.3552)	loss -27.1803 (-27.0772)	grad_norm 0.5237 (0.5187)	mem 44912MB
Train: [108/180][300/625]	eta 0:07:15 lr 0.273237	data 0.0005 (0.0710)	batch 1.2595 (1.3399)	loss -27.1061 (-27.0796)	grad_norm 0.5151 (0.5190)	mem 44912MB
Train: [108/180][350/625]	eta 0:06:05 lr 0.272707	data 0.0005 (0.0610)	batch 1.2429 (1.3297)	loss -27.1382 (-27.0824)	grad_norm 0.5157 (0.5187)	mem 44912MB
Train: [108/180][400/625]	eta 0:04:57 lr 0.272178	data 0.0005 (0.0535)	batch 1.2241 (1.3221)	loss -27.0433 (-27.0799)	grad_norm 0.5039 (0.5186)	mem 44912MB
Train: [108/180][450/625]	eta 0:03:50 lr 0.271649	data 0.0005 (0.0476)	batch 1.2569 (1.3165)	loss -27.1551 (-27.0812)	grad_norm 0.5088 (0.5190)	mem 44912MB
Train: [108/180][500/625]	eta 0:02:43 lr 0.271120	data 0.0005 (0.0429)	batch 1.2608 (1.3110)	loss -27.1426 (-27.0829)	grad_norm 0.5276 (0.5192)	mem 44912MB
Train: [108/180][550/625]	eta 0:01:38 lr 0.270592	data 0.0006 (0.0391)	batch 1.2672 (1.3077)	loss -27.0648 (-27.0830)	grad_norm 0.5247 (0.5193)	mem 44912MB
Train: [108/180][600/625]	eta 0:00:32 lr 0.270063	data 0.0005 (0.0359)	batch 1.2434 (1.3043)	loss -27.1899 (-27.0829)	grad_norm 0.5197 (0.5191)	mem 44912MB
Current slope: None 	
EPOCH 108 training takes 0:13:35
Test: [0/25]	Time 14.517 (14.517)	Loss 1.2496 (1.2496)	Acc@1 71.289 (71.289)	Acc@5 89.844 (89.844)	Mem 44912MB
 * Acc@1 58.250 Acc@5 81.846
Accuracy of the network on the 50000 test images: 58.25%
Max accuracy (after decay): 58.25%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [109/180][0/625]	eta 3:57:52 lr 0.269799	data 19.7882 (19.7882)	batch 22.8360 (22.8360)	loss -27.3712 (-27.3712)	grad_norm 0.5043 (0.5043)	mem 44912MB
Train: [109/180][50/625]	eta 0:16:11 lr 0.269271	data 0.0005 (0.3886)	batch 1.2231 (1.6894)	loss -27.2678 (-27.1093)	grad_norm 0.5057 (0.5194)	mem 44912MB
Train: [109/180][100/625]	eta 0:12:58 lr 0.268744	data 0.0005 (0.1965)	batch 1.2627 (1.4824)	loss -26.8855 (-27.1041)	grad_norm 0.5136 (0.5179)	mem 44912MB
Train: [109/180][150/625]	eta 0:11:10 lr 0.268216	data 0.0006 (0.1316)	batch 1.2729 (1.4122)	loss -27.1839 (-27.1054)	grad_norm 0.5064 (0.5189)	mem 44912MB
Train: [109/180][200/625]	eta 0:09:44 lr 0.267689	data 0.0005 (0.0990)	batch 1.2731 (1.3758)	loss -27.0107 (-27.1029)	grad_norm 0.5347 (0.5186)	mem 44912MB
Train: [109/180][250/625]	eta 0:08:27 lr 0.267162	data 0.0010 (0.0794)	batch 1.2728 (1.3532)	loss -27.1566 (-27.1037)	grad_norm 0.5222 (0.5192)	mem 44912MB
Train: [109/180][300/625]	eta 0:07:14 lr 0.266636	data 0.0005 (0.0663)	batch 1.2743 (1.3383)	loss -27.1343 (-27.0986)	grad_norm 0.5083 (0.5196)	mem 44912MB
Train: [109/180][350/625]	eta 0:06:05 lr 0.266109	data 0.0004 (0.0570)	batch 1.2669 (1.3279)	loss -26.9818 (-27.0992)	grad_norm 0.5224 (0.5202)	mem 44912MB
Train: [109/180][400/625]	eta 0:04:57 lr 0.265583	data 0.0007 (0.0499)	batch 1.2368 (1.3206)	loss -26.9668 (-27.0973)	grad_norm 0.5119 (0.5202)	mem 44912MB
Train: [109/180][450/625]	eta 0:03:50 lr 0.265057	data 0.0006 (0.0444)	batch 1.2840 (1.3150)	loss -26.9762 (-27.0982)	grad_norm 0.5278 (0.5204)	mem 44912MB
Train: [109/180][500/625]	eta 0:02:43 lr 0.264532	data 0.0005 (0.0401)	batch 1.2557 (1.3101)	loss -27.0653 (-27.0978)	grad_norm 0.5343 (0.5204)	mem 44912MB
Train: [109/180][550/625]	eta 0:01:38 lr 0.264006	data 0.0004 (0.0365)	batch 1.2428 (1.3067)	loss -26.9081 (-27.0967)	grad_norm 0.5224 (0.5206)	mem 44912MB
Train: [109/180][600/625]	eta 0:00:32 lr 0.263481	data 0.0005 (0.0335)	batch 1.2533 (1.3031)	loss -27.1390 (-27.0964)	grad_norm 0.5233 (0.5207)	mem 44912MB
Current slope: None 	
EPOCH 109 training takes 0:13:34
Test: [0/25]	Time 14.987 (14.987)	Loss 1.2955 (1.2955)	Acc@1 71.045 (71.045)	Acc@5 89.795 (89.795)	Mem 44912MB
 * Acc@1 57.932 Acc@5 81.582
Accuracy of the network on the 50000 test images: 57.93%
Max accuracy (after decay): 58.25%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [110/180][0/625]	eta 3:55:12 lr 0.263219	data 20.8079 (20.8079)	batch 22.5799 (22.5799)	loss -26.8660 (-26.8660)	grad_norm 0.5312 (0.5312)	mem 44912MB
Train: [110/180][50/625]	eta 0:16:11 lr 0.262694	data 0.0005 (0.4088)	batch 1.2765 (1.6892)	loss -27.0054 (-27.1127)	grad_norm 0.5106 (0.5238)	mem 44912MB
Train: [110/180][100/625]	eta 0:12:55 lr 0.262170	data 0.0007 (0.2067)	batch 1.2320 (1.4765)	loss -27.1830 (-27.1099)	grad_norm 0.5222 (0.5209)	mem 44912MB
Train: [110/180][150/625]	eta 0:11:07 lr 0.261646	data 0.0004 (0.1385)	batch 1.2637 (1.4054)	loss -26.9801 (-27.0966)	grad_norm 0.5228 (0.5215)	mem 44912MB
Train: [110/180][200/625]	eta 0:09:43 lr 0.261122	data 0.0007 (0.1042)	batch 1.2332 (1.3721)	loss -26.9643 (-27.0906)	grad_norm 0.5157 (0.5219)	mem 44912MB
Train: [110/180][250/625]	eta 0:08:26 lr 0.260598	data 0.0010 (0.0835)	batch 1.2673 (1.3515)	loss -27.0790 (-27.0954)	grad_norm 0.5269 (0.5218)	mem 44912MB
Train: [110/180][300/625]	eta 0:07:14 lr 0.260075	data 0.0006 (0.0698)	batch 1.2627 (1.3367)	loss -27.1261 (-27.0914)	grad_norm 0.5312 (0.5217)	mem 44912MB
Train: [110/180][350/625]	eta 0:06:04 lr 0.259552	data 0.0006 (0.0599)	batch 1.2694 (1.3265)	loss -27.1164 (-27.0965)	grad_norm 0.5190 (0.5215)	mem 44912MB
Train: [110/180][400/625]	eta 0:04:56 lr 0.259029	data 0.0006 (0.0525)	batch 1.2884 (1.3195)	loss -27.1582 (-27.0984)	grad_norm 0.5228 (0.5219)	mem 44912MB
Train: [110/180][450/625]	eta 0:03:49 lr 0.258507	data 0.0007 (0.0467)	batch 1.2666 (1.3134)	loss -27.0249 (-27.0991)	grad_norm 0.5242 (0.5222)	mem 44912MB
Train: [110/180][500/625]	eta 0:02:43 lr 0.257984	data 0.0005 (0.0421)	batch 1.2744 (1.3083)	loss -26.9019 (-27.1007)	grad_norm 0.5146 (0.5227)	mem 44912MB
Train: [110/180][550/625]	eta 0:01:37 lr 0.257462	data 0.0005 (0.0384)	batch 1.2557 (1.3044)	loss -27.1040 (-27.0987)	grad_norm 0.5329 (0.5230)	mem 44912MB
Train: [110/180][600/625]	eta 0:00:32 lr 0.256941	data 0.0005 (0.0352)	batch 1.3101 (1.3012)	loss -26.9974 (-27.0992)	grad_norm 0.5336 (0.5230)	mem 44912MB
Current slope: None 	
EPOCH 110 training takes 0:13:33
Test: [0/25]	Time 14.870 (14.870)	Loss 1.3434 (1.3434)	Acc@1 69.580 (69.580)	Acc@5 88.428 (88.428)	Mem 44912MB
 * Acc@1 58.262 Acc@5 81.792
Accuracy of the network on the 50000 test images: 58.26%
Max accuracy (after decay): 58.26%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [111/180][0/625]	eta 4:00:28 lr 0.256680	data 21.4166 (21.4166)	batch 23.0862 (23.0862)	loss -27.0298 (-27.0298)	grad_norm 0.5283 (0.5283)	mem 44912MB
Train: [111/180][50/625]	eta 0:16:14 lr 0.256159	data 0.0007 (0.4207)	batch 1.2504 (1.6951)	loss -27.1098 (-27.1284)	grad_norm 0.5296 (0.5294)	mem 44912MB
Train: [111/180][100/625]	eta 0:12:58 lr 0.255638	data 0.0007 (0.2129)	batch 1.2707 (1.4829)	loss -26.9974 (-27.1284)	grad_norm 0.5254 (0.5278)	mem 44912MB
Train: [111/180][150/625]	eta 0:11:10 lr 0.255117	data 0.0006 (0.1427)	batch 1.2809 (1.4105)	loss -26.7832 (-27.1205)	grad_norm 0.5199 (0.5269)	mem 44912MB
Train: [111/180][200/625]	eta 0:09:43 lr 0.254597	data 0.0007 (0.1074)	batch 1.2494 (1.3731)	loss -27.0699 (-27.1213)	grad_norm 0.5111 (0.5262)	mem 44912MB
Train: [111/180][250/625]	eta 0:08:26 lr 0.254077	data 0.0006 (0.0861)	batch 1.2460 (1.3519)	loss -27.0313 (-27.1240)	grad_norm 0.5180 (0.5265)	mem 44912MB
Train: [111/180][300/625]	eta 0:07:14 lr 0.253557	data 0.0006 (0.0719)	batch 1.2571 (1.3373)	loss -27.1400 (-27.1217)	grad_norm 0.5360 (0.5264)	mem 44912MB
Train: [111/180][350/625]	eta 0:06:04 lr 0.253037	data 0.0006 (0.0617)	batch 1.2214 (1.3268)	loss -27.0871 (-27.1178)	grad_norm 0.5256 (0.5265)	mem 44912MB
Train: [111/180][400/625]	eta 0:04:56 lr 0.252518	data 0.0007 (0.0541)	batch 1.2648 (1.3191)	loss -27.1924 (-27.1173)	grad_norm 0.5295 (0.5265)	mem 44912MB
Train: [111/180][450/625]	eta 0:03:49 lr 0.251999	data 0.0004 (0.0482)	batch 1.2892 (1.3135)	loss -27.0033 (-27.1153)	grad_norm 0.5059 (0.5266)	mem 44912MB
Train: [111/180][500/625]	eta 0:02:43 lr 0.251480	data 0.0005 (0.0434)	batch 1.2448 (1.3083)	loss -27.0841 (-27.1148)	grad_norm 0.5224 (0.5266)	mem 44912MB
Train: [111/180][550/625]	eta 0:01:37 lr 0.250962	data 0.0005 (0.0395)	batch 1.2394 (1.3044)	loss -27.1506 (-27.1165)	grad_norm 0.5353 (0.5265)	mem 44912MB
Train: [111/180][600/625]	eta 0:00:32 lr 0.250444	data 0.0006 (0.0363)	batch 1.2355 (1.3010)	loss -27.1000 (-27.1165)	grad_norm 0.5237 (0.5263)	mem 44912MB
Current slope: None 	
EPOCH 111 training takes 0:13:33
Test: [0/25]	Time 14.587 (14.587)	Loss 1.3082 (1.3082)	Acc@1 69.189 (69.189)	Acc@5 89.600 (89.600)	Mem 44912MB
 * Acc@1 58.152 Acc@5 81.930
Accuracy of the network on the 50000 test images: 58.15%
Max accuracy (after decay): 58.26%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [112/180][0/625]	eta 4:05:37 lr 0.250185	data 20.6764 (20.6764)	batch 23.5806 (23.5806)	loss -27.1695 (-27.1695)	grad_norm 0.5226 (0.5226)	mem 44912MB
Train: [112/180][50/625]	eta 0:16:20 lr 0.249667	data 0.0009 (0.4061)	batch 1.2610 (1.7053)	loss -27.0690 (-27.1042)	grad_norm 0.5371 (0.5268)	mem 44912MB
Train: [112/180][100/625]	eta 0:13:01 lr 0.249150	data 0.0005 (0.2054)	batch 1.2545 (1.4888)	loss -27.1960 (-27.1155)	grad_norm 0.5333 (0.5261)	mem 44912MB
Train: [112/180][150/625]	eta 0:11:12 lr 0.248633	data 0.0006 (0.1376)	batch 1.2320 (1.4148)	loss -26.9931 (-27.1221)	grad_norm 0.5463 (0.5273)	mem 44912MB
Train: [112/180][200/625]	eta 0:09:45 lr 0.248116	data 0.0005 (0.1035)	batch 1.3076 (1.3777)	loss -26.9801 (-27.1201)	grad_norm 0.5438 (0.5276)	mem 44912MB
Train: [112/180][250/625]	eta 0:08:28 lr 0.247599	data 0.0006 (0.0830)	batch 1.2367 (1.3553)	loss -27.2075 (-27.1220)	grad_norm 0.5169 (0.5283)	mem 44912MB
Train: [112/180][300/625]	eta 0:07:15 lr 0.247083	data 0.0006 (0.0693)	batch 1.2533 (1.3411)	loss -26.8755 (-27.1228)	grad_norm 0.5187 (0.5281)	mem 44912MB
Train: [112/180][350/625]	eta 0:06:05 lr 0.246567	data 0.0005 (0.0595)	batch 1.2163 (1.3305)	loss -27.2450 (-27.1213)	grad_norm 0.5358 (0.5284)	mem 44912MB
Train: [112/180][400/625]	eta 0:04:57 lr 0.246052	data 0.0007 (0.0522)	batch 1.2253 (1.3223)	loss -27.1739 (-27.1184)	grad_norm 0.5267 (0.5282)	mem 44912MB
Train: [112/180][450/625]	eta 0:03:50 lr 0.245537	data 0.0009 (0.0465)	batch 1.3821 (1.3165)	loss -27.1267 (-27.1181)	grad_norm 0.5113 (0.5280)	mem 44912MB
Train: [112/180][500/625]	eta 0:02:43 lr 0.245022	data 0.0006 (0.0419)	batch 1.2836 (1.3117)	loss -27.3780 (-27.1212)	grad_norm 0.5550 (0.5281)	mem 44912MB
Train: [112/180][550/625]	eta 0:01:38 lr 0.244507	data 0.0004 (0.0381)	batch 1.2433 (1.3078)	loss -27.1181 (-27.1204)	grad_norm 0.5477 (0.5281)	mem 44912MB
Train: [112/180][600/625]	eta 0:00:32 lr 0.243992	data 0.0006 (0.0350)	batch 1.2392 (1.3039)	loss -27.2257 (-27.1194)	grad_norm 0.5562 (0.5283)	mem 44912MB
Current slope: None 	
EPOCH 112 training takes 0:13:35
Test: [0/25]	Time 14.748 (14.748)	Loss 1.2792 (1.2792)	Acc@1 70.068 (70.068)	Acc@5 89.893 (89.893)	Mem 44912MB
 * Acc@1 58.428 Acc@5 81.980
Accuracy of the network on the 50000 test images: 58.43%
Max accuracy (after decay): 58.43%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [113/180][0/625]	eta 4:01:12 lr 0.243735	data 21.5106 (21.5106)	batch 23.1557 (23.1557)	loss -27.1779 (-27.1779)	grad_norm 0.5159 (0.5159)	mem 44912MB
Train: [113/180][50/625]	eta 0:16:15 lr 0.243221	data 0.0006 (0.4229)	batch 1.2834 (1.6959)	loss -27.2494 (-27.1183)	grad_norm 0.5253 (0.5295)	mem 44912MB
Train: [113/180][100/625]	eta 0:12:59 lr 0.242708	data 0.0008 (0.2139)	batch 1.2571 (1.4841)	loss -27.0709 (-27.1308)	grad_norm 0.5187 (0.5291)	mem 44912MB
Train: [113/180][150/625]	eta 0:11:10 lr 0.242194	data 0.0005 (0.1433)	batch 1.2252 (1.4124)	loss -27.1680 (-27.1396)	grad_norm 0.5322 (0.5295)	mem 44912MB
Train: [113/180][200/625]	eta 0:09:44 lr 0.241681	data 0.0005 (0.1078)	batch 1.2361 (1.3761)	loss -27.2422 (-27.1406)	grad_norm 0.5341 (0.5295)	mem 44912MB
Train: [113/180][250/625]	eta 0:08:27 lr 0.241169	data 0.0006 (0.0864)	batch 1.2982 (1.3537)	loss -27.0790 (-27.1404)	grad_norm 0.5475 (0.5298)	mem 44912MB
Train: [113/180][300/625]	eta 0:07:15 lr 0.240656	data 0.0005 (0.0723)	batch 1.2423 (1.3392)	loss -27.0604 (-27.1435)	grad_norm 0.5389 (0.5307)	mem 44912MB
Train: [113/180][350/625]	eta 0:06:05 lr 0.240144	data 0.0006 (0.0620)	batch 1.2494 (1.3286)	loss -27.3318 (-27.1440)	grad_norm 0.5056 (0.5307)	mem 44912MB
Train: [113/180][400/625]	eta 0:04:57 lr 0.239633	data 0.0006 (0.0544)	batch 1.2387 (1.3209)	loss -27.0854 (-27.1433)	grad_norm 0.5461 (0.5307)	mem 44912MB
Train: [113/180][450/625]	eta 0:03:50 lr 0.239121	data 0.0005 (0.0484)	batch 1.2860 (1.3145)	loss -27.1044 (-27.1446)	grad_norm 0.5317 (0.5306)	mem 44912MB
Train: [113/180][500/625]	eta 0:02:43 lr 0.238610	data 0.0004 (0.0436)	batch 1.2765 (1.3101)	loss -27.2127 (-27.1426)	grad_norm 0.5164 (0.5308)	mem 44912MB
Train: [113/180][550/625]	eta 0:01:37 lr 0.238099	data 0.0005 (0.0397)	batch 1.2798 (1.3064)	loss -27.1288 (-27.1428)	grad_norm 0.5307 (0.5310)	mem 44912MB
Train: [113/180][600/625]	eta 0:00:32 lr 0.237589	data 0.0005 (0.0365)	batch 1.2611 (1.3037)	loss -27.2112 (-27.1431)	grad_norm 0.5299 (0.5310)	mem 44912MB
Current slope: None 	
EPOCH 113 training takes 0:13:35
Test: [0/25]	Time 14.769 (14.769)	Loss 1.3474 (1.3474)	Acc@1 70.508 (70.508)	Acc@5 89.551 (89.551)	Mem 44912MB
 * Acc@1 58.538 Acc@5 82.024
Accuracy of the network on the 50000 test images: 58.54%
Max accuracy (after decay): 58.54%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [114/180][0/625]	eta 4:02:25 lr 0.237333	data 21.3850 (21.3850)	batch 23.2733 (23.2733)	loss -27.0400 (-27.0400)	grad_norm 0.5416 (0.5416)	mem 44912MB
Train: [114/180][50/625]	eta 0:16:16 lr 0.236823	data 0.0004 (0.4199)	batch 1.2529 (1.6977)	loss -27.0921 (-27.1743)	grad_norm 0.5319 (0.5328)	mem 44912MB
Train: [114/180][100/625]	eta 0:12:58 lr 0.236314	data 0.0006 (0.2123)	batch 1.2489 (1.4832)	loss -27.2260 (-27.1616)	grad_norm 0.5431 (0.5359)	mem 44912MB
Train: [114/180][150/625]	eta 0:11:10 lr 0.235804	data 0.0006 (0.1422)	batch 1.2700 (1.4113)	loss -27.1217 (-27.1579)	grad_norm 0.5231 (0.5355)	mem 44912MB
Train: [114/180][200/625]	eta 0:09:44 lr 0.235295	data 0.0005 (0.1069)	batch 1.2671 (1.3759)	loss -26.9758 (-27.1537)	grad_norm 0.5972 (0.5356)	mem 44912MB
Train: [114/180][250/625]	eta 0:08:27 lr 0.234786	data 0.0006 (0.0857)	batch 1.2376 (1.3543)	loss -27.1646 (-27.1510)	grad_norm 0.5312 (0.5354)	mem 44912MB
Train: [114/180][300/625]	eta 0:07:15 lr 0.234278	data 0.0005 (0.0716)	batch 1.2884 (1.3391)	loss -27.1677 (-27.1493)	grad_norm 0.5440 (0.5351)	mem 44912MB
Train: [114/180][350/625]	eta 0:06:05 lr 0.233770	data 0.0004 (0.0615)	batch 1.2608 (1.3286)	loss -27.3494 (-27.1454)	grad_norm 0.5377 (0.5346)	mem 44912MB
Train: [114/180][400/625]	eta 0:04:57 lr 0.233262	data 0.0005 (0.0539)	batch 1.2532 (1.3210)	loss -27.1837 (-27.1490)	grad_norm 0.5296 (0.5347)	mem 44912MB
Train: [114/180][450/625]	eta 0:03:50 lr 0.232755	data 0.0005 (0.0480)	batch 1.2528 (1.3143)	loss -27.0027 (-27.1489)	grad_norm 0.5379 (0.5344)	mem 44912MB
Train: [114/180][500/625]	eta 0:02:43 lr 0.232248	data 0.0004 (0.0432)	batch 1.2521 (1.3096)	loss -27.2632 (-27.1471)	grad_norm 0.5311 (0.5346)	mem 44912MB
Train: [114/180][550/625]	eta 0:01:37 lr 0.231741	data 0.0005 (0.0394)	batch 1.2653 (1.3054)	loss -27.0418 (-27.1476)	grad_norm 0.5211 (0.5346)	mem 44912MB
Train: [114/180][600/625]	eta 0:00:32 lr 0.231234	data 0.0006 (0.0361)	batch 1.2539 (1.3020)	loss -27.2533 (-27.1494)	grad_norm 0.5224 (0.5345)	mem 44912MB
Current slope: None 	
EPOCH 114 training takes 0:13:34
Test: [0/25]	Time 14.995 (14.995)	Loss 1.3547 (1.3547)	Acc@1 69.727 (69.727)	Acc@5 88.818 (88.818)	Mem 44912MB
 * Acc@1 58.554 Acc@5 81.986
Accuracy of the network on the 50000 test images: 58.55%
Max accuracy (after decay): 58.55%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [115/180][0/625]	eta 3:54:12 lr 0.230981	data 20.6068 (20.6068)	batch 22.4841 (22.4841)	loss -26.9779 (-26.9779)	grad_norm 0.5221 (0.5221)	mem 44912MB
Train: [115/180][50/625]	eta 0:16:08 lr 0.230475	data 0.0005 (0.4047)	batch 1.2753 (1.6845)	loss -27.1352 (-27.1573)	grad_norm 0.5199 (0.5346)	mem 44912MB
Train: [115/180][100/625]	eta 0:12:57 lr 0.229970	data 0.0005 (0.2047)	batch 1.2548 (1.4811)	loss -27.0951 (-27.1568)	grad_norm 0.5241 (0.5357)	mem 44912MB
Train: [115/180][150/625]	eta 0:11:10 lr 0.229464	data 0.0005 (0.1371)	batch 1.2675 (1.4108)	loss -26.9920 (-27.1499)	grad_norm 0.5347 (0.5359)	mem 44912MB
Train: [115/180][200/625]	eta 0:09:44 lr 0.228959	data 0.0006 (0.1031)	batch 1.2920 (1.3760)	loss -27.2649 (-27.1545)	grad_norm 0.5370 (0.5363)	mem 44912MB
Train: [115/180][250/625]	eta 0:08:27 lr 0.228455	data 0.0005 (0.0827)	batch 1.1983 (1.3542)	loss -27.2599 (-27.1579)	grad_norm 0.5334 (0.5356)	mem 44912MB
Train: [115/180][300/625]	eta 0:07:16 lr 0.227950	data 0.0003 (0.0690)	batch 1.2677 (1.3416)	loss -27.0041 (-27.1567)	grad_norm 0.5780 (0.5363)	mem 44912MB
Train: [115/180][350/625]	eta 0:06:05 lr 0.227446	data 0.0009 (0.0593)	batch 1.2969 (1.3308)	loss -27.1270 (-27.1587)	grad_norm 0.5429 (0.5361)	mem 44912MB
Train: [115/180][400/625]	eta 0:04:57 lr 0.226943	data 0.0006 (0.0520)	batch 1.2582 (1.3228)	loss -27.3108 (-27.1603)	grad_norm 0.5295 (0.5365)	mem 44912MB
Train: [115/180][450/625]	eta 0:03:50 lr 0.226439	data 0.0007 (0.0463)	batch 1.2598 (1.3161)	loss -27.1052 (-27.1614)	grad_norm 0.5208 (0.5365)	mem 44912MB
Train: [115/180][500/625]	eta 0:02:43 lr 0.225936	data 0.0006 (0.0418)	batch 1.2718 (1.3116)	loss -27.0849 (-27.1592)	grad_norm 0.5277 (0.5363)	mem 44912MB
Train: [115/180][550/625]	eta 0:01:38 lr 0.225434	data 0.0003 (0.0380)	batch 1.2683 (1.3076)	loss -27.1964 (-27.1596)	grad_norm 0.5373 (0.5365)	mem 44912MB
Train: [115/180][600/625]	eta 0:00:32 lr 0.224931	data 0.0006 (0.0349)	batch 1.3181 (1.3039)	loss -27.1301 (-27.1626)	grad_norm 0.5458 (0.5364)	mem 44912MB
Current slope: None 	
EPOCH 115 training takes 0:13:35
Test: [0/25]	Time 14.657 (14.657)	Loss 1.3316 (1.3316)	Acc@1 68.994 (68.994)	Acc@5 89.307 (89.307)	Mem 44912MB
 * Acc@1 58.294 Acc@5 81.826
Accuracy of the network on the 50000 test images: 58.29%
Max accuracy (after decay): 58.55%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [116/180][0/625]	eta 3:59:47 lr 0.224680	data 21.7521 (21.7521)	batch 23.0204 (23.0204)	loss -27.1496 (-27.1496)	grad_norm 0.5375 (0.5375)	mem 44912MB
Train: [116/180][50/625]	eta 0:16:12 lr 0.224179	data 0.0006 (0.4275)	batch 1.2247 (1.6921)	loss -27.0497 (-27.1729)	grad_norm 0.5518 (0.5365)	mem 44912MB
Train: [116/180][100/625]	eta 0:12:57 lr 0.223677	data 0.0009 (0.2162)	batch 1.2750 (1.4813)	loss -26.9740 (-27.1729)	grad_norm 0.5469 (0.5357)	mem 44912MB
Train: [116/180][150/625]	eta 0:11:10 lr 0.223176	data 0.0006 (0.1449)	batch 1.2767 (1.4108)	loss -27.2639 (-27.1754)	grad_norm 0.5386 (0.5365)	mem 44912MB
Train: [116/180][200/625]	eta 0:09:44 lr 0.222675	data 0.0006 (0.1090)	batch 1.2873 (1.3759)	loss -27.3662 (-27.1746)	grad_norm 0.5410 (0.5380)	mem 44912MB
Train: [116/180][250/625]	eta 0:08:27 lr 0.222175	data 0.0005 (0.0875)	batch 1.2322 (1.3527)	loss -27.0479 (-27.1734)	grad_norm 0.5712 (0.5382)	mem 44912MB
Train: [116/180][300/625]	eta 0:07:14 lr 0.221675	data 0.0004 (0.0730)	batch 1.3306 (1.3382)	loss -27.2136 (-27.1709)	grad_norm 0.5366 (0.5380)	mem 44912MB
Train: [116/180][350/625]	eta 0:06:05 lr 0.221175	data 0.0005 (0.0627)	batch 1.2752 (1.3279)	loss -27.0342 (-27.1703)	grad_norm 0.5552 (0.5380)	mem 44912MB
Train: [116/180][400/625]	eta 0:04:57 lr 0.220676	data 0.0004 (0.0550)	batch 1.2829 (1.3204)	loss -27.1618 (-27.1698)	grad_norm 0.5926 (0.5381)	mem 44912MB
Train: [116/180][450/625]	eta 0:03:50 lr 0.220177	data 0.0005 (0.0489)	batch 1.2587 (1.3146)	loss -27.2765 (-27.1719)	grad_norm 0.5265 (0.5384)	mem 44912MB
Train: [116/180][500/625]	eta 0:02:43 lr 0.219678	data 0.0005 (0.0441)	batch 1.2580 (1.3099)	loss -27.0718 (-27.1730)	grad_norm 0.5253 (0.5383)	mem 44912MB
Train: [116/180][550/625]	eta 0:01:37 lr 0.219180	data 0.0005 (0.0402)	batch 1.2441 (1.3064)	loss -27.3799 (-27.1716)	grad_norm 0.5278 (0.5385)	mem 44912MB
Train: [116/180][600/625]	eta 0:00:32 lr 0.218682	data 0.0005 (0.0369)	batch 1.2604 (1.3030)	loss -27.4763 (-27.1716)	grad_norm 0.5421 (0.5384)	mem 44912MB
Current slope: None 	
EPOCH 116 training takes 0:13:34
Test: [0/25]	Time 14.702 (14.702)	Loss 1.2700 (1.2700)	Acc@1 71.240 (71.240)	Acc@5 89.990 (89.990)	Mem 44912MB
 * Acc@1 58.598 Acc@5 81.976
Accuracy of the network on the 50000 test images: 58.60%
Max accuracy (after decay): 58.60%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [117/180][0/625]	eta 4:02:24 lr 0.218433	data 21.8478 (21.8478)	batch 23.2711 (23.2711)	loss -27.3133 (-27.3133)	grad_norm 0.5374 (0.5374)	mem 44912MB
Train: [117/180][50/625]	eta 0:16:18 lr 0.217935	data 0.0008 (0.4294)	batch 1.2440 (1.7019)	loss -27.1727 (-27.1843)	grad_norm 0.5348 (0.5366)	mem 44912MB
Train: [117/180][100/625]	eta 0:13:00 lr 0.217438	data 0.0007 (0.2172)	batch 1.2788 (1.4859)	loss -27.1584 (-27.1920)	grad_norm 0.5237 (0.5385)	mem 44912MB
Train: [117/180][150/625]	eta 0:11:11 lr 0.216942	data 0.0008 (0.1455)	batch 1.2517 (1.4138)	loss -27.2303 (-27.1872)	grad_norm 0.5417 (0.5390)	mem 44912MB
Train: [117/180][200/625]	eta 0:09:44 lr 0.216445	data 0.0007 (0.1095)	batch 1.2563 (1.3760)	loss -27.2105 (-27.1882)	grad_norm 0.5545 (0.5393)	mem 44912MB
Train: [117/180][250/625]	eta 0:08:28 lr 0.215949	data 0.0005 (0.0880)	batch 1.2453 (1.3551)	loss -27.4497 (-27.1890)	grad_norm 0.5289 (0.5398)	mem 44912MB
Train: [117/180][300/625]	eta 0:07:15 lr 0.215454	data 0.0005 (0.0735)	batch 1.2312 (1.3402)	loss -27.1548 (-27.1891)	grad_norm 0.5367 (0.5404)	mem 44912MB
Train: [117/180][350/625]	eta 0:06:05 lr 0.214958	data 0.0005 (0.0631)	batch 1.2790 (1.3304)	loss -27.0870 (-27.1833)	grad_norm 0.5432 (0.5402)	mem 44912MB
Train: [117/180][400/625]	eta 0:04:57 lr 0.214463	data 0.0005 (0.0553)	batch 1.2506 (1.3220)	loss -27.3237 (-27.1829)	grad_norm 0.5403 (0.5406)	mem 44912MB
Train: [117/180][450/625]	eta 0:03:50 lr 0.213969	data 0.0004 (0.0492)	batch 1.2198 (1.3168)	loss -27.2705 (-27.1852)	grad_norm 0.5433 (0.5408)	mem 44912MB
Train: [117/180][500/625]	eta 0:02:44 lr 0.213475	data 0.0006 (0.0444)	batch 1.2505 (1.3121)	loss -27.1938 (-27.1844)	grad_norm 0.5377 (0.5411)	mem 44912MB
Train: [117/180][550/625]	eta 0:01:38 lr 0.212981	data 0.0004 (0.0404)	batch 1.2551 (1.3086)	loss -27.1466 (-27.1846)	grad_norm 0.5510 (0.5408)	mem 44912MB
Train: [117/180][600/625]	eta 0:00:32 lr 0.212487	data 0.0005 (0.0371)	batch 1.2577 (1.3047)	loss -27.3639 (-27.1821)	grad_norm 0.5179 (0.5410)	mem 44912MB
Current slope: None 	
EPOCH 117 training takes 0:13:36
Test: [0/25]	Time 14.942 (14.942)	Loss 1.3239 (1.3239)	Acc@1 70.264 (70.264)	Acc@5 89.062 (89.062)	Mem 44912MB
 * Acc@1 58.994 Acc@5 82.296
Accuracy of the network on the 50000 test images: 58.99%
Max accuracy (after decay): 58.99%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [118/180][0/625]	eta 4:03:26 lr 0.212241	data 21.0838 (21.0838)	batch 23.3704 (23.3704)	loss -27.1001 (-27.1001)	grad_norm 0.5622 (0.5622)	mem 44912MB
Train: [118/180][50/625]	eta 0:16:22 lr 0.211748	data 0.0005 (0.4140)	batch 1.2422 (1.7081)	loss -27.2997 (-27.2015)	grad_norm 0.5374 (0.5421)	mem 44912MB
Train: [118/180][100/625]	eta 0:13:01 lr 0.211255	data 0.0006 (0.2093)	batch 1.2580 (1.4889)	loss -27.1149 (-27.2071)	grad_norm 0.5395 (0.5430)	mem 44912MB
Train: [118/180][150/625]	eta 0:11:11 lr 0.210763	data 0.0006 (0.1402)	batch 1.2594 (1.4133)	loss -27.0854 (-27.1977)	grad_norm 0.5402 (0.5438)	mem 44912MB
Train: [118/180][200/625]	eta 0:09:44 lr 0.210271	data 0.0005 (0.1054)	batch 1.2422 (1.3756)	loss -27.2186 (-27.2014)	grad_norm 0.5235 (0.5433)	mem 44912MB
Train: [118/180][250/625]	eta 0:08:27 lr 0.209780	data 0.0004 (0.0845)	batch 1.2531 (1.3540)	loss -27.3674 (-27.1968)	grad_norm 0.5247 (0.5434)	mem 44912MB
Train: [118/180][300/625]	eta 0:07:15 lr 0.209289	data 0.0006 (0.0706)	batch 1.2452 (1.3391)	loss -27.1974 (-27.1940)	grad_norm 0.5346 (0.5434)	mem 44912MB
Train: [118/180][350/625]	eta 0:06:05 lr 0.208798	data 0.0005 (0.0606)	batch 1.2489 (1.3278)	loss -27.1939 (-27.1925)	grad_norm 0.5368 (0.5432)	mem 44912MB
Train: [118/180][400/625]	eta 0:04:57 lr 0.208308	data 0.0006 (0.0531)	batch 1.2531 (1.3206)	loss -27.3859 (-27.1934)	grad_norm 0.5503 (0.5435)	mem 44912MB
Train: [118/180][450/625]	eta 0:03:50 lr 0.207818	data 0.0006 (0.0473)	batch 1.2205 (1.3146)	loss -27.4809 (-27.1913)	grad_norm 0.5298 (0.5435)	mem 44912MB
Train: [118/180][500/625]	eta 0:02:43 lr 0.207328	data 0.0005 (0.0426)	batch 1.2300 (1.3096)	loss -27.2774 (-27.1939)	grad_norm 0.5446 (0.5436)	mem 44912MB
Train: [118/180][550/625]	eta 0:01:37 lr 0.206839	data 0.0006 (0.0388)	batch 1.2114 (1.3053)	loss -27.0963 (-27.1913)	grad_norm 0.5567 (0.5437)	mem 44912MB
Train: [118/180][600/625]	eta 0:00:32 lr 0.206350	data 0.0005 (0.0356)	batch 1.2561 (1.3021)	loss -27.2531 (-27.1903)	grad_norm 0.5242 (0.5436)	mem 44912MB
Current slope: None 	
EPOCH 118 training takes 0:13:34
Test: [0/25]	Time 14.252 (14.252)	Loss 1.3264 (1.3264)	Acc@1 71.289 (71.289)	Acc@5 89.258 (89.258)	Mem 44912MB
 * Acc@1 58.890 Acc@5 82.368
Accuracy of the network on the 50000 test images: 58.89%
Max accuracy (after decay): 58.99%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [119/180][0/625]	eta 4:04:09 lr 0.206106	data 21.5777 (21.5777)	batch 23.4397 (23.4397)	loss -27.1122 (-27.1122)	grad_norm 0.5451 (0.5451)	mem 44912MB
Train: [119/180][50/625]	eta 0:16:23 lr 0.205618	data 0.0005 (0.4236)	batch 1.2596 (1.7109)	loss -27.2393 (-27.2131)	grad_norm 0.5546 (0.5419)	mem 44912MB
Train: [119/180][100/625]	eta 0:13:02 lr 0.205130	data 0.0008 (0.2142)	batch 1.2545 (1.4906)	loss -27.3494 (-27.2184)	grad_norm 0.5499 (0.5446)	mem 44912MB
Train: [119/180][150/625]	eta 0:11:13 lr 0.204642	data 0.0005 (0.1435)	batch 1.2533 (1.4186)	loss -27.1611 (-27.2160)	grad_norm 0.5303 (0.5462)	mem 44912MB
Train: [119/180][200/625]	eta 0:09:46 lr 0.204155	data 0.0005 (0.1079)	batch 1.2917 (1.3801)	loss -27.1160 (-27.2087)	grad_norm 0.5428 (0.5458)	mem 44912MB
Train: [119/180][250/625]	eta 0:08:29 lr 0.203668	data 0.0005 (0.0865)	batch 1.2600 (1.3577)	loss -27.2326 (-27.2089)	grad_norm 0.5418 (0.5461)	mem 44912MB
Train: [119/180][300/625]	eta 0:07:16 lr 0.203182	data 0.0006 (0.0722)	batch 1.2214 (1.3431)	loss -27.1705 (-27.2048)	grad_norm 0.5717 (0.5465)	mem 44912MB
Train: [119/180][350/625]	eta 0:06:06 lr 0.202696	data 0.0011 (0.0622)	batch 1.2479 (1.3321)	loss -27.1249 (-27.2038)	grad_norm 0.5342 (0.5461)	mem 44912MB
Train: [119/180][400/625]	eta 0:04:57 lr 0.202210	data 0.0004 (0.0545)	batch 1.2833 (1.3234)	loss -27.3307 (-27.2045)	grad_norm 0.5479 (0.5458)	mem 44912MB
Train: [119/180][450/625]	eta 0:03:50 lr 0.201725	data 0.0004 (0.0486)	batch 1.2792 (1.3167)	loss -27.4016 (-27.2044)	grad_norm 0.5310 (0.5456)	mem 44912MB
Train: [119/180][500/625]	eta 0:02:44 lr 0.201240	data 0.0004 (0.0438)	batch 1.2470 (1.3121)	loss -27.1617 (-27.2032)	grad_norm 0.5335 (0.5458)	mem 44912MB
Train: [119/180][550/625]	eta 0:01:38 lr 0.200756	data 0.0004 (0.0398)	batch 1.3026 (1.3082)	loss -27.1677 (-27.2021)	grad_norm 0.5362 (0.5460)	mem 44912MB
Train: [119/180][600/625]	eta 0:00:32 lr 0.200272	data 0.0005 (0.0366)	batch 1.2676 (1.3045)	loss -27.3271 (-27.2013)	grad_norm 0.5417 (0.5462)	mem 44912MB
Current slope: None 	
EPOCH 119 training takes 0:13:35
Test: [0/25]	Time 14.646 (14.646)	Loss 1.2978 (1.2978)	Acc@1 71.729 (71.729)	Acc@5 89.502 (89.502)	Mem 44912MB
 * Acc@1 58.476 Acc@5 81.934
Accuracy of the network on the 50000 test images: 58.48%
Max accuracy (after decay): 58.99%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [120/180][0/625]	eta 3:55:52 lr 0.200030	data 21.3384 (21.3384)	batch 22.6434 (22.6434)	loss -27.2088 (-27.2088)	grad_norm 0.5597 (0.5597)	mem 44912MB
Train: [120/180][50/625]	eta 0:16:13 lr 0.199547	data 0.0005 (0.4192)	batch 1.2739 (1.6935)	loss -27.2045 (-27.2145)	grad_norm 0.5513 (0.5500)	mem 44912MB
Train: [120/180][100/625]	eta 0:12:57 lr 0.199063	data 0.0006 (0.2120)	batch 1.2542 (1.4805)	loss -27.3048 (-27.2102)	grad_norm 0.5421 (0.5506)	mem 44912MB
Train: [120/180][150/625]	eta 0:11:09 lr 0.198581	data 0.0004 (0.1420)	batch 1.2618 (1.4099)	loss -27.1833 (-27.2097)	grad_norm 0.5535 (0.5513)	mem 44912MB
Train: [120/180][200/625]	eta 0:09:43 lr 0.198099	data 0.0006 (0.1068)	batch 1.2815 (1.3741)	loss -27.2237 (-27.2064)	grad_norm 0.5384 (0.5509)	mem 44912MB
Train: [120/180][250/625]	eta 0:08:27 lr 0.197617	data 0.0010 (0.0857)	batch 1.2551 (1.3532)	loss -27.2166 (-27.2069)	grad_norm 0.5571 (0.5504)	mem 44912MB
Train: [120/180][300/625]	eta 0:07:14 lr 0.197135	data 0.0004 (0.0715)	batch 1.2647 (1.3376)	loss -27.0846 (-27.2071)	grad_norm 0.5475 (0.5501)	mem 44912MB
Train: [120/180][350/625]	eta 0:06:05 lr 0.196654	data 0.0006 (0.0614)	batch 1.3259 (1.3277)	loss -27.3579 (-27.2084)	grad_norm 0.5389 (0.5499)	mem 44912MB
Train: [120/180][400/625]	eta 0:04:57 lr 0.196173	data 0.0005 (0.0538)	batch 1.2811 (1.3200)	loss -27.1825 (-27.2072)	grad_norm 0.5589 (0.5500)	mem 44912MB
Train: [120/180][450/625]	eta 0:03:50 lr 0.195693	data 0.0005 (0.0479)	batch 1.3147 (1.3146)	loss -27.3257 (-27.2078)	grad_norm 0.5460 (0.5501)	mem 44912MB
Train: [120/180][500/625]	eta 0:02:43 lr 0.195213	data 0.0005 (0.0432)	batch 1.2801 (1.3090)	loss -27.1450 (-27.2093)	grad_norm 0.5631 (0.5499)	mem 44912MB
Train: [120/180][550/625]	eta 0:01:37 lr 0.194734	data 0.0004 (0.0393)	batch 1.2563 (1.3048)	loss -27.0268 (-27.2097)	grad_norm 0.5646 (0.5498)	mem 44912MB
Train: [120/180][600/625]	eta 0:00:32 lr 0.194254	data 0.0005 (0.0361)	batch 1.2793 (1.3011)	loss -27.1052 (-27.2079)	grad_norm 0.5557 (0.5498)	mem 44912MB
Current slope: None 	
EPOCH 120 training takes 0:13:33
Test: [0/25]	Time 15.665 (15.665)	Loss 1.2699 (1.2699)	Acc@1 71.826 (71.826)	Acc@5 89.551 (89.551)	Mem 44912MB
 * Acc@1 59.152 Acc@5 82.426
Accuracy of the network on the 50000 test images: 59.15%
Max accuracy (after decay): 59.15%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [121/180][0/625]	eta 4:12:29 lr 0.194015	data 21.4769 (21.4769)	batch 24.2393 (24.2393)	loss -27.2903 (-27.2903)	grad_norm 0.5371 (0.5371)	mem 44912MB
Train: [121/180][50/625]	eta 0:16:26 lr 0.193537	data 0.0005 (0.4217)	batch 1.3352 (1.7154)	loss -27.3583 (-27.2305)	grad_norm 0.5598 (0.5513)	mem 44912MB
Train: [121/180][100/625]	eta 0:13:01 lr 0.193058	data 0.0005 (0.2132)	batch 1.2565 (1.4889)	loss -27.3129 (-27.2249)	grad_norm 0.5415 (0.5516)	mem 44912MB
Train: [121/180][150/625]	eta 0:11:10 lr 0.192581	data 0.0005 (0.1428)	batch 1.2436 (1.4119)	loss -27.2652 (-27.2245)	grad_norm 0.5523 (0.5508)	mem 44912MB
Train: [121/180][200/625]	eta 0:09:43 lr 0.192103	data 0.0013 (0.1074)	batch 1.2712 (1.3731)	loss -27.2071 (-27.2223)	grad_norm 0.5475 (0.5513)	mem 44912MB
Train: [121/180][250/625]	eta 0:08:26 lr 0.191627	data 0.0006 (0.0861)	batch 1.2446 (1.3517)	loss -27.1547 (-27.2258)	grad_norm 0.5559 (0.5521)	mem 44912MB
Train: [121/180][300/625]	eta 0:07:14 lr 0.191150	data 0.0010 (0.0719)	batch 1.2959 (1.3383)	loss -27.2625 (-27.2246)	grad_norm 0.5387 (0.5525)	mem 44912MB
Train: [121/180][350/625]	eta 0:06:05 lr 0.190674	data 0.0007 (0.0618)	batch 1.1876 (1.3274)	loss -27.0145 (-27.2239)	grad_norm 0.5590 (0.5527)	mem 44912MB
Train: [121/180][400/625]	eta 0:04:56 lr 0.190198	data 0.0006 (0.0541)	batch 1.2127 (1.3196)	loss -27.4370 (-27.2219)	grad_norm 0.5504 (0.5526)	mem 44912MB
Train: [121/180][450/625]	eta 0:03:49 lr 0.189723	data 0.0005 (0.0482)	batch 1.2817 (1.3132)	loss -27.4688 (-27.2204)	grad_norm 0.5391 (0.5524)	mem 44912MB
Train: [121/180][500/625]	eta 0:02:43 lr 0.189248	data 0.0005 (0.0435)	batch 1.2076 (1.3078)	loss -27.1029 (-27.2193)	grad_norm 0.5642 (0.5521)	mem 44912MB
Train: [121/180][550/625]	eta 0:01:37 lr 0.188774	data 0.0005 (0.0396)	batch 1.2872 (1.3035)	loss -27.2559 (-27.2194)	grad_norm 0.5341 (0.5519)	mem 44912MB
Train: [121/180][600/625]	eta 0:00:32 lr 0.188300	data 0.0006 (0.0363)	batch 1.3701 (1.2999)	loss -27.2149 (-27.2194)	grad_norm 0.5556 (0.5520)	mem 44912MB
Current slope: None 	
EPOCH 121 training takes 0:13:33
Test: [0/25]	Time 14.799 (14.799)	Loss 1.3099 (1.3099)	Acc@1 71.484 (71.484)	Acc@5 89.258 (89.258)	Mem 44912MB
 * Acc@1 59.014 Acc@5 82.226
Accuracy of the network on the 50000 test images: 59.01%
Max accuracy (after decay): 59.15%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [122/180][0/625]	eta 4:04:19 lr 0.188063	data 21.8333 (21.8333)	batch 23.4549 (23.4549)	loss -27.2153 (-27.2153)	grad_norm 0.5577 (0.5577)	mem 44912MB
Train: [122/180][50/625]	eta 0:16:25 lr 0.187589	data 0.0005 (0.4288)	batch 1.3832 (1.7132)	loss -27.2674 (-27.2319)	grad_norm 0.5400 (0.5515)	mem 44912MB
Train: [122/180][100/625]	eta 0:13:04 lr 0.187116	data 0.0005 (0.2168)	batch 1.2467 (1.4942)	loss -27.3005 (-27.2349)	grad_norm 0.5696 (0.5548)	mem 44912MB
Train: [122/180][150/625]	eta 0:11:13 lr 0.186644	data 0.0005 (0.1452)	batch 1.2442 (1.4180)	loss -27.2511 (-27.2338)	grad_norm 0.5566 (0.5548)	mem 44912MB
Train: [122/180][200/625]	eta 0:09:47 lr 0.186172	data 0.0005 (0.1092)	batch 1.2825 (1.3812)	loss -27.0563 (-27.2298)	grad_norm 0.5478 (0.5552)	mem 44912MB
Train: [122/180][250/625]	eta 0:08:28 lr 0.185700	data 0.0005 (0.0876)	batch 1.2940 (1.3573)	loss -27.3645 (-27.2296)	grad_norm 0.5624 (0.5550)	mem 44912MB
Train: [122/180][300/625]	eta 0:07:16 lr 0.185229	data 0.0005 (0.0731)	batch 1.2499 (1.3421)	loss -27.2720 (-27.2309)	grad_norm 0.5439 (0.5549)	mem 44912MB
Train: [122/180][350/625]	eta 0:06:06 lr 0.184758	data 0.0005 (0.0628)	batch 1.2865 (1.3315)	loss -27.3254 (-27.2320)	grad_norm 0.5387 (0.5548)	mem 44912MB
Train: [122/180][400/625]	eta 0:04:57 lr 0.184287	data 0.0007 (0.0550)	batch 1.2433 (1.3232)	loss -27.3228 (-27.2339)	grad_norm 0.5620 (0.5547)	mem 44912MB
Train: [122/180][450/625]	eta 0:03:50 lr 0.183817	data 0.0005 (0.0490)	batch 1.2141 (1.3166)	loss -27.1904 (-27.2332)	grad_norm 0.5660 (0.5548)	mem 44912MB
Train: [122/180][500/625]	eta 0:02:43 lr 0.183348	data 0.0006 (0.0442)	batch 1.3312 (1.3118)	loss -27.6545 (-27.2306)	grad_norm 0.5593 (0.5549)	mem 44912MB
Train: [122/180][550/625]	eta 0:01:38 lr 0.182878	data 0.0005 (0.0402)	batch 1.3375 (1.3077)	loss -27.2721 (-27.2289)	grad_norm 0.5560 (0.5549)	mem 44912MB
Train: [122/180][600/625]	eta 0:00:32 lr 0.182410	data 0.0005 (0.0369)	batch 1.2621 (1.3038)	loss -27.1766 (-27.2282)	grad_norm 0.5415 (0.5549)	mem 44912MB
Current slope: None 	
EPOCH 122 training takes 0:13:35
Test: [0/25]	Time 14.804 (14.804)	Loss 1.2298 (1.2298)	Acc@1 72.217 (72.217)	Acc@5 90.137 (90.137)	Mem 44912MB
 * Acc@1 59.532 Acc@5 82.758
Accuracy of the network on the 50000 test images: 59.53%
Max accuracy (after decay): 59.53%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [123/180][0/625]	eta 4:02:12 lr 0.182175	data 21.6968 (21.6968)	batch 23.2525 (23.2525)	loss -27.1649 (-27.1649)	grad_norm 0.5518 (0.5518)	mem 44912MB
Train: [123/180][50/625]	eta 0:16:18 lr 0.181707	data 0.0005 (0.4261)	batch 1.3619 (1.7014)	loss -27.4034 (-27.2631)	grad_norm 0.5531 (0.5568)	mem 44912MB
Train: [123/180][100/625]	eta 0:13:00 lr 0.181239	data 0.0006 (0.2155)	batch 1.2526 (1.4865)	loss -27.1235 (-27.2577)	grad_norm 0.5721 (0.5584)	mem 44912MB
Train: [123/180][150/625]	eta 0:11:11 lr 0.180772	data 0.0006 (0.1443)	batch 1.2384 (1.4134)	loss -27.4314 (-27.2561)	grad_norm 0.5495 (0.5572)	mem 44912MB
Train: [123/180][200/625]	eta 0:09:44 lr 0.180305	data 0.0005 (0.1086)	batch 1.2533 (1.3761)	loss -27.1619 (-27.2445)	grad_norm 0.5615 (0.5582)	mem 44912MB
Train: [123/180][250/625]	eta 0:08:28 lr 0.179839	data 0.0003 (0.0870)	batch 1.2617 (1.3550)	loss -27.3030 (-27.2453)	grad_norm 0.5497 (0.5581)	mem 44912MB
Train: [123/180][300/625]	eta 0:07:15 lr 0.179373	data 0.0005 (0.0727)	batch 1.3021 (1.3405)	loss -27.3092 (-27.2424)	grad_norm 0.5626 (0.5582)	mem 44912MB
Train: [123/180][350/625]	eta 0:06:05 lr 0.178907	data 0.0007 (0.0624)	batch 1.3483 (1.3306)	loss -27.2531 (-27.2408)	grad_norm 0.5656 (0.5585)	mem 44912MB
Train: [123/180][400/625]	eta 0:04:57 lr 0.178442	data 0.0005 (0.0547)	batch 1.2754 (1.3221)	loss -27.3741 (-27.2402)	grad_norm 0.5534 (0.5587)	mem 44912MB
Train: [123/180][450/625]	eta 0:03:50 lr 0.177977	data 0.0005 (0.0487)	batch 1.2425 (1.3164)	loss -27.2676 (-27.2387)	grad_norm 0.5564 (0.5583)	mem 44912MB
Train: [123/180][500/625]	eta 0:02:43 lr 0.177513	data 0.0005 (0.0439)	batch 1.2545 (1.3114)	loss -27.2021 (-27.2359)	grad_norm 0.5753 (0.5585)	mem 44912MB
Train: [123/180][550/625]	eta 0:01:38 lr 0.177049	data 0.0006 (0.0399)	batch 1.2384 (1.3074)	loss -27.2125 (-27.2344)	grad_norm 0.5538 (0.5586)	mem 44912MB
Train: [123/180][600/625]	eta 0:00:32 lr 0.176586	data 0.0005 (0.0367)	batch 1.2855 (1.3037)	loss -27.3694 (-27.2337)	grad_norm 0.5614 (0.5585)	mem 44912MB
Current slope: None 	
EPOCH 123 training takes 0:13:35
Test: [0/25]	Time 14.401 (14.401)	Loss 1.2578 (1.2578)	Acc@1 71.777 (71.777)	Acc@5 89.941 (89.941)	Mem 44912MB
 * Acc@1 59.456 Acc@5 82.684
Accuracy of the network on the 50000 test images: 59.46%
Max accuracy (after decay): 59.53%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [124/180][0/625]	eta 4:05:28 lr 0.176354	data 20.9354 (20.9354)	batch 23.5650 (23.5650)	loss -27.3119 (-27.3119)	grad_norm 0.5532 (0.5532)	mem 44912MB
Train: [124/180][50/625]	eta 0:16:21 lr 0.175891	data 0.0005 (0.4111)	batch 1.2523 (1.7076)	loss -27.2399 (-27.2419)	grad_norm 0.5649 (0.5588)	mem 44912MB
Train: [124/180][100/625]	eta 0:13:02 lr 0.175429	data 0.0006 (0.2079)	batch 1.2470 (1.4898)	loss -27.2875 (-27.2416)	grad_norm 0.5524 (0.5608)	mem 44912MB
Train: [124/180][150/625]	eta 0:11:12 lr 0.174967	data 0.0005 (0.1392)	batch 1.2632 (1.4163)	loss -27.2437 (-27.2462)	grad_norm 0.5587 (0.5613)	mem 44912MB
Train: [124/180][200/625]	eta 0:09:46 lr 0.174506	data 0.0006 (0.1047)	batch 1.2423 (1.3790)	loss -27.4194 (-27.2485)	grad_norm 0.5476 (0.5608)	mem 44912MB
Train: [124/180][250/625]	eta 0:08:28 lr 0.174044	data 0.0005 (0.0840)	batch 1.3398 (1.3561)	loss -27.2725 (-27.2460)	grad_norm 0.5685 (0.5607)	mem 44912MB
Train: [124/180][300/625]	eta 0:07:15 lr 0.173584	data 0.0005 (0.0701)	batch 1.2212 (1.3401)	loss -27.0931 (-27.2452)	grad_norm 0.5601 (0.5605)	mem 44912MB
Train: [124/180][350/625]	eta 0:06:05 lr 0.173124	data 0.0005 (0.0602)	batch 1.2576 (1.3296)	loss -27.2801 (-27.2456)	grad_norm 0.6536 (0.5606)	mem 44912MB
Train: [124/180][400/625]	eta 0:04:57 lr 0.172664	data 0.0005 (0.0528)	batch 1.2599 (1.3212)	loss -27.1697 (-27.2480)	grad_norm 0.5613 (0.5605)	mem 44912MB
Train: [124/180][450/625]	eta 0:03:50 lr 0.172205	data 0.0006 (0.0470)	batch 1.2179 (1.3149)	loss -27.2658 (-27.2467)	grad_norm 0.5726 (0.5605)	mem 44912MB
Train: [124/180][500/625]	eta 0:02:43 lr 0.171746	data 0.0006 (0.0423)	batch 1.2134 (1.3092)	loss -27.2233 (-27.2477)	grad_norm 0.5568 (0.5607)	mem 44912MB
Train: [124/180][550/625]	eta 0:01:37 lr 0.171288	data 0.0005 (0.0386)	batch 1.2482 (1.3046)	loss -27.1776 (-27.2455)	grad_norm 0.5736 (0.5606)	mem 44912MB
Train: [124/180][600/625]	eta 0:00:32 lr 0.170830	data 0.0005 (0.0354)	batch 1.2649 (1.3009)	loss -27.3884 (-27.2452)	grad_norm 0.5700 (0.5608)	mem 44912MB
Current slope: None 	
EPOCH 124 training takes 0:13:33
Test: [0/25]	Time 14.634 (14.634)	Loss 1.2860 (1.2860)	Acc@1 69.873 (69.873)	Acc@5 89.697 (89.697)	Mem 44912MB
 * Acc@1 59.028 Acc@5 82.564
Accuracy of the network on the 50000 test images: 59.03%
Max accuracy (after decay): 59.53%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [125/180][0/625]	eta 4:01:46 lr 0.170601	data 21.4875 (21.4875)	batch 23.2099 (23.2099)	loss -27.1507 (-27.1507)	grad_norm 0.5646 (0.5646)	mem 44912MB
Train: [125/180][50/625]	eta 0:16:15 lr 0.170144	data 0.0006 (0.4221)	batch 1.2996 (1.6971)	loss -27.3574 (-27.2700)	grad_norm 0.5636 (0.5651)	mem 44912MB
Train: [125/180][100/625]	eta 0:12:57 lr 0.169687	data 0.0007 (0.2135)	batch 1.2300 (1.4809)	loss -27.2140 (-27.2736)	grad_norm 0.5758 (0.5656)	mem 44912MB
Train: [125/180][150/625]	eta 0:11:09 lr 0.169230	data 0.0005 (0.1431)	batch 1.2549 (1.4095)	loss -27.0530 (-27.2754)	grad_norm 0.5783 (0.5659)	mem 44912MB
Train: [125/180][200/625]	eta 0:09:44 lr 0.168775	data 0.0006 (0.1077)	batch 1.2863 (1.3759)	loss -27.1167 (-27.2654)	grad_norm 0.5551 (0.5654)	mem 44912MB
Train: [125/180][250/625]	eta 0:08:26 lr 0.168319	data 0.0006 (0.0864)	batch 1.2147 (1.3517)	loss -27.3440 (-27.2639)	grad_norm 0.5497 (0.5650)	mem 44912MB
Train: [125/180][300/625]	eta 0:07:14 lr 0.167864	data 0.0005 (0.0722)	batch 1.2515 (1.3368)	loss -27.2663 (-27.2631)	grad_norm 0.5497 (0.5648)	mem 44912MB
Train: [125/180][350/625]	eta 0:06:04 lr 0.167410	data 0.0008 (0.0620)	batch 1.2646 (1.3267)	loss -27.0497 (-27.2605)	grad_norm 0.5462 (0.5648)	mem 44912MB
Train: [125/180][400/625]	eta 0:04:56 lr 0.166955	data 0.0007 (0.0544)	batch 1.2844 (1.3188)	loss -27.2178 (-27.2566)	grad_norm 0.5693 (0.5648)	mem 44912MB
Train: [125/180][450/625]	eta 0:03:49 lr 0.166502	data 0.0006 (0.0484)	batch 1.2419 (1.3126)	loss -27.2232 (-27.2548)	grad_norm 0.5759 (0.5643)	mem 44912MB
Train: [125/180][500/625]	eta 0:02:43 lr 0.166049	data 0.0008 (0.0437)	batch 1.2188 (1.3075)	loss -27.1261 (-27.2563)	grad_norm 0.5607 (0.5640)	mem 44912MB
Train: [125/180][550/625]	eta 0:01:37 lr 0.165596	data 0.0011 (0.0398)	batch 1.2096 (1.3038)	loss -27.2727 (-27.2562)	grad_norm 0.5575 (0.5639)	mem 44912MB
Train: [125/180][600/625]	eta 0:00:32 lr 0.165144	data 0.0008 (0.0365)	batch 1.2382 (1.3008)	loss -27.1955 (-27.2559)	grad_norm 0.5613 (0.5639)	mem 44912MB
Current slope: None 	
EPOCH 125 training takes 0:13:33
Test: [0/25]	Time 14.545 (14.545)	Loss 1.2948 (1.2948)	Acc@1 71.338 (71.338)	Acc@5 89.258 (89.258)	Mem 44912MB
 * Acc@1 59.326 Acc@5 82.512
Accuracy of the network on the 50000 test images: 59.33%
Max accuracy (after decay): 59.53%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [126/180][0/625]	eta 3:55:17 lr 0.164918	data 20.9539 (20.9539)	batch 22.5879 (22.5879)	loss -27.1352 (-27.1352)	grad_norm 0.5668 (0.5668)	mem 44912MB
Train: [126/180][50/625]	eta 0:16:10 lr 0.164466	data 0.0007 (0.4119)	batch 1.2000 (1.6876)	loss -27.1139 (-27.2705)	grad_norm 0.5572 (0.5615)	mem 44912MB
Train: [126/180][100/625]	eta 0:12:55 lr 0.164015	data 0.0008 (0.2084)	batch 1.2164 (1.4772)	loss -27.2877 (-27.2510)	grad_norm 0.5589 (0.5630)	mem 44912MB
Train: [126/180][150/625]	eta 0:11:08 lr 0.163564	data 0.0009 (0.1397)	batch 1.2688 (1.4075)	loss -27.4939 (-27.2619)	grad_norm 0.5508 (0.5638)	mem 44912MB
Train: [126/180][200/625]	eta 0:09:43 lr 0.163114	data 0.0007 (0.1052)	batch 1.2745 (1.3728)	loss -27.1414 (-27.2609)	grad_norm 0.5635 (0.5657)	mem 44912MB
Train: [126/180][250/625]	eta 0:08:26 lr 0.162664	data 0.0007 (0.0844)	batch 1.2351 (1.3503)	loss -27.2837 (-27.2612)	grad_norm 0.5628 (0.5662)	mem 44912MB
Train: [126/180][300/625]	eta 0:07:13 lr 0.162215	data 0.0006 (0.0705)	batch 1.2429 (1.3352)	loss -27.3236 (-27.2614)	grad_norm 0.5643 (0.5667)	mem 44912MB
Train: [126/180][350/625]	eta 0:06:04 lr 0.161766	data 0.0004 (0.0606)	batch 1.2821 (1.3251)	loss -27.1222 (-27.2613)	grad_norm 0.5737 (0.5665)	mem 44912MB
Train: [126/180][400/625]	eta 0:04:56 lr 0.161318	data 0.0005 (0.0531)	batch 1.2725 (1.3188)	loss -27.0917 (-27.2602)	grad_norm 0.5546 (0.5664)	mem 44912MB
Train: [126/180][450/625]	eta 0:03:49 lr 0.160870	data 0.0006 (0.0473)	batch 1.2681 (1.3125)	loss -27.3386 (-27.2594)	grad_norm 0.5719 (0.5665)	mem 44912MB
Train: [126/180][500/625]	eta 0:02:43 lr 0.160423	data 0.0005 (0.0426)	batch 1.3097 (1.3077)	loss -27.3126 (-27.2572)	grad_norm 0.5810 (0.5668)	mem 44912MB
Train: [126/180][550/625]	eta 0:01:37 lr 0.159976	data 0.0005 (0.0388)	batch 1.2744 (1.3038)	loss -27.3908 (-27.2593)	grad_norm 0.5777 (0.5671)	mem 44912MB
Train: [126/180][600/625]	eta 0:00:32 lr 0.159529	data 0.0008 (0.0356)	batch 1.2491 (1.3009)	loss -27.3042 (-27.2594)	grad_norm 0.5683 (0.5672)	mem 44912MB
Current slope: None 	
EPOCH 126 training takes 0:13:33
Test: [0/25]	Time 14.930 (14.930)	Loss 1.2808 (1.2808)	Acc@1 71.045 (71.045)	Acc@5 89.502 (89.502)	Mem 44912MB
 * Acc@1 59.760 Acc@5 82.704
Accuracy of the network on the 50000 test images: 59.76%
Max accuracy (after decay): 59.76%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [127/180][0/625]	eta 4:02:37 lr 0.159306	data 21.4988 (21.4988)	batch 23.2925 (23.2925)	loss -27.1940 (-27.1940)	grad_norm 0.5718 (0.5718)	mem 44912MB
Train: [127/180][50/625]	eta 0:16:19 lr 0.158860	data 0.0009 (0.4222)	batch 1.2252 (1.7034)	loss -27.2608 (-27.2746)	grad_norm 0.5652 (0.5659)	mem 44912MB
Train: [127/180][100/625]	eta 0:13:00 lr 0.158415	data 0.0006 (0.2135)	batch 1.2471 (1.4860)	loss -27.4434 (-27.2787)	grad_norm 0.5544 (0.5676)	mem 44912MB
Train: [127/180][150/625]	eta 0:11:11 lr 0.157970	data 0.0004 (0.1430)	batch 1.2668 (1.4137)	loss -27.3308 (-27.2755)	grad_norm 0.5669 (0.5691)	mem 44912MB
Train: [127/180][200/625]	eta 0:09:45 lr 0.157526	data 0.0005 (0.1075)	batch 1.2683 (1.3766)	loss -27.4679 (-27.2766)	grad_norm 0.5733 (0.5681)	mem 44912MB
Train: [127/180][250/625]	eta 0:08:28 lr 0.157082	data 0.0005 (0.0862)	batch 1.3158 (1.3552)	loss -27.1217 (-27.2748)	grad_norm 0.5678 (0.5689)	mem 44912MB
Train: [127/180][300/625]	eta 0:07:16 lr 0.156638	data 0.0006 (0.0720)	batch 1.2691 (1.3416)	loss -27.2489 (-27.2693)	grad_norm 0.5541 (0.5698)	mem 44912MB
Train: [127/180][350/625]	eta 0:06:06 lr 0.156195	data 0.0005 (0.0618)	batch 1.2944 (1.3318)	loss -27.3153 (-27.2725)	grad_norm 0.5408 (0.5692)	mem 44912MB
Train: [127/180][400/625]	eta 0:04:57 lr 0.155753	data 0.0004 (0.0542)	batch 1.2660 (1.3234)	loss -27.1828 (-27.2697)	grad_norm 0.5885 (0.5695)	mem 44912MB
Train: [127/180][450/625]	eta 0:03:50 lr 0.155311	data 0.0005 (0.0482)	batch 1.2457 (1.3175)	loss -27.1846 (-27.2710)	grad_norm 0.5667 (0.5694)	mem 44912MB
Train: [127/180][500/625]	eta 0:02:44 lr 0.154869	data 0.0006 (0.0435)	batch 1.2663 (1.3124)	loss -27.4206 (-27.2719)	grad_norm 0.5806 (0.5696)	mem 44912MB
Train: [127/180][550/625]	eta 0:01:38 lr 0.154428	data 0.0005 (0.0396)	batch 1.2506 (1.3079)	loss -27.2619 (-27.2695)	grad_norm 0.5538 (0.5697)	mem 44912MB
Train: [127/180][600/625]	eta 0:00:32 lr 0.153988	data 0.0006 (0.0363)	batch 1.2494 (1.3041)	loss -27.1946 (-27.2703)	grad_norm 0.5614 (0.5694)	mem 44912MB
Current slope: None 	
EPOCH 127 training takes 0:13:35
Test: [0/25]	Time 14.511 (14.511)	Loss 1.2641 (1.2641)	Acc@1 71.729 (71.729)	Acc@5 89.648 (89.648)	Mem 44912MB
 * Acc@1 59.390 Acc@5 82.662
Accuracy of the network on the 50000 test images: 59.39%
Max accuracy (after decay): 59.76%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [128/180][0/625]	eta 4:13:44 lr 0.153768	data 22.0036 (22.0036)	batch 24.3585 (24.3585)	loss -27.1346 (-27.1346)	grad_norm 0.5649 (0.5649)	mem 44912MB
Train: [128/180][50/625]	eta 0:16:32 lr 0.153328	data 0.0009 (0.4323)	batch 1.3022 (1.7265)	loss -27.3943 (-27.2777)	grad_norm 0.5754 (0.5702)	mem 44912MB
Train: [128/180][100/625]	eta 0:13:05 lr 0.152889	data 0.0007 (0.2187)	batch 1.2386 (1.4958)	loss -27.3874 (-27.2845)	grad_norm 0.5636 (0.5735)	mem 44912MB
Train: [128/180][150/625]	eta 0:11:14 lr 0.152450	data 0.0005 (0.1465)	batch 1.2812 (1.4198)	loss -27.4147 (-27.2873)	grad_norm 0.5772 (0.5732)	mem 44912MB
Train: [128/180][200/625]	eta 0:09:47 lr 0.152011	data 0.0007 (0.1103)	batch 1.2383 (1.3812)	loss -27.2493 (-27.2826)	grad_norm 0.5580 (0.5732)	mem 44912MB
Train: [128/180][250/625]	eta 0:08:29 lr 0.151573	data 0.0008 (0.0885)	batch 1.2618 (1.3593)	loss -27.4032 (-27.2837)	grad_norm 0.5637 (0.5727)	mem 44912MB
Train: [128/180][300/625]	eta 0:07:16 lr 0.151136	data 0.0005 (0.0739)	batch 1.2890 (1.3433)	loss -27.3138 (-27.2796)	grad_norm 0.5667 (0.5730)	mem 44912MB
Train: [128/180][350/625]	eta 0:06:06 lr 0.150699	data 0.0007 (0.0635)	batch 1.2415 (1.3328)	loss -27.3848 (-27.2803)	grad_norm 0.5586 (0.5729)	mem 44912MB
Train: [128/180][400/625]	eta 0:04:57 lr 0.150262	data 0.0010 (0.0557)	batch 1.2562 (1.3240)	loss -27.2898 (-27.2800)	grad_norm 0.5686 (0.5729)	mem 44912MB
Train: [128/180][450/625]	eta 0:03:50 lr 0.149826	data 0.0006 (0.0496)	batch 1.3639 (1.3180)	loss -27.3015 (-27.2776)	grad_norm 0.5596 (0.5726)	mem 44912MB
Train: [128/180][500/625]	eta 0:02:44 lr 0.149391	data 0.0005 (0.0447)	batch 1.2876 (1.3121)	loss -27.2978 (-27.2777)	grad_norm 0.5596 (0.5728)	mem 44912MB
Train: [128/180][550/625]	eta 0:01:38 lr 0.148956	data 0.0005 (0.0407)	batch 1.2547 (1.3080)	loss -27.2394 (-27.2782)	grad_norm 0.5554 (0.5725)	mem 44912MB
Train: [128/180][600/625]	eta 0:00:32 lr 0.148522	data 0.0005 (0.0373)	batch 1.2334 (1.3038)	loss -27.3080 (-27.2774)	grad_norm 0.5720 (0.5724)	mem 44912MB
Current slope: None 	
EPOCH 128 training takes 0:13:35
Test: [0/25]	Time 14.700 (14.700)	Loss 1.2461 (1.2461)	Acc@1 72.900 (72.900)	Acc@5 89.941 (89.941)	Mem 44912MB
 * Acc@1 59.994 Acc@5 83.066
Accuracy of the network on the 50000 test images: 59.99%
Max accuracy (after decay): 59.99%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [129/180][0/625]	eta 4:05:08 lr 0.148304	data 20.4433 (20.4433)	batch 23.5333 (23.5333)	loss -27.1074 (-27.1074)	grad_norm 0.5612 (0.5612)	mem 44912MB
Train: [129/180][50/625]	eta 0:16:23 lr 0.147871	data 0.0005 (0.4014)	batch 1.3101 (1.7101)	loss -27.3952 (-27.2861)	grad_norm 0.5695 (0.5695)	mem 44912MB
Train: [129/180][100/625]	eta 0:13:03 lr 0.147437	data 0.0296 (0.2033)	batch 1.2938 (1.4925)	loss -27.2831 (-27.2892)	grad_norm 0.5801 (0.5710)	mem 44912MB
Train: [129/180][150/625]	eta 0:11:13 lr 0.147005	data 0.0004 (0.1362)	batch 1.3202 (1.4174)	loss -27.3026 (-27.2888)	grad_norm 0.5592 (0.5727)	mem 44912MB
Train: [129/180][200/625]	eta 0:09:46 lr 0.146572	data 0.0005 (0.1026)	batch 1.3467 (1.3806)	loss -27.1792 (-27.2888)	grad_norm 0.5642 (0.5725)	mem 44912MB
Train: [129/180][250/625]	eta 0:08:29 lr 0.146140	data 0.0005 (0.0822)	batch 1.2893 (1.3580)	loss -27.2782 (-27.2835)	grad_norm 0.5765 (0.5732)	mem 44912MB
Train: [129/180][300/625]	eta 0:07:16 lr 0.145709	data 0.0004 (0.0687)	batch 1.3016 (1.3423)	loss -27.3678 (-27.2853)	grad_norm 0.5674 (0.5733)	mem 44912MB
Train: [129/180][350/625]	eta 0:06:06 lr 0.145278	data 0.0005 (0.0590)	batch 1.2883 (1.3311)	loss -27.1491 (-27.2840)	grad_norm 0.5799 (0.5738)	mem 44912MB
Train: [129/180][400/625]	eta 0:04:57 lr 0.144848	data 0.0008 (0.0517)	batch 1.2602 (1.3229)	loss -27.3088 (-27.2797)	grad_norm 0.5937 (0.5739)	mem 44912MB
Train: [129/180][450/625]	eta 0:03:50 lr 0.144418	data 0.0005 (0.0460)	batch 1.2789 (1.3168)	loss -27.3464 (-27.2779)	grad_norm 0.5674 (0.5740)	mem 44912MB
Train: [129/180][500/625]	eta 0:02:43 lr 0.143989	data 0.0006 (0.0415)	batch 1.2494 (1.3110)	loss -27.4425 (-27.2793)	grad_norm 0.5774 (0.5742)	mem 44912MB
Train: [129/180][550/625]	eta 0:01:38 lr 0.143560	data 0.0005 (0.0378)	batch 1.2582 (1.3072)	loss -27.2769 (-27.2770)	grad_norm 0.5721 (0.5745)	mem 44912MB
Train: [129/180][600/625]	eta 0:00:32 lr 0.143132	data 0.0007 (0.0347)	batch 1.2822 (1.3035)	loss -27.1961 (-27.2758)	grad_norm 0.5990 (0.5745)	mem 44912MB
Current slope: None 	
EPOCH 129 training takes 0:13:35
Test: [0/25]	Time 14.861 (14.861)	Loss 1.2521 (1.2521)	Acc@1 71.582 (71.582)	Acc@5 89.844 (89.844)	Mem 44912MB
 * Acc@1 59.832 Acc@5 82.996
Accuracy of the network on the 50000 test images: 59.83%
Max accuracy (after decay): 59.99%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [130/180][0/625]	eta 4:01:20 lr 0.142918	data 20.1016 (20.1016)	batch 23.1683 (23.1683)	loss -27.4033 (-27.4033)	grad_norm 0.5527 (0.5527)	mem 44912MB
Train: [130/180][50/625]	eta 0:16:15 lr 0.142490	data 0.0005 (0.3948)	batch 1.2513 (1.6969)	loss -27.2187 (-27.3108)	grad_norm 0.5806 (0.5730)	mem 44912MB
Train: [130/180][100/625]	eta 0:12:59 lr 0.142063	data 0.0004 (0.1996)	batch 1.2533 (1.4844)	loss -27.2640 (-27.2994)	grad_norm 0.5863 (0.5764)	mem 44912MB
Train: [130/180][150/625]	eta 0:11:09 lr 0.141637	data 0.0005 (0.1337)	batch 1.2757 (1.4103)	loss -27.2850 (-27.2963)	grad_norm 0.5651 (0.5771)	mem 44912MB
Train: [130/180][200/625]	eta 0:09:44 lr 0.141211	data 0.0005 (0.1006)	batch 1.2744 (1.3748)	loss -27.3376 (-27.2946)	grad_norm 0.5647 (0.5769)	mem 44912MB
Train: [130/180][250/625]	eta 0:08:27 lr 0.140785	data 0.0005 (0.0807)	batch 1.2570 (1.3526)	loss -27.1106 (-27.2946)	grad_norm 0.5810 (0.5770)	mem 44912MB
Train: [130/180][300/625]	eta 0:07:15 lr 0.140360	data 0.0005 (0.0674)	batch 1.2458 (1.3388)	loss -27.4591 (-27.2943)	grad_norm 0.5763 (0.5767)	mem 44912MB
Train: [130/180][350/625]	eta 0:06:05 lr 0.139935	data 0.0005 (0.0578)	batch 1.2483 (1.3276)	loss -27.1924 (-27.2912)	grad_norm 0.5918 (0.5771)	mem 44912MB
Train: [130/180][400/625]	eta 0:04:56 lr 0.139511	data 0.0006 (0.0507)	batch 1.2418 (1.3199)	loss -27.1734 (-27.2937)	grad_norm 0.6009 (0.5772)	mem 44912MB
Train: [130/180][450/625]	eta 0:03:49 lr 0.139088	data 0.0005 (0.0452)	batch 1.2780 (1.3137)	loss -27.2335 (-27.2947)	grad_norm 0.5820 (0.5773)	mem 44912MB
Train: [130/180][500/625]	eta 0:02:43 lr 0.138665	data 0.0006 (0.0408)	batch 1.2645 (1.3093)	loss -27.2659 (-27.2933)	grad_norm 0.5831 (0.5775)	mem 44912MB
Train: [130/180][550/625]	eta 0:01:37 lr 0.138242	data 0.0006 (0.0371)	batch 1.3028 (1.3053)	loss -27.2432 (-27.2900)	grad_norm 0.5891 (0.5776)	mem 44912MB
Train: [130/180][600/625]	eta 0:00:32 lr 0.137820	data 0.0005 (0.0341)	batch 1.2435 (1.3026)	loss -27.2264 (-27.2906)	grad_norm 0.5701 (0.5774)	mem 44912MB
Current slope: None 	
EPOCH 130 training takes 0:13:34
Test: [0/25]	Time 14.776 (14.776)	Loss 1.2619 (1.2619)	Acc@1 72.070 (72.070)	Acc@5 90.332 (90.332)	Mem 44912MB
 * Acc@1 60.002 Acc@5 83.020
Accuracy of the network on the 50000 test images: 60.00%
Max accuracy (after decay): 60.00%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [131/180][0/625]	eta 4:13:41 lr 0.137610	data 23.1569 (23.1569)	batch 24.3537 (24.3537)	loss -27.3565 (-27.3565)	grad_norm 0.5915 (0.5915)	mem 44912MB
Train: [131/180][50/625]	eta 0:16:28 lr 0.137188	data 0.0007 (0.4547)	batch 1.2651 (1.7188)	loss -27.2468 (-27.3425)	grad_norm 0.5825 (0.5782)	mem 44912MB
Train: [131/180][100/625]	eta 0:13:05 lr 0.136768	data 0.0005 (0.2299)	batch 1.3097 (1.4970)	loss -27.3179 (-27.3352)	grad_norm 0.5906 (0.5805)	mem 44912MB
Train: [131/180][150/625]	eta 0:11:15 lr 0.136347	data 0.0005 (0.1540)	batch 1.2808 (1.4227)	loss -27.2931 (-27.3286)	grad_norm 0.5770 (0.5801)	mem 44912MB
Train: [131/180][200/625]	eta 0:09:50 lr 0.135928	data 0.0005 (0.1159)	batch 1.2782 (1.3890)	loss -27.4354 (-27.3178)	grad_norm 0.5741 (0.5804)	mem 44912MB
Train: [131/180][250/625]	eta 0:08:38 lr 0.135508	data 0.0006 (0.0933)	batch 1.2721 (1.3837)	loss -27.3395 (-27.3177)	grad_norm 0.5843 (0.5805)	mem 44912MB
Train: [131/180][300/625]	eta 0:07:23 lr 0.135090	data 0.0005 (0.0779)	batch 1.2611 (1.3651)	loss -27.2803 (-27.3140)	grad_norm 0.5638 (0.5804)	mem 44912MB
Train: [131/180][350/625]	eta 0:06:11 lr 0.134672	data 0.0005 (0.0669)	batch 1.2867 (1.3520)	loss -27.3234 (-27.3175)	grad_norm 0.5708 (0.5803)	mem 44912MB
Train: [131/180][400/625]	eta 0:05:01 lr 0.134254	data 0.0006 (0.0586)	batch 1.2375 (1.3415)	loss -27.3174 (-27.3118)	grad_norm 0.5778 (0.5805)	mem 44912MB
Train: [131/180][450/625]	eta 0:03:53 lr 0.133837	data 0.0005 (0.0522)	batch 1.2657 (1.3333)	loss -27.3122 (-27.3115)	grad_norm 0.5790 (0.5805)	mem 44912MB
Train: [131/180][500/625]	eta 0:02:45 lr 0.133420	data 0.0004 (0.0470)	batch 1.2529 (1.3270)	loss -27.3098 (-27.3078)	grad_norm 0.5826 (0.5805)	mem 44912MB
Train: [131/180][550/625]	eta 0:01:39 lr 0.133004	data 0.0004 (0.0428)	batch 1.2582 (1.3218)	loss -27.1302 (-27.3045)	grad_norm 0.5694 (0.5807)	mem 44912MB
Train: [131/180][600/625]	eta 0:00:32 lr 0.132589	data 0.0004 (0.0393)	batch 1.2663 (1.3172)	loss -27.3050 (-27.3032)	grad_norm 0.5893 (0.5807)	mem 44912MB
Current slope: None 	
EPOCH 131 training takes 0:13:43
Test: [0/25]	Time 15.492 (15.492)	Loss 1.2768 (1.2768)	Acc@1 70.996 (70.996)	Acc@5 89.551 (89.551)	Mem 44912MB
 * Acc@1 60.140 Acc@5 83.084
Accuracy of the network on the 50000 test images: 60.14%
Max accuracy (after decay): 60.14%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [132/180][0/625]	eta 3:58:40 lr 0.132381	data 21.5873 (21.5873)	batch 22.9121 (22.9121)	loss -27.4852 (-27.4852)	grad_norm 0.5905 (0.5905)	mem 44912MB
Train: [132/180][50/625]	eta 0:16:18 lr 0.131966	data 0.0005 (0.4238)	batch 1.2622 (1.7016)	loss -27.4865 (-27.2903)	grad_norm 0.5858 (0.5809)	mem 44912MB
Train: [132/180][100/625]	eta 0:13:01 lr 0.131552	data 0.0005 (0.2143)	batch 1.2453 (1.4885)	loss -27.3651 (-27.2951)	grad_norm 0.5703 (0.5809)	mem 44912MB
Train: [132/180][150/625]	eta 0:11:11 lr 0.131138	data 0.0005 (0.1435)	batch 1.2397 (1.4145)	loss -27.4198 (-27.3043)	grad_norm 0.5612 (0.5819)	mem 44912MB
Train: [132/180][200/625]	eta 0:09:44 lr 0.130725	data 0.0006 (0.1079)	batch 1.2696 (1.3763)	loss -27.3624 (-27.3072)	grad_norm 0.5808 (0.5823)	mem 44912MB
Train: [132/180][250/625]	eta 0:08:27 lr 0.130313	data 0.0005 (0.0866)	batch 1.2665 (1.3543)	loss -27.2683 (-27.3087)	grad_norm 0.5802 (0.5824)	mem 44912MB
Train: [132/180][300/625]	eta 0:07:15 lr 0.129900	data 0.0006 (0.0723)	batch 1.2637 (1.3397)	loss -27.1146 (-27.3080)	grad_norm 0.5904 (0.5820)	mem 44912MB
Train: [132/180][350/625]	eta 0:06:05 lr 0.129489	data 0.0005 (0.0621)	batch 1.2720 (1.3290)	loss -27.2758 (-27.3058)	grad_norm 0.6001 (0.5823)	mem 44912MB
Train: [132/180][400/625]	eta 0:04:57 lr 0.129078	data 0.0005 (0.0544)	batch 1.2749 (1.3206)	loss -27.3707 (-27.3063)	grad_norm 0.5808 (0.5829)	mem 44912MB
Train: [132/180][450/625]	eta 0:03:50 lr 0.128667	data 0.0005 (0.0484)	batch 1.2643 (1.3149)	loss -27.2526 (-27.3038)	grad_norm 0.5845 (0.5828)	mem 44912MB
Train: [132/180][500/625]	eta 0:02:43 lr 0.128257	data 0.0006 (0.0436)	batch 1.3142 (1.3104)	loss -27.4890 (-27.3030)	grad_norm 0.5757 (0.5828)	mem 44912MB
Train: [132/180][550/625]	eta 0:01:37 lr 0.127848	data 0.0006 (0.0397)	batch 1.2516 (1.3059)	loss -27.1046 (-27.3014)	grad_norm 0.5660 (0.5833)	mem 44912MB
Train: [132/180][600/625]	eta 0:00:32 lr 0.127439	data 0.0005 (0.0365)	batch 1.3063 (1.3027)	loss -27.1669 (-27.3021)	grad_norm 0.5831 (0.5837)	mem 44912MB
Current slope: None 	
EPOCH 132 training takes 0:13:34
Test: [0/25]	Time 14.875 (14.875)	Loss 1.2232 (1.2232)	Acc@1 71.484 (71.484)	Acc@5 90.479 (90.479)	Mem 44912MB
 * Acc@1 60.062 Acc@5 83.198
Accuracy of the network on the 50000 test images: 60.06%
Max accuracy (after decay): 60.14%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [133/180][0/625]	eta 3:58:17 lr 0.127234	data 21.4177 (21.4177)	batch 22.8757 (22.8757)	loss -27.3659 (-27.3659)	grad_norm 0.5864 (0.5864)	mem 44912MB
Train: [133/180][50/625]	eta 0:16:09 lr 0.126826	data 0.0005 (0.4205)	batch 1.2827 (1.6866)	loss -27.5507 (-27.3442)	grad_norm 0.5881 (0.5837)	mem 44912MB
Train: [133/180][100/625]	eta 0:12:56 lr 0.126418	data 0.0005 (0.2126)	batch 1.2621 (1.4793)	loss -27.1378 (-27.3205)	grad_norm 0.5727 (0.5854)	mem 44912MB
Train: [133/180][150/625]	eta 0:11:08 lr 0.126011	data 0.0005 (0.1424)	batch 1.2656 (1.4066)	loss -27.3395 (-27.3264)	grad_norm 0.5800 (0.5868)	mem 44912MB
Train: [133/180][200/625]	eta 0:09:43 lr 0.125605	data 0.0006 (0.1071)	batch 1.2255 (1.3719)	loss -27.3228 (-27.3242)	grad_norm 0.5704 (0.5862)	mem 44912MB
Train: [133/180][250/625]	eta 0:08:26 lr 0.125199	data 0.0006 (0.0859)	batch 1.3072 (1.3509)	loss -27.2538 (-27.3198)	grad_norm 0.5790 (0.5863)	mem 44912MB
Train: [133/180][300/625]	eta 0:07:14 lr 0.124793	data 0.0006 (0.0717)	batch 1.2632 (1.3368)	loss -27.1968 (-27.3170)	grad_norm 0.5796 (0.5868)	mem 44912MB
Train: [133/180][350/625]	eta 0:06:04 lr 0.124388	data 0.0005 (0.0616)	batch 1.2527 (1.3260)	loss -27.1771 (-27.3170)	grad_norm 0.5704 (0.5873)	mem 44912MB
Train: [133/180][400/625]	eta 0:04:56 lr 0.123984	data 0.0009 (0.0540)	batch 1.2421 (1.3187)	loss -27.1947 (-27.3178)	grad_norm 0.5958 (0.5874)	mem 44912MB
Train: [133/180][450/625]	eta 0:03:49 lr 0.123580	data 0.0005 (0.0481)	batch 1.2789 (1.3126)	loss -27.1681 (-27.3178)	grad_norm 0.5860 (0.5869)	mem 44912MB
Train: [133/180][500/625]	eta 0:02:43 lr 0.123177	data 0.0004 (0.0434)	batch 1.2477 (1.3077)	loss -27.4496 (-27.3178)	grad_norm 0.6035 (0.5873)	mem 44912MB
Train: [133/180][550/625]	eta 0:01:37 lr 0.122774	data 0.0005 (0.0395)	batch 1.2225 (1.3032)	loss -27.3879 (-27.3169)	grad_norm 0.5928 (0.5870)	mem 44912MB
Train: [133/180][600/625]	eta 0:00:32 lr 0.122371	data 0.0005 (0.0362)	batch 1.2769 (1.3005)	loss -27.0930 (-27.3179)	grad_norm 0.5990 (0.5871)	mem 44912MB
Current slope: None 	
EPOCH 133 training takes 0:13:33
Test: [0/25]	Time 15.110 (15.110)	Loss 1.2485 (1.2485)	Acc@1 71.826 (71.826)	Acc@5 89.795 (89.795)	Mem 44912MB
 * Acc@1 60.400 Acc@5 83.230
Accuracy of the network on the 50000 test images: 60.40%
Max accuracy (after decay): 60.40%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [134/180][0/625]	eta 4:02:47 lr 0.122171	data 21.2569 (21.2569)	batch 23.3072 (23.3072)	loss -27.4091 (-27.4091)	grad_norm 0.5569 (0.5569)	mem 44912MB
Train: [134/180][50/625]	eta 0:16:15 lr 0.121769	data 0.0004 (0.4176)	batch 1.2804 (1.6970)	loss -27.2686 (-27.3442)	grad_norm 0.5811 (0.5891)	mem 44912MB
Train: [134/180][100/625]	eta 0:12:58 lr 0.121368	data 0.0005 (0.2112)	batch 1.2516 (1.4835)	loss -27.4912 (-27.3421)	grad_norm 0.5873 (0.5888)	mem 44912MB
Train: [134/180][150/625]	eta 0:11:10 lr 0.120968	data 0.0005 (0.1414)	batch 1.2334 (1.4121)	loss -27.3654 (-27.3406)	grad_norm 0.5840 (0.5899)	mem 44912MB
Train: [134/180][200/625]	eta 0:09:45 lr 0.120568	data 0.0006 (0.1064)	batch 1.2709 (1.3769)	loss -27.2315 (-27.3310)	grad_norm 0.6160 (0.5894)	mem 44912MB
Train: [134/180][250/625]	eta 0:08:27 lr 0.120169	data 0.0004 (0.0853)	batch 1.2493 (1.3544)	loss -27.4280 (-27.3265)	grad_norm 0.5887 (0.5901)	mem 44912MB
Train: [134/180][300/625]	eta 0:07:15 lr 0.119770	data 0.0005 (0.0712)	batch 1.2763 (1.3395)	loss -27.1976 (-27.3252)	grad_norm 0.5876 (0.5899)	mem 44912MB
Train: [134/180][350/625]	eta 0:06:05 lr 0.119372	data 0.0006 (0.0612)	batch 1.3230 (1.3288)	loss -27.3713 (-27.3203)	grad_norm 0.6021 (0.5903)	mem 44912MB
Train: [134/180][400/625]	eta 0:04:57 lr 0.118974	data 0.0004 (0.0536)	batch 1.2685 (1.3208)	loss -27.2118 (-27.3184)	grad_norm 0.5779 (0.5907)	mem 44912MB
Train: [134/180][450/625]	eta 0:03:50 lr 0.118577	data 0.0005 (0.0477)	batch 1.2388 (1.3149)	loss -27.3216 (-27.3164)	grad_norm 0.5910 (0.5909)	mem 44912MB
Train: [134/180][500/625]	eta 0:02:43 lr 0.118180	data 0.0005 (0.0431)	batch 1.2421 (1.3100)	loss -27.2621 (-27.3185)	grad_norm 0.5948 (0.5910)	mem 44912MB
Train: [134/180][550/625]	eta 0:01:37 lr 0.117784	data 0.0005 (0.0392)	batch 1.2636 (1.3063)	loss -27.1862 (-27.3187)	grad_norm 0.5911 (0.5908)	mem 44912MB
Train: [134/180][600/625]	eta 0:00:32 lr 0.117389	data 0.0008 (0.0360)	batch 1.2680 (1.3031)	loss -27.2359 (-27.3183)	grad_norm 0.5809 (0.5908)	mem 44912MB
Current slope: None 	
EPOCH 134 training takes 0:13:34
Test: [0/25]	Time 14.901 (14.901)	Loss 1.2360 (1.2360)	Acc@1 72.412 (72.412)	Acc@5 89.697 (89.697)	Mem 44912MB
 * Acc@1 60.058 Acc@5 83.160
Accuracy of the network on the 50000 test images: 60.06%
Max accuracy (after decay): 60.40%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [135/180][0/625]	eta 3:59:05 lr 0.117191	data 20.7413 (20.7413)	batch 22.9535 (22.9535)	loss -27.3890 (-27.3890)	grad_norm 0.5809 (0.5809)	mem 44912MB
Train: [135/180][50/625]	eta 0:16:13 lr 0.116797	data 0.0006 (0.4072)	batch 1.2577 (1.6935)	loss -27.3619 (-27.2993)	grad_norm 0.6034 (0.5901)	mem 44912MB
Train: [135/180][100/625]	eta 0:12:56 lr 0.116403	data 0.0006 (0.2059)	batch 1.2697 (1.4799)	loss -27.5050 (-27.3268)	grad_norm 0.5948 (0.5897)	mem 44912MB
Train: [135/180][150/625]	eta 0:11:09 lr 0.116009	data 0.0006 (0.1379)	batch 1.2493 (1.4090)	loss -27.4000 (-27.3275)	grad_norm 0.5958 (0.5910)	mem 44912MB
Train: [135/180][200/625]	eta 0:09:43 lr 0.115616	data 0.0005 (0.1039)	batch 1.2924 (1.3730)	loss -27.2954 (-27.3279)	grad_norm 0.5927 (0.5920)	mem 44912MB
Train: [135/180][250/625]	eta 0:08:27 lr 0.115224	data 0.0005 (0.0833)	batch 1.2895 (1.3525)	loss -27.2742 (-27.3235)	grad_norm 0.5930 (0.5924)	mem 44912MB
Train: [135/180][300/625]	eta 0:07:14 lr 0.114832	data 0.0004 (0.0696)	batch 1.2568 (1.3371)	loss -27.2592 (-27.3251)	grad_norm 0.5776 (0.5921)	mem 44912MB
Train: [135/180][350/625]	eta 0:06:04 lr 0.114441	data 0.0005 (0.0597)	batch 1.2545 (1.3266)	loss -27.2463 (-27.3214)	grad_norm 0.5964 (0.5925)	mem 44912MB
Train: [135/180][400/625]	eta 0:04:56 lr 0.114050	data 0.0004 (0.0524)	batch 1.2802 (1.3188)	loss -27.3511 (-27.3202)	grad_norm 0.5835 (0.5926)	mem 44912MB
Train: [135/180][450/625]	eta 0:03:49 lr 0.113660	data 0.0006 (0.0466)	batch 1.2742 (1.3134)	loss -27.4024 (-27.3219)	grad_norm 0.6196 (0.5928)	mem 44912MB
Train: [135/180][500/625]	eta 0:02:43 lr 0.113270	data 0.0005 (0.0420)	batch 1.2637 (1.3082)	loss -27.3441 (-27.3201)	grad_norm 0.5920 (0.5935)	mem 44912MB
Train: [135/180][550/625]	eta 0:01:37 lr 0.112881	data 0.0005 (0.0383)	batch 1.2523 (1.3048)	loss -27.3266 (-27.3192)	grad_norm 0.5879 (0.5931)	mem 44912MB
Train: [135/180][600/625]	eta 0:00:32 lr 0.112493	data 0.0005 (0.0351)	batch 1.2513 (1.3017)	loss -27.2894 (-27.3195)	grad_norm 0.5897 (0.5932)	mem 44912MB
Current slope: None 	
EPOCH 135 training takes 0:13:34
Test: [0/25]	Time 15.033 (15.033)	Loss 1.2675 (1.2675)	Acc@1 71.436 (71.436)	Acc@5 89.600 (89.600)	Mem 44912MB
 * Acc@1 60.488 Acc@5 83.180
Accuracy of the network on the 50000 test images: 60.49%
Max accuracy (after decay): 60.49%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [136/180][0/625]	eta 4:06:28 lr 0.112298	data 20.7095 (20.7095)	batch 23.6622 (23.6622)	loss -27.4067 (-27.4067)	grad_norm 0.5899 (0.5899)	mem 44912MB
Train: [136/180][50/625]	eta 0:16:22 lr 0.111911	data 0.0009 (0.4069)	batch 1.2441 (1.7083)	loss -27.3360 (-27.3423)	grad_norm 0.5968 (0.5931)	mem 44912MB
Train: [136/180][100/625]	eta 0:13:02 lr 0.111524	data 0.0007 (0.2062)	batch 1.2521 (1.4909)	loss -27.3958 (-27.3437)	grad_norm 0.5950 (0.5951)	mem 44912MB
Train: [136/180][150/625]	eta 0:11:12 lr 0.111137	data 0.0009 (0.1382)	batch 1.3100 (1.4162)	loss -27.3592 (-27.3362)	grad_norm 0.5992 (0.5949)	mem 44912MB
Train: [136/180][200/625]	eta 0:09:45 lr 0.110751	data 0.0009 (0.1042)	batch 1.2877 (1.3784)	loss -27.6309 (-27.3347)	grad_norm 0.6089 (0.5945)	mem 44912MB
Train: [136/180][250/625]	eta 0:08:28 lr 0.110366	data 0.0010 (0.0836)	batch 1.2475 (1.3566)	loss -27.3765 (-27.3338)	grad_norm 0.5882 (0.5946)	mem 44912MB
Train: [136/180][300/625]	eta 0:07:16 lr 0.109981	data 0.0004 (0.0698)	batch 1.2969 (1.3425)	loss -27.1193 (-27.3309)	grad_norm 0.6087 (0.5947)	mem 44912MB
Train: [136/180][350/625]	eta 0:06:06 lr 0.109597	data 0.0007 (0.0600)	batch 1.2176 (1.3321)	loss -27.2363 (-27.3307)	grad_norm 0.6046 (0.5951)	mem 44912MB
Train: [136/180][400/625]	eta 0:04:57 lr 0.109213	data 0.0005 (0.0526)	batch 1.2604 (1.3233)	loss -27.2127 (-27.3256)	grad_norm 0.5819 (0.5952)	mem 44912MB
Train: [136/180][450/625]	eta 0:03:50 lr 0.108830	data 0.0006 (0.0468)	batch 1.2673 (1.3168)	loss -27.2897 (-27.3264)	grad_norm 0.6013 (0.5955)	mem 44912MB
Train: [136/180][500/625]	eta 0:02:44 lr 0.108447	data 0.0005 (0.0422)	batch 1.3138 (1.3121)	loss -27.3441 (-27.3268)	grad_norm 0.5847 (0.5954)	mem 44912MB
Train: [136/180][550/625]	eta 0:01:38 lr 0.108065	data 0.0005 (0.0384)	batch 1.3230 (1.3075)	loss -27.2229 (-27.3291)	grad_norm 0.6148 (0.5956)	mem 44912MB
Train: [136/180][600/625]	eta 0:00:32 lr 0.107684	data 0.0008 (0.0352)	batch 1.3178 (1.3046)	loss -26.9220 (-27.3289)	grad_norm 0.5996 (0.5956)	mem 44912MB
Current slope: None 	
EPOCH 136 training takes 0:13:35
Test: [0/25]	Time 14.395 (14.395)	Loss 1.2541 (1.2541)	Acc@1 72.559 (72.559)	Acc@5 90.039 (90.039)	Mem 44912MB
 * Acc@1 60.484 Acc@5 83.268
Accuracy of the network on the 50000 test images: 60.48%
Max accuracy (after decay): 60.49%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [137/180][0/625]	eta 3:59:40 lr 0.107493	data 20.1972 (20.1972)	batch 23.0089 (23.0089)	loss -27.3700 (-27.3700)	grad_norm 0.5784 (0.5784)	mem 44912MB
Train: [137/180][50/625]	eta 0:16:16 lr 0.107113	data 0.0006 (0.3981)	batch 1.2782 (1.6981)	loss -27.4674 (-27.3592)	grad_norm 0.6048 (0.5955)	mem 44912MB
Train: [137/180][100/625]	eta 0:13:00 lr 0.106733	data 0.0005 (0.2013)	batch 1.2478 (1.4866)	loss -27.1686 (-27.3467)	grad_norm 0.5998 (0.5972)	mem 44912MB
Train: [137/180][150/625]	eta 0:11:11 lr 0.106353	data 0.0006 (0.1349)	batch 1.2592 (1.4130)	loss -27.2040 (-27.3445)	grad_norm 0.5960 (0.5963)	mem 44912MB
Train: [137/180][200/625]	eta 0:09:45 lr 0.105974	data 0.0006 (0.1014)	batch 1.3085 (1.3771)	loss -27.4556 (-27.3449)	grad_norm 0.5848 (0.5973)	mem 44912MB
Train: [137/180][250/625]	eta 0:08:28 lr 0.105596	data 0.0010 (0.0813)	batch 1.2469 (1.3549)	loss -27.1804 (-27.3380)	grad_norm 0.5985 (0.5977)	mem 44912MB
Train: [137/180][300/625]	eta 0:07:15 lr 0.105218	data 0.0005 (0.0679)	batch 1.2645 (1.3398)	loss -27.2525 (-27.3415)	grad_norm 0.5996 (0.5974)	mem 44912MB
Train: [137/180][350/625]	eta 0:06:05 lr 0.104841	data 0.0008 (0.0583)	batch 1.2552 (1.3298)	loss -27.5080 (-27.3391)	grad_norm 0.6134 (0.5977)	mem 44912MB
Train: [137/180][400/625]	eta 0:04:57 lr 0.104464	data 0.0003 (0.0511)	batch 1.2524 (1.3214)	loss -27.2814 (-27.3345)	grad_norm 0.6041 (0.5984)	mem 44912MB
Train: [137/180][450/625]	eta 0:03:50 lr 0.104088	data 0.0004 (0.0455)	batch 1.2642 (1.3157)	loss -27.4391 (-27.3324)	grad_norm 0.6029 (0.5988)	mem 44912MB
Train: [137/180][500/625]	eta 0:02:43 lr 0.103713	data 0.0004 (0.0411)	batch 1.3914 (1.3115)	loss -27.5063 (-27.3307)	grad_norm 0.6027 (0.5992)	mem 44912MB
Train: [137/180][550/625]	eta 0:01:38 lr 0.103338	data 0.0006 (0.0374)	batch 1.2077 (1.3077)	loss -27.2640 (-27.3311)	grad_norm 0.6023 (0.5993)	mem 44912MB
Train: [137/180][600/625]	eta 0:00:32 lr 0.102964	data 0.0005 (0.0343)	batch 1.2970 (1.3040)	loss -27.5148 (-27.3326)	grad_norm 0.5953 (0.5992)	mem 44912MB
Current slope: None 	
EPOCH 137 training takes 0:13:35
Test: [0/25]	Time 14.466 (14.466)	Loss 1.2641 (1.2641)	Acc@1 71.826 (71.826)	Acc@5 89.697 (89.697)	Mem 44912MB
 * Acc@1 60.408 Acc@5 83.308
Accuracy of the network on the 50000 test images: 60.41%
Max accuracy (after decay): 60.49%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [138/180][0/625]	eta 3:59:59 lr 0.102777	data 21.5342 (21.5342)	batch 23.0393 (23.0393)	loss -27.2805 (-27.2805)	grad_norm 0.5926 (0.5926)	mem 44912MB
Train: [138/180][50/625]	eta 0:16:16 lr 0.102404	data 0.0011 (0.4229)	batch 1.2432 (1.6987)	loss -27.2801 (-27.3703)	grad_norm 0.6082 (0.6015)	mem 44912MB
Train: [138/180][100/625]	eta 0:12:59 lr 0.102031	data 0.0005 (0.2139)	batch 1.2930 (1.4842)	loss -27.2521 (-27.3592)	grad_norm 0.6018 (0.6017)	mem 44912MB
Train: [138/180][150/625]	eta 0:11:10 lr 0.101658	data 0.0005 (0.1435)	batch 1.2233 (1.4111)	loss -27.2609 (-27.3587)	grad_norm 0.6144 (0.6010)	mem 44912MB
Train: [138/180][200/625]	eta 0:09:44 lr 0.101287	data 0.0005 (0.1079)	batch 1.2466 (1.3761)	loss -27.4031 (-27.3523)	grad_norm 0.5874 (0.6001)	mem 44912MB
Train: [138/180][250/625]	eta 0:08:28 lr 0.100916	data 0.0006 (0.0865)	batch 1.2406 (1.3549)	loss -27.3236 (-27.3552)	grad_norm 0.6460 (0.6004)	mem 44912MB
Train: [138/180][300/625]	eta 0:07:15 lr 0.100545	data 0.0005 (0.0723)	batch 1.2441 (1.3404)	loss -27.2602 (-27.3526)	grad_norm 0.5920 (0.6010)	mem 44912MB
Train: [138/180][350/625]	eta 0:06:05 lr 0.100175	data 0.0008 (0.0620)	batch 1.2719 (1.3297)	loss -27.2888 (-27.3516)	grad_norm 0.6302 (0.6011)	mem 44912MB
Train: [138/180][400/625]	eta 0:04:57 lr 0.099806	data 0.0006 (0.0544)	batch 1.2387 (1.3219)	loss -27.3158 (-27.3502)	grad_norm 0.6196 (0.6009)	mem 44912MB
Train: [138/180][450/625]	eta 0:03:50 lr 0.099437	data 0.0005 (0.0484)	batch 1.2561 (1.3162)	loss -27.3321 (-27.3513)	grad_norm 0.6189 (0.6009)	mem 44912MB
Train: [138/180][500/625]	eta 0:02:43 lr 0.099069	data 0.0378 (0.0437)	batch 1.2740 (1.3109)	loss -27.2895 (-27.3488)	grad_norm 0.5874 (0.6008)	mem 44912MB
Train: [138/180][550/625]	eta 0:01:37 lr 0.098702	data 0.0005 (0.0398)	batch 1.2860 (1.3066)	loss -27.2783 (-27.3483)	grad_norm 0.6192 (0.6011)	mem 44912MB
Train: [138/180][600/625]	eta 0:00:32 lr 0.098335	data 0.0004 (0.0365)	batch 1.2751 (1.3031)	loss -27.2547 (-27.3471)	grad_norm 0.6163 (0.6014)	mem 44912MB
Current slope: None 	
EPOCH 138 training takes 0:13:35
Test: [0/25]	Time 15.092 (15.092)	Loss 1.2267 (1.2267)	Acc@1 72.461 (72.461)	Acc@5 90.479 (90.479)	Mem 44912MB
 * Acc@1 60.598 Acc@5 83.438
Accuracy of the network on the 50000 test images: 60.60%
Max accuracy (after decay): 60.60%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [139/180][0/625]	eta 4:00:26 lr 0.098151	data 20.7506 (20.7506)	batch 23.0818 (23.0818)	loss -27.2380 (-27.2380)	grad_norm 0.6060 (0.6060)	mem 44912MB
Train: [139/180][50/625]	eta 0:16:14 lr 0.097785	data 0.0005 (0.4076)	batch 1.2446 (1.6950)	loss -27.1841 (-27.3303)	grad_norm 0.6036 (0.6000)	mem 44912MB
Train: [139/180][100/625]	eta 0:12:57 lr 0.097420	data 0.0007 (0.2061)	batch 1.2297 (1.4809)	loss -27.3094 (-27.3374)	grad_norm 0.5981 (0.6019)	mem 44912MB
Train: [139/180][150/625]	eta 0:11:09 lr 0.097055	data 0.0005 (0.1380)	batch 1.2255 (1.4101)	loss -27.4030 (-27.3339)	grad_norm 0.6006 (0.6026)	mem 44912MB
Train: [139/180][200/625]	eta 0:09:44 lr 0.096690	data 0.0008 (0.1038)	batch 1.2512 (1.3744)	loss -27.5615 (-27.3349)	grad_norm 0.5940 (0.6033)	mem 44912MB
Train: [139/180][250/625]	eta 0:08:27 lr 0.096327	data 0.0005 (0.0833)	batch 1.2741 (1.3527)	loss -27.3025 (-27.3378)	grad_norm 0.6050 (0.6035)	mem 44912MB
Train: [139/180][300/625]	eta 0:07:14 lr 0.095964	data 0.0005 (0.0695)	batch 1.2328 (1.3377)	loss -27.4121 (-27.3428)	grad_norm 0.6016 (0.6037)	mem 44912MB
Train: [139/180][350/625]	eta 0:06:05 lr 0.095601	data 0.0005 (0.0597)	batch 1.2247 (1.3273)	loss -27.3559 (-27.3430)	grad_norm 0.5941 (0.6039)	mem 44912MB
Train: [139/180][400/625]	eta 0:04:57 lr 0.095239	data 0.0004 (0.0523)	batch 1.4129 (1.3204)	loss -27.4674 (-27.3444)	grad_norm 0.5976 (0.6042)	mem 44912MB
Train: [139/180][450/625]	eta 0:03:49 lr 0.094878	data 0.0006 (0.0466)	batch 1.2470 (1.3140)	loss -27.2535 (-27.3440)	grad_norm 0.6003 (0.6043)	mem 44912MB
Train: [139/180][500/625]	eta 0:02:43 lr 0.094517	data 0.0005 (0.0420)	batch 1.2578 (1.3087)	loss -27.1455 (-27.3441)	grad_norm 0.6135 (0.6044)	mem 44912MB
Train: [139/180][550/625]	eta 0:01:37 lr 0.094157	data 0.0006 (0.0382)	batch 1.2834 (1.3043)	loss -27.4916 (-27.3444)	grad_norm 0.6244 (0.6043)	mem 44912MB
Train: [139/180][600/625]	eta 0:00:32 lr 0.093797	data 0.0005 (0.0352)	batch 1.2367 (1.3012)	loss -27.2693 (-27.3455)	grad_norm 0.6324 (0.6045)	mem 44912MB
Current slope: None 	
EPOCH 139 training takes 0:13:33
Test: [0/25]	Time 14.683 (14.683)	Loss 1.2707 (1.2707)	Acc@1 72.559 (72.559)	Acc@5 89.404 (89.404)	Mem 44912MB
 * Acc@1 60.824 Acc@5 83.306
Accuracy of the network on the 50000 test images: 60.82%
Max accuracy (after decay): 60.82%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [140/180][0/625]	eta 3:59:35 lr 0.093618	data 20.9532 (20.9532)	batch 23.0011 (23.0011)	loss -27.3216 (-27.3216)	grad_norm 0.5880 (0.5880)	mem 44912MB
Train: [140/180][50/625]	eta 0:16:13 lr 0.093259	data 0.0006 (0.4115)	batch 1.2870 (1.6928)	loss -27.3515 (-27.3554)	grad_norm 0.6073 (0.6055)	mem 44912MB
Train: [140/180][100/625]	eta 0:12:57 lr 0.092901	data 0.0006 (0.2080)	batch 1.2383 (1.4814)	loss -27.2543 (-27.3580)	grad_norm 0.6222 (0.6059)	mem 44912MB
Train: [140/180][150/625]	eta 0:11:09 lr 0.092543	data 0.0006 (0.1393)	batch 1.2658 (1.4099)	loss -27.3939 (-27.3541)	grad_norm 0.6115 (0.6063)	mem 44912MB
Train: [140/180][200/625]	eta 0:09:44 lr 0.092186	data 0.0006 (0.1048)	batch 1.2731 (1.3757)	loss -27.4882 (-27.3534)	grad_norm 0.6253 (0.6068)	mem 44912MB
Train: [140/180][250/625]	eta 0:08:27 lr 0.091830	data 0.0005 (0.0840)	batch 1.2804 (1.3539)	loss -27.1020 (-27.3567)	grad_norm 0.5998 (0.6069)	mem 44912MB
Train: [140/180][300/625]	eta 0:07:15 lr 0.091474	data 0.0005 (0.0702)	batch 1.3845 (1.3396)	loss -27.5421 (-27.3584)	grad_norm 0.5873 (0.6071)	mem 44912MB
Train: [140/180][350/625]	eta 0:06:05 lr 0.091119	data 0.0005 (0.0603)	batch 1.2325 (1.3288)	loss -27.4377 (-27.3585)	grad_norm 0.6101 (0.6075)	mem 44912MB
Train: [140/180][400/625]	eta 0:04:57 lr 0.090765	data 0.0005 (0.0528)	batch 1.2734 (1.3217)	loss -27.4190 (-27.3589)	grad_norm 0.6405 (0.6082)	mem 44912MB
Train: [140/180][450/625]	eta 0:03:50 lr 0.090411	data 0.0006 (0.0470)	batch 1.2620 (1.3154)	loss -27.4043 (-27.3611)	grad_norm 0.6097 (0.6085)	mem 44912MB
Train: [140/180][500/625]	eta 0:02:43 lr 0.090058	data 0.0005 (0.0424)	batch 1.2534 (1.3102)	loss -27.3167 (-27.3601)	grad_norm 0.6102 (0.6085)	mem 44912MB
Train: [140/180][550/625]	eta 0:01:37 lr 0.089705	data 0.0004 (0.0386)	batch 1.2424 (1.3065)	loss -27.1882 (-27.3585)	grad_norm 0.6250 (0.6086)	mem 44912MB
Train: [140/180][600/625]	eta 0:00:32 lr 0.089353	data 0.0004 (0.0354)	batch 1.2607 (1.3029)	loss -27.1450 (-27.3541)	grad_norm 0.6159 (0.6085)	mem 44912MB
Current slope: None 	
EPOCH 140 training takes 0:13:34
Test: [0/25]	Time 15.153 (15.153)	Loss 1.2208 (1.2208)	Acc@1 72.314 (72.314)	Acc@5 90.039 (90.039)	Mem 44912MB
 * Acc@1 60.618 Acc@5 83.538
Accuracy of the network on the 50000 test images: 60.62%
Max accuracy (after decay): 60.82%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [141/180][0/625]	eta 3:59:35 lr 0.089177	data 21.4004 (21.4004)	batch 23.0010 (23.0010)	loss -27.5709 (-27.5709)	grad_norm 0.5961 (0.5961)	mem 44912MB
Train: [141/180][50/625]	eta 0:16:10 lr 0.088826	data 0.0005 (0.4202)	batch 1.2575 (1.6886)	loss -27.6507 (-27.3838)	grad_norm 0.6566 (0.6099)	mem 44912MB
Train: [141/180][100/625]	eta 0:12:56 lr 0.088475	data 0.0003 (0.2125)	batch 1.2662 (1.4798)	loss -27.4299 (-27.3805)	grad_norm 0.6202 (0.6115)	mem 44912MB
Train: [141/180][150/625]	eta 0:11:10 lr 0.088126	data 0.0006 (0.1423)	batch 1.2251 (1.4109)	loss -27.1764 (-27.3840)	grad_norm 0.6087 (0.6116)	mem 44912MB
Train: [141/180][200/625]	eta 0:09:44 lr 0.087776	data 0.0006 (0.1070)	batch 1.2681 (1.3747)	loss -27.3424 (-27.3751)	grad_norm 0.6258 (0.6114)	mem 44912MB
Train: [141/180][250/625]	eta 0:08:27 lr 0.087427	data 0.0009 (0.0858)	batch 1.2604 (1.3541)	loss -27.4085 (-27.3671)	grad_norm 0.5992 (0.6119)	mem 44912MB
Train: [141/180][300/625]	eta 0:07:15 lr 0.087079	data 0.0006 (0.0717)	batch 1.2907 (1.3408)	loss -27.4751 (-27.3643)	grad_norm 0.6076 (0.6115)	mem 44912MB
Train: [141/180][350/625]	eta 0:06:05 lr 0.086732	data 0.0006 (0.0615)	batch 1.2208 (1.3301)	loss -27.3144 (-27.3623)	grad_norm 0.6475 (0.6120)	mem 44912MB
Train: [141/180][400/625]	eta 0:04:57 lr 0.086385	data 0.0005 (0.0539)	batch 1.2211 (1.3222)	loss -27.4437 (-27.3638)	grad_norm 0.6144 (0.6124)	mem 44912MB
Train: [141/180][450/625]	eta 0:03:50 lr 0.086039	data 0.0005 (0.0480)	batch 1.2611 (1.3160)	loss -27.2171 (-27.3650)	grad_norm 0.6194 (0.6127)	mem 44912MB
Train: [141/180][500/625]	eta 0:02:43 lr 0.085693	data 0.0005 (0.0433)	batch 1.2469 (1.3108)	loss -27.3570 (-27.3643)	grad_norm 0.6437 (0.6125)	mem 44912MB
Train: [141/180][550/625]	eta 0:01:38 lr 0.085348	data 0.0005 (0.0394)	batch 1.2273 (1.3070)	loss -27.1693 (-27.3608)	grad_norm 0.6113 (0.6122)	mem 44912MB
Train: [141/180][600/625]	eta 0:00:32 lr 0.085003	data 0.0004 (0.0362)	batch 1.3278 (1.3036)	loss -27.4881 (-27.3609)	grad_norm 0.6173 (0.6122)	mem 44912MB
Current slope: None 	
EPOCH 141 training takes 0:13:35
Test: [0/25]	Time 14.802 (14.802)	Loss 1.2186 (1.2186)	Acc@1 72.412 (72.412)	Acc@5 90.771 (90.771)	Mem 44912MB
 * Acc@1 60.656 Acc@5 83.350
Accuracy of the network on the 50000 test images: 60.66%
Max accuracy (after decay): 60.82%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [142/180][0/625]	eta 4:02:32 lr 0.084831	data 21.5659 (21.5659)	batch 23.2843 (23.2843)	loss -27.5486 (-27.5486)	grad_norm 0.5973 (0.5973)	mem 44912MB
Train: [142/180][50/625]	eta 0:16:15 lr 0.084488	data 0.0006 (0.4235)	batch 1.3161 (1.6962)	loss -27.3628 (-27.3593)	grad_norm 0.5997 (0.6137)	mem 44912MB
Train: [142/180][100/625]	eta 0:12:59 lr 0.084145	data 0.0010 (0.2147)	batch 1.4149 (1.4853)	loss -27.2213 (-27.3594)	grad_norm 0.6020 (0.6144)	mem 44912MB
Train: [142/180][150/625]	eta 0:11:11 lr 0.083803	data 0.0006 (0.1438)	batch 1.2137 (1.4142)	loss -27.2788 (-27.3587)	grad_norm 0.6362 (0.6141)	mem 44912MB
Train: [142/180][200/625]	eta 0:09:45 lr 0.083461	data 0.0005 (0.1082)	batch 1.2751 (1.3778)	loss -27.1210 (-27.3560)	grad_norm 0.6244 (0.6140)	mem 44912MB
Train: [142/180][250/625]	eta 0:08:28 lr 0.083120	data 0.0004 (0.0867)	batch 1.2675 (1.3554)	loss -27.2635 (-27.3610)	grad_norm 0.6073 (0.6136)	mem 44912MB
Train: [142/180][300/625]	eta 0:07:15 lr 0.082780	data 0.0004 (0.0724)	batch 1.2400 (1.3413)	loss -27.3875 (-27.3592)	grad_norm 0.6111 (0.6135)	mem 44912MB
Train: [142/180][350/625]	eta 0:06:06 lr 0.082440	data 0.0010 (0.0622)	batch 1.2709 (1.3311)	loss -27.4577 (-27.3561)	grad_norm 0.6005 (0.6131)	mem 44912MB
Train: [142/180][400/625]	eta 0:04:57 lr 0.082101	data 0.0005 (0.0546)	batch 1.2400 (1.3232)	loss -27.0747 (-27.3568)	grad_norm 0.6280 (0.6136)	mem 44912MB
Train: [142/180][450/625]	eta 0:03:50 lr 0.081762	data 0.0005 (0.0487)	batch 1.2636 (1.3165)	loss -27.5227 (-27.3600)	grad_norm 0.6230 (0.6131)	mem 44912MB
Train: [142/180][500/625]	eta 0:02:43 lr 0.081424	data 0.0005 (0.0439)	batch 1.2419 (1.3120)	loss -27.2348 (-27.3608)	grad_norm 0.6181 (0.6134)	mem 44912MB
Train: [142/180][550/625]	eta 0:01:38 lr 0.081087	data 0.0005 (0.0400)	batch 1.2911 (1.3082)	loss -27.2069 (-27.3631)	grad_norm 0.6069 (0.6135)	mem 44912MB
Train: [142/180][600/625]	eta 0:00:32 lr 0.080750	data 0.0005 (0.0367)	batch 1.2574 (1.3050)	loss -27.3282 (-27.3629)	grad_norm 0.6217 (0.6140)	mem 44912MB
Current slope: None 	
EPOCH 142 training takes 0:13:36
Test: [0/25]	Time 14.640 (14.640)	Loss 1.2331 (1.2331)	Acc@1 71.777 (71.777)	Acc@5 90.283 (90.283)	Mem 44912MB
 * Acc@1 60.772 Acc@5 83.442
Accuracy of the network on the 50000 test images: 60.77%
Max accuracy (after decay): 60.82%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [143/180][0/625]	eta 4:01:08 lr 0.080582	data 21.0785 (21.0785)	batch 23.1502 (23.1502)	loss -27.4033 (-27.4033)	grad_norm 0.6161 (0.6161)	mem 44912MB
Train: [143/180][50/625]	eta 0:16:20 lr 0.080246	data 0.0014 (0.4140)	batch 1.2299 (1.7056)	loss -27.3699 (-27.3793)	grad_norm 0.6092 (0.6156)	mem 44912MB
Train: [143/180][100/625]	eta 0:12:59 lr 0.079911	data 0.0006 (0.2098)	batch 1.2401 (1.4850)	loss -27.4039 (-27.3662)	grad_norm 0.6070 (0.6157)	mem 44912MB
Train: [143/180][150/625]	eta 0:11:10 lr 0.079576	data 0.0005 (0.1405)	batch 1.2746 (1.4121)	loss -27.3695 (-27.3710)	grad_norm 0.6252 (0.6162)	mem 44912MB
Train: [143/180][200/625]	eta 0:09:44 lr 0.079242	data 0.0003 (0.1057)	batch 1.3651 (1.3764)	loss -27.3574 (-27.3613)	grad_norm 0.5993 (0.6163)	mem 44912MB
Train: [143/180][250/625]	eta 0:08:28 lr 0.078909	data 0.0006 (0.0848)	batch 1.2593 (1.3551)	loss -27.4336 (-27.3658)	grad_norm 0.6066 (0.6155)	mem 44912MB
Train: [143/180][300/625]	eta 0:07:15 lr 0.078576	data 0.0004 (0.0708)	batch 1.2605 (1.3408)	loss -27.3905 (-27.3665)	grad_norm 0.6083 (0.6152)	mem 44912MB
Train: [143/180][350/625]	eta 0:06:05 lr 0.078244	data 0.0005 (0.0608)	batch 1.3045 (1.3296)	loss -27.2032 (-27.3675)	grad_norm 0.6152 (0.6154)	mem 44912MB
Train: [143/180][400/625]	eta 0:04:57 lr 0.077913	data 0.0007 (0.0533)	batch 1.2728 (1.3212)	loss -27.2531 (-27.3669)	grad_norm 0.6293 (0.6159)	mem 44912MB
Train: [143/180][450/625]	eta 0:03:50 lr 0.077582	data 0.0006 (0.0474)	batch 1.2654 (1.3155)	loss -27.2341 (-27.3671)	grad_norm 0.6330 (0.6158)	mem 44912MB
Train: [143/180][500/625]	eta 0:02:43 lr 0.077252	data 0.0006 (0.0428)	batch 1.2491 (1.3098)	loss -27.2727 (-27.3696)	grad_norm 0.6223 (0.6161)	mem 44912MB
Train: [143/180][550/625]	eta 0:01:37 lr 0.076922	data 0.0005 (0.0389)	batch 1.2534 (1.3053)	loss -27.3630 (-27.3691)	grad_norm 0.6089 (0.6161)	mem 44912MB
Train: [143/180][600/625]	eta 0:00:32 lr 0.076594	data 0.0004 (0.0357)	batch 1.2547 (1.3022)	loss -27.3335 (-27.3695)	grad_norm 0.6302 (0.6161)	mem 44912MB
Current slope: None 	
EPOCH 143 training takes 0:13:34
Test: [0/25]	Time 14.490 (14.490)	Loss 1.1719 (1.1719)	Acc@1 72.559 (72.559)	Acc@5 91.504 (91.504)	Mem 44912MB
 * Acc@1 60.868 Acc@5 83.744
Accuracy of the network on the 50000 test images: 60.87%
Max accuracy (after decay): 60.87%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [144/180][0/625]	eta 4:01:55 lr 0.076429	data 21.6527 (21.6527)	batch 23.2246 (23.2246)	loss -27.4036 (-27.4036)	grad_norm 0.6251 (0.6251)	mem 44912MB
Train: [144/180][50/625]	eta 0:16:16 lr 0.076101	data 0.0005 (0.4255)	batch 1.2739 (1.6985)	loss -27.2587 (-27.3576)	grad_norm 0.6299 (0.6160)	mem 44912MB
Train: [144/180][100/625]	eta 0:12:59 lr 0.075774	data 0.0013 (0.2153)	batch 1.2205 (1.4839)	loss -27.6268 (-27.3704)	grad_norm 0.6250 (0.6169)	mem 44912MB
Train: [144/180][150/625]	eta 0:11:09 lr 0.075447	data 0.0006 (0.1443)	batch 1.2227 (1.4102)	loss -27.5632 (-27.3748)	grad_norm 0.6268 (0.6179)	mem 44912MB
Train: [144/180][200/625]	eta 0:09:44 lr 0.075121	data 0.0451 (0.1088)	batch 1.2653 (1.3752)	loss -27.1616 (-27.3713)	grad_norm 0.6331 (0.6182)	mem 44912MB
Train: [144/180][250/625]	eta 0:08:27 lr 0.074796	data 0.0006 (0.0873)	batch 1.2740 (1.3541)	loss -27.3818 (-27.3742)	grad_norm 0.6218 (0.6186)	mem 44912MB
Train: [144/180][300/625]	eta 0:07:15 lr 0.074471	data 0.0006 (0.0729)	batch 1.2593 (1.3401)	loss -27.4167 (-27.3730)	grad_norm 0.6166 (0.6193)	mem 44912MB
Train: [144/180][350/625]	eta 0:06:05 lr 0.074147	data 0.0026 (0.0626)	batch 1.3318 (1.3299)	loss -27.3204 (-27.3753)	grad_norm 0.6358 (0.6192)	mem 44912MB
Train: [144/180][400/625]	eta 0:04:57 lr 0.073824	data 0.0004 (0.0548)	batch 1.2435 (1.3220)	loss -27.3253 (-27.3698)	grad_norm 0.6236 (0.6196)	mem 44912MB
Train: [144/180][450/625]	eta 0:03:50 lr 0.073501	data 0.0005 (0.0488)	batch 1.2586 (1.3162)	loss -27.2619 (-27.3713)	grad_norm 0.6250 (0.6194)	mem 44912MB
Train: [144/180][500/625]	eta 0:02:43 lr 0.073178	data 0.0006 (0.0440)	batch 1.2500 (1.3118)	loss -27.3856 (-27.3691)	grad_norm 0.6201 (0.6195)	mem 44912MB
Train: [144/180][550/625]	eta 0:01:38 lr 0.072857	data 0.0003 (0.0401)	batch 1.2822 (1.3076)	loss -27.5829 (-27.3686)	grad_norm 0.6203 (0.6195)	mem 44912MB
Train: [144/180][600/625]	eta 0:00:32 lr 0.072536	data 0.0007 (0.0368)	batch 1.2787 (1.3043)	loss -27.4416 (-27.3711)	grad_norm 0.6039 (0.6197)	mem 44912MB
Current slope: None 	
EPOCH 144 training takes 0:13:35
Test: [0/25]	Time 14.759 (14.759)	Loss 1.1910 (1.1910)	Acc@1 72.021 (72.021)	Acc@5 91.064 (91.064)	Mem 44912MB
 * Acc@1 61.020 Acc@5 83.660
Accuracy of the network on the 50000 test images: 61.02%
Max accuracy (after decay): 61.02%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [145/180][0/625]	eta 3:58:52 lr 0.072376	data 20.7092 (20.7092)	batch 22.9320 (22.9320)	loss -27.4964 (-27.4964)	grad_norm 0.6364 (0.6364)	mem 44912MB
Train: [145/180][50/625]	eta 0:16:11 lr 0.072056	data 0.0005 (0.4068)	batch 1.2558 (1.6901)	loss -27.5486 (-27.3915)	grad_norm 0.6368 (0.6199)	mem 44912MB
Train: [145/180][100/625]	eta 0:12:56 lr 0.071736	data 0.0004 (0.2057)	batch 1.2420 (1.4793)	loss -27.3497 (-27.3840)	grad_norm 0.6082 (0.6207)	mem 44912MB
Train: [145/180][150/625]	eta 0:11:09 lr 0.071417	data 0.0006 (0.1378)	batch 1.2545 (1.4095)	loss -27.5701 (-27.3947)	grad_norm 0.6267 (0.6211)	mem 44912MB
Train: [145/180][200/625]	eta 0:09:45 lr 0.071099	data 0.0009 (0.1036)	batch 1.2194 (1.3765)	loss -27.5863 (-27.3912)	grad_norm 0.6096 (0.6214)	mem 44912MB
Train: [145/180][250/625]	eta 0:08:27 lr 0.070782	data 0.0005 (0.0831)	batch 1.2782 (1.3530)	loss -27.2264 (-27.3885)	grad_norm 0.6098 (0.6219)	mem 44912MB
Train: [145/180][300/625]	eta 0:07:14 lr 0.070465	data 0.0005 (0.0694)	batch 1.2439 (1.3369)	loss -27.3333 (-27.3878)	grad_norm 0.6146 (0.6219)	mem 44912MB
Train: [145/180][350/625]	eta 0:06:05 lr 0.070149	data 0.0008 (0.0596)	batch 1.2720 (1.3274)	loss -27.4538 (-27.3857)	grad_norm 0.6017 (0.6219)	mem 44912MB
Train: [145/180][400/625]	eta 0:04:57 lr 0.069833	data 0.0005 (0.0522)	batch 1.2618 (1.3204)	loss -27.5191 (-27.3838)	grad_norm 0.6126 (0.6220)	mem 44912MB
Train: [145/180][450/625]	eta 0:03:49 lr 0.069519	data 0.0007 (0.0465)	batch 1.2663 (1.3136)	loss -27.3745 (-27.3843)	grad_norm 0.6196 (0.6222)	mem 44912MB
Train: [145/180][500/625]	eta 0:02:43 lr 0.069204	data 0.0004 (0.0419)	batch 1.2549 (1.3084)	loss -27.2880 (-27.3836)	grad_norm 0.6100 (0.6221)	mem 44912MB
Train: [145/180][550/625]	eta 0:01:37 lr 0.068891	data 0.0004 (0.0382)	batch 1.2644 (1.3044)	loss -27.1347 (-27.3831)	grad_norm 0.6189 (0.6222)	mem 44912MB
Train: [145/180][600/625]	eta 0:00:32 lr 0.068578	data 0.0005 (0.0350)	batch 1.2557 (1.3012)	loss -27.4061 (-27.3831)	grad_norm 0.6018 (0.6222)	mem 44912MB
Current slope: None 	
EPOCH 145 training takes 0:13:33
Test: [0/25]	Time 14.768 (14.768)	Loss 1.2276 (1.2276)	Acc@1 72.559 (72.559)	Acc@5 90.479 (90.479)	Mem 44912MB
 * Acc@1 61.044 Acc@5 83.750
Accuracy of the network on the 50000 test images: 61.04%
Max accuracy (after decay): 61.04%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [146/180][0/625]	eta 3:59:53 lr 0.068422	data 21.0237 (21.0237)	batch 23.0302 (23.0302)	loss -27.4022 (-27.4022)	grad_norm 0.6212 (0.6212)	mem 44912MB
Train: [146/180][50/625]	eta 0:16:18 lr 0.068110	data 0.0009 (0.4130)	batch 1.2418 (1.7013)	loss -27.2589 (-27.3978)	grad_norm 0.6187 (0.6227)	mem 44912MB
Train: [146/180][100/625]	eta 0:13:00 lr 0.067798	data 0.0010 (0.2089)	batch 1.2728 (1.4857)	loss -27.6188 (-27.3879)	grad_norm 0.6035 (0.6219)	mem 44912MB
Train: [146/180][150/625]	eta 0:11:10 lr 0.067488	data 0.0006 (0.1399)	batch 1.2435 (1.4111)	loss -27.3598 (-27.3877)	grad_norm 0.6417 (0.6232)	mem 44912MB
Train: [146/180][200/625]	eta 0:09:44 lr 0.067178	data 0.0007 (0.1053)	batch 1.2271 (1.3742)	loss -27.2919 (-27.3924)	grad_norm 0.6111 (0.6238)	mem 44912MB
Train: [146/180][250/625]	eta 0:08:27 lr 0.066868	data 0.0005 (0.0844)	batch 1.3031 (1.3535)	loss -27.4974 (-27.3940)	grad_norm 0.6193 (0.6241)	mem 44912MB
Train: [146/180][300/625]	eta 0:07:15 lr 0.066559	data 0.0004 (0.0706)	batch 1.2725 (1.3386)	loss -27.3165 (-27.3951)	grad_norm 0.6211 (0.6244)	mem 44912MB
Train: [146/180][350/625]	eta 0:06:05 lr 0.066251	data 0.0006 (0.0606)	batch 1.2374 (1.3278)	loss -27.1983 (-27.3950)	grad_norm 0.6164 (0.6241)	mem 44912MB
Train: [146/180][400/625]	eta 0:04:56 lr 0.065944	data 0.0005 (0.0531)	batch 1.3259 (1.3196)	loss -27.4061 (-27.3919)	grad_norm 0.6201 (0.6241)	mem 44912MB
Train: [146/180][450/625]	eta 0:03:49 lr 0.065637	data 0.0005 (0.0473)	batch 1.2812 (1.3141)	loss -27.2113 (-27.3948)	grad_norm 0.6361 (0.6246)	mem 44912MB
Train: [146/180][500/625]	eta 0:02:43 lr 0.065331	data 0.0007 (0.0426)	batch 1.2884 (1.3090)	loss -27.2919 (-27.3929)	grad_norm 0.6184 (0.6245)	mem 44912MB
Train: [146/180][550/625]	eta 0:01:37 lr 0.065026	data 0.0005 (0.0388)	batch 1.3045 (1.3048)	loss -27.4429 (-27.3929)	grad_norm 0.6279 (0.6245)	mem 44912MB
Train: [146/180][600/625]	eta 0:00:32 lr 0.064721	data 0.0006 (0.0356)	batch 1.4423 (1.3015)	loss -27.2413 (-27.3932)	grad_norm 0.6216 (0.6242)	mem 44912MB
Current slope: None 	
EPOCH 146 training takes 0:13:33
Test: [0/25]	Time 14.815 (14.815)	Loss 1.1767 (1.1767)	Acc@1 73.242 (73.242)	Acc@5 91.064 (91.064)	Mem 44912MB
 * Acc@1 61.066 Acc@5 83.886
Accuracy of the network on the 50000 test images: 61.07%
Max accuracy (after decay): 61.07%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [147/180][0/625]	eta 4:01:33 lr 0.064569	data 21.2275 (21.2275)	batch 23.1900 (23.1900)	loss -27.3466 (-27.3466)	grad_norm 0.6408 (0.6408)	mem 44912MB
Train: [147/180][50/625]	eta 0:16:19 lr 0.064265	data 0.0010 (0.4168)	batch 1.2473 (1.7029)	loss -27.4164 (-27.3953)	grad_norm 0.6254 (0.6253)	mem 44912MB
Train: [147/180][100/625]	eta 0:12:59 lr 0.063962	data 0.0006 (0.2108)	batch 1.2174 (1.4840)	loss -27.3112 (-27.3941)	grad_norm 0.6176 (0.6237)	mem 44912MB
Train: [147/180][150/625]	eta 0:11:10 lr 0.063659	data 0.0005 (0.1412)	batch 1.2844 (1.4114)	loss -27.3431 (-27.3985)	grad_norm 0.6256 (0.6254)	mem 44912MB
Train: [147/180][200/625]	eta 0:09:44 lr 0.063357	data 0.0004 (0.1062)	batch 1.2734 (1.3752)	loss -27.3021 (-27.3921)	grad_norm 0.6324 (0.6256)	mem 44912MB
Train: [147/180][250/625]	eta 0:08:27 lr 0.063056	data 0.0005 (0.0851)	batch 1.2606 (1.3535)	loss -27.3639 (-27.3935)	grad_norm 0.6411 (0.6257)	mem 44912MB
Train: [147/180][300/625]	eta 0:07:15 lr 0.062755	data 0.0005 (0.0711)	batch 1.2385 (1.3386)	loss -27.3232 (-27.3910)	grad_norm 0.6275 (0.6261)	mem 44912MB
Train: [147/180][350/625]	eta 0:06:05 lr 0.062455	data 0.0006 (0.0610)	batch 1.2543 (1.3273)	loss -27.4667 (-27.3937)	grad_norm 0.6259 (0.6262)	mem 44912MB
Train: [147/180][400/625]	eta 0:04:57 lr 0.062156	data 0.0005 (0.0535)	batch 1.2505 (1.3202)	loss -27.4549 (-27.3946)	grad_norm 0.6177 (0.6260)	mem 44912MB
Train: [147/180][450/625]	eta 0:03:50 lr 0.061858	data 0.0004 (0.0476)	batch 1.2857 (1.3145)	loss -27.2621 (-27.3954)	grad_norm 0.6300 (0.6263)	mem 44912MB
Train: [147/180][500/625]	eta 0:02:43 lr 0.061560	data 0.0004 (0.0430)	batch 1.2680 (1.3093)	loss -27.4166 (-27.3950)	grad_norm 0.6130 (0.6263)	mem 44912MB
Train: [147/180][550/625]	eta 0:01:37 lr 0.061262	data 0.0006 (0.0392)	batch 1.2555 (1.3051)	loss -27.3144 (-27.3922)	grad_norm 0.6282 (0.6264)	mem 44912MB
Train: [147/180][600/625]	eta 0:00:32 lr 0.060966	data 0.0005 (0.0359)	batch 1.2764 (1.3018)	loss -27.3546 (-27.3914)	grad_norm 0.6330 (0.6268)	mem 44912MB
Current slope: None 	
EPOCH 147 training takes 0:13:33
Test: [0/25]	Time 14.934 (14.934)	Loss 1.2294 (1.2294)	Acc@1 72.656 (72.656)	Acc@5 90.479 (90.479)	Mem 44912MB
 * Acc@1 61.042 Acc@5 83.752
Accuracy of the network on the 50000 test images: 61.04%
Max accuracy (after decay): 61.07%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [148/180][0/625]	eta 4:05:14 lr 0.060818	data 20.8030 (20.8030)	batch 23.5438 (23.5438)	loss -27.2469 (-27.2469)	grad_norm 0.6161 (0.6161)	mem 44912MB
Train: [148/180][50/625]	eta 0:16:20 lr 0.060522	data 0.0004 (0.4095)	batch 1.2264 (1.7046)	loss -27.5344 (-27.4064)	grad_norm 0.6194 (0.6242)	mem 44912MB
Train: [148/180][100/625]	eta 0:13:00 lr 0.060227	data 0.0005 (0.2071)	batch 1.2552 (1.4875)	loss -27.4831 (-27.4075)	grad_norm 0.6433 (0.6262)	mem 44912MB
Train: [148/180][150/625]	eta 0:11:11 lr 0.059933	data 0.0006 (0.1387)	batch 1.2561 (1.4137)	loss -27.2648 (-27.4066)	grad_norm 0.6314 (0.6264)	mem 44912MB
Train: [148/180][200/625]	eta 0:09:45 lr 0.059639	data 0.0005 (0.1043)	batch 1.2882 (1.3778)	loss -27.3665 (-27.4010)	grad_norm 0.6271 (0.6267)	mem 44912MB
Train: [148/180][250/625]	eta 0:08:28 lr 0.059346	data 0.0005 (0.0837)	batch 1.2630 (1.3570)	loss -27.4928 (-27.4022)	grad_norm 0.6311 (0.6277)	mem 44912MB
Train: [148/180][300/625]	eta 0:07:16 lr 0.059054	data 0.0005 (0.0699)	batch 1.2393 (1.3423)	loss -27.6109 (-27.3972)	grad_norm 0.6217 (0.6281)	mem 44912MB
Train: [148/180][350/625]	eta 0:06:06 lr 0.058762	data 0.0006 (0.0600)	batch 1.2367 (1.3316)	loss -27.3844 (-27.3958)	grad_norm 0.6225 (0.6283)	mem 44912MB
Train: [148/180][400/625]	eta 0:04:57 lr 0.058471	data 0.0005 (0.0526)	batch 1.2968 (1.3239)	loss -27.4442 (-27.3989)	grad_norm 0.6252 (0.6285)	mem 44912MB
Train: [148/180][450/625]	eta 0:03:50 lr 0.058181	data 0.0005 (0.0468)	batch 1.2908 (1.3173)	loss -27.1434 (-27.3974)	grad_norm 0.6272 (0.6293)	mem 44912MB
Train: [148/180][500/625]	eta 0:02:44 lr 0.057891	data 0.0009 (0.0422)	batch 1.2816 (1.3131)	loss -27.4767 (-27.3992)	grad_norm 0.6236 (0.6295)	mem 44912MB
Train: [148/180][550/625]	eta 0:01:38 lr 0.057602	data 0.0005 (0.0384)	batch 1.2595 (1.3083)	loss -27.4987 (-27.3987)	grad_norm 0.6232 (0.6297)	mem 44912MB
Train: [148/180][600/625]	eta 0:00:32 lr 0.057314	data 0.0004 (0.0353)	batch 1.2919 (1.3051)	loss -27.3009 (-27.3977)	grad_norm 0.6254 (0.6297)	mem 44912MB
Current slope: None 	
EPOCH 148 training takes 0:13:36
Test: [0/25]	Time 14.829 (14.829)	Loss 1.2062 (1.2062)	Acc@1 72.900 (72.900)	Acc@5 90.186 (90.186)	Mem 44912MB
 * Acc@1 61.430 Acc@5 83.764
Accuracy of the network on the 50000 test images: 61.43%
Max accuracy (after decay): 61.43%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [149/180][0/625]	eta 4:00:26 lr 0.057170	data 20.8955 (20.8955)	batch 23.0818 (23.0818)	loss -27.4106 (-27.4106)	grad_norm 0.6377 (0.6377)	mem 44912MB
Train: [149/180][50/625]	eta 0:16:12 lr 0.056883	data 0.0006 (0.4105)	batch 1.2463 (1.6914)	loss -27.2709 (-27.4166)	grad_norm 0.6494 (0.6308)	mem 44912MB
Train: [149/180][100/625]	eta 0:12:57 lr 0.056596	data 0.0006 (0.2076)	batch 1.2763 (1.4804)	loss -27.3974 (-27.4152)	grad_norm 0.6200 (0.6307)	mem 44912MB
Train: [149/180][150/625]	eta 0:11:09 lr 0.056310	data 0.0004 (0.1390)	batch 1.3126 (1.4099)	loss -27.4664 (-27.4105)	grad_norm 0.6449 (0.6302)	mem 44912MB
Train: [149/180][200/625]	eta 0:09:44 lr 0.056025	data 0.0004 (0.1046)	batch 1.2398 (1.3749)	loss -27.3999 (-27.4093)	grad_norm 0.6401 (0.6305)	mem 44912MB
Train: [149/180][250/625]	eta 0:08:27 lr 0.055740	data 0.0005 (0.0838)	batch 1.3330 (1.3523)	loss -27.5173 (-27.4052)	grad_norm 0.6375 (0.6311)	mem 44912MB
Train: [149/180][300/625]	eta 0:07:14 lr 0.055456	data 0.0005 (0.0700)	batch 1.2523 (1.3382)	loss -27.2820 (-27.4047)	grad_norm 0.6272 (0.6315)	mem 44912MB
Train: [149/180][350/625]	eta 0:06:05 lr 0.055173	data 0.0006 (0.0601)	batch 1.3780 (1.3279)	loss -27.3731 (-27.4022)	grad_norm 0.6348 (0.6315)	mem 44912MB
Train: [149/180][400/625]	eta 0:04:57 lr 0.054891	data 0.0005 (0.0527)	batch 1.2549 (1.3205)	loss -27.3955 (-27.4068)	grad_norm 0.6115 (0.6313)	mem 44912MB
Train: [149/180][450/625]	eta 0:03:49 lr 0.054609	data 0.0005 (0.0469)	batch 1.2542 (1.3142)	loss -27.1853 (-27.4066)	grad_norm 0.6258 (0.6315)	mem 44912MB
Train: [149/180][500/625]	eta 0:02:43 lr 0.054327	data 0.0005 (0.0423)	batch 1.2600 (1.3097)	loss -27.2503 (-27.4028)	grad_norm 0.6218 (0.6317)	mem 44912MB
Train: [149/180][550/625]	eta 0:01:37 lr 0.054047	data 0.0005 (0.0385)	batch 1.2847 (1.3061)	loss -27.4600 (-27.4016)	grad_norm 0.6190 (0.6317)	mem 44912MB
Train: [149/180][600/625]	eta 0:00:32 lr 0.053767	data 0.0004 (0.0353)	batch 1.2501 (1.3025)	loss -27.3975 (-27.3995)	grad_norm 0.6286 (0.6315)	mem 44912MB
Current slope: None 	
EPOCH 149 training takes 0:13:34
Test: [0/25]	Time 14.635 (14.635)	Loss 1.1934 (1.1934)	Acc@1 73.486 (73.486)	Acc@5 90.869 (90.869)	Mem 44912MB
 * Acc@1 61.420 Acc@5 83.854
Accuracy of the network on the 50000 test images: 61.42%
Max accuracy (after decay): 61.43%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [150/180][0/625]	eta 4:04:06 lr 0.053627	data 20.6947 (20.6947)	batch 23.4337 (23.4337)	loss -27.4096 (-27.4096)	grad_norm 0.6346 (0.6346)	mem 44912MB
Train: [150/180][50/625]	eta 0:16:18 lr 0.053348	data 0.0009 (0.4066)	batch 1.2189 (1.7021)	loss -27.5770 (-27.3994)	grad_norm 0.6362 (0.6313)	mem 44912MB
Train: [150/180][100/625]	eta 0:12:58 lr 0.053070	data 0.0008 (0.2058)	batch 1.2226 (1.4833)	loss -27.3516 (-27.3932)	grad_norm 0.6254 (0.6347)	mem 44912MB
Train: [150/180][150/625]	eta 0:11:11 lr 0.052792	data 0.0006 (0.1379)	batch 1.2319 (1.4144)	loss -27.5812 (-27.4072)	grad_norm 0.6274 (0.6343)	mem 44912MB
Train: [150/180][200/625]	eta 0:09:44 lr 0.052516	data 0.0006 (0.1038)	batch 1.2947 (1.3762)	loss -27.5481 (-27.4057)	grad_norm 0.6419 (0.6344)	mem 44912MB
Train: [150/180][250/625]	eta 0:08:28 lr 0.052239	data 0.0009 (0.0833)	batch 1.2503 (1.3556)	loss -27.4155 (-27.4050)	grad_norm 0.6302 (0.6348)	mem 44912MB
Train: [150/180][300/625]	eta 0:07:15 lr 0.051964	data 0.0006 (0.0696)	batch 1.2385 (1.3395)	loss -27.3373 (-27.3998)	grad_norm 0.6330 (0.6345)	mem 44912MB
Train: [150/180][350/625]	eta 0:06:05 lr 0.051689	data 0.0006 (0.0598)	batch 1.2612 (1.3304)	loss -27.5478 (-27.4033)	grad_norm 0.6469 (0.6347)	mem 44912MB
Train: [150/180][400/625]	eta 0:04:57 lr 0.051415	data 0.0007 (0.0524)	batch 1.2409 (1.3223)	loss -27.4960 (-27.4032)	grad_norm 0.6365 (0.6351)	mem 44912MB
Train: [150/180][450/625]	eta 0:03:50 lr 0.051141	data 0.0007 (0.0467)	batch 1.2196 (1.3163)	loss -27.5299 (-27.4040)	grad_norm 0.6437 (0.6348)	mem 44912MB
Train: [150/180][500/625]	eta 0:02:43 lr 0.050869	data 0.0007 (0.0421)	batch 1.2661 (1.3108)	loss -27.3938 (-27.4047)	grad_norm 0.6246 (0.6345)	mem 44912MB
Train: [150/180][550/625]	eta 0:01:38 lr 0.050597	data 0.0004 (0.0384)	batch 1.2711 (1.3067)	loss -27.5167 (-27.4042)	grad_norm 0.6207 (0.6344)	mem 44912MB
Train: [150/180][600/625]	eta 0:00:32 lr 0.050325	data 0.0004 (0.0352)	batch 1.2581 (1.3028)	loss -27.1997 (-27.4023)	grad_norm 0.6464 (0.6346)	mem 44912MB
Current slope: None 	
EPOCH 150 training takes 0:13:34
Test: [0/25]	Time 14.645 (14.645)	Loss 1.1817 (1.1817)	Acc@1 72.705 (72.705)	Acc@5 90.820 (90.820)	Mem 44912MB
 * Acc@1 61.360 Acc@5 83.872
Accuracy of the network on the 50000 test images: 61.36%
Max accuracy (after decay): 61.43%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [151/180][0/625]	eta 4:02:30 lr 0.050190	data 21.3348 (21.3348)	batch 23.2813 (23.2813)	loss -27.3794 (-27.3794)	grad_norm 0.6302 (0.6302)	mem 44912MB
Train: [151/180][50/625]	eta 0:16:17 lr 0.049919	data 0.0006 (0.4194)	batch 1.2605 (1.6998)	loss -27.3588 (-27.4292)	grad_norm 0.6336 (0.6370)	mem 44912MB
Train: [151/180][100/625]	eta 0:13:00 lr 0.049649	data 0.0005 (0.2120)	batch 1.2155 (1.4867)	loss -27.6218 (-27.4178)	grad_norm 0.6419 (0.6367)	mem 44912MB
Train: [151/180][150/625]	eta 0:11:11 lr 0.049380	data 0.0008 (0.1420)	batch 1.2701 (1.4131)	loss -27.3161 (-27.4052)	grad_norm 0.6523 (0.6363)	mem 44912MB
Train: [151/180][200/625]	eta 0:09:44 lr 0.049112	data 0.0005 (0.1068)	batch 1.3323 (1.3746)	loss -27.4513 (-27.4035)	grad_norm 0.6302 (0.6362)	mem 44912MB
Train: [151/180][250/625]	eta 0:08:27 lr 0.048844	data 0.0010 (0.0857)	batch 1.2609 (1.3532)	loss -27.3570 (-27.4086)	grad_norm 0.6369 (0.6367)	mem 44912MB
Train: [151/180][300/625]	eta 0:07:15 lr 0.048577	data 0.0005 (0.0715)	batch 1.2613 (1.3385)	loss -27.3428 (-27.4128)	grad_norm 0.6397 (0.6365)	mem 44912MB
Train: [151/180][350/625]	eta 0:06:05 lr 0.048311	data 0.0007 (0.0614)	batch 1.2136 (1.3288)	loss -27.4668 (-27.4132)	grad_norm 0.6321 (0.6367)	mem 44912MB
Train: [151/180][400/625]	eta 0:04:57 lr 0.048045	data 0.0005 (0.0538)	batch 1.2353 (1.3214)	loss -27.5312 (-27.4129)	grad_norm 0.6332 (0.6370)	mem 44912MB
Train: [151/180][450/625]	eta 0:03:50 lr 0.047780	data 0.0006 (0.0479)	batch 1.2510 (1.3151)	loss -27.2139 (-27.4155)	grad_norm 0.6791 (0.6370)	mem 44912MB
Train: [151/180][500/625]	eta 0:02:43 lr 0.047516	data 0.0005 (0.0432)	batch 1.3255 (1.3103)	loss -27.3205 (-27.4155)	grad_norm 0.6318 (0.6374)	mem 44912MB
Train: [151/180][550/625]	eta 0:01:37 lr 0.047253	data 0.0004 (0.0394)	batch 1.3118 (1.3058)	loss -27.5151 (-27.4163)	grad_norm 0.6521 (0.6374)	mem 44912MB
Train: [151/180][600/625]	eta 0:00:32 lr 0.046990	data 0.0005 (0.0362)	batch 1.2288 (1.3018)	loss -27.4830 (-27.4154)	grad_norm 0.6368 (0.6377)	mem 44912MB
Current slope: None 	
EPOCH 151 training takes 0:13:34
Test: [0/25]	Time 14.303 (14.303)	Loss 1.2009 (1.2009)	Acc@1 72.900 (72.900)	Acc@5 90.869 (90.869)	Mem 44912MB
 * Acc@1 61.372 Acc@5 83.776
Accuracy of the network on the 50000 test images: 61.37%
Max accuracy (after decay): 61.43%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [152/180][0/625]	eta 3:56:08 lr 0.046859	data 20.6425 (20.6425)	batch 22.6702 (22.6702)	loss -27.4534 (-27.4534)	grad_norm 0.6428 (0.6428)	mem 44912MB
Train: [152/180][50/625]	eta 0:16:08 lr 0.046597	data 0.0011 (0.4056)	batch 1.2544 (1.6837)	loss -27.5123 (-27.4131)	grad_norm 0.6291 (0.6370)	mem 44912MB
Train: [152/180][100/625]	eta 0:12:56 lr 0.046336	data 0.0006 (0.2052)	batch 1.2239 (1.4791)	loss -27.4129 (-27.4117)	grad_norm 0.6490 (0.6363)	mem 44912MB
Train: [152/180][150/625]	eta 0:11:08 lr 0.046075	data 0.0005 (0.1375)	batch 1.2641 (1.4082)	loss -27.2740 (-27.4194)	grad_norm 0.6382 (0.6372)	mem 44912MB
Train: [152/180][200/625]	eta 0:09:43 lr 0.045815	data 0.0005 (0.1034)	batch 1.2577 (1.3733)	loss -27.5778 (-27.4135)	grad_norm 0.6450 (0.6386)	mem 44912MB
Train: [152/180][250/625]	eta 0:08:26 lr 0.045556	data 0.0005 (0.0829)	batch 1.2731 (1.3504)	loss -27.2684 (-27.4201)	grad_norm 0.6754 (0.6395)	mem 44912MB
Train: [152/180][300/625]	eta 0:07:14 lr 0.045298	data 0.0005 (0.0692)	batch 1.2645 (1.3376)	loss -27.4008 (-27.4138)	grad_norm 0.6376 (0.6396)	mem 44912MB
Train: [152/180][350/625]	eta 0:06:05 lr 0.045040	data 0.0010 (0.0595)	batch 1.2871 (1.3297)	loss -27.5150 (-27.4155)	grad_norm 0.6503 (0.6394)	mem 44912MB
Train: [152/180][400/625]	eta 0:04:57 lr 0.044783	data 0.0006 (0.0521)	batch 1.2790 (1.3237)	loss -27.5581 (-27.4184)	grad_norm 0.6538 (0.6393)	mem 44912MB
Train: [152/180][450/625]	eta 0:03:50 lr 0.044527	data 0.0130 (0.0464)	batch 1.2855 (1.3173)	loss -27.3745 (-27.4179)	grad_norm 0.6318 (0.6395)	mem 44912MB
Train: [152/180][500/625]	eta 0:02:45 lr 0.044271	data 0.0003 (0.0431)	batch 1.6515 (1.3221)	loss -27.3591 (-27.4173)	grad_norm 0.6437 (0.6395)	mem 44912MB
Train: [152/180][550/625]	eta 0:01:38 lr 0.044016	data 0.0005 (0.0393)	batch 1.2779 (1.3181)	loss -27.4372 (-27.4194)	grad_norm 0.6483 (0.6395)	mem 44912MB
Train: [152/180][600/625]	eta 0:00:32 lr 0.043762	data 0.0004 (0.0361)	batch 1.2179 (1.3140)	loss -27.4431 (-27.4184)	grad_norm 0.6350 (0.6398)	mem 44912MB
Current slope: None 	
EPOCH 152 training takes 0:13:41
Test: [0/25]	Time 15.881 (15.881)	Loss 1.2098 (1.2098)	Acc@1 73.340 (73.340)	Acc@5 90.527 (90.527)	Mem 44912MB
 * Acc@1 61.492 Acc@5 84.044
Accuracy of the network on the 50000 test images: 61.49%
Max accuracy (after decay): 61.49%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [153/180][0/625]	eta 3:53:41 lr 0.043635	data 21.1823 (21.1823)	batch 22.4348 (22.4348)	loss -27.5086 (-27.5086)	grad_norm 0.6286 (0.6286)	mem 44912MB
Train: [153/180][50/625]	eta 0:16:14 lr 0.043382	data 0.0005 (0.4159)	batch 1.2614 (1.6946)	loss -27.6251 (-27.4308)	grad_norm 0.6505 (0.6406)	mem 44912MB
Train: [153/180][100/625]	eta 0:13:01 lr 0.043130	data 0.0004 (0.2103)	batch 1.2535 (1.4883)	loss -27.3289 (-27.4231)	grad_norm 0.6345 (0.6421)	mem 44912MB
Train: [153/180][150/625]	eta 0:11:13 lr 0.042878	data 0.0007 (0.1408)	batch 1.2578 (1.4182)	loss -27.5372 (-27.4220)	grad_norm 0.6359 (0.6422)	mem 44912MB
Train: [153/180][200/625]	eta 0:09:48 lr 0.042627	data 0.0005 (0.1059)	batch 1.2837 (1.3843)	loss -27.4230 (-27.4152)	grad_norm 0.6292 (0.6414)	mem 44912MB
Train: [153/180][250/625]	eta 0:08:33 lr 0.042376	data 0.0004 (0.0851)	batch 1.2244 (1.3696)	loss -27.3042 (-27.4108)	grad_norm 0.6504 (0.6419)	mem 44912MB
Train: [153/180][300/625]	eta 0:07:20 lr 0.042126	data 0.0004 (0.0711)	batch 1.4022 (1.3541)	loss -27.4593 (-27.4049)	grad_norm 0.6487 (0.6418)	mem 44912MB
Train: [153/180][350/625]	eta 0:06:12 lr 0.041877	data 0.0005 (0.0647)	batch 1.2949 (1.3550)	loss -27.4540 (-27.4069)	grad_norm 0.6160 (0.6416)	mem 44912MB
Train: [153/180][400/625]	eta 0:05:04 lr 0.041629	data 0.0035 (0.0569)	batch 1.6402 (1.3527)	loss -27.4450 (-27.4096)	grad_norm 0.6426 (0.6418)	mem 44912MB
Train: [153/180][450/625]	eta 0:03:56 lr 0.041382	data 0.0097 (0.0509)	batch 1.2582 (1.3519)	loss -27.4460 (-27.4079)	grad_norm 0.6515 (0.6417)	mem 44912MB
Train: [153/180][500/625]	eta 0:02:47 lr 0.041135	data 0.0005 (0.0459)	batch 1.2668 (1.3439)	loss -27.4863 (-27.4083)	grad_norm 0.6626 (0.6420)	mem 44912MB
Train: [153/180][550/625]	eta 0:01:40 lr 0.040888	data 0.0006 (0.0418)	batch 1.2824 (1.3377)	loss -27.4302 (-27.4077)	grad_norm 0.6407 (0.6421)	mem 44912MB
Train: [153/180][600/625]	eta 0:00:33 lr 0.040643	data 0.0005 (0.0384)	batch 1.2694 (1.3320)	loss -27.3085 (-27.4081)	grad_norm 0.6456 (0.6421)	mem 44912MB
Current slope: None 	
EPOCH 153 training takes 0:13:52
Test: [0/25]	Time 15.447 (15.447)	Loss 1.1949 (1.1949)	Acc@1 73.145 (73.145)	Acc@5 90.479 (90.479)	Mem 44912MB
 * Acc@1 61.436 Acc@5 84.028
Accuracy of the network on the 50000 test images: 61.44%
Max accuracy (after decay): 61.49%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [154/180][0/625]	eta 3:57:22 lr 0.040520	data 21.1889 (21.1889)	batch 22.7884 (22.7884)	loss -27.5260 (-27.5260)	grad_norm 0.6458 (0.6458)	mem 44912MB
Train: [154/180][50/625]	eta 0:16:15 lr 0.040276	data 0.0005 (0.4160)	batch 1.2418 (1.6973)	loss -27.4742 (-27.4451)	grad_norm 0.6357 (0.6418)	mem 44912MB
Train: [154/180][100/625]	eta 0:12:58 lr 0.040032	data 0.0008 (0.2103)	batch 1.2328 (1.4822)	loss -27.5081 (-27.4475)	grad_norm 0.6415 (0.6414)	mem 44912MB
Train: [154/180][150/625]	eta 0:11:10 lr 0.039789	data 0.0005 (0.1409)	batch 1.2489 (1.4109)	loss -27.4090 (-27.4459)	grad_norm 0.6566 (0.6427)	mem 44912MB
Train: [154/180][200/625]	eta 0:09:43 lr 0.039547	data 0.0004 (0.1060)	batch 1.2703 (1.3735)	loss -27.4938 (-27.4366)	grad_norm 0.6449 (0.6425)	mem 44912MB
Train: [154/180][250/625]	eta 0:08:27 lr 0.039305	data 0.0005 (0.0850)	batch 1.2547 (1.3532)	loss -27.4777 (-27.4332)	grad_norm 0.6346 (0.6428)	mem 44912MB
Train: [154/180][300/625]	eta 0:07:15 lr 0.039064	data 0.0006 (0.0710)	batch 1.2238 (1.3386)	loss -27.4412 (-27.4324)	grad_norm 0.6439 (0.6429)	mem 44912MB
Train: [154/180][350/625]	eta 0:06:05 lr 0.038824	data 0.0005 (0.0609)	batch 1.2779 (1.3287)	loss -27.3123 (-27.4345)	grad_norm 0.6602 (0.6431)	mem 44912MB
Train: [154/180][400/625]	eta 0:04:57 lr 0.038584	data 0.0006 (0.0534)	batch 1.3539 (1.3212)	loss -27.4436 (-27.4326)	grad_norm 0.6652 (0.6433)	mem 44912MB
Train: [154/180][450/625]	eta 0:03:50 lr 0.038345	data 0.0005 (0.0475)	batch 1.2528 (1.3157)	loss -27.3539 (-27.4273)	grad_norm 0.6567 (0.6438)	mem 44912MB
Train: [154/180][500/625]	eta 0:02:43 lr 0.038107	data 0.0005 (0.0428)	batch 1.2444 (1.3108)	loss -27.1711 (-27.4258)	grad_norm 0.6500 (0.6440)	mem 44912MB
Train: [154/180][550/625]	eta 0:01:38 lr 0.037870	data 0.0005 (0.0390)	batch 1.2600 (1.3068)	loss -27.4536 (-27.4254)	grad_norm 0.6512 (0.6439)	mem 44912MB
Train: [154/180][600/625]	eta 0:00:32 lr 0.037633	data 0.0005 (0.0358)	batch 1.3034 (1.3032)	loss -27.2781 (-27.4219)	grad_norm 0.6476 (0.6440)	mem 44912MB
Current slope: None 	
EPOCH 154 training takes 0:13:35
Test: [0/25]	Time 14.417 (14.417)	Loss 1.2011 (1.2011)	Acc@1 73.242 (73.242)	Acc@5 90.723 (90.723)	Mem 44912MB
 * Acc@1 61.682 Acc@5 84.112
Accuracy of the network on the 50000 test images: 61.68%
Max accuracy (after decay): 61.68%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [155/180][0/625]	eta 3:56:59 lr 0.037515	data 21.0686 (21.0686)	batch 22.7510 (22.7510)	loss -27.7124 (-27.7124)	grad_norm 0.6363 (0.6363)	mem 44912MB
Train: [155/180][50/625]	eta 0:16:13 lr 0.037279	data 0.0005 (0.4137)	batch 1.2209 (1.6936)	loss -27.3826 (-27.4444)	grad_norm 0.6599 (0.6453)	mem 44912MB
Train: [155/180][100/625]	eta 0:12:59 lr 0.037044	data 0.0006 (0.2091)	batch 1.4479 (1.4846)	loss -27.3526 (-27.4405)	grad_norm 0.6487 (0.6434)	mem 44912MB
Train: [155/180][150/625]	eta 0:11:10 lr 0.036810	data 0.0007 (0.1401)	batch 1.2462 (1.4116)	loss -27.3676 (-27.4351)	grad_norm 0.6392 (0.6445)	mem 44912MB
Train: [155/180][200/625]	eta 0:09:45 lr 0.036577	data 0.0005 (0.1054)	batch 1.2749 (1.3768)	loss -27.6709 (-27.4419)	grad_norm 0.6340 (0.6454)	mem 44912MB
Train: [155/180][250/625]	eta 0:08:28 lr 0.036344	data 0.0005 (0.0845)	batch 1.2548 (1.3555)	loss -27.5863 (-27.4366)	grad_norm 0.6182 (0.6451)	mem 44912MB
Train: [155/180][300/625]	eta 0:07:16 lr 0.036112	data 0.0005 (0.0705)	batch 1.3053 (1.3424)	loss -27.6343 (-27.4370)	grad_norm 0.6335 (0.6454)	mem 44912MB
Train: [155/180][350/625]	eta 0:06:06 lr 0.035880	data 0.0005 (0.0606)	batch 1.3192 (1.3310)	loss -27.6133 (-27.4344)	grad_norm 0.6697 (0.6456)	mem 44912MB
Train: [155/180][400/625]	eta 0:04:57 lr 0.035649	data 0.0004 (0.0531)	batch 1.2356 (1.3233)	loss -27.4166 (-27.4325)	grad_norm 0.6522 (0.6459)	mem 44912MB
Train: [155/180][450/625]	eta 0:03:50 lr 0.035419	data 0.0006 (0.0473)	batch 1.2751 (1.3172)	loss -27.4920 (-27.4316)	grad_norm 0.6501 (0.6454)	mem 44912MB
Train: [155/180][500/625]	eta 0:02:43 lr 0.035190	data 0.0008 (0.0426)	batch 1.2559 (1.3118)	loss -27.4893 (-27.4320)	grad_norm 0.6393 (0.6454)	mem 44912MB
Train: [155/180][550/625]	eta 0:01:38 lr 0.034962	data 0.0003 (0.0388)	batch 1.2659 (1.3073)	loss -27.3763 (-27.4296)	grad_norm 0.6662 (0.6454)	mem 44912MB
Train: [155/180][600/625]	eta 0:00:32 lr 0.034734	data 0.0006 (0.0356)	batch 1.2778 (1.3038)	loss -27.5204 (-27.4290)	grad_norm 0.6618 (0.6456)	mem 44912MB
Current slope: None 	
EPOCH 155 training takes 0:13:35
Test: [0/25]	Time 14.505 (14.505)	Loss 1.1956 (1.1956)	Acc@1 72.559 (72.559)	Acc@5 90.723 (90.723)	Mem 44912MB
 * Acc@1 61.666 Acc@5 84.022
Accuracy of the network on the 50000 test images: 61.67%
Max accuracy (after decay): 61.68%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [156/180][0/625]	eta 4:01:03 lr 0.034620	data 20.7248 (20.7248)	batch 23.1413 (23.1413)	loss -27.6264 (-27.6264)	grad_norm 0.6423 (0.6423)	mem 44912MB
Train: [156/180][50/625]	eta 0:16:15 lr 0.034393	data 0.0006 (0.4071)	batch 1.3376 (1.6963)	loss -27.3919 (-27.4467)	grad_norm 0.6672 (0.6458)	mem 44912MB
Train: [156/180][100/625]	eta 0:12:57 lr 0.034167	data 0.0005 (0.2058)	batch 1.2607 (1.4807)	loss -27.6147 (-27.4369)	grad_norm 0.6441 (0.6465)	mem 44912MB
Train: [156/180][150/625]	eta 0:11:10 lr 0.033942	data 0.0006 (0.1379)	batch 1.2799 (1.4109)	loss -27.2609 (-27.4340)	grad_norm 0.6636 (0.6468)	mem 44912MB
Train: [156/180][200/625]	eta 0:09:44 lr 0.033717	data 0.0004 (0.1037)	batch 1.2791 (1.3757)	loss -27.4903 (-27.4334)	grad_norm 0.6564 (0.6466)	mem 44912MB
Train: [156/180][250/625]	eta 0:08:27 lr 0.033493	data 0.0005 (0.0832)	batch 1.2208 (1.3527)	loss -27.4439 (-27.4285)	grad_norm 0.6535 (0.6471)	mem 44912MB
Train: [156/180][300/625]	eta 0:07:14 lr 0.033270	data 0.0005 (0.0694)	batch 1.2756 (1.3383)	loss -27.2596 (-27.4282)	grad_norm 0.6362 (0.6473)	mem 44912MB
Train: [156/180][350/625]	eta 0:06:04 lr 0.033047	data 0.0007 (0.0596)	batch 1.2181 (1.3269)	loss -27.5171 (-27.4337)	grad_norm 0.6383 (0.6473)	mem 44912MB
Train: [156/180][400/625]	eta 0:04:56 lr 0.032826	data 0.0006 (0.0522)	batch 1.2442 (1.3191)	loss -27.3909 (-27.4325)	grad_norm 0.6593 (0.6478)	mem 44912MB
Train: [156/180][450/625]	eta 0:03:49 lr 0.032605	data 0.0006 (0.0465)	batch 1.2248 (1.3126)	loss -27.4729 (-27.4311)	grad_norm 0.6635 (0.6483)	mem 44912MB
Train: [156/180][500/625]	eta 0:02:43 lr 0.032384	data 0.0023 (0.0419)	batch 1.2753 (1.3073)	loss -27.3497 (-27.4311)	grad_norm 0.6660 (0.6483)	mem 44912MB
Train: [156/180][550/625]	eta 0:01:37 lr 0.032165	data 0.0005 (0.0382)	batch 1.2543 (1.3030)	loss -27.4693 (-27.4314)	grad_norm 0.6536 (0.6486)	mem 44912MB
Train: [156/180][600/625]	eta 0:00:32 lr 0.031946	data 0.0005 (0.0351)	batch 1.2365 (1.2996)	loss -27.5334 (-27.4326)	grad_norm 0.6554 (0.6488)	mem 44912MB
Current slope: None 	
EPOCH 156 training takes 0:13:32
Test: [0/25]	Time 14.334 (14.334)	Loss 1.1871 (1.1871)	Acc@1 73.291 (73.291)	Acc@5 90.918 (90.918)	Mem 44912MB
 * Acc@1 61.842 Acc@5 84.228
Accuracy of the network on the 50000 test images: 61.84%
Max accuracy (after decay): 61.84%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [157/180][0/625]	eta 4:00:33 lr 0.031836	data 20.9670 (20.9670)	batch 23.0943 (23.0943)	loss -27.3814 (-27.3814)	grad_norm 0.6419 (0.6419)	mem 44912MB
Train: [157/180][50/625]	eta 0:16:18 lr 0.031619	data 0.0013 (0.4127)	batch 1.2839 (1.7015)	loss -27.4667 (-27.4412)	grad_norm 0.6525 (0.6517)	mem 44912MB
Train: [157/180][100/625]	eta 0:12:59 lr 0.031401	data 0.0010 (0.2088)	batch 1.2453 (1.4856)	loss -27.4085 (-27.4369)	grad_norm 0.6371 (0.6482)	mem 44912MB
Train: [157/180][150/625]	eta 0:11:11 lr 0.031185	data 0.0006 (0.1399)	batch 1.2634 (1.4128)	loss -27.2908 (-27.4284)	grad_norm 0.6569 (0.6495)	mem 44912MB
Train: [157/180][200/625]	eta 0:09:44 lr 0.030969	data 0.0006 (0.1053)	batch 1.2969 (1.3757)	loss -27.6221 (-27.4269)	grad_norm 0.6517 (0.6497)	mem 44912MB
Train: [157/180][250/625]	eta 0:08:27 lr 0.030754	data 0.0005 (0.0844)	batch 1.2827 (1.3542)	loss -27.5649 (-27.4274)	grad_norm 0.6344 (0.6503)	mem 44912MB
Train: [157/180][300/625]	eta 0:07:15 lr 0.030540	data 0.0005 (0.0705)	batch 1.3003 (1.3393)	loss -27.4340 (-27.4331)	grad_norm 0.6481 (0.6497)	mem 44912MB
Train: [157/180][350/625]	eta 0:06:05 lr 0.030327	data 0.0004 (0.0605)	batch 1.3154 (1.3290)	loss -27.3412 (-27.4307)	grad_norm 0.6730 (0.6499)	mem 44912MB
Train: [157/180][400/625]	eta 0:04:57 lr 0.030114	data 0.0006 (0.0531)	batch 1.2083 (1.3210)	loss -27.1429 (-27.4298)	grad_norm 0.6676 (0.6498)	mem 44912MB
Train: [157/180][450/625]	eta 0:03:50 lr 0.029902	data 0.0015 (0.0472)	batch 1.3494 (1.3151)	loss -27.3044 (-27.4308)	grad_norm 0.6610 (0.6497)	mem 44912MB
Train: [157/180][500/625]	eta 0:02:43 lr 0.029690	data 0.0006 (0.0426)	batch 1.2211 (1.3096)	loss -27.4209 (-27.4332)	grad_norm 0.6449 (0.6498)	mem 44912MB
Train: [157/180][550/625]	eta 0:01:37 lr 0.029480	data 0.0005 (0.0388)	batch 1.2564 (1.3057)	loss -27.6892 (-27.4328)	grad_norm 0.6530 (0.6502)	mem 44912MB
Train: [157/180][600/625]	eta 0:00:32 lr 0.029270	data 0.0005 (0.0356)	batch 1.2583 (1.3020)	loss -27.4861 (-27.4321)	grad_norm 0.6508 (0.6503)	mem 44912MB
Current slope: None 	
EPOCH 157 training takes 0:13:34
Test: [0/25]	Time 14.795 (14.795)	Loss 1.1747 (1.1747)	Acc@1 73.047 (73.047)	Acc@5 91.064 (91.064)	Mem 44912MB
 * Acc@1 61.716 Acc@5 84.190
Accuracy of the network on the 50000 test images: 61.72%
Max accuracy (after decay): 61.84%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [158/180][0/625]	eta 4:03:14 lr 0.029165	data 21.2928 (21.2928)	batch 23.3519 (23.3519)	loss -27.4737 (-27.4737)	grad_norm 0.6516 (0.6516)	mem 44912MB
Train: [158/180][50/625]	eta 0:16:23 lr 0.028956	data 0.0009 (0.4182)	batch 1.2994 (1.7096)	loss -27.3670 (-27.4435)	grad_norm 0.6363 (0.6517)	mem 44912MB
Train: [158/180][100/625]	eta 0:13:02 lr 0.028748	data 0.0006 (0.2114)	batch 1.2556 (1.4906)	loss -27.3782 (-27.4408)	grad_norm 0.6437 (0.6509)	mem 44912MB
Train: [158/180][150/625]	eta 0:11:14 lr 0.028541	data 0.0005 (0.1416)	batch 1.2780 (1.4190)	loss -27.4494 (-27.4346)	grad_norm 0.6490 (0.6516)	mem 44912MB
Train: [158/180][200/625]	eta 0:09:46 lr 0.028334	data 0.0005 (0.1065)	batch 1.3050 (1.3805)	loss -27.4272 (-27.4351)	grad_norm 0.6526 (0.6512)	mem 44912MB
Train: [158/180][250/625]	eta 0:08:29 lr 0.028128	data 0.0006 (0.0854)	batch 1.2728 (1.3591)	loss -27.6703 (-27.4381)	grad_norm 0.6445 (0.6518)	mem 44912MB
Train: [158/180][300/625]	eta 0:07:16 lr 0.027923	data 0.0008 (0.0713)	batch 1.2749 (1.3438)	loss -27.2043 (-27.4365)	grad_norm 0.6504 (0.6516)	mem 44912MB
Train: [158/180][350/625]	eta 0:06:06 lr 0.027718	data 0.0005 (0.0612)	batch 1.2629 (1.3341)	loss -27.4078 (-27.4345)	grad_norm 0.6420 (0.6515)	mem 44912MB
Train: [158/180][400/625]	eta 0:04:58 lr 0.027514	data 0.0009 (0.0537)	batch 1.2512 (1.3253)	loss -27.2673 (-27.4344)	grad_norm 0.6730 (0.6519)	mem 44912MB
Train: [158/180][450/625]	eta 0:03:50 lr 0.027311	data 0.0004 (0.0478)	batch 1.2407 (1.3189)	loss -27.1676 (-27.4345)	grad_norm 0.6622 (0.6520)	mem 44912MB
Train: [158/180][500/625]	eta 0:02:44 lr 0.027109	data 0.0005 (0.0431)	batch 1.2405 (1.3137)	loss -27.4388 (-27.4347)	grad_norm 0.6700 (0.6521)	mem 44912MB
Train: [158/180][550/625]	eta 0:01:38 lr 0.026908	data 0.0006 (0.0392)	batch 1.3131 (1.3095)	loss -27.4334 (-27.4347)	grad_norm 0.6488 (0.6522)	mem 44912MB
Train: [158/180][600/625]	eta 0:00:32 lr 0.026707	data 0.0006 (0.0360)	batch 1.2340 (1.3057)	loss -27.4582 (-27.4337)	grad_norm 0.6475 (0.6519)	mem 44912MB
Current slope: None 	
EPOCH 158 training takes 0:13:36
Test: [0/25]	Time 14.515 (14.515)	Loss 1.1595 (1.1595)	Acc@1 73.145 (73.145)	Acc@5 90.625 (90.625)	Mem 44912MB
 * Acc@1 61.988 Acc@5 84.186
Accuracy of the network on the 50000 test images: 61.99%
Max accuracy (after decay): 61.99%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [159/180][0/625]	eta 4:00:12 lr 0.026607	data 20.6267 (20.6267)	batch 23.0601 (23.0601)	loss -27.3398 (-27.3398)	grad_norm 0.6444 (0.6444)	mem 44912MB
Train: [159/180][50/625]	eta 0:16:14 lr 0.026407	data 0.0005 (0.4056)	batch 1.2417 (1.6940)	loss -27.4639 (-27.4343)	grad_norm 0.6515 (0.6524)	mem 44912MB
Train: [159/180][100/625]	eta 0:12:58 lr 0.026208	data 0.0006 (0.2053)	batch 1.2816 (1.4828)	loss -27.3241 (-27.4523)	grad_norm 0.6767 (0.6518)	mem 44912MB
Train: [159/180][150/625]	eta 0:11:10 lr 0.026009	data 0.0006 (0.1375)	batch 1.2183 (1.4109)	loss -27.3398 (-27.4534)	grad_norm 0.6511 (0.6527)	mem 44912MB
Train: [159/180][200/625]	eta 0:09:45 lr 0.025812	data 0.0005 (0.1035)	batch 1.2682 (1.3779)	loss -27.2711 (-27.4526)	grad_norm 0.6402 (0.6526)	mem 44912MB
Train: [159/180][250/625]	eta 0:08:28 lr 0.025615	data 0.0006 (0.0830)	batch 1.2054 (1.3550)	loss -27.5844 (-27.4476)	grad_norm 0.6298 (0.6528)	mem 44912MB
Train: [159/180][300/625]	eta 0:07:15 lr 0.025419	data 0.0005 (0.0693)	batch 1.2358 (1.3404)	loss -27.6604 (-27.4476)	grad_norm 0.6494 (0.6532)	mem 44912MB
Train: [159/180][350/625]	eta 0:06:05 lr 0.025223	data 0.0006 (0.0595)	batch 1.3137 (1.3298)	loss -27.5362 (-27.4453)	grad_norm 0.6425 (0.6531)	mem 44912MB
Train: [159/180][400/625]	eta 0:04:57 lr 0.025029	data 0.0005 (0.0522)	batch 1.2998 (1.3229)	loss -27.2982 (-27.4392)	grad_norm 0.6655 (0.6531)	mem 44912MB
Train: [159/180][450/625]	eta 0:03:50 lr 0.024835	data 0.0007 (0.0464)	batch 1.2444 (1.3160)	loss -27.4721 (-27.4390)	grad_norm 0.6518 (0.6533)	mem 44912MB
Train: [159/180][500/625]	eta 0:02:43 lr 0.024642	data 0.0006 (0.0419)	batch 1.2602 (1.3108)	loss -27.3668 (-27.4388)	grad_norm 0.6430 (0.6530)	mem 44912MB
Train: [159/180][550/625]	eta 0:01:38 lr 0.024449	data 0.0005 (0.0381)	batch 1.2708 (1.3071)	loss -27.4958 (-27.4369)	grad_norm 0.6547 (0.6530)	mem 44912MB
Train: [159/180][600/625]	eta 0:00:32 lr 0.024257	data 0.0007 (0.0350)	batch 1.2935 (1.3045)	loss -27.4627 (-27.4351)	grad_norm 0.6399 (0.6532)	mem 44912MB
Current slope: None 	
EPOCH 159 training takes 0:13:35
Test: [0/25]	Time 14.512 (14.512)	Loss 1.1959 (1.1959)	Acc@1 72.949 (72.949)	Acc@5 90.771 (90.771)	Mem 44912MB
 * Acc@1 61.922 Acc@5 84.296
Accuracy of the network on the 50000 test images: 61.92%
Max accuracy (after decay): 61.99%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [160/180][0/625]	eta 4:02:06 lr 0.024162	data 21.6220 (21.6220)	batch 23.2421 (23.2421)	loss -27.4638 (-27.4638)	grad_norm 0.6544 (0.6544)	mem 44912MB
Train: [160/180][50/625]	eta 0:16:15 lr 0.023971	data 0.0005 (0.4252)	batch 1.2670 (1.6968)	loss -27.4587 (-27.4309)	grad_norm 0.6566 (0.6536)	mem 44912MB
Train: [160/180][100/625]	eta 0:12:59 lr 0.023781	data 0.0008 (0.2150)	batch 1.2604 (1.4855)	loss -27.2581 (-27.4565)	grad_norm 0.7047 (0.6547)	mem 44912MB
Train: [160/180][150/625]	eta 0:11:11 lr 0.023592	data 0.0005 (0.1440)	batch 1.2680 (1.4136)	loss -27.4023 (-27.4544)	grad_norm 0.6269 (0.6554)	mem 44912MB
Train: [160/180][200/625]	eta 0:09:45 lr 0.023404	data 0.0005 (0.1083)	batch 1.2632 (1.3787)	loss -27.3993 (-27.4531)	grad_norm 0.6607 (0.6546)	mem 44912MB
Train: [160/180][250/625]	eta 0:08:28 lr 0.023216	data 0.0006 (0.0869)	batch 1.2562 (1.3558)	loss -27.2677 (-27.4499)	grad_norm 0.6799 (0.6553)	mem 44912MB
Train: [160/180][300/625]	eta 0:07:15 lr 0.023029	data 0.0005 (0.0725)	batch 1.2259 (1.3407)	loss -27.4588 (-27.4481)	grad_norm 0.6419 (0.6551)	mem 44912MB
Train: [160/180][350/625]	eta 0:06:05 lr 0.022843	data 0.0005 (0.0623)	batch 1.2700 (1.3304)	loss -27.4929 (-27.4434)	grad_norm 0.6585 (0.6548)	mem 44912MB
Train: [160/180][400/625]	eta 0:04:57 lr 0.022657	data 0.0005 (0.0546)	batch 1.2873 (1.3229)	loss -27.4552 (-27.4446)	grad_norm 0.6548 (0.6545)	mem 44912MB
Train: [160/180][450/625]	eta 0:03:50 lr 0.022472	data 0.0005 (0.0486)	batch 1.2489 (1.3164)	loss -27.1785 (-27.4460)	grad_norm 0.6502 (0.6547)	mem 44912MB
Train: [160/180][500/625]	eta 0:02:43 lr 0.022288	data 0.0004 (0.0438)	batch 1.2488 (1.3109)	loss -27.3706 (-27.4447)	grad_norm 0.6477 (0.6547)	mem 44912MB
Train: [160/180][550/625]	eta 0:01:37 lr 0.022105	data 0.0006 (0.0399)	batch 1.2215 (1.3061)	loss -27.4346 (-27.4458)	grad_norm 0.6394 (0.6548)	mem 44912MB
Train: [160/180][600/625]	eta 0:00:32 lr 0.021922	data 0.0005 (0.0366)	batch 1.2416 (1.3024)	loss -27.3934 (-27.4432)	grad_norm 0.6469 (0.6549)	mem 44912MB
Current slope: None 	
EPOCH 160 training takes 0:13:34
Test: [0/25]	Time 14.478 (14.478)	Loss 1.1881 (1.1881)	Acc@1 73.242 (73.242)	Acc@5 90.820 (90.820)	Mem 44912MB
 * Acc@1 62.024 Acc@5 84.178
Accuracy of the network on the 50000 test images: 62.02%
Max accuracy (after decay): 62.02%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [161/180][0/625]	eta 4:03:33 lr 0.021831	data 21.5510 (21.5510)	batch 23.3817 (23.3817)	loss -27.2712 (-27.2712)	grad_norm 0.6495 (0.6495)	mem 44912MB
Train: [161/180][50/625]	eta 0:16:19 lr 0.021650	data 0.0006 (0.4233)	batch 1.2612 (1.7043)	loss -27.3138 (-27.4577)	grad_norm 0.6675 (0.6551)	mem 44912MB
Train: [161/180][100/625]	eta 0:13:00 lr 0.021469	data 0.0005 (0.2140)	batch 1.2503 (1.4867)	loss -27.5464 (-27.4612)	grad_norm 0.6573 (0.6535)	mem 44912MB
Train: [161/180][150/625]	eta 0:11:12 lr 0.021289	data 0.0005 (0.1433)	batch 1.3010 (1.4160)	loss -27.4845 (-27.4586)	grad_norm 0.6537 (0.6536)	mem 44912MB
Train: [161/180][200/625]	eta 0:09:45 lr 0.021110	data 0.0008 (0.1080)	batch 1.2238 (1.3781)	loss -27.3975 (-27.4508)	grad_norm 0.6552 (0.6543)	mem 44912MB
Train: [161/180][250/625]	eta 0:08:28 lr 0.020932	data 0.0005 (0.0866)	batch 1.2423 (1.3558)	loss -27.3426 (-27.4471)	grad_norm 0.6513 (0.6550)	mem 44912MB
Train: [161/180][300/625]	eta 0:07:15 lr 0.020754	data 0.0004 (0.0723)	batch 1.2713 (1.3401)	loss -27.2662 (-27.4464)	grad_norm 0.6772 (0.6549)	mem 44912MB
Train: [161/180][350/625]	eta 0:06:05 lr 0.020577	data 0.0005 (0.0621)	batch 1.2301 (1.3301)	loss -27.4890 (-27.4487)	grad_norm 0.6597 (0.6551)	mem 44912MB
Train: [161/180][400/625]	eta 0:04:57 lr 0.020401	data 0.0005 (0.0544)	batch 1.2528 (1.3216)	loss -27.5287 (-27.4531)	grad_norm 0.6461 (0.6552)	mem 44912MB
Train: [161/180][450/625]	eta 0:03:50 lr 0.020225	data 0.0004 (0.0484)	batch 1.2785 (1.3149)	loss -27.2408 (-27.4514)	grad_norm 0.6572 (0.6555)	mem 44912MB
Train: [161/180][500/625]	eta 0:02:43 lr 0.020050	data 0.0005 (0.0437)	batch 1.3050 (1.3094)	loss -27.3308 (-27.4522)	grad_norm 0.6605 (0.6556)	mem 44912MB
Train: [161/180][550/625]	eta 0:01:37 lr 0.019876	data 0.0006 (0.0398)	batch 1.2671 (1.3056)	loss -27.5138 (-27.4515)	grad_norm 0.6628 (0.6559)	mem 44912MB
Train: [161/180][600/625]	eta 0:00:32 lr 0.019703	data 0.0005 (0.0365)	batch 1.3134 (1.3021)	loss -27.6660 (-27.4545)	grad_norm 0.6660 (0.6559)	mem 44912MB
Current slope: None 	
EPOCH 161 training takes 0:13:34
Test: [0/25]	Time 14.762 (14.762)	Loss 1.1806 (1.1806)	Acc@1 74.072 (74.072)	Acc@5 90.723 (90.723)	Mem 44912MB
 * Acc@1 61.958 Acc@5 84.320
Accuracy of the network on the 50000 test images: 61.96%
Max accuracy (after decay): 62.02%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [162/180][0/625]	eta 3:59:56 lr 0.019616	data 20.4978 (20.4978)	batch 23.0351 (23.0351)	loss -27.4272 (-27.4272)	grad_norm 0.6579 (0.6579)	mem 44912MB
Train: [162/180][50/625]	eta 0:16:19 lr 0.019444	data 0.0007 (0.4026)	batch 1.2372 (1.7027)	loss -27.3147 (-27.4528)	grad_norm 0.6640 (0.6570)	mem 44912MB
Train: [162/180][100/625]	eta 0:12:59 lr 0.019273	data 0.0008 (0.2036)	batch 1.2441 (1.4852)	loss -27.6000 (-27.4429)	grad_norm 0.6584 (0.6572)	mem 44912MB
Train: [162/180][150/625]	eta 0:11:11 lr 0.019102	data 0.0006 (0.1364)	batch 1.2878 (1.4139)	loss -27.6776 (-27.4413)	grad_norm 0.6535 (0.6568)	mem 44912MB
Train: [162/180][200/625]	eta 0:09:45 lr 0.018932	data 0.0006 (0.1026)	batch 1.2650 (1.3767)	loss -27.4421 (-27.4400)	grad_norm 0.6620 (0.6571)	mem 44912MB
Train: [162/180][250/625]	eta 0:08:28 lr 0.018763	data 0.0005 (0.0823)	batch 1.2545 (1.3552)	loss -27.5393 (-27.4438)	grad_norm 0.6473 (0.6563)	mem 44912MB
Train: [162/180][300/625]	eta 0:07:15 lr 0.018594	data 0.0005 (0.0687)	batch 1.2467 (1.3398)	loss -27.3289 (-27.4460)	grad_norm 0.6512 (0.6566)	mem 44912MB
Train: [162/180][350/625]	eta 0:06:05 lr 0.018427	data 0.0005 (0.0590)	batch 1.3409 (1.3294)	loss -27.4927 (-27.4500)	grad_norm 0.6495 (0.6567)	mem 44912MB
Train: [162/180][400/625]	eta 0:04:57 lr 0.018260	data 0.0006 (0.0517)	batch 1.2652 (1.3210)	loss -27.5589 (-27.4493)	grad_norm 0.6691 (0.6570)	mem 44912MB
Train: [162/180][450/625]	eta 0:03:50 lr 0.018093	data 0.0005 (0.0461)	batch 1.2528 (1.3154)	loss -27.4620 (-27.4501)	grad_norm 0.6438 (0.6572)	mem 44912MB
Train: [162/180][500/625]	eta 0:02:43 lr 0.017928	data 0.0005 (0.0415)	batch 1.4241 (1.3102)	loss -27.4671 (-27.4505)	grad_norm 0.6412 (0.6573)	mem 44912MB
Train: [162/180][550/625]	eta 0:01:37 lr 0.017763	data 0.0006 (0.0378)	batch 1.2347 (1.3064)	loss -27.5075 (-27.4502)	grad_norm 0.6583 (0.6574)	mem 44912MB
Train: [162/180][600/625]	eta 0:00:32 lr 0.017599	data 0.0005 (0.0347)	batch 1.2583 (1.3027)	loss -27.3114 (-27.4507)	grad_norm 0.6659 (0.6573)	mem 44912MB
Current slope: None 	
EPOCH 162 training takes 0:13:34
Test: [0/25]	Time 14.494 (14.494)	Loss 1.1907 (1.1907)	Acc@1 73.389 (73.389)	Acc@5 90.771 (90.771)	Mem 44912MB
 * Acc@1 62.068 Acc@5 84.332
Accuracy of the network on the 50000 test images: 62.07%
Max accuracy (after decay): 62.07%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [163/180][0/625]	eta 3:57:55 lr 0.017517	data 20.8242 (20.8242)	batch 22.8406 (22.8406)	loss -27.6030 (-27.6030)	grad_norm 0.6440 (0.6440)	mem 44912MB
Train: [163/180][50/625]	eta 0:16:09 lr 0.017354	data 0.0005 (0.4089)	batch 1.2396 (1.6865)	loss -27.4057 (-27.4379)	grad_norm 0.6667 (0.6563)	mem 44912MB
Train: [163/180][100/625]	eta 0:12:58 lr 0.017192	data 0.0005 (0.2068)	batch 1.2410 (1.4834)	loss -27.5421 (-27.4443)	grad_norm 0.6697 (0.6564)	mem 44912MB
Train: [163/180][150/625]	eta 0:11:10 lr 0.017031	data 0.0004 (0.1385)	batch 1.2616 (1.4109)	loss -27.6090 (-27.4479)	grad_norm 0.6490 (0.6574)	mem 44912MB
Train: [163/180][200/625]	eta 0:09:44 lr 0.016870	data 0.0006 (0.1042)	batch 1.2628 (1.3752)	loss -27.4595 (-27.4503)	grad_norm 0.6594 (0.6567)	mem 44912MB
Train: [163/180][250/625]	eta 0:08:26 lr 0.016710	data 0.0005 (0.0835)	batch 1.2656 (1.3516)	loss -27.5285 (-27.4481)	grad_norm 0.6475 (0.6571)	mem 44912MB
Train: [163/180][300/625]	eta 0:07:14 lr 0.016551	data 0.0006 (0.0698)	batch 1.2324 (1.3379)	loss -27.6489 (-27.4541)	grad_norm 0.6559 (0.6571)	mem 44912MB
Train: [163/180][350/625]	eta 0:06:04 lr 0.016393	data 0.0006 (0.0599)	batch 1.2717 (1.3268)	loss -27.5885 (-27.4565)	grad_norm 0.6477 (0.6575)	mem 44912MB
Train: [163/180][400/625]	eta 0:04:56 lr 0.016235	data 0.0004 (0.0525)	batch 1.2877 (1.3192)	loss -27.5286 (-27.4560)	grad_norm 0.6575 (0.6577)	mem 44912MB
Train: [163/180][450/625]	eta 0:03:49 lr 0.016078	data 0.0006 (0.0468)	batch 1.2977 (1.3133)	loss -27.2971 (-27.4575)	grad_norm 0.6484 (0.6578)	mem 44912MB
Train: [163/180][500/625]	eta 0:02:43 lr 0.015922	data 0.0005 (0.0421)	batch 1.2487 (1.3088)	loss -27.3741 (-27.4570)	grad_norm 0.6536 (0.6581)	mem 44912MB
Train: [163/180][550/625]	eta 0:01:37 lr 0.015766	data 0.0004 (0.0384)	batch 1.2892 (1.3045)	loss -27.5426 (-27.4550)	grad_norm 0.6552 (0.6580)	mem 44912MB
Train: [163/180][600/625]	eta 0:00:32 lr 0.015612	data 0.0005 (0.0352)	batch 1.2650 (1.3008)	loss -27.3597 (-27.4550)	grad_norm 0.6543 (0.6581)	mem 44912MB
Current slope: None 	
EPOCH 163 training takes 0:13:33
Test: [0/25]	Time 14.364 (14.364)	Loss 1.1772 (1.1772)	Acc@1 73.340 (73.340)	Acc@5 91.016 (91.016)	Mem 44912MB
 * Acc@1 62.162 Acc@5 84.426
Accuracy of the network on the 50000 test images: 62.16%
Max accuracy (after decay): 62.16%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [164/180][0/625]	eta 3:58:08 lr 0.015535	data 19.7457 (19.7457)	batch 22.8614 (22.8614)	loss -27.4465 (-27.4465)	grad_norm 0.6513 (0.6513)	mem 44912MB
Train: [164/180][50/625]	eta 0:16:15 lr 0.015381	data 0.0005 (0.3893)	batch 1.3010 (1.6973)	loss -27.4580 (-27.4793)	grad_norm 0.6628 (0.6544)	mem 44912MB
Train: [164/180][100/625]	eta 0:12:59 lr 0.015228	data 0.0004 (0.1969)	batch 1.2452 (1.4840)	loss -27.5748 (-27.4788)	grad_norm 0.6716 (0.6570)	mem 44912MB
Train: [164/180][150/625]	eta 0:11:10 lr 0.015076	data 0.0006 (0.1319)	batch 1.2937 (1.4112)	loss -27.4934 (-27.4718)	grad_norm 0.6623 (0.6579)	mem 44912MB
Train: [164/180][200/625]	eta 0:09:44 lr 0.014925	data 0.0006 (0.0994)	batch 1.2378 (1.3745)	loss -27.4735 (-27.4636)	grad_norm 0.6678 (0.6583)	mem 44912MB
Train: [164/180][250/625]	eta 0:08:27 lr 0.014774	data 0.0004 (0.0797)	batch 1.2863 (1.3542)	loss -27.2170 (-27.4552)	grad_norm 0.6574 (0.6586)	mem 44912MB
Train: [164/180][300/625]	eta 0:07:15 lr 0.014624	data 0.0006 (0.0666)	batch 1.2321 (1.3400)	loss -27.1950 (-27.4543)	grad_norm 0.6554 (0.6588)	mem 44912MB
Train: [164/180][350/625]	eta 0:06:05 lr 0.014475	data 0.0006 (0.0572)	batch 1.1974 (1.3296)	loss -27.5179 (-27.4528)	grad_norm 0.6610 (0.6592)	mem 44912MB
Train: [164/180][400/625]	eta 0:04:57 lr 0.014327	data 0.0007 (0.0501)	batch 1.2841 (1.3209)	loss -27.4049 (-27.4542)	grad_norm 0.6554 (0.6594)	mem 44912MB
Train: [164/180][450/625]	eta 0:03:50 lr 0.014180	data 0.0006 (0.0446)	batch 1.3673 (1.3151)	loss -27.4251 (-27.4565)	grad_norm 0.6542 (0.6593)	mem 44912MB
Train: [164/180][500/625]	eta 0:02:43 lr 0.014033	data 0.0005 (0.0402)	batch 1.2394 (1.3095)	loss -27.5057 (-27.4553)	grad_norm 0.6505 (0.6593)	mem 44912MB
Train: [164/180][550/625]	eta 0:01:37 lr 0.013887	data 0.0005 (0.0366)	batch 1.2593 (1.3051)	loss -27.3964 (-27.4555)	grad_norm 0.6580 (0.6593)	mem 44912MB
Train: [164/180][600/625]	eta 0:00:32 lr 0.013741	data 0.0005 (0.0336)	batch 1.2471 (1.3014)	loss -27.4710 (-27.4548)	grad_norm 0.6474 (0.6594)	mem 44912MB
Current slope: None 	
EPOCH 164 training takes 0:13:33
Test: [0/25]	Time 14.446 (14.446)	Loss 1.1752 (1.1752)	Acc@1 73.145 (73.145)	Acc@5 90.869 (90.869)	Mem 44912MB
 * Acc@1 62.270 Acc@5 84.370
Accuracy of the network on the 50000 test images: 62.27%
Max accuracy (after decay): 62.27%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [165/180][0/625]	eta 3:58:29 lr 0.013669	data 21.0213 (21.0213)	batch 22.8945 (22.8945)	loss -27.5095 (-27.5095)	grad_norm 0.6485 (0.6485)	mem 44912MB
Train: [165/180][50/625]	eta 0:16:17 lr 0.013525	data 0.0006 (0.4129)	batch 1.2460 (1.6995)	loss -27.4147 (-27.4648)	grad_norm 0.6652 (0.6609)	mem 44912MB
Train: [165/180][100/625]	eta 0:13:01 lr 0.013381	data 0.0006 (0.2088)	batch 1.3561 (1.4878)	loss -27.3663 (-27.4610)	grad_norm 0.6623 (0.6610)	mem 44912MB
Train: [165/180][150/625]	eta 0:11:12 lr 0.013239	data 0.0005 (0.1399)	batch 1.2735 (1.4160)	loss -27.4832 (-27.4628)	grad_norm 0.6491 (0.6612)	mem 44912MB
Train: [165/180][200/625]	eta 0:09:45 lr 0.013097	data 0.0003 (0.1052)	batch 1.2599 (1.3786)	loss -27.4724 (-27.4572)	grad_norm 0.6724 (0.6607)	mem 44912MB
Train: [165/180][250/625]	eta 0:08:29 lr 0.012956	data 0.0005 (0.0844)	batch 1.2821 (1.3575)	loss -27.4457 (-27.4545)	grad_norm 0.6422 (0.6602)	mem 44912MB
Train: [165/180][300/625]	eta 0:07:16 lr 0.012815	data 0.0005 (0.0704)	batch 1.2326 (1.3417)	loss -27.3494 (-27.4529)	grad_norm 0.6453 (0.6596)	mem 44912MB
Train: [165/180][350/625]	eta 0:06:06 lr 0.012676	data 0.0005 (0.0606)	batch 1.2706 (1.3310)	loss -27.4991 (-27.4568)	grad_norm 0.6560 (0.6597)	mem 44912MB
Train: [165/180][400/625]	eta 0:04:57 lr 0.012537	data 0.0005 (0.0531)	batch 1.2039 (1.3219)	loss -27.5363 (-27.4602)	grad_norm 0.6648 (0.6600)	mem 44912MB
Train: [165/180][450/625]	eta 0:03:50 lr 0.012399	data 0.0005 (0.0473)	batch 1.2608 (1.3163)	loss -27.4419 (-27.4619)	grad_norm 0.6712 (0.6600)	mem 44912MB
Train: [165/180][500/625]	eta 0:02:43 lr 0.012261	data 0.0006 (0.0426)	batch 1.2027 (1.3110)	loss -27.4047 (-27.4602)	grad_norm 0.6475 (0.6596)	mem 44912MB
Train: [165/180][550/625]	eta 0:01:38 lr 0.012125	data 0.0009 (0.0388)	batch 1.2969 (1.3069)	loss -27.4885 (-27.4579)	grad_norm 0.6589 (0.6595)	mem 44912MB
Train: [165/180][600/625]	eta 0:00:32 lr 0.011989	data 0.0005 (0.0356)	batch 1.2634 (1.3032)	loss -27.5364 (-27.4586)	grad_norm 0.6526 (0.6596)	mem 44912MB
Current slope: None 	
EPOCH 165 training takes 0:13:35
Test: [0/25]	Time 14.712 (14.712)	Loss 1.1686 (1.1686)	Acc@1 73.926 (73.926)	Acc@5 91.309 (91.309)	Mem 44912MB
 * Acc@1 62.270 Acc@5 84.454
Accuracy of the network on the 50000 test images: 62.27%
Max accuracy (after decay): 62.27%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [166/180][0/625]	eta 4:02:16 lr 0.011921	data 21.7174 (21.7174)	batch 23.2588 (23.2588)	loss -27.4352 (-27.4352)	grad_norm 0.6622 (0.6622)	mem 44912MB
Train: [166/180][50/625]	eta 0:16:14 lr 0.011786	data 0.0005 (0.4265)	batch 1.2578 (1.6941)	loss -27.5386 (-27.4380)	grad_norm 0.6693 (0.6604)	mem 44912MB
Train: [166/180][100/625]	eta 0:12:59 lr 0.011652	data 0.0005 (0.2157)	batch 1.2561 (1.4839)	loss -27.5436 (-27.4525)	grad_norm 0.6547 (0.6604)	mem 44912MB
Train: [166/180][150/625]	eta 0:11:09 lr 0.011519	data 0.0004 (0.1444)	batch 1.2535 (1.4091)	loss -27.4376 (-27.4594)	grad_norm 0.6888 (0.6617)	mem 44912MB
Train: [166/180][200/625]	eta 0:09:43 lr 0.011387	data 0.0006 (0.1088)	batch 1.2493 (1.3730)	loss -27.3590 (-27.4578)	grad_norm 0.6669 (0.6614)	mem 44912MB
Train: [166/180][250/625]	eta 0:08:26 lr 0.011255	data 0.0005 (0.0873)	batch 1.2614 (1.3517)	loss -27.4197 (-27.4543)	grad_norm 0.6634 (0.6612)	mem 44912MB
Train: [166/180][300/625]	eta 0:07:14 lr 0.011124	data 0.0004 (0.0729)	batch 1.2668 (1.3383)	loss -27.6616 (-27.4582)	grad_norm 0.6736 (0.6615)	mem 44912MB
Train: [166/180][350/625]	eta 0:06:04 lr 0.010994	data 0.0005 (0.0626)	batch 1.2500 (1.3272)	loss -27.4049 (-27.4544)	grad_norm 0.6667 (0.6614)	mem 44912MB
Train: [166/180][400/625]	eta 0:04:56 lr 0.010864	data 0.0005 (0.0549)	batch 1.2637 (1.3196)	loss -27.6465 (-27.4571)	grad_norm 0.6424 (0.6612)	mem 44912MB
Train: [166/180][450/625]	eta 0:03:49 lr 0.010736	data 0.0005 (0.0489)	batch 1.2162 (1.3133)	loss -27.3859 (-27.4596)	grad_norm 0.6587 (0.6612)	mem 44912MB
Train: [166/180][500/625]	eta 0:02:43 lr 0.010608	data 0.0005 (0.0440)	batch 1.2606 (1.3091)	loss -27.4228 (-27.4593)	grad_norm 0.6612 (0.6610)	mem 44912MB
Train: [166/180][550/625]	eta 0:01:37 lr 0.010481	data 0.0005 (0.0401)	batch 1.2577 (1.3047)	loss -27.5881 (-27.4595)	grad_norm 0.6441 (0.6609)	mem 44912MB
Train: [166/180][600/625]	eta 0:00:32 lr 0.010354	data 0.0006 (0.0368)	batch 1.2402 (1.3012)	loss -27.4544 (-27.4566)	grad_norm 0.6602 (0.6611)	mem 44912MB
Current slope: None 	
EPOCH 166 training takes 0:13:33
Test: [0/25]	Time 15.064 (15.064)	Loss 1.1629 (1.1629)	Acc@1 73.535 (73.535)	Acc@5 91.211 (91.211)	Mem 44912MB
 * Acc@1 62.304 Acc@5 84.482
Accuracy of the network on the 50000 test images: 62.30%
Max accuracy (after decay): 62.30%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [167/180][0/625]	eta 4:01:12 lr 0.010291	data 21.5837 (21.5837)	batch 23.1568 (23.1568)	loss -27.4424 (-27.4424)	grad_norm 0.6605 (0.6605)	mem 44912MB
Train: [167/180][50/625]	eta 0:16:17 lr 0.010166	data 0.0006 (0.4237)	batch 1.2657 (1.7001)	loss -27.4951 (-27.4655)	grad_norm 0.6447 (0.6596)	mem 44912MB
Train: [167/180][100/625]	eta 0:13:01 lr 0.010042	data 0.0006 (0.2142)	batch 1.2581 (1.4877)	loss -27.5566 (-27.4564)	grad_norm 0.6353 (0.6605)	mem 44912MB
Train: [167/180][150/625]	eta 0:11:11 lr 0.009918	data 0.0005 (0.1435)	batch 1.2886 (1.4137)	loss -27.6308 (-27.4542)	grad_norm 0.6599 (0.6604)	mem 44912MB
Train: [167/180][200/625]	eta 0:09:45 lr 0.009795	data 0.0004 (0.1079)	batch 1.2789 (1.3781)	loss -27.3609 (-27.4574)	grad_norm 0.6627 (0.6618)	mem 44912MB
Train: [167/180][250/625]	eta 0:08:28 lr 0.009673	data 0.0005 (0.0865)	batch 1.2450 (1.3558)	loss -27.3160 (-27.4558)	grad_norm 0.6669 (0.6622)	mem 44912MB
Train: [167/180][300/625]	eta 0:07:15 lr 0.009551	data 0.0005 (0.0723)	batch 1.2354 (1.3411)	loss -27.6390 (-27.4546)	grad_norm 0.6699 (0.6626)	mem 44912MB
Train: [167/180][350/625]	eta 0:06:05 lr 0.009431	data 0.0005 (0.0620)	batch 1.2769 (1.3299)	loss -27.3621 (-27.4526)	grad_norm 0.6569 (0.6624)	mem 44912MB
Train: [167/180][400/625]	eta 0:04:57 lr 0.009311	data 0.0004 (0.0544)	batch 1.2797 (1.3220)	loss -27.4401 (-27.4544)	grad_norm 0.6602 (0.6625)	mem 44912MB
Train: [167/180][450/625]	eta 0:03:50 lr 0.009192	data 0.0005 (0.0484)	batch 1.2374 (1.3158)	loss -27.4118 (-27.4529)	grad_norm 0.6727 (0.6626)	mem 44912MB
Train: [167/180][500/625]	eta 0:02:43 lr 0.009073	data 0.0005 (0.0436)	batch 1.2361 (1.3104)	loss -27.3461 (-27.4516)	grad_norm 0.6608 (0.6627)	mem 44912MB
Train: [167/180][550/625]	eta 0:01:37 lr 0.008956	data 0.0005 (0.0397)	batch 1.2485 (1.3058)	loss -27.6322 (-27.4505)	grad_norm 0.6705 (0.6627)	mem 44912MB
Train: [167/180][600/625]	eta 0:00:32 lr 0.008839	data 0.0007 (0.0365)	batch 1.2532 (1.3025)	loss -27.2332 (-27.4505)	grad_norm 0.6622 (0.6624)	mem 44912MB
Current slope: None 	
EPOCH 167 training takes 0:13:34
Test: [0/25]	Time 14.684 (14.684)	Loss 1.1677 (1.1677)	Acc@1 73.193 (73.193)	Acc@5 91.406 (91.406)	Mem 44912MB
 * Acc@1 62.346 Acc@5 84.478
Accuracy of the network on the 50000 test images: 62.35%
Max accuracy (after decay): 62.35%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [168/180][0/625]	eta 4:00:34 lr 0.008781	data 21.4852 (21.4852)	batch 23.0945 (23.0945)	loss -27.6009 (-27.6009)	grad_norm 0.6549 (0.6549)	mem 44912MB
Train: [168/180][50/625]	eta 0:16:14 lr 0.008665	data 0.0006 (0.4221)	batch 1.2537 (1.6953)	loss -27.4400 (-27.4698)	grad_norm 0.6618 (0.6628)	mem 44912MB
Train: [168/180][100/625]	eta 0:12:59 lr 0.008550	data 0.0005 (0.2134)	batch 1.2651 (1.4854)	loss -27.6270 (-27.4692)	grad_norm 0.6412 (0.6616)	mem 44912MB
Train: [168/180][150/625]	eta 0:11:12 lr 0.008436	data 0.0009 (0.1429)	batch 1.3454 (1.4150)	loss -27.3635 (-27.4677)	grad_norm 0.6544 (0.6612)	mem 44912MB
Train: [168/180][200/625]	eta 0:09:44 lr 0.008322	data 0.0004 (0.1075)	batch 1.2368 (1.3758)	loss -27.5033 (-27.4663)	grad_norm 0.6617 (0.6615)	mem 44912MB
Train: [168/180][250/625]	eta 0:08:27 lr 0.008209	data 0.0005 (0.0862)	batch 1.3825 (1.3539)	loss -27.4424 (-27.4677)	grad_norm 0.6538 (0.6610)	mem 44912MB
Train: [168/180][300/625]	eta 0:07:14 lr 0.008098	data 0.0004 (0.0720)	batch 1.2369 (1.3381)	loss -27.5464 (-27.4642)	grad_norm 0.6644 (0.6610)	mem 44912MB
Train: [168/180][350/625]	eta 0:06:05 lr 0.007986	data 0.0006 (0.0618)	batch 1.2517 (1.3282)	loss -27.3296 (-27.4626)	grad_norm 0.6844 (0.6613)	mem 44912MB
Train: [168/180][400/625]	eta 0:04:56 lr 0.007876	data 0.0006 (0.0542)	batch 1.2431 (1.3199)	loss -27.6822 (-27.4648)	grad_norm 0.6640 (0.6617)	mem 44912MB
Train: [168/180][450/625]	eta 0:03:50 lr 0.007766	data 0.0008 (0.0482)	batch 1.3390 (1.3143)	loss -27.4753 (-27.4646)	grad_norm 0.6661 (0.6616)	mem 44912MB
Train: [168/180][500/625]	eta 0:02:43 lr 0.007658	data 0.0005 (0.0435)	batch 1.2357 (1.3087)	loss -27.2331 (-27.4623)	grad_norm 0.6682 (0.6619)	mem 44912MB
Train: [168/180][550/625]	eta 0:01:37 lr 0.007549	data 0.0005 (0.0396)	batch 1.2231 (1.3047)	loss -27.4366 (-27.4615)	grad_norm 0.6704 (0.6621)	mem 44912MB
Train: [168/180][600/625]	eta 0:00:32 lr 0.007442	data 0.0009 (0.0363)	batch 1.2396 (1.3012)	loss -27.3015 (-27.4629)	grad_norm 0.6680 (0.6621)	mem 44912MB
Current slope: None 	
EPOCH 168 training takes 0:13:33
Test: [0/25]	Time 14.699 (14.699)	Loss 1.1781 (1.1781)	Acc@1 73.486 (73.486)	Acc@5 91.406 (91.406)	Mem 44912MB
 * Acc@1 62.390 Acc@5 84.512
Accuracy of the network on the 50000 test images: 62.39%
Max accuracy (after decay): 62.39%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [169/180][0/625]	eta 3:58:04 lr 0.007389	data 19.8043 (19.8043)	batch 22.8546 (22.8546)	loss -27.4687 (-27.4687)	grad_norm 0.6599 (0.6599)	mem 44912MB
Train: [169/180][50/625]	eta 0:16:14 lr 0.007283	data 0.0004 (0.3889)	batch 1.2869 (1.6950)	loss -27.3594 (-27.4561)	grad_norm 0.6525 (0.6620)	mem 44912MB
Train: [169/180][100/625]	eta 0:13:00 lr 0.007177	data 0.0005 (0.1967)	batch 1.3001 (1.4864)	loss -27.2506 (-27.4539)	grad_norm 0.6820 (0.6620)	mem 44912MB
Train: [169/180][150/625]	eta 0:11:11 lr 0.007073	data 0.0005 (0.1317)	batch 1.2365 (1.4138)	loss -27.4977 (-27.4564)	grad_norm 0.6601 (0.6618)	mem 44912MB
Train: [169/180][200/625]	eta 0:09:45 lr 0.006969	data 0.0005 (0.0991)	batch 1.2926 (1.3766)	loss -27.2938 (-27.4561)	grad_norm 0.6721 (0.6619)	mem 44912MB
Train: [169/180][250/625]	eta 0:08:28 lr 0.006866	data 0.0003 (0.0795)	batch 1.2534 (1.3560)	loss -27.4374 (-27.4559)	grad_norm 0.6760 (0.6618)	mem 44912MB
Train: [169/180][300/625]	eta 0:07:16 lr 0.006763	data 0.0005 (0.0663)	batch 1.3085 (1.3420)	loss -27.3672 (-27.4577)	grad_norm 0.6746 (0.6618)	mem 44912MB
Train: [169/180][350/625]	eta 0:06:06 lr 0.006662	data 0.0005 (0.0570)	batch 1.2807 (1.3312)	loss -27.6050 (-27.4574)	grad_norm 0.6647 (0.6618)	mem 44912MB
Train: [169/180][400/625]	eta 0:04:57 lr 0.006561	data 0.0005 (0.0499)	batch 1.3113 (1.3227)	loss -27.6272 (-27.4573)	grad_norm 0.6605 (0.6617)	mem 44912MB
Train: [169/180][450/625]	eta 0:03:50 lr 0.006461	data 0.0006 (0.0445)	batch 1.2611 (1.3161)	loss -27.3730 (-27.4601)	grad_norm 0.6674 (0.6615)	mem 44912MB
Train: [169/180][500/625]	eta 0:02:43 lr 0.006361	data 0.0005 (0.0401)	batch 1.2965 (1.3115)	loss -27.4440 (-27.4568)	grad_norm 0.6430 (0.6616)	mem 44912MB
Train: [169/180][550/625]	eta 0:01:38 lr 0.006263	data 0.0005 (0.0365)	batch 1.2642 (1.3067)	loss -27.4537 (-27.4572)	grad_norm 0.6485 (0.6615)	mem 44912MB
Train: [169/180][600/625]	eta 0:00:32 lr 0.006165	data 0.0005 (0.0335)	batch 1.3022 (1.3029)	loss -27.7127 (-27.4591)	grad_norm 0.6593 (0.6616)	mem 44912MB
Current slope: None 	
EPOCH 169 training takes 0:13:34
Test: [0/25]	Time 14.772 (14.772)	Loss 1.1734 (1.1734)	Acc@1 73.633 (73.633)	Acc@5 90.771 (90.771)	Mem 44912MB
 * Acc@1 62.324 Acc@5 84.530
Accuracy of the network on the 50000 test images: 62.32%
Max accuracy (after decay): 62.39%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [170/180][0/625]	eta 4:02:12 lr 0.006117	data 21.5837 (21.5837)	batch 23.2522 (23.2522)	loss -27.4469 (-27.4469)	grad_norm 0.6758 (0.6758)	mem 44912MB
Train: [170/180][50/625]	eta 0:16:19 lr 0.006020	data 0.0006 (0.4239)	batch 1.2561 (1.7036)	loss -27.4772 (-27.4808)	grad_norm 0.6501 (0.6619)	mem 44912MB
Train: [170/180][100/625]	eta 0:13:02 lr 0.005924	data 0.0011 (0.2143)	batch 1.2982 (1.4901)	loss -27.5376 (-27.4703)	grad_norm 0.6634 (0.6627)	mem 44912MB
Train: [170/180][150/625]	eta 0:11:12 lr 0.005829	data 0.0005 (0.1435)	batch 1.2379 (1.4160)	loss -27.4624 (-27.4642)	grad_norm 0.6691 (0.6632)	mem 44912MB
Train: [170/180][200/625]	eta 0:09:45 lr 0.005735	data 0.0006 (0.1080)	batch 1.2424 (1.3776)	loss -27.5077 (-27.4591)	grad_norm 0.6600 (0.6632)	mem 44912MB
Train: [170/180][250/625]	eta 0:08:28 lr 0.005641	data 0.0007 (0.0866)	batch 1.2931 (1.3568)	loss -27.5094 (-27.4616)	grad_norm 0.6579 (0.6626)	mem 44912MB
Train: [170/180][300/625]	eta 0:07:16 lr 0.005549	data 0.0005 (0.0723)	batch 1.2586 (1.3422)	loss -27.3098 (-27.4604)	grad_norm 0.6532 (0.6623)	mem 44912MB
Train: [170/180][350/625]	eta 0:06:06 lr 0.005457	data 0.0005 (0.0621)	batch 1.2821 (1.3313)	loss -27.5253 (-27.4603)	grad_norm 0.6551 (0.6623)	mem 44912MB
Train: [170/180][400/625]	eta 0:04:57 lr 0.005365	data 0.0005 (0.0544)	batch 1.2544 (1.3231)	loss -27.5095 (-27.4597)	grad_norm 0.6650 (0.6625)	mem 44912MB
Train: [170/180][450/625]	eta 0:03:50 lr 0.005275	data 0.0005 (0.0484)	batch 1.2486 (1.3170)	loss -27.5627 (-27.4600)	grad_norm 0.6461 (0.6624)	mem 44912MB
Train: [170/180][500/625]	eta 0:02:44 lr 0.005185	data 0.0005 (0.0437)	batch 1.2898 (1.3124)	loss -27.6519 (-27.4603)	grad_norm 0.6610 (0.6623)	mem 44912MB
Train: [170/180][550/625]	eta 0:01:38 lr 0.005096	data 0.0005 (0.0397)	batch 1.2472 (1.3078)	loss -27.6266 (-27.4592)	grad_norm 0.6609 (0.6624)	mem 44912MB
Train: [170/180][600/625]	eta 0:00:32 lr 0.005008	data 0.0006 (0.0365)	batch 1.2761 (1.3045)	loss -27.4233 (-27.4581)	grad_norm 0.6790 (0.6626)	mem 44912MB
Current slope: None 	
EPOCH 170 training takes 0:13:35
Test: [0/25]	Time 14.819 (14.819)	Loss 1.1663 (1.1663)	Acc@1 73.633 (73.633)	Acc@5 91.211 (91.211)	Mem 44912MB
 * Acc@1 62.346 Acc@5 84.498
Accuracy of the network on the 50000 test images: 62.35%
Max accuracy (after decay): 62.39%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [171/180][0/625]	eta 3:59:53 lr 0.004964	data 19.3936 (19.3936)	batch 23.0297 (23.0297)	loss -27.3116 (-27.3116)	grad_norm 0.6444 (0.6444)	mem 44912MB
Train: [171/180][50/625]	eta 0:16:20 lr 0.004877	data 0.0006 (0.3809)	batch 1.2558 (1.7053)	loss -27.5810 (-27.4621)	grad_norm 0.6632 (0.6619)	mem 44912MB
Train: [171/180][100/625]	eta 0:13:00 lr 0.004791	data 0.0005 (0.1926)	batch 1.2612 (1.4875)	loss -27.5818 (-27.4702)	grad_norm 0.6411 (0.6632)	mem 44912MB
Train: [171/180][150/625]	eta 0:11:12 lr 0.004706	data 0.0007 (0.1290)	batch 1.2757 (1.4153)	loss -27.5025 (-27.4712)	grad_norm 0.6650 (0.6633)	mem 44912MB
Train: [171/180][200/625]	eta 0:09:45 lr 0.004621	data 0.0005 (0.0971)	batch 1.2121 (1.3767)	loss -27.4126 (-27.4715)	grad_norm 0.6710 (0.6626)	mem 44912MB
Train: [171/180][250/625]	eta 0:08:28 lr 0.004537	data 0.0005 (0.0778)	batch 1.2601 (1.3567)	loss -27.3787 (-27.4663)	grad_norm 0.6473 (0.6624)	mem 44912MB
Train: [171/180][300/625]	eta 0:07:16 lr 0.004454	data 0.0005 (0.0650)	batch 1.2082 (1.3417)	loss -27.4313 (-27.4647)	grad_norm 0.6634 (0.6627)	mem 44912MB
Train: [171/180][350/625]	eta 0:06:06 lr 0.004372	data 0.0007 (0.0560)	batch 1.2144 (1.3309)	loss -27.3069 (-27.4631)	grad_norm 0.6722 (0.6630)	mem 44912MB
Train: [171/180][400/625]	eta 0:04:57 lr 0.004290	data 0.0007 (0.0490)	batch 1.3684 (1.3226)	loss -27.6379 (-27.4648)	grad_norm 0.6493 (0.6630)	mem 44912MB
Train: [171/180][450/625]	eta 0:03:50 lr 0.004209	data 0.0005 (0.0437)	batch 1.3129 (1.3174)	loss -27.5273 (-27.4627)	grad_norm 0.6687 (0.6631)	mem 44912MB
Train: [171/180][500/625]	eta 0:02:43 lr 0.004129	data 0.0005 (0.0394)	batch 1.2455 (1.3115)	loss -27.4811 (-27.4603)	grad_norm 0.6567 (0.6632)	mem 44912MB
Train: [171/180][550/625]	eta 0:01:38 lr 0.004050	data 0.0006 (0.0358)	batch 1.2442 (1.3072)	loss -27.4166 (-27.4626)	grad_norm 0.6900 (0.6632)	mem 44912MB
Train: [171/180][600/625]	eta 0:00:32 lr 0.003972	data 0.0008 (0.0330)	batch 1.1978 (1.3040)	loss -27.4755 (-27.4613)	grad_norm 0.6508 (0.6630)	mem 44912MB
Current slope: None 	
EPOCH 171 training takes 0:13:35
Test: [0/25]	Time 14.967 (14.967)	Loss 1.1714 (1.1714)	Acc@1 73.730 (73.730)	Acc@5 91.113 (91.113)	Mem 44912MB
 * Acc@1 62.398 Acc@5 84.520
Accuracy of the network on the 50000 test images: 62.40%
Max accuracy (after decay): 62.40%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [172/180][0/625]	eta 4:04:50 lr 0.003933	data 22.0808 (22.0808)	batch 23.5042 (23.5042)	loss -27.5390 (-27.5390)	grad_norm 0.6557 (0.6557)	mem 44912MB
Train: [172/180][50/625]	eta 0:16:20 lr 0.003855	data 0.0005 (0.4335)	batch 1.2577 (1.7057)	loss -27.4297 (-27.4559)	grad_norm 0.6697 (0.6606)	mem 44912MB
Train: [172/180][100/625]	eta 0:13:01 lr 0.003779	data 0.0004 (0.2192)	batch 1.2549 (1.4881)	loss -27.6112 (-27.4603)	grad_norm 0.6610 (0.6609)	mem 44912MB
Train: [172/180][150/625]	eta 0:11:12 lr 0.003703	data 0.0005 (0.1468)	batch 1.2449 (1.4162)	loss -27.6040 (-27.4530)	grad_norm 0.6588 (0.6620)	mem 44912MB
Train: [172/180][200/625]	eta 0:09:45 lr 0.003628	data 0.0022 (0.1104)	batch 1.2487 (1.3774)	loss -27.4476 (-27.4564)	grad_norm 0.6459 (0.6622)	mem 44912MB
Train: [172/180][250/625]	eta 0:08:28 lr 0.003554	data 0.0005 (0.0885)	batch 1.3046 (1.3550)	loss -27.4804 (-27.4607)	grad_norm 0.6635 (0.6622)	mem 44912MB
Train: [172/180][300/625]	eta 0:07:15 lr 0.003480	data 0.0005 (0.0739)	batch 1.2672 (1.3404)	loss -27.4462 (-27.4607)	grad_norm 0.6577 (0.6619)	mem 44912MB
Train: [172/180][350/625]	eta 0:06:05 lr 0.003407	data 0.0005 (0.0635)	batch 1.2307 (1.3295)	loss -27.2770 (-27.4608)	grad_norm 0.6675 (0.6622)	mem 44912MB
Train: [172/180][400/625]	eta 0:04:57 lr 0.003336	data 0.0005 (0.0556)	batch 1.2608 (1.3212)	loss -27.6402 (-27.4639)	grad_norm 0.6600 (0.6625)	mem 44912MB
Train: [172/180][450/625]	eta 0:03:50 lr 0.003264	data 0.0004 (0.0495)	batch 1.2521 (1.3152)	loss -27.4467 (-27.4658)	grad_norm 0.6525 (0.6624)	mem 44912MB
Train: [172/180][500/625]	eta 0:02:43 lr 0.003194	data 0.0005 (0.0446)	batch 1.4836 (1.3111)	loss -27.4473 (-27.4667)	grad_norm 0.6521 (0.6625)	mem 44912MB
Train: [172/180][550/625]	eta 0:01:38 lr 0.003124	data 0.0005 (0.0406)	batch 1.2285 (1.3068)	loss -27.4850 (-27.4657)	grad_norm 0.6540 (0.6625)	mem 44912MB
Train: [172/180][600/625]	eta 0:00:32 lr 0.003056	data 0.0005 (0.0373)	batch 1.2431 (1.3033)	loss -27.4598 (-27.4658)	grad_norm 0.6653 (0.6622)	mem 44912MB
Current slope: None 	
EPOCH 172 training takes 0:13:35
Test: [0/25]	Time 14.998 (14.998)	Loss 1.1684 (1.1684)	Acc@1 73.535 (73.535)	Acc@5 91.016 (91.016)	Mem 44912MB
 * Acc@1 62.388 Acc@5 84.542
Accuracy of the network on the 50000 test images: 62.39%
Max accuracy (after decay): 62.40%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [173/180][0/625]	eta 4:02:38 lr 0.003021	data 20.4643 (20.4643)	batch 23.2933 (23.2933)	loss -27.6348 (-27.6348)	grad_norm 0.6727 (0.6727)	mem 44912MB
Train: [173/180][50/625]	eta 0:16:16 lr 0.002954	data 0.0006 (0.4023)	batch 1.4054 (1.6988)	loss -27.5212 (-27.4707)	grad_norm 0.6656 (0.6624)	mem 44912MB
Train: [173/180][100/625]	eta 0:12:59 lr 0.002887	data 0.0004 (0.2034)	batch 1.2492 (1.4847)	loss -27.4256 (-27.4615)	grad_norm 0.6472 (0.6643)	mem 44912MB
Train: [173/180][150/625]	eta 0:11:10 lr 0.002821	data 0.0004 (0.1362)	batch 1.2617 (1.4116)	loss -27.4842 (-27.4566)	grad_norm 0.6648 (0.6639)	mem 44912MB
Train: [173/180][200/625]	eta 0:09:43 lr 0.002755	data 0.0005 (0.1025)	batch 1.2577 (1.3739)	loss -27.3720 (-27.4634)	grad_norm 0.6563 (0.6645)	mem 44912MB
Train: [173/180][250/625]	eta 0:08:26 lr 0.002691	data 0.0006 (0.0822)	batch 1.2475 (1.3519)	loss -27.5635 (-27.4684)	grad_norm 0.6543 (0.6640)	mem 44912MB
Train: [173/180][300/625]	eta 0:07:14 lr 0.002627	data 0.0006 (0.0686)	batch 1.2750 (1.3379)	loss -27.5924 (-27.4682)	grad_norm 0.6705 (0.6640)	mem 44912MB
Train: [173/180][350/625]	eta 0:06:04 lr 0.002564	data 0.0005 (0.0591)	batch 1.2605 (1.3272)	loss -27.3391 (-27.4714)	grad_norm 0.6561 (0.6637)	mem 44912MB
Train: [173/180][400/625]	eta 0:04:56 lr 0.002502	data 0.0005 (0.0518)	batch 1.2616 (1.3192)	loss -27.4072 (-27.4700)	grad_norm 0.6525 (0.6637)	mem 44912MB
Train: [173/180][450/625]	eta 0:03:49 lr 0.002440	data 0.0005 (0.0461)	batch 1.2703 (1.3128)	loss -27.4738 (-27.4672)	grad_norm 0.6588 (0.6639)	mem 44912MB
Train: [173/180][500/625]	eta 0:02:43 lr 0.002379	data 0.0003 (0.0415)	batch 1.2840 (1.3078)	loss -27.3919 (-27.4647)	grad_norm 0.6731 (0.6638)	mem 44912MB
Train: [173/180][550/625]	eta 0:01:37 lr 0.002320	data 0.0007 (0.0378)	batch 1.2962 (1.3037)	loss -27.4070 (-27.4639)	grad_norm 0.6702 (0.6637)	mem 44912MB
Train: [173/180][600/625]	eta 0:00:32 lr 0.002260	data 0.0005 (0.0347)	batch 1.2567 (1.3006)	loss -27.5420 (-27.4631)	grad_norm 0.6864 (0.6640)	mem 44912MB
Current slope: None 	
EPOCH 173 training takes 0:13:33
Test: [0/25]	Time 14.827 (14.827)	Loss 1.1668 (1.1668)	Acc@1 73.242 (73.242)	Acc@5 91.162 (91.162)	Mem 44912MB
 * Acc@1 62.346 Acc@5 84.508
Accuracy of the network on the 50000 test images: 62.35%
Max accuracy (after decay): 62.40%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [174/180][0/625]	eta 3:56:52 lr 0.002231	data 20.6149 (20.6149)	batch 22.7403 (22.7403)	loss -27.4758 (-27.4758)	grad_norm 0.6797 (0.6797)	mem 44912MB
Train: [174/180][50/625]	eta 0:16:15 lr 0.002173	data 0.0006 (0.4049)	batch 1.2225 (1.6970)	loss -27.5111 (-27.4983)	grad_norm 0.6643 (0.6634)	mem 44912MB
Train: [174/180][100/625]	eta 0:12:58 lr 0.002116	data 0.0005 (0.2048)	batch 1.2563 (1.4822)	loss -27.5577 (-27.4828)	grad_norm 0.6591 (0.6630)	mem 44912MB
Train: [174/180][150/625]	eta 0:11:09 lr 0.002059	data 0.0006 (0.1372)	batch 1.3138 (1.4095)	loss -27.4303 (-27.4744)	grad_norm 0.6886 (0.6627)	mem 44912MB
Train: [174/180][200/625]	eta 0:09:45 lr 0.002004	data 0.0008 (0.1032)	batch 1.3869 (1.3778)	loss -27.2544 (-27.4747)	grad_norm 0.6567 (0.6629)	mem 44912MB
Train: [174/180][250/625]	eta 0:08:28 lr 0.001949	data 0.0006 (0.0827)	batch 1.2844 (1.3572)	loss -27.5456 (-27.4686)	grad_norm 0.6527 (0.6631)	mem 44912MB
Train: [174/180][300/625]	eta 0:07:15 lr 0.001895	data 0.0006 (0.0691)	batch 1.2981 (1.3415)	loss -27.2528 (-27.4648)	grad_norm 0.6633 (0.6633)	mem 44912MB
Train: [174/180][350/625]	eta 0:06:05 lr 0.001842	data 0.0006 (0.0593)	batch 1.2387 (1.3299)	loss -27.5270 (-27.4641)	grad_norm 0.6503 (0.6631)	mem 44912MB
Train: [174/180][400/625]	eta 0:04:57 lr 0.001789	data 0.0005 (0.0520)	batch 1.2156 (1.3221)	loss -27.3985 (-27.4633)	grad_norm 0.6713 (0.6632)	mem 44912MB
Train: [174/180][450/625]	eta 0:03:50 lr 0.001737	data 0.0005 (0.0463)	batch 1.2798 (1.3168)	loss -27.3791 (-27.4599)	grad_norm 0.6677 (0.6630)	mem 44912MB
Train: [174/180][500/625]	eta 0:02:43 lr 0.001686	data 0.0007 (0.0417)	batch 1.2662 (1.3112)	loss -27.5678 (-27.4609)	grad_norm 0.6772 (0.6630)	mem 44912MB
Train: [174/180][550/625]	eta 0:01:37 lr 0.001636	data 0.0006 (0.0380)	batch 1.2681 (1.3065)	loss -27.4388 (-27.4608)	grad_norm 0.6726 (0.6630)	mem 44912MB
Train: [174/180][600/625]	eta 0:00:32 lr 0.001586	data 0.0005 (0.0349)	batch 1.2292 (1.3035)	loss -27.5066 (-27.4596)	grad_norm 0.6686 (0.6629)	mem 44912MB
Current slope: None 	
EPOCH 174 training takes 0:13:35
Test: [0/25]	Time 14.735 (14.735)	Loss 1.1690 (1.1690)	Acc@1 73.535 (73.535)	Acc@5 91.406 (91.406)	Mem 44912MB
 * Acc@1 62.410 Acc@5 84.488
Accuracy of the network on the 50000 test images: 62.41%
Max accuracy (after decay): 62.41%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [175/180][0/625]	eta 4:01:20 lr 0.001562	data 20.7305 (20.7305)	batch 23.1689 (23.1689)	loss -27.5461 (-27.5461)	grad_norm 0.6588 (0.6588)	mem 44912MB
Train: [175/180][50/625]	eta 0:16:13 lr 0.001514	data 0.0005 (0.4083)	batch 1.2190 (1.6925)	loss -27.5698 (-27.4545)	grad_norm 0.6627 (0.6626)	mem 44912MB
Train: [175/180][100/625]	eta 0:12:58 lr 0.001466	data 0.0004 (0.2064)	batch 1.3002 (1.4819)	loss -27.5181 (-27.4755)	grad_norm 0.6669 (0.6625)	mem 44912MB
Train: [175/180][150/625]	eta 0:11:09 lr 0.001420	data 0.0005 (0.1383)	batch 1.3899 (1.4103)	loss -27.6016 (-27.4682)	grad_norm 0.6583 (0.6626)	mem 44912MB
Train: [175/180][200/625]	eta 0:09:43 lr 0.001374	data 0.0005 (0.1040)	batch 1.2712 (1.3730)	loss -27.4585 (-27.4665)	grad_norm 0.7020 (0.6631)	mem 44912MB
Train: [175/180][250/625]	eta 0:08:26 lr 0.001328	data 0.0009 (0.0834)	batch 1.2646 (1.3514)	loss -27.3971 (-27.4706)	grad_norm 0.6639 (0.6630)	mem 44912MB
Train: [175/180][300/625]	eta 0:07:14 lr 0.001284	data 0.0005 (0.0697)	batch 1.2917 (1.3369)	loss -27.7026 (-27.4694)	grad_norm 0.6551 (0.6633)	mem 44912MB
Train: [175/180][350/625]	eta 0:06:04 lr 0.001240	data 0.0005 (0.0598)	batch 1.3116 (1.3266)	loss -27.4297 (-27.4683)	grad_norm 0.6740 (0.6632)	mem 44912MB
Train: [175/180][400/625]	eta 0:04:56 lr 0.001198	data 0.0006 (0.0524)	batch 1.2952 (1.3179)	loss -27.5217 (-27.4665)	grad_norm 0.6561 (0.6633)	mem 44912MB
Train: [175/180][450/625]	eta 0:03:49 lr 0.001155	data 0.0005 (0.0467)	batch 1.3176 (1.3116)	loss -27.5020 (-27.4643)	grad_norm 0.6697 (0.6635)	mem 44912MB
Train: [175/180][500/625]	eta 0:02:43 lr 0.001114	data 0.0006 (0.0421)	batch 1.1984 (1.3069)	loss -27.3075 (-27.4669)	grad_norm 0.6777 (0.6633)	mem 44912MB
Train: [175/180][550/625]	eta 0:01:37 lr 0.001074	data 0.0005 (0.0383)	batch 1.2254 (1.3025)	loss -27.4379 (-27.4664)	grad_norm 0.6445 (0.6632)	mem 44912MB
Train: [175/180][600/625]	eta 0:00:32 lr 0.001034	data 0.0005 (0.0352)	batch 1.2679 (1.2987)	loss -27.5078 (-27.4675)	grad_norm 0.6627 (0.6632)	mem 44912MB
Current slope: None 	
EPOCH 175 training takes 0:13:32
Test: [0/25]	Time 14.949 (14.949)	Loss 1.1695 (1.1695)	Acc@1 73.438 (73.438)	Acc@5 91.211 (91.211)	Mem 44912MB
 * Acc@1 62.410 Acc@5 84.496
Accuracy of the network on the 50000 test images: 62.41%
Max accuracy (after decay): 62.41%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [176/180][0/625]	eta 4:02:01 lr 0.001014	data 20.9086 (20.9086)	batch 23.2344 (23.2344)	loss -27.6862 (-27.6862)	grad_norm 0.6596 (0.6596)	mem 44912MB
Train: [176/180][50/625]	eta 0:16:18 lr 0.000976	data 0.0005 (0.4106)	batch 1.2787 (1.7009)	loss -27.4401 (-27.4763)	grad_norm 0.6634 (0.6616)	mem 44912MB
Train: [176/180][100/625]	eta 0:12:59 lr 0.000938	data 0.0006 (0.2076)	batch 1.3075 (1.4850)	loss -27.4180 (-27.4724)	grad_norm 0.6693 (0.6641)	mem 44912MB
Train: [176/180][150/625]	eta 0:11:11 lr 0.000901	data 0.0006 (0.1391)	batch 1.2789 (1.4141)	loss -27.5026 (-27.4758)	grad_norm 0.6642 (0.6637)	mem 44912MB
Train: [176/180][200/625]	eta 0:09:46 lr 0.000865	data 0.0007 (0.1046)	batch 1.2053 (1.3788)	loss -27.3728 (-27.4784)	grad_norm 0.6503 (0.6633)	mem 44912MB
Train: [176/180][250/625]	eta 0:08:28 lr 0.000829	data 0.0005 (0.0839)	batch 1.2092 (1.3559)	loss -27.5958 (-27.4771)	grad_norm 0.6623 (0.6630)	mem 44912MB
Train: [176/180][300/625]	eta 0:07:15 lr 0.000795	data 0.0005 (0.0700)	batch 1.2917 (1.3410)	loss -27.3591 (-27.4773)	grad_norm 0.6634 (0.6625)	mem 44912MB
Train: [176/180][350/625]	eta 0:06:05 lr 0.000761	data 0.0005 (0.0601)	batch 1.2453 (1.3299)	loss -27.3239 (-27.4744)	grad_norm 0.6643 (0.6625)	mem 44912MB
Train: [176/180][400/625]	eta 0:04:57 lr 0.000728	data 0.0006 (0.0527)	batch 1.2378 (1.3223)	loss -27.4256 (-27.4745)	grad_norm 0.6493 (0.6622)	mem 44912MB
Train: [176/180][450/625]	eta 0:03:50 lr 0.000695	data 0.0005 (0.0469)	batch 1.2588 (1.3152)	loss -27.4695 (-27.4717)	grad_norm 0.6525 (0.6625)	mem 44912MB
Train: [176/180][500/625]	eta 0:02:43 lr 0.000664	data 0.0004 (0.0423)	batch 1.2664 (1.3103)	loss -27.5294 (-27.4733)	grad_norm 0.6660 (0.6625)	mem 44912MB
Train: [176/180][550/625]	eta 0:01:37 lr 0.000633	data 0.0006 (0.0385)	batch 1.2221 (1.3058)	loss -27.3954 (-27.4727)	grad_norm 0.6640 (0.6626)	mem 44912MB
Train: [176/180][600/625]	eta 0:00:32 lr 0.000603	data 0.0006 (0.0353)	batch 1.2160 (1.3026)	loss -27.4425 (-27.4728)	grad_norm 0.6612 (0.6626)	mem 44912MB
Current slope: None 	
EPOCH 176 training takes 0:13:34
Test: [0/25]	Time 14.495 (14.495)	Loss 1.1679 (1.1679)	Acc@1 73.828 (73.828)	Acc@5 91.064 (91.064)	Mem 44912MB
 * Acc@1 62.458 Acc@5 84.512
Accuracy of the network on the 50000 test images: 62.46%
Max accuracy (after decay): 62.46%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [177/180][0/625]	eta 4:00:19 lr 0.000588	data 20.1913 (20.1913)	batch 23.0710 (23.0710)	loss -27.5918 (-27.5918)	grad_norm 0.6506 (0.6506)	mem 44912MB
Train: [177/180][50/625]	eta 0:16:16 lr 0.000559	data 0.0005 (0.3965)	batch 1.2610 (1.6983)	loss -27.5157 (-27.4542)	grad_norm 0.6571 (0.6638)	mem 44912MB
Train: [177/180][100/625]	eta 0:12:59 lr 0.000531	data 0.0005 (0.2005)	batch 1.2410 (1.4851)	loss -27.4828 (-27.4631)	grad_norm 0.6575 (0.6638)	mem 44912MB
Train: [177/180][150/625]	eta 0:11:10 lr 0.000504	data 0.0006 (0.1345)	batch 1.2601 (1.4112)	loss -27.3259 (-27.4656)	grad_norm 0.6776 (0.6638)	mem 44912MB
Train: [177/180][200/625]	eta 0:09:45 lr 0.000477	data 0.0005 (0.1012)	batch 1.2635 (1.3766)	loss -27.5617 (-27.4657)	grad_norm 0.6630 (0.6629)	mem 44912MB
Train: [177/180][250/625]	eta 0:08:28 lr 0.000452	data 0.0005 (0.0813)	batch 1.2389 (1.3552)	loss -27.2656 (-27.4657)	grad_norm 0.6483 (0.6631)	mem 44912MB
Train: [177/180][300/625]	eta 0:07:16 lr 0.000427	data 0.0005 (0.0679)	batch 1.2571 (1.3417)	loss -27.6117 (-27.4695)	grad_norm 0.6672 (0.6631)	mem 44912MB
Train: [177/180][350/625]	eta 0:06:05 lr 0.000403	data 0.0005 (0.0583)	batch 1.2534 (1.3309)	loss -27.2402 (-27.4664)	grad_norm 0.6589 (0.6633)	mem 44912MB
Train: [177/180][400/625]	eta 0:04:57 lr 0.000379	data 0.0008 (0.0511)	batch 1.2552 (1.3235)	loss -27.2738 (-27.4705)	grad_norm 0.6591 (0.6632)	mem 44912MB
Train: [177/180][450/625]	eta 0:03:50 lr 0.000357	data 0.0005 (0.0455)	batch 1.2805 (1.3175)	loss -27.5707 (-27.4728)	grad_norm 0.6679 (0.6631)	mem 44912MB
Train: [177/180][500/625]	eta 0:02:44 lr 0.000335	data 0.0006 (0.0410)	batch 1.2581 (1.3124)	loss -27.5605 (-27.4746)	grad_norm 0.6754 (0.6629)	mem 44912MB
Train: [177/180][550/625]	eta 0:01:38 lr 0.000314	data 0.0006 (0.0373)	batch 1.2421 (1.3077)	loss -27.3419 (-27.4730)	grad_norm 0.6727 (0.6631)	mem 44912MB
Train: [177/180][600/625]	eta 0:00:32 lr 0.000293	data 0.0005 (0.0343)	batch 1.3027 (1.3036)	loss -27.4891 (-27.4744)	grad_norm 0.6681 (0.6632)	mem 44912MB
Current slope: None 	
EPOCH 177 training takes 0:13:35
Test: [0/25]	Time 14.813 (14.813)	Loss 1.1675 (1.1675)	Acc@1 73.682 (73.682)	Acc@5 91.211 (91.211)	Mem 44912MB
 * Acc@1 62.440 Acc@5 84.564
Accuracy of the network on the 50000 test images: 62.44%
Max accuracy (after decay): 62.46%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [178/180][0/625]	eta 4:02:12 lr 0.000284	data 21.9133 (21.9133)	batch 23.2526 (23.2526)	loss -27.3538 (-27.3538)	grad_norm 0.6815 (0.6815)	mem 44912MB
Train: [178/180][50/625]	eta 0:16:20 lr 0.000265	data 0.0004 (0.4302)	batch 1.2736 (1.7048)	loss -27.2210 (-27.4427)	grad_norm 0.6887 (0.6650)	mem 44912MB
Train: [178/180][100/625]	eta 0:13:00 lr 0.000246	data 0.0005 (0.2175)	batch 1.2624 (1.4861)	loss -27.5898 (-27.4532)	grad_norm 0.6450 (0.6631)	mem 44912MB
Train: [178/180][150/625]	eta 0:11:11 lr 0.000229	data 0.0007 (0.1457)	batch 1.2501 (1.4138)	loss -27.3549 (-27.4582)	grad_norm 0.6714 (0.6622)	mem 44912MB
Train: [178/180][200/625]	eta 0:09:45 lr 0.000212	data 0.0005 (0.1096)	batch 1.3199 (1.3780)	loss -27.5232 (-27.4582)	grad_norm 0.6654 (0.6621)	mem 44912MB
Train: [178/180][250/625]	eta 0:08:28 lr 0.000196	data 0.0005 (0.0879)	batch 1.2295 (1.3565)	loss -27.5121 (-27.4595)	grad_norm 0.6665 (0.6626)	mem 44912MB
Train: [178/180][300/625]	eta 0:07:15 lr 0.000181	data 0.0005 (0.0734)	batch 1.2545 (1.3413)	loss -27.5570 (-27.4560)	grad_norm 0.6647 (0.6625)	mem 44912MB
Train: [178/180][350/625]	eta 0:06:05 lr 0.000166	data 0.0007 (0.0630)	batch 1.3046 (1.3306)	loss -27.3079 (-27.4580)	grad_norm 0.6529 (0.6625)	mem 44912MB
Train: [178/180][400/625]	eta 0:04:57 lr 0.000153	data 0.0007 (0.0552)	batch 1.2671 (1.3227)	loss -27.3849 (-27.4588)	grad_norm 0.6649 (0.6627)	mem 44912MB
Train: [178/180][450/625]	eta 0:03:50 lr 0.000140	data 0.0004 (0.0491)	batch 1.2620 (1.3167)	loss -27.4196 (-27.4598)	grad_norm 0.6608 (0.6625)	mem 44912MB
Train: [178/180][500/625]	eta 0:02:43 lr 0.000128	data 0.0005 (0.0443)	batch 1.2333 (1.3115)	loss -27.4628 (-27.4615)	grad_norm 0.6561 (0.6624)	mem 44912MB
Train: [178/180][550/625]	eta 0:01:38 lr 0.000116	data 0.0005 (0.0403)	batch 1.4939 (1.3076)	loss -27.4934 (-27.4623)	grad_norm 0.6608 (0.6622)	mem 44912MB
Train: [178/180][600/625]	eta 0:00:32 lr 0.000106	data 0.0005 (0.0370)	batch 1.2697 (1.3045)	loss -27.5286 (-27.4631)	grad_norm 0.6647 (0.6623)	mem 44912MB
Current slope: None 	
EPOCH 178 training takes 0:13:35
Test: [0/25]	Time 14.938 (14.938)	Loss 1.1626 (1.1626)	Acc@1 73.682 (73.682)	Acc@5 91.260 (91.260)	Mem 44912MB
 * Acc@1 62.472 Acc@5 84.538
Accuracy of the network on the 50000 test images: 62.47%
Max accuracy (after decay): 62.47%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [179/180][0/625]	eta 3:57:27 lr 0.000101	data 20.5121 (20.5121)	batch 22.7956 (22.7956)	loss -27.4908 (-27.4908)	grad_norm 0.6591 (0.6591)	mem 44912MB
Train: [179/180][50/625]	eta 0:16:13 lr 0.000092	data 0.0005 (0.4030)	batch 1.2823 (1.6931)	loss -27.4947 (-27.4604)	grad_norm 0.6555 (0.6651)	mem 44912MB
Train: [179/180][100/625]	eta 0:12:57 lr 0.000083	data 0.0006 (0.2038)	batch 1.2453 (1.4815)	loss -27.1226 (-27.4663)	grad_norm 0.6686 (0.6631)	mem 44912MB
Train: [179/180][150/625]	eta 0:11:10 lr 0.000075	data 0.0007 (0.1365)	batch 1.2741 (1.4120)	loss -27.3600 (-27.4575)	grad_norm 0.6678 (0.6630)	mem 44912MB
Train: [179/180][200/625]	eta 0:09:44 lr 0.000068	data 0.0006 (0.1027)	batch 1.2849 (1.3755)	loss -27.3269 (-27.4604)	grad_norm 0.6482 (0.6621)	mem 44912MB
Train: [179/180][250/625]	eta 0:08:28 lr 0.000062	data 0.0005 (0.0823)	batch 1.4223 (1.3549)	loss -27.5385 (-27.4613)	grad_norm 0.6612 (0.6621)	mem 44912MB
Train: [179/180][300/625]	eta 0:07:15 lr 0.000056	data 0.0006 (0.0688)	batch 1.2656 (1.3403)	loss -27.6346 (-27.4642)	grad_norm 0.6554 (0.6620)	mem 44912MB
Train: [179/180][350/625]	eta 0:06:05 lr 0.000052	data 0.0006 (0.0591)	batch 1.2764 (1.3305)	loss -27.3186 (-27.4598)	grad_norm 0.6633 (0.6624)	mem 44912MB
Train: [179/180][400/625]	eta 0:04:57 lr 0.000048	data 0.0006 (0.0518)	batch 1.2376 (1.3223)	loss -27.6482 (-27.4626)	grad_norm 0.6422 (0.6624)	mem 44912MB
Train: [179/180][450/625]	eta 0:03:50 lr 0.000045	data 0.0005 (0.0461)	batch 1.2967 (1.3166)	loss -27.5450 (-27.4640)	grad_norm 0.6662 (0.6625)	mem 44912MB
Train: [179/180][500/625]	eta 0:02:43 lr 0.000042	data 0.0006 (0.0416)	batch 1.2535 (1.3111)	loss -27.6073 (-27.4658)	grad_norm 0.6652 (0.6625)	mem 44912MB
Train: [179/180][550/625]	eta 0:01:38 lr 0.000041	data 0.0006 (0.0378)	batch 1.2241 (1.3076)	loss -27.4090 (-27.4657)	grad_norm 0.6712 (0.6628)	mem 44912MB
Train: [179/180][600/625]	eta 0:00:32 lr 0.000040	data 0.0006 (0.0347)	batch 1.2393 (1.3040)	loss -27.4927 (-27.4652)	grad_norm 0.6615 (0.6627)	mem 44912MB
Current slope: None 	
EPOCH 179 training takes 0:13:35
Test: [0/25]	Time 14.760 (14.760)	Loss 1.1663 (1.1663)	Acc@1 73.828 (73.828)	Acc@5 91.113 (91.113)	Mem 44912MB
 * Acc@1 62.408 Acc@5 84.550
Accuracy of the network on the 50000 test images: 62.41%
Max accuracy (after decay): 62.47%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Training time 1 day, 18:08:10
Keep 80.0%  activation funtions: [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0.]
Keep 60.0%  activation funtions: [0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0.]
Keep 50.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]
Keep 40.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
Keep 30.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Keep 20.0%  activation funtions: [0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Keep 10.0%  activation funtions: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 256
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 41.78
  - 5.45
  - 6.68
  - 3.23
  - 4.12
  - 4.12
  - 2.38
  - 2.72
  - 2.72
  - 2.72
  - 3.75
  - 5.04
  - 5.04
  - 3.44
  - 2.8
  - 2.8
  - 4.38
  - 0
  LAT_BEFORE:
  - 0
  - 56.97
  - 138.79
  - 82.45
  - 47.03
  - 34.51
  - 34.51
  - 21.19
  - 17.91
  - 17.91
  - 17.91
  - 20.75
  - 31.27
  - 31.27
  - 16.67
  - 14.21
  - 14.21
  - 18.77
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: false
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.8
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 4.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 4.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
Keep 40.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act()
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act()
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act()
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::leaky_relu encountered 44 time(s)
Unsupported operator aten::sub encountered 44 time(s)
Unsupported operator aten::mul encountered 44 time(s)
Unsupported operator aten::add encountered 44 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
auto resuming from manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
==============> Resuming form manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth....................
_IncompatibleKeys(missing_keys=[], unexpected_keys=['act1.act_fun.slope_param', 'blocks.0.0.act1.act_fun.slope_param', 'blocks.1.0.act.act_fun.slope_param', 'blocks.1.1.act.act_fun.slope_param', 'blocks.2.0.act.act_fun.slope_param', 'blocks.2.1.act.act_fun.slope_param', 'blocks.2.2.act.act_fun.slope_param', 'blocks.3.0.act.act_fun.slope_param', 'blocks.3.1.act.act_fun.slope_param', 'blocks.3.2.act.act_fun.slope_param', 'blocks.3.3.act.act_fun.slope_param', 'blocks.4.0.act.act_fun.slope_param', 'blocks.4.1.act.act_fun.slope_param', 'blocks.4.2.act.act_fun.slope_param', 'blocks.5.0.act.act_fun.slope_param', 'blocks.5.1.act.act_fun.slope_param', 'blocks.5.2.act.act_fun.slope_param', 'blocks.6.0.act.act_fun.slope_param', 'act2.act_fun.slope_param'])
=> loaded successfully 'manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth' (epoch 179)
Start training
Training time 0:00:00
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 256
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 41.78
  - 5.45
  - 6.68
  - 3.23
  - 4.12
  - 4.12
  - 2.38
  - 2.72
  - 2.72
  - 2.72
  - 3.75
  - 5.04
  - 5.04
  - 3.44
  - 2.8
  - 2.8
  - 4.38
  - 0
  LAT_BEFORE:
  - 0
  - 56.97
  - 138.79
  - 82.45
  - 47.03
  - 34.51
  - 34.51
  - 21.19
  - 17.91
  - 17.91
  - 17.91
  - 20.75
  - 31.27
  - 31.27
  - 16.67
  - 14.21
  - 14.21
  - 18.77
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: false
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.8
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 4.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 4.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
Keep 40.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act()
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act()
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act()
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::leaky_relu encountered 44 time(s)
Unsupported operator aten::sub encountered 44 time(s)
Unsupported operator aten::mul encountered 44 time(s)
Unsupported operator aten::add encountered 44 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
auto resuming from manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
==============> Resuming form manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth....................
_IncompatibleKeys(missing_keys=[], unexpected_keys=['act1.act_fun.slope_param', 'blocks.0.0.act1.act_fun.slope_param', 'blocks.1.0.act.act_fun.slope_param', 'blocks.1.1.act.act_fun.slope_param', 'blocks.2.0.act.act_fun.slope_param', 'blocks.2.1.act.act_fun.slope_param', 'blocks.2.2.act.act_fun.slope_param', 'blocks.3.0.act.act_fun.slope_param', 'blocks.3.1.act.act_fun.slope_param', 'blocks.3.2.act.act_fun.slope_param', 'blocks.3.3.act.act_fun.slope_param', 'blocks.4.0.act.act_fun.slope_param', 'blocks.4.1.act.act_fun.slope_param', 'blocks.4.2.act.act_fun.slope_param', 'blocks.5.0.act.act_fun.slope_param', 'blocks.5.1.act.act_fun.slope_param', 'blocks.5.2.act.act_fun.slope_param', 'blocks.6.0.act.act_fun.slope_param', 'act2.act_fun.slope_param'])
=> loaded successfully 'manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth' (epoch 179)
Start training
Training time 0:00:00
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 256
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 41.78
  - 5.45
  - 6.68
  - 3.23
  - 4.12
  - 4.12
  - 2.38
  - 2.72
  - 2.72
  - 2.72
  - 3.75
  - 5.04
  - 5.04
  - 3.44
  - 2.8
  - 2.8
  - 4.38
  - 0
  LAT_BEFORE:
  - 0
  - 56.97
  - 138.79
  - 82.45
  - 47.03
  - 34.51
  - 34.51
  - 21.19
  - 17.91
  - 17.91
  - 17.91
  - 20.75
  - 31.27
  - 31.27
  - 16.67
  - 14.21
  - 14.21
  - 18.77
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: false
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.8
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 4.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 4.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
Keep 40.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act()
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act()
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act()
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::leaky_relu encountered 44 time(s)
Unsupported operator aten::sub encountered 44 time(s)
Unsupported operator aten::mul encountered 44 time(s)
Unsupported operator aten::add encountered 44 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
auto resuming from manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
==============> Resuming form manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth....................
_IncompatibleKeys(missing_keys=[], unexpected_keys=['act1.act_fun.slope_param', 'blocks.0.0.act1.act_fun.slope_param', 'blocks.1.0.act.act_fun.slope_param', 'blocks.1.1.act.act_fun.slope_param', 'blocks.2.0.act.act_fun.slope_param', 'blocks.2.1.act.act_fun.slope_param', 'blocks.2.2.act.act_fun.slope_param', 'blocks.3.0.act.act_fun.slope_param', 'blocks.3.1.act.act_fun.slope_param', 'blocks.3.2.act.act_fun.slope_param', 'blocks.3.3.act.act_fun.slope_param', 'blocks.4.0.act.act_fun.slope_param', 'blocks.4.1.act.act_fun.slope_param', 'blocks.4.2.act.act_fun.slope_param', 'blocks.5.0.act.act_fun.slope_param', 'blocks.5.1.act.act_fun.slope_param', 'blocks.5.2.act.act_fun.slope_param', 'blocks.6.0.act.act_fun.slope_param', 'act2.act_fun.slope_param'])
=> loaded successfully 'manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth' (epoch 179)
Start training
Training time 0:00:00
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 256
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 41.78
  - 5.45
  - 6.68
  - 3.23
  - 4.12
  - 4.12
  - 2.38
  - 2.72
  - 2.72
  - 2.72
  - 3.75
  - 5.04
  - 5.04
  - 3.44
  - 2.8
  - 2.8
  - 4.38
  - 0
  LAT_BEFORE:
  - 0
  - 56.97
  - 138.79
  - 82.45
  - 47.03
  - 34.51
  - 34.51
  - 21.19
  - 17.91
  - 17.91
  - 17.91
  - 20.75
  - 31.27
  - 31.27
  - 16.67
  - 14.21
  - 14.21
  - 18.77
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: false
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.8
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 4.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 4.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
Keep 40.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act()
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act()
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act()
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::leaky_relu encountered 44 time(s)
Unsupported operator aten::sub encountered 44 time(s)
Unsupported operator aten::mul encountered 44 time(s)
Unsupported operator aten::add encountered 44 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
auto resuming from manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
==============> Resuming form manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth....................
_IncompatibleKeys(missing_keys=[], unexpected_keys=['act1.act_fun.slope_param', 'blocks.0.0.act1.act_fun.slope_param', 'blocks.1.0.act.act_fun.slope_param', 'blocks.1.1.act.act_fun.slope_param', 'blocks.2.0.act.act_fun.slope_param', 'blocks.2.1.act.act_fun.slope_param', 'blocks.2.2.act.act_fun.slope_param', 'blocks.3.0.act.act_fun.slope_param', 'blocks.3.1.act.act_fun.slope_param', 'blocks.3.2.act.act_fun.slope_param', 'blocks.3.3.act.act_fun.slope_param', 'blocks.4.0.act.act_fun.slope_param', 'blocks.4.1.act.act_fun.slope_param', 'blocks.4.2.act.act_fun.slope_param', 'blocks.5.0.act.act_fun.slope_param', 'blocks.5.1.act.act_fun.slope_param', 'blocks.5.2.act.act_fun.slope_param', 'blocks.6.0.act.act_fun.slope_param', 'act2.act_fun.slope_param'])
=> loaded successfully 'manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth' (epoch 179)
Start training
Training time 0:00:00
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 256
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 41.78
  - 5.45
  - 6.68
  - 3.23
  - 4.12
  - 4.12
  - 2.38
  - 2.72
  - 2.72
  - 2.72
  - 3.75
  - 5.04
  - 5.04
  - 3.44
  - 2.8
  - 2.8
  - 4.38
  - 0
  LAT_BEFORE:
  - 0
  - 56.97
  - 138.79
  - 82.45
  - 47.03
  - 34.51
  - 34.51
  - 21.19
  - 17.91
  - 17.91
  - 17.91
  - 20.75
  - 31.27
  - 31.27
  - 16.67
  - 14.21
  - 14.21
  - 18.77
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: false
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.8
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 4.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 4.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
Keep 40.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act()
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act()
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act()
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::leaky_relu encountered 44 time(s)
Unsupported operator aten::sub encountered 44 time(s)
Unsupported operator aten::mul encountered 44 time(s)
Unsupported operator aten::add encountered 44 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
auto resuming from manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
==============> Resuming form manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth....................
_IncompatibleKeys(missing_keys=[], unexpected_keys=['act1.act_fun.slope_param', 'blocks.0.0.act1.act_fun.slope_param', 'blocks.1.0.act.act_fun.slope_param', 'blocks.1.1.act.act_fun.slope_param', 'blocks.2.0.act.act_fun.slope_param', 'blocks.2.1.act.act_fun.slope_param', 'blocks.2.2.act.act_fun.slope_param', 'blocks.3.0.act.act_fun.slope_param', 'blocks.3.1.act.act_fun.slope_param', 'blocks.3.2.act.act_fun.slope_param', 'blocks.3.3.act.act_fun.slope_param', 'blocks.4.0.act.act_fun.slope_param', 'blocks.4.1.act.act_fun.slope_param', 'blocks.4.2.act.act_fun.slope_param', 'blocks.5.0.act.act_fun.slope_param', 'blocks.5.1.act.act_fun.slope_param', 'blocks.5.2.act.act_fun.slope_param', 'blocks.6.0.act.act_fun.slope_param', 'act2.act_fun.slope_param'])
=> loaded successfully 'manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth' (epoch 179)
Start training
Training time 0:00:00
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 256
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: false
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 41.78
  - 5.45
  - 6.68
  - 3.23
  - 4.12
  - 4.12
  - 2.38
  - 2.72
  - 2.72
  - 2.72
  - 3.75
  - 5.04
  - 5.04
  - 3.44
  - 2.8
  - 2.8
  - 4.38
  - 0
  LAT_BEFORE:
  - 0
  - 56.97
  - 138.79
  - 82.45
  - 47.03
  - 34.51
  - 34.51
  - 21.19
  - 17.91
  - 17.91
  - 17.91
  - 20.75
  - 31.27
  - 31.27
  - 16.67
  - 14.21
  - 14.21
  - 18.77
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: ''
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.8
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 4.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 4.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108795
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
auto resuming from manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
==============> Resuming form manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth....................
<All keys matched successfully>
=> loaded successfully 'manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth' (epoch 179)
Start training
Training time 0:00:00
Keep 80.0%  activation funtions: [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0.]
Keep 60.0%  activation funtions: [0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0.]
Keep 50.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]
Keep 40.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
Keep 30.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Keep 20.0%  activation funtions: [0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Keep 10.0%  activation funtions: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 256
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: false
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 41.78
  - 5.45
  - 6.68
  - 3.23
  - 4.12
  - 4.12
  - 2.38
  - 2.72
  - 2.72
  - 2.72
  - 3.75
  - 5.04
  - 5.04
  - 3.44
  - 2.8
  - 2.8
  - 4.38
  - 0
  LAT_BEFORE:
  - 0
  - 56.97
  - 138.79
  - 82.45
  - 47.03
  - 34.51
  - 34.51
  - 21.19
  - 17.91
  - 17.91
  - 17.91
  - 20.75
  - 31.27
  - 31.27
  - 16.67
  - 14.21
  - 14.21
  - 18.77
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: ''
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.8
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 4.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 4.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108795
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
auto resuming from manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
==============> Resuming form manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth....................
<All keys matched successfully>
=> loaded successfully 'manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth' (epoch 179)
Start training
Training time 0:00:00
Keep 80.0%  activation funtions: [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0.]
Keep 60.0%  activation funtions: [0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0.]
Keep 50.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]
Keep 40.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
Keep 30.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Keep 20.0%  activation funtions: [0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Keep 10.0%  activation funtions: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 256
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: false
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 41.78
  - 5.45
  - 6.68
  - 3.23
  - 4.12
  - 4.12
  - 2.38
  - 2.72
  - 2.72
  - 2.72
  - 3.75
  - 5.04
  - 5.04
  - 3.44
  - 2.8
  - 2.8
  - 4.38
  - 0
  LAT_BEFORE:
  - 0
  - 56.97
  - 138.79
  - 82.45
  - 47.03
  - 34.51
  - 34.51
  - 21.19
  - 17.91
  - 17.91
  - 17.91
  - 20.75
  - 31.27
  - 31.27
  - 16.67
  - 14.21
  - 14.21
  - 18.77
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: ''
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.8
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 4.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 4.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108795
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
auto resuming from manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
==============> Resuming form manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth....................
<All keys matched successfully>
=> loaded successfully 'manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth' (epoch 179)
Start training
Training time 0:00:00
Keep 80.0%  activation funtions: [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0.]
Keep 60.0%  activation funtions: [0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0.]
Keep 50.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]
Keep 40.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
Keep 30.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Keep 20.0%  activation funtions: [0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Keep 10.0%  activation funtions: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /data1/dataset/ILSVRC/Data/CLS-LOC/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: false
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 41.78
  - 5.45
  - 6.68
  - 3.23
  - 4.12
  - 4.12
  - 2.38
  - 2.72
  - 2.72
  - 2.72
  - 3.75
  - 5.04
  - 5.04
  - 3.44
  - 2.8
  - 2.8
  - 4.38
  - 0
  LAT_BEFORE:
  - 0
  - 56.97
  - 138.79
  - 82.45
  - 47.03
  - 34.51
  - 34.51
  - 21.19
  - 17.91
  - 17.91
  - 17.91
  - 20.75
  - 31.27
  - 31.27
  - 16.67
  - 14.21
  - 14.21
  - 18.77
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: ''
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: false
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 41.78
  - 5.45
  - 6.68
  - 3.23
  - 4.12
  - 4.12
  - 2.38
  - 2.72
  - 2.72
  - 2.72
  - 3.75
  - 5.04
  - 5.04
  - 3.44
  - 2.8
  - 2.8
  - 4.38
  - 0
  LAT_BEFORE:
  - 0
  - 56.97
  - 138.79
  - 82.45
  - 47.03
  - 34.51
  - 34.51
  - 21.19
  - 17.91
  - 17.91
  - 17.91
  - 20.75
  - 31.27
  - 31.27
  - 16.67
  - 14.21
  - 14.21
  - 18.77
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: ''
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108795
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
auto resuming from manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
==============> Resuming form manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth....................
<All keys matched successfully>
=> loaded successfully 'manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth' (epoch 179)
Start training
Training time 0:00:00
Keep 80.0%  activation funtions: [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0.]
Keep 60.0%  activation funtions: [0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0.]
Keep 50.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]
Keep 40.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
Keep 30.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Keep 20.0%  activation funtions: [0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Keep 10.0%  activation funtions: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: false
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 41.78
  - 5.45
  - 6.68
  - 3.23
  - 4.12
  - 4.12
  - 2.38
  - 2.72
  - 2.72
  - 2.72
  - 3.75
  - 5.04
  - 5.04
  - 3.44
  - 2.8
  - 2.8
  - 4.38
  - 0
  LAT_BEFORE:
  - 0
  - 56.97
  - 138.79
  - 82.45
  - 47.03
  - 34.51
  - 34.51
  - 21.19
  - 17.91
  - 17.91
  - 17.91
  - 20.75
  - 31.27
  - 31.27
  - 16.67
  - 14.21
  - 14.21
  - 18.77
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: ''
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10002
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108795
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
auto resuming from manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
==============> Resuming form manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth....................
<All keys matched successfully>
=> loaded successfully 'manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth' (epoch 179)
Start training
Training time 0:00:00
Keep 80.0%  activation funtions: [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0.]
Keep 60.0%  activation funtions: [0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0.]
Keep 50.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]
Keep 40.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
Keep 30.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Keep 20.0%  activation funtions: [0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Keep 10.0%  activation funtions: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: false
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 24.7
  - 4.03
  - 5.16
  - 1.73
  - 2.41
  - 2.41
  - 1.12
  - 1.6
  - 1.6
  - 1.6
  - 2.03
  - 2.99
  - 2.99
  - 2.28
  - 1.79
  - 1.79
  - 2.68
  - 0
  LAT_BEFORE:
  - 0
  - 42.85
  - 89.55
  - 63.13
  - 37.51
  - 23.34
  - 23.34
  - 13.63
  - 13.05
  - 13.05
  - 13.05
  - 13.67
  - 20.84
  - 20.84
  - 11.77
  - 9.14
  - 9.14
  - 11.16
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: ''
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_100_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_100_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_100_block_ds/mobilenetv2_100_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
        (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
        (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)
        (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
        (bn2): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
        (bn2): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
        (bn2): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1280, out_features=1000, bias=True)
)
number of params (M): 3.504891
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.314193216
auto resuming from manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
==============> Resuming form manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth....................
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: false
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 41.78
  - 5.45
  - 6.68
  - 3.23
  - 4.12
  - 4.12
  - 2.38
  - 2.72
  - 2.72
  - 2.72
  - 3.75
  - 5.04
  - 5.04
  - 3.44
  - 2.8
  - 2.8
  - 4.38
  - 0
  LAT_BEFORE:
  - 0
  - 56.97
  - 138.79
  - 82.45
  - 47.03
  - 34.51
  - 34.51
  - 21.19
  - 17.91
  - 17.91
  - 17.91
  - 20.75
  - 31.27
  - 31.27
  - 16.67
  - 14.21
  - 14.21
  - 18.77
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: ''
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108795
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
auto resuming from manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
==============> Resuming form manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth....................
<All keys matched successfully>
=> loaded successfully 'manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth' (epoch 179)
Start training
Training time 0:00:00
Keep 80.0%  activation funtions: [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0.]
Keep 60.0%  activation funtions: [0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0.]
Keep 50.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]
Keep 40.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
Keep 30.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Keep 20.0%  activation funtions: [0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Keep 10.0%  activation funtions: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: false
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 41.78
  - 5.45
  - 6.68
  - 3.23
  - 4.12
  - 4.12
  - 2.38
  - 2.72
  - 2.72
  - 2.72
  - 3.75
  - 5.04
  - 5.04
  - 3.44
  - 2.8
  - 2.8
  - 4.38
  - 0
  LAT_BEFORE:
  - 0
  - 56.97
  - 138.79
  - 82.45
  - 47.03
  - 34.51
  - 34.51
  - 21.19
  - 17.91
  - 17.91
  - 17.91
  - 20.75
  - 31.27
  - 31.27
  - 16.67
  - 14.21
  - 14.21
  - 18.77
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: ''
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108795
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
auto resuming from manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
==============> Resuming form manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth....................
<All keys matched successfully>
=> loaded successfully 'manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth' (epoch 179)
Start training
Training time 0:00:00
Keep 80.0%  activation funtions: [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0.]
Keep 60.0%  activation funtions: [0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0.]
Keep 50.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]
Keep 40.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
Keep 30.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Keep 20.0%  activation funtions: [0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Keep 10.0%  activation funtions: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 41.78
  - 5.45
  - 6.68
  - 3.23
  - 4.12
  - 4.12
  - 2.38
  - 2.72
  - 2.72
  - 2.72
  - 3.75
  - 5.04
  - 5.04
  - 3.44
  - 2.8
  - 2.8
  - 4.38
  - 0
  LAT_BEFORE:
  - 0
  - 56.97
  - 138.79
  - 82.45
  - 47.03
  - 34.51
  - 34.51
  - 21.19
  - 17.91
  - 17.91
  - 17.91
  - 20.75
  - 31.27
  - 31.27
  - 16.67
  - 14.21
  - 14.21
  - 18.77
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: false
  SEARCH_CKPT: ''
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 41.78
  - 5.45
  - 6.68
  - 3.23
  - 4.12
  - 4.12
  - 2.38
  - 2.72
  - 2.72
  - 2.72
  - 3.75
  - 5.04
  - 5.04
  - 3.44
  - 2.8
  - 2.8
  - 4.38
  - 0
  LAT_BEFORE:
  - 0
  - 56.97
  - 138.79
  - 82.45
  - 47.03
  - 34.51
  - 34.51
  - 21.19
  - 17.91
  - 17.91
  - 17.91
  - 20.75
  - 31.27
  - 31.27
  - 16.67
  - 14.21
  - 14.21
  - 18.77
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: false
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
Keep 40.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act()
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act()
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act()
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::leaky_relu encountered 44 time(s)
Unsupported operator aten::sub encountered 44 time(s)
Unsupported operator aten::mul encountered 44 time(s)
Unsupported operator aten::add encountered 44 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
auto resuming from manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
==============> Resuming form manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth....................
_IncompatibleKeys(missing_keys=[], unexpected_keys=['act1.act_fun.slope_param', 'blocks.0.0.act1.act_fun.slope_param', 'blocks.1.0.act.act_fun.slope_param', 'blocks.1.1.act.act_fun.slope_param', 'blocks.2.0.act.act_fun.slope_param', 'blocks.2.1.act.act_fun.slope_param', 'blocks.2.2.act.act_fun.slope_param', 'blocks.3.0.act.act_fun.slope_param', 'blocks.3.1.act.act_fun.slope_param', 'blocks.3.2.act.act_fun.slope_param', 'blocks.3.3.act.act_fun.slope_param', 'blocks.4.0.act.act_fun.slope_param', 'blocks.4.1.act.act_fun.slope_param', 'blocks.4.2.act.act_fun.slope_param', 'blocks.5.0.act.act_fun.slope_param', 'blocks.5.1.act.act_fun.slope_param', 'blocks.5.2.act.act_fun.slope_param', 'blocks.6.0.act.act_fun.slope_param', 'act2.act_fun.slope_param'])
=> loaded successfully 'manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth' (epoch 179)
Start training
Training time 0:00:00
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 256
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 41.78
  - 5.45
  - 6.68
  - 3.23
  - 4.12
  - 4.12
  - 2.38
  - 2.72
  - 2.72
  - 2.72
  - 3.75
  - 5.04
  - 5.04
  - 3.44
  - 2.8
  - 2.8
  - 4.38
  - 0
  LAT_BEFORE:
  - 0
  - 56.97
  - 138.79
  - 82.45
  - 47.03
  - 34.51
  - 34.51
  - 21.19
  - 17.91
  - 17.91
  - 17.91
  - 20.75
  - 31.27
  - 31.27
  - 16.67
  - 14.21
  - 14.21
  - 18.77
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: false
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.8
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 4.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 4.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
Keep 40.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act()
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act()
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act()
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::leaky_relu encountered 44 time(s)
Unsupported operator aten::sub encountered 44 time(s)
Unsupported operator aten::mul encountered 44 time(s)
Unsupported operator aten::add encountered 44 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
auto resuming from manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
==============> Resuming form manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth....................
_IncompatibleKeys(missing_keys=[], unexpected_keys=['act1.act_fun.slope_param', 'blocks.0.0.act1.act_fun.slope_param', 'blocks.1.0.act.act_fun.slope_param', 'blocks.1.1.act.act_fun.slope_param', 'blocks.2.0.act.act_fun.slope_param', 'blocks.2.1.act.act_fun.slope_param', 'blocks.2.2.act.act_fun.slope_param', 'blocks.3.0.act.act_fun.slope_param', 'blocks.3.1.act.act_fun.slope_param', 'blocks.3.2.act.act_fun.slope_param', 'blocks.3.3.act.act_fun.slope_param', 'blocks.4.0.act.act_fun.slope_param', 'blocks.4.1.act.act_fun.slope_param', 'blocks.4.2.act.act_fun.slope_param', 'blocks.5.0.act.act_fun.slope_param', 'blocks.5.1.act.act_fun.slope_param', 'blocks.5.2.act.act_fun.slope_param', 'blocks.6.0.act.act_fun.slope_param', 'act2.act_fun.slope_param'])
=> loaded successfully 'manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth' (epoch 179)
Start training
Training time 0:00:00
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 256
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 41.78
  - 5.45
  - 6.68
  - 3.23
  - 4.12
  - 4.12
  - 2.38
  - 2.72
  - 2.72
  - 2.72
  - 3.75
  - 5.04
  - 5.04
  - 3.44
  - 2.8
  - 2.8
  - 4.38
  - 0
  LAT_BEFORE:
  - 0
  - 56.97
  - 138.79
  - 82.45
  - 47.03
  - 34.51
  - 34.51
  - 21.19
  - 17.91
  - 17.91
  - 17.91
  - 20.75
  - 31.27
  - 31.27
  - 16.67
  - 14.21
  - 14.21
  - 18.77
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: false
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.8
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 4.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 4.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
Keep 40.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act()
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act()
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act()
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::leaky_relu encountered 44 time(s)
Unsupported operator aten::sub encountered 44 time(s)
Unsupported operator aten::mul encountered 44 time(s)
Unsupported operator aten::add encountered 44 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
auto resuming from manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
==============> Resuming form manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth....................
_IncompatibleKeys(missing_keys=[], unexpected_keys=['act1.act_fun.slope_param', 'blocks.0.0.act1.act_fun.slope_param', 'blocks.1.0.act.act_fun.slope_param', 'blocks.1.1.act.act_fun.slope_param', 'blocks.2.0.act.act_fun.slope_param', 'blocks.2.1.act.act_fun.slope_param', 'blocks.2.2.act.act_fun.slope_param', 'blocks.3.0.act.act_fun.slope_param', 'blocks.3.1.act.act_fun.slope_param', 'blocks.3.2.act.act_fun.slope_param', 'blocks.3.3.act.act_fun.slope_param', 'blocks.4.0.act.act_fun.slope_param', 'blocks.4.1.act.act_fun.slope_param', 'blocks.4.2.act.act_fun.slope_param', 'blocks.5.0.act.act_fun.slope_param', 'blocks.5.1.act.act_fun.slope_param', 'blocks.5.2.act.act_fun.slope_param', 'blocks.6.0.act.act_fun.slope_param', 'act2.act_fun.slope_param'])
=> loaded successfully 'manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth' (epoch 179)
Start training
Training time 0:00:00
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 256
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 41.78
  - 5.45
  - 6.68
  - 3.23
  - 4.12
  - 4.12
  - 2.38
  - 2.72
  - 2.72
  - 2.72
  - 3.75
  - 5.04
  - 5.04
  - 3.44
  - 2.8
  - 2.8
  - 4.38
  - 0
  LAT_BEFORE:
  - 0
  - 56.97
  - 138.79
  - 82.45
  - 47.03
  - 34.51
  - 34.51
  - 21.19
  - 17.91
  - 17.91
  - 17.91
  - 20.75
  - 31.27
  - 31.27
  - 16.67
  - 14.21
  - 14.21
  - 18.77
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: false
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.8
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 4.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 4.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
Keep 40.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act()
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act()
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act()
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::leaky_relu encountered 44 time(s)
Unsupported operator aten::sub encountered 44 time(s)
Unsupported operator aten::mul encountered 44 time(s)
Unsupported operator aten::add encountered 44 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/625]	eta 5:32:25 lr 0.800000	data 21.6444 (21.6444)	batch 31.9129 (31.9129)	loss 6.9462 (6.9462)	grad_norm 1.2312 (1.2312)	mem 38886MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 256
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 41.78
  - 5.45
  - 6.68
  - 3.23
  - 4.12
  - 4.12
  - 2.38
  - 2.72
  - 2.72
  - 2.72
  - 3.75
  - 5.04
  - 5.04
  - 3.44
  - 2.8
  - 2.8
  - 4.38
  - 0
  LAT_BEFORE:
  - 0
  - 56.97
  - 138.79
  - 82.45
  - 47.03
  - 34.51
  - 34.51
  - 21.19
  - 17.91
  - 17.91
  - 17.91
  - 20.75
  - 31.27
  - 31.27
  - 16.67
  - 14.21
  - 14.21
  - 18.77
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: false
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.8
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 4.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 4.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
Keep 40.0%  activation funtions: [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act()
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act()
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act()
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Final_Act()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act()
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::leaky_relu encountered 44 time(s)
Unsupported operator aten::sub encountered 44 time(s)
Unsupported operator aten::mul encountered 44 time(s)
Unsupported operator aten::add encountered 44 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/625]	eta 4:43:25 lr 0.800000	data 20.3470 (20.3470)	batch 27.2095 (27.2095)	loss 6.9462 (6.9462)	grad_norm 1.2262 (1.2262)	mem 38886MB
Train: [0/180][50/625]	eta 0:13:35 lr 0.800000	data 0.0005 (0.3996)	batch 0.8743 (1.4183)	loss 6.6060 (6.7788)	grad_norm 0.5111 (0.6081)	mem 38886MB
Train: [0/180][100/625]	eta 0:10:08 lr 0.799998	data 0.0004 (0.2022)	batch 0.9316 (1.1582)	loss 6.2266 (6.5802)	grad_norm 0.5053 (0.5470)	mem 38886MB
Train: [0/180][150/625]	eta 0:08:29 lr 0.799996	data 0.0008 (0.1355)	batch 0.9125 (1.0736)	loss 6.0602 (6.4178)	grad_norm 0.4945 (0.5259)	mem 38886MB
Train: [0/180][200/625]	eta 0:07:18 lr 0.799994	data 0.0006 (0.1019)	batch 0.8854 (1.0313)	loss 5.9419 (6.2861)	grad_norm 0.4608 (0.5228)	mem 38886MB
Train: [0/180][250/625]	eta 0:06:16 lr 0.799990	data 0.0007 (0.0818)	batch 0.8923 (1.0048)	loss 5.7440 (6.1746)	grad_norm 0.5840 (0.5211)	mem 38886MB
Train: [0/180][300/625]	eta 0:05:21 lr 0.799986	data 0.0006 (0.0683)	batch 0.8767 (0.9893)	loss 5.5946 (6.0802)	grad_norm 0.4984 (0.5229)	mem 38886MB
Train: [0/180][350/625]	eta 0:04:28 lr 0.799981	data 0.0007 (0.0587)	batch 0.8873 (0.9770)	loss 5.3796 (5.9933)	grad_norm 0.5695 (0.5218)	mem 38886MB
Train: [0/180][400/625]	eta 0:03:37 lr 0.799975	data 0.0005 (0.0515)	batch 0.9385 (0.9679)	loss 5.2211 (5.9171)	grad_norm 0.5055 (0.5213)	mem 38886MB
Train: [0/180][450/625]	eta 0:02:48 lr 0.799968	data 0.0006 (0.0459)	batch 0.8915 (0.9613)	loss 5.0313 (5.8461)	grad_norm 0.6029 (0.5208)	mem 38886MB
Train: [0/180][500/625]	eta 0:01:59 lr 0.799961	data 0.0007 (0.0413)	batch 0.8490 (0.9555)	loss 5.1443 (5.7806)	grad_norm 0.4997 (0.5224)	mem 38886MB
Train: [0/180][550/625]	eta 0:01:11 lr 0.799953	data 0.0007 (0.0377)	batch 0.8774 (0.9515)	loss 5.1844 (5.7174)	grad_norm 0.5213 (0.5216)	mem 38886MB
Train: [0/180][600/625]	eta 0:00:23 lr 0.799944	data 0.0005 (0.0346)	batch 0.8712 (0.9470)	loss 4.9595 (5.6596)	grad_norm 0.4884 (0.5213)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 0 training takes 0:09:52
Test: [0/25]	Time 14.373 (14.373)	Loss 3.8851 (3.8851)	Acc@1 23.145 (23.145)	Acc@5 45.850 (45.850)	Mem 38886MB
 * Acc@1 19.514 Acc@5 40.792
Accuracy of the network on the 50000 test images: 19.51%
Max accuracy (after decay): 19.51%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [1/180][0/625]	eta 4:02:41 lr 0.799939	data 21.4125 (21.4125)	batch 23.2983 (23.2983)	loss 4.8893 (4.8893)	grad_norm 0.5808 (0.5808)	mem 38886MB
Train: [1/180][50/625]	eta 0:13:00 lr 0.799929	data 0.0006 (0.4208)	batch 0.9009 (1.3578)	loss 4.8583 (4.9076)	grad_norm 0.5007 (0.5146)	mem 38886MB
Train: [1/180][100/625]	eta 0:09:53 lr 0.799918	data 0.0007 (0.2129)	batch 0.9117 (1.1314)	loss 4.6892 (4.8959)	grad_norm 0.4840 (0.5125)	mem 38886MB
Train: [1/180][150/625]	eta 0:08:22 lr 0.799906	data 0.0008 (0.1426)	batch 0.8957 (1.0572)	loss 4.8385 (4.8726)	grad_norm 0.5171 (0.5116)	mem 38886MB
Train: [1/180][200/625]	eta 0:07:13 lr 0.799894	data 0.0006 (0.1073)	batch 0.9272 (1.0204)	loss 4.7757 (4.8478)	grad_norm 0.5267 (0.5125)	mem 38886MB
Train: [1/180][250/625]	eta 0:06:13 lr 0.799881	data 0.0010 (0.0861)	batch 0.9134 (0.9971)	loss 4.8804 (4.8206)	grad_norm 0.5402 (0.5120)	mem 38886MB
Train: [1/180][300/625]	eta 0:05:19 lr 0.799867	data 0.0006 (0.0719)	batch 0.8988 (0.9833)	loss 4.5262 (4.7939)	grad_norm 0.5505 (0.5103)	mem 38886MB
Train: [1/180][350/625]	eta 0:04:27 lr 0.799852	data 0.0006 (0.0618)	batch 0.8864 (0.9716)	loss 4.9126 (4.7743)	grad_norm 0.5099 (0.5092)	mem 38886MB
Train: [1/180][400/625]	eta 0:03:36 lr 0.799836	data 0.0005 (0.0542)	batch 0.9144 (0.9628)	loss 4.6475 (4.7527)	grad_norm 0.5076 (0.5081)	mem 38886MB
Train: [1/180][450/625]	eta 0:02:47 lr 0.799820	data 0.0006 (0.0482)	batch 0.8713 (0.9565)	loss 4.5969 (4.7335)	grad_norm 0.5068 (0.5077)	mem 38886MB
Train: [1/180][500/625]	eta 0:01:58 lr 0.799803	data 0.0006 (0.0435)	batch 0.9347 (0.9515)	loss 4.3909 (4.7150)	grad_norm 0.5207 (0.5066)	mem 38886MB
Train: [1/180][550/625]	eta 0:01:11 lr 0.799785	data 0.0004 (0.0396)	batch 0.9729 (0.9504)	loss 4.4196 (4.6941)	grad_norm 0.4958 (0.5054)	mem 38886MB
Train: [1/180][600/625]	eta 0:00:24 lr 0.799766	data 0.0007 (0.0364)	batch 1.0969 (0.9643)	loss 4.4229 (4.6751)	grad_norm 0.5316 (0.5047)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 1 training takes 0:10:08
Test: [0/25]	Time 15.063 (15.063)	Loss 2.8362 (2.8362)	Acc@1 39.404 (39.404)	Acc@5 66.650 (66.650)	Mem 38886MB
 * Acc@1 30.726 Acc@5 55.668
Accuracy of the network on the 50000 test images: 30.73%
Max accuracy (after decay): 30.73%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [2/180][0/625]	eta 4:01:05 lr 0.799756	data 22.0206 (22.0206)	batch 23.1449 (23.1449)	loss 4.4324 (4.4324)	grad_norm 0.5021 (0.5021)	mem 38886MB
Train: [2/180][50/625]	eta 0:12:54 lr 0.799736	data 0.0007 (0.4327)	batch 0.9094 (1.3465)	loss 4.4294 (4.4049)	grad_norm 0.4847 (0.4940)	mem 38886MB
Train: [2/180][100/625]	eta 0:09:51 lr 0.799716	data 0.0006 (0.2189)	batch 0.9182 (1.1260)	loss 4.3700 (4.3922)	grad_norm 0.4801 (0.4954)	mem 38886MB
Train: [2/180][150/625]	eta 0:08:18 lr 0.799694	data 0.0006 (0.1466)	batch 0.8971 (1.0503)	loss 4.3969 (4.3704)	grad_norm 0.5439 (0.4935)	mem 38886MB
Train: [2/180][200/625]	eta 0:07:10 lr 0.799672	data 0.0005 (0.1103)	batch 0.9259 (1.0136)	loss 4.3400 (4.3596)	grad_norm 0.5263 (0.4931)	mem 38886MB
Train: [2/180][250/625]	eta 0:06:11 lr 0.799649	data 0.0005 (0.0885)	batch 0.9027 (0.9904)	loss 4.3244 (4.3515)	grad_norm 0.4767 (0.4916)	mem 38886MB
Train: [2/180][300/625]	eta 0:05:17 lr 0.799625	data 0.0005 (0.0739)	batch 0.9434 (0.9765)	loss 4.3676 (4.3421)	grad_norm 0.4802 (0.4913)	mem 38886MB
Train: [2/180][350/625]	eta 0:04:25 lr 0.799601	data 0.0004 (0.0634)	batch 0.9116 (0.9664)	loss 4.3378 (4.3312)	grad_norm 0.4771 (0.4908)	mem 38886MB
Train: [2/180][400/625]	eta 0:03:35 lr 0.799575	data 0.0006 (0.0556)	batch 0.9078 (0.9583)	loss 4.1554 (4.3187)	grad_norm 0.4738 (0.4905)	mem 38886MB
Train: [2/180][450/625]	eta 0:02:46 lr 0.799549	data 0.0005 (0.0495)	batch 0.8793 (0.9514)	loss 4.3947 (4.3098)	grad_norm 0.4933 (0.4895)	mem 38886MB
Train: [2/180][500/625]	eta 0:01:58 lr 0.799522	data 0.0005 (0.0446)	batch 0.9019 (0.9460)	loss 4.0781 (4.2968)	grad_norm 0.4799 (0.4884)	mem 38886MB
Train: [2/180][550/625]	eta 0:01:10 lr 0.799495	data 0.0005 (0.0406)	batch 0.9164 (0.9429)	loss 4.2894 (4.2879)	grad_norm 0.4640 (0.4876)	mem 38886MB
Train: [2/180][600/625]	eta 0:00:23 lr 0.799466	data 0.0006 (0.0373)	batch 0.9256 (0.9396)	loss 4.2563 (4.2790)	grad_norm 0.4823 (0.4869)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 2 training takes 0:09:47
Test: [0/25]	Time 14.882 (14.882)	Loss 2.3935 (2.3935)	Acc@1 47.217 (47.217)	Acc@5 72.363 (72.363)	Mem 38886MB
 * Acc@1 37.950 Acc@5 63.254
Accuracy of the network on the 50000 test images: 37.95%
Max accuracy (after decay): 37.95%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [3/180][0/625]	eta 3:53:32 lr 0.799452	data 21.2152 (21.2152)	batch 22.4202 (22.4202)	loss 4.1752 (4.1752)	grad_norm 0.4604 (0.4604)	mem 38886MB
Train: [3/180][50/625]	eta 0:12:49 lr 0.799422	data 0.0005 (0.4167)	batch 0.9026 (1.3386)	loss 4.0894 (4.0993)	grad_norm 0.4844 (0.4771)	mem 38886MB
Train: [3/180][100/625]	eta 0:09:50 lr 0.799392	data 0.0003 (0.2108)	batch 0.8832 (1.1252)	loss 4.0064 (4.1129)	grad_norm 0.4898 (0.4792)	mem 38886MB
Train: [3/180][150/625]	eta 0:08:19 lr 0.799361	data 0.0013 (0.1412)	batch 0.9019 (1.0523)	loss 3.9431 (4.1030)	grad_norm 0.4643 (0.4781)	mem 38886MB
Train: [3/180][200/625]	eta 0:07:12 lr 0.799329	data 0.0006 (0.1063)	batch 0.9265 (1.0182)	loss 4.1855 (4.1078)	grad_norm 0.4682 (0.4785)	mem 38886MB
Train: [3/180][250/625]	eta 0:06:15 lr 0.799296	data 0.0005 (0.0852)	batch 1.0322 (1.0023)	loss 4.0369 (4.1031)	grad_norm 0.4705 (0.4783)	mem 38886MB
Train: [3/180][300/625]	eta 0:05:31 lr 0.799262	data 0.0005 (0.0712)	batch 0.9090 (1.0198)	loss 3.9483 (4.0945)	grad_norm 0.4646 (0.4776)	mem 38886MB
Train: [3/180][350/625]	eta 0:04:36 lr 0.799228	data 0.0004 (0.0611)	batch 0.9391 (1.0071)	loss 4.2429 (4.0879)	grad_norm 0.4760 (0.4766)	mem 38886MB
Train: [3/180][400/625]	eta 0:03:46 lr 0.799193	data 0.0005 (0.0536)	batch 1.1428 (1.0080)	loss 4.0581 (4.0803)	grad_norm 0.4649 (0.4763)	mem 38886MB
Train: [3/180][450/625]	eta 0:02:56 lr 0.799157	data 0.0004 (0.0477)	batch 0.9198 (1.0086)	loss 4.1089 (4.0768)	grad_norm 0.4715 (0.4759)	mem 38886MB
Train: [3/180][500/625]	eta 0:02:04 lr 0.799121	data 0.0006 (0.0430)	batch 0.9006 (0.9985)	loss 3.9750 (4.0703)	grad_norm 0.4615 (0.4754)	mem 38886MB
Train: [3/180][550/625]	eta 0:01:14 lr 0.799083	data 0.0005 (0.0391)	batch 0.8721 (0.9923)	loss 3.9123 (4.0626)	grad_norm 0.4728 (0.4746)	mem 38886MB
Train: [3/180][600/625]	eta 0:00:24 lr 0.799045	data 0.0005 (0.0359)	batch 1.2078 (0.9998)	loss 4.1867 (4.0579)	grad_norm 0.4589 (0.4743)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 3 training takes 0:10:25
Test: [0/25]	Time 15.088 (15.088)	Loss 2.3372 (2.3372)	Acc@1 49.463 (49.463)	Acc@5 73.438 (73.438)	Mem 38886MB
 * Acc@1 41.378 Acc@5 66.648
Accuracy of the network on the 50000 test images: 41.38%
Max accuracy (after decay): 41.38%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [4/180][0/625]	eta 3:53:55 lr 0.799026	data 20.8280 (20.8280)	batch 22.4575 (22.4575)	loss 3.7618 (3.7618)	grad_norm 0.4678 (0.4678)	mem 38886MB
Train: [4/180][50/625]	eta 0:12:42 lr 0.798986	data 0.0006 (0.4100)	batch 0.9014 (1.3256)	loss 4.0781 (3.9467)	grad_norm 0.4592 (0.4651)	mem 38886MB
Train: [4/180][100/625]	eta 0:09:46 lr 0.798946	data 0.0006 (0.2073)	batch 0.8751 (1.1169)	loss 3.9595 (3.9394)	grad_norm 0.4504 (0.4663)	mem 38886MB
Train: [4/180][150/625]	eta 0:08:17 lr 0.798905	data 0.0004 (0.1388)	batch 0.9109 (1.0471)	loss 3.8974 (3.9396)	grad_norm 0.4530 (0.4675)	mem 38886MB
Train: [4/180][200/625]	eta 0:07:09 lr 0.798864	data 0.0005 (0.1044)	batch 0.8763 (1.0104)	loss 4.0142 (3.9297)	grad_norm 0.4630 (0.4665)	mem 38886MB
Train: [4/180][250/625]	eta 0:06:10 lr 0.798821	data 0.0004 (0.0837)	batch 0.8987 (0.9893)	loss 3.7204 (3.9330)	grad_norm 0.4562 (0.4666)	mem 38886MB
Train: [4/180][300/625]	eta 0:05:16 lr 0.798778	data 0.0005 (0.0699)	batch 0.9207 (0.9752)	loss 3.9212 (3.9348)	grad_norm 0.4655 (0.4663)	mem 38886MB
Train: [4/180][350/625]	eta 0:04:25 lr 0.798734	data 0.0006 (0.0600)	batch 0.9193 (0.9655)	loss 3.8671 (3.9266)	grad_norm 0.4593 (0.4653)	mem 38886MB
Train: [4/180][400/625]	eta 0:03:35 lr 0.798689	data 0.0006 (0.0527)	batch 0.8648 (0.9568)	loss 3.7981 (3.9219)	grad_norm 0.4594 (0.4650)	mem 38886MB
Train: [4/180][450/625]	eta 0:02:46 lr 0.798644	data 0.0004 (0.0469)	batch 0.9245 (0.9513)	loss 4.1557 (3.9211)	grad_norm 0.4574 (0.4646)	mem 38886MB
Train: [4/180][500/625]	eta 0:01:58 lr 0.798597	data 0.0005 (0.0423)	batch 0.8994 (0.9468)	loss 3.8092 (3.9165)	grad_norm 0.4565 (0.4645)	mem 38886MB
Train: [4/180][550/625]	eta 0:01:10 lr 0.798550	data 0.0005 (0.0385)	batch 0.8862 (0.9426)	loss 3.8037 (3.9120)	grad_norm 0.4490 (0.4641)	mem 38886MB
Train: [4/180][600/625]	eta 0:00:23 lr 0.798502	data 0.0005 (0.0353)	batch 0.8985 (0.9390)	loss 3.8252 (3.9088)	grad_norm 0.4547 (0.4638)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 4 training takes 0:09:47
Test: [0/25]	Time 14.868 (14.868)	Loss 2.1323 (2.1323)	Acc@1 53.320 (53.320)	Acc@5 77.393 (77.393)	Mem 38886MB
 * Acc@1 43.838 Acc@5 69.282
Accuracy of the network on the 50000 test images: 43.84%
Max accuracy (after decay): 43.84%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [5/180][0/625]	eta 3:53:51 lr 0.798478	data 20.7822 (20.7822)	batch 22.4499 (22.4499)	loss 3.9262 (3.9262)	grad_norm 0.4597 (0.4597)	mem 38886MB
Train: [5/180][50/625]	eta 0:12:44 lr 0.798429	data 0.0005 (0.4083)	batch 0.9150 (1.3292)	loss 3.6482 (3.8098)	grad_norm 0.4725 (0.4599)	mem 38886MB
Train: [5/180][100/625]	eta 0:09:47 lr 0.798379	data 0.0006 (0.2065)	batch 0.8478 (1.1196)	loss 3.8616 (3.8037)	grad_norm 0.4523 (0.4601)	mem 38886MB
Train: [5/180][150/625]	eta 0:08:17 lr 0.798328	data 0.0005 (0.1383)	batch 0.8757 (1.0472)	loss 3.7366 (3.8102)	grad_norm 0.4479 (0.4604)	mem 38886MB
Train: [5/180][200/625]	eta 0:07:12 lr 0.798277	data 0.0005 (0.1040)	batch 0.9470 (1.0169)	loss 3.8866 (3.8131)	grad_norm 0.4607 (0.4604)	mem 38886MB
Train: [5/180][250/625]	eta 0:06:26 lr 0.798225	data 0.0006 (0.0834)	batch 1.1346 (1.0309)	loss 3.7653 (3.8141)	grad_norm 0.4594 (0.4601)	mem 38886MB
Train: [5/180][300/625]	eta 0:05:42 lr 0.798172	data 0.0006 (0.0696)	batch 1.1337 (1.0525)	loss 3.8960 (3.8120)	grad_norm 0.4518 (0.4598)	mem 38886MB
Train: [5/180][350/625]	eta 0:04:53 lr 0.798118	data 0.0005 (0.0598)	batch 1.1483 (1.0683)	loss 3.8874 (3.8083)	grad_norm 0.4576 (0.4599)	mem 38886MB
Train: [5/180][400/625]	eta 0:04:03 lr 0.798064	data 0.0005 (0.0524)	batch 1.1074 (1.0804)	loss 3.7736 (3.8044)	grad_norm 0.4880 (0.4594)	mem 38886MB
Train: [5/180][450/625]	eta 0:03:10 lr 0.798008	data 0.0005 (0.0467)	batch 1.1655 (1.0907)	loss 3.6183 (3.8030)	grad_norm 0.4533 (0.4591)	mem 38886MB
Train: [5/180][500/625]	eta 0:02:17 lr 0.797952	data 0.0006 (0.0421)	batch 1.1800 (1.0983)	loss 3.5007 (3.8013)	grad_norm 0.4506 (0.4588)	mem 38886MB
Train: [5/180][550/625]	eta 0:01:22 lr 0.797896	data 0.0005 (0.0383)	batch 1.1713 (1.1053)	loss 3.8434 (3.7997)	grad_norm 0.4441 (0.4582)	mem 38886MB
Train: [5/180][600/625]	eta 0:00:27 lr 0.797838	data 0.0006 (0.0352)	batch 1.1576 (1.1102)	loss 3.9368 (3.7944)	grad_norm 0.4576 (0.4577)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 5 training takes 0:11:36
Test: [0/25]	Time 15.052 (15.052)	Loss 1.9823 (1.9823)	Acc@1 56.787 (56.787)	Acc@5 80.469 (80.469)	Mem 38886MB
 * Acc@1 46.118 Acc@5 71.594
Accuracy of the network on the 50000 test images: 46.12%
Max accuracy (after decay): 46.12%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [6/180][0/625]	eta 4:02:19 lr 0.797809	data 20.6498 (20.6498)	batch 23.2633 (23.2633)	loss 3.8537 (3.8537)	grad_norm 0.4377 (0.4377)	mem 38886MB
Train: [6/180][50/625]	eta 0:15:20 lr 0.797750	data 0.0006 (0.4055)	batch 1.1914 (1.6010)	loss 3.6384 (3.7173)	grad_norm 0.4856 (0.4543)	mem 38886MB
Train: [6/180][100/625]	eta 0:12:08 lr 0.797691	data 0.0010 (0.2050)	batch 1.1778 (1.3881)	loss 3.7141 (3.7290)	grad_norm 0.4764 (0.4549)	mem 38886MB
Train: [6/180][150/625]	eta 0:10:24 lr 0.797630	data 0.0004 (0.1373)	batch 1.1570 (1.3158)	loss 3.8482 (3.7292)	grad_norm 0.4624 (0.4554)	mem 38886MB
Train: [6/180][200/625]	eta 0:09:03 lr 0.797569	data 0.0005 (0.1033)	batch 1.1595 (1.2779)	loss 3.8650 (3.7318)	grad_norm 0.4651 (0.4548)	mem 38886MB
Train: [6/180][250/625]	eta 0:07:50 lr 0.797507	data 0.0004 (0.0828)	batch 1.2144 (1.2553)	loss 3.8564 (3.7302)	grad_norm 0.4671 (0.4552)	mem 38886MB
Train: [6/180][300/625]	eta 0:06:43 lr 0.797445	data 0.0006 (0.0692)	batch 1.1548 (1.2404)	loss 3.7514 (3.7272)	grad_norm 0.4595 (0.4546)	mem 38886MB
Train: [6/180][350/625]	eta 0:05:38 lr 0.797381	data 0.0005 (0.0594)	batch 1.1544 (1.2298)	loss 3.6073 (3.7239)	grad_norm 0.4390 (0.4545)	mem 38886MB
Train: [6/180][400/625]	eta 0:04:35 lr 0.797317	data 0.0005 (0.0521)	batch 1.1704 (1.2224)	loss 3.7187 (3.7234)	grad_norm 0.4446 (0.4544)	mem 38886MB
Train: [6/180][450/625]	eta 0:03:32 lr 0.797252	data 0.0005 (0.0463)	batch 1.2312 (1.2161)	loss 3.6452 (3.7193)	grad_norm 0.4580 (0.4542)	mem 38886MB
Train: [6/180][500/625]	eta 0:02:31 lr 0.797186	data 0.0005 (0.0418)	batch 1.1652 (1.2121)	loss 3.7602 (3.7187)	grad_norm 0.4464 (0.4538)	mem 38886MB
Train: [6/180][550/625]	eta 0:01:30 lr 0.797120	data 0.0004 (0.0380)	batch 1.2057 (1.2084)	loss 3.7288 (3.7177)	grad_norm 0.4504 (0.4537)	mem 38886MB
Train: [6/180][600/625]	eta 0:00:30 lr 0.797053	data 0.0005 (0.0349)	batch 1.1600 (1.2054)	loss 3.5181 (3.7153)	grad_norm 0.4367 (0.4532)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 6 training takes 0:12:33
Test: [0/25]	Time 14.938 (14.938)	Loss 1.8878 (1.8878)	Acc@1 57.227 (57.227)	Acc@5 81.982 (81.982)	Mem 38886MB
 * Acc@1 46.914 Acc@5 72.112
Accuracy of the network on the 50000 test images: 46.91%
Max accuracy (after decay): 46.91%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [7/180][0/625]	eta 4:05:50 lr 0.797019	data 22.2028 (22.2028)	batch 23.6009 (23.6009)	loss 3.6541 (3.6541)	grad_norm 0.4574 (0.4574)	mem 38886MB
Train: [7/180][50/625]	eta 0:15:25 lr 0.796950	data 0.0005 (0.4359)	batch 1.1828 (1.6103)	loss 3.7119 (3.6311)	grad_norm 0.4433 (0.4504)	mem 38886MB
Train: [7/180][100/625]	eta 0:12:10 lr 0.796881	data 0.0006 (0.2204)	batch 1.1742 (1.3912)	loss 3.6959 (3.6496)	grad_norm 0.4655 (0.4511)	mem 38886MB
Train: [7/180][150/625]	eta 0:10:25 lr 0.796811	data 0.0005 (0.1476)	batch 1.1368 (1.3167)	loss 3.6036 (3.6458)	grad_norm 0.4649 (0.4509)	mem 38886MB
Train: [7/180][200/625]	eta 0:09:04 lr 0.796740	data 0.0005 (0.1110)	batch 1.1405 (1.2804)	loss 3.5884 (3.6413)	grad_norm 0.4454 (0.4521)	mem 38886MB
Train: [7/180][250/625]	eta 0:07:51 lr 0.796669	data 0.0007 (0.0890)	batch 1.1754 (1.2582)	loss 3.5470 (3.6433)	grad_norm 0.4705 (0.4518)	mem 38886MB
Train: [7/180][300/625]	eta 0:06:44 lr 0.796596	data 0.0005 (0.0743)	batch 1.2020 (1.2442)	loss 3.5743 (3.6427)	grad_norm 0.4589 (0.4516)	mem 38886MB
Train: [7/180][350/625]	eta 0:05:39 lr 0.796523	data 0.0005 (0.0638)	batch 1.1825 (1.2331)	loss 3.6185 (3.6441)	grad_norm 0.4356 (0.4512)	mem 38886MB
Train: [7/180][400/625]	eta 0:04:35 lr 0.796449	data 0.0005 (0.0559)	batch 1.1904 (1.2243)	loss 3.6757 (3.6460)	grad_norm 0.4394 (0.4506)	mem 38886MB
Train: [7/180][450/625]	eta 0:03:33 lr 0.796375	data 0.0009 (0.0498)	batch 1.1486 (1.2176)	loss 3.5357 (3.6417)	grad_norm 0.4456 (0.4506)	mem 38886MB
Train: [7/180][500/625]	eta 0:02:31 lr 0.796299	data 0.0005 (0.0449)	batch 1.1467 (1.2123)	loss 3.5308 (3.6397)	grad_norm 0.4382 (0.4507)	mem 38886MB
Train: [7/180][550/625]	eta 0:01:30 lr 0.796223	data 0.0005 (0.0409)	batch 1.1537 (1.2084)	loss 3.3234 (3.6394)	grad_norm 0.4389 (0.4504)	mem 38886MB
Train: [7/180][600/625]	eta 0:00:30 lr 0.796146	data 0.0006 (0.0375)	batch 1.1662 (1.2050)	loss 3.5316 (3.6380)	grad_norm 0.4562 (0.4503)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 7 training takes 0:12:33
Test: [0/25]	Time 14.665 (14.665)	Loss 1.8058 (1.8058)	Acc@1 59.863 (59.863)	Acc@5 82.715 (82.715)	Mem 38886MB
 * Acc@1 49.062 Acc@5 73.786
Accuracy of the network on the 50000 test images: 49.06%
Max accuracy (after decay): 49.06%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [8/180][0/625]	eta 4:08:21 lr 0.796107	data 20.7654 (20.7654)	batch 23.8431 (23.8431)	loss 3.7772 (3.7772)	grad_norm 0.4426 (0.4426)	mem 38886MB
Train: [8/180][50/625]	eta 0:15:28 lr 0.796029	data 0.0009 (0.4078)	batch 1.1905 (1.6152)	loss 3.7280 (3.6392)	grad_norm 0.4545 (0.4471)	mem 38886MB
Train: [8/180][100/625]	eta 0:12:12 lr 0.795950	data 0.0007 (0.2062)	batch 1.1589 (1.3947)	loss 3.8150 (3.6223)	grad_norm 0.4706 (0.4480)	mem 38886MB
Train: [8/180][150/625]	eta 0:10:26 lr 0.795871	data 0.0005 (0.1381)	batch 1.1684 (1.3190)	loss 3.6122 (3.6129)	grad_norm 0.4494 (0.4476)	mem 38886MB
Train: [8/180][200/625]	eta 0:09:04 lr 0.795790	data 0.0005 (0.1039)	batch 1.1599 (1.2819)	loss 3.4795 (3.6030)	grad_norm 0.4320 (0.4472)	mem 38886MB
Train: [8/180][250/625]	eta 0:07:52 lr 0.795709	data 0.0005 (0.0833)	batch 1.1348 (1.2598)	loss 3.8661 (3.6050)	grad_norm 0.4476 (0.4472)	mem 38886MB
Train: [8/180][300/625]	eta 0:06:44 lr 0.795627	data 0.0005 (0.0696)	batch 1.1522 (1.2450)	loss 3.6928 (3.6062)	grad_norm 0.4485 (0.4472)	mem 38886MB
Train: [8/180][350/625]	eta 0:05:39 lr 0.795544	data 0.0005 (0.0597)	batch 1.1398 (1.2348)	loss 3.5158 (3.6033)	grad_norm 0.4393 (0.4470)	mem 38886MB
Train: [8/180][400/625]	eta 0:04:36 lr 0.795461	data 0.0005 (0.0523)	batch 1.1619 (1.2267)	loss 3.7336 (3.6013)	grad_norm 0.4444 (0.4467)	mem 38886MB
Train: [8/180][450/625]	eta 0:03:33 lr 0.795377	data 0.0005 (0.0466)	batch 1.1925 (1.2206)	loss 3.3972 (3.5995)	grad_norm 0.4454 (0.4467)	mem 38886MB
Train: [8/180][500/625]	eta 0:02:31 lr 0.795292	data 0.0004 (0.0420)	batch 1.1986 (1.2155)	loss 3.7137 (3.6000)	grad_norm 0.4491 (0.4466)	mem 38886MB
Train: [8/180][550/625]	eta 0:01:30 lr 0.795206	data 0.0005 (0.0383)	batch 1.1820 (1.2111)	loss 3.7557 (3.6004)	grad_norm 0.4452 (0.4467)	mem 38886MB
Train: [8/180][600/625]	eta 0:00:30 lr 0.795119	data 0.0003 (0.0351)	batch 1.1615 (1.2077)	loss 3.8186 (3.5997)	grad_norm 0.4590 (0.4464)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 8 training takes 0:12:35
Test: [0/25]	Time 15.333 (15.333)	Loss 1.7034 (1.7034)	Acc@1 62.988 (62.988)	Acc@5 83.594 (83.594)	Mem 38886MB
 * Acc@1 50.094 Acc@5 74.708
Accuracy of the network on the 50000 test images: 50.09%
Max accuracy (after decay): 50.09%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [9/180][0/625]	eta 4:05:55 lr 0.795076	data 22.2231 (22.2231)	batch 23.6083 (23.6083)	loss 3.5495 (3.5495)	grad_norm 0.4406 (0.4406)	mem 38886MB
Train: [9/180][50/625]	eta 0:15:24 lr 0.794988	data 0.0006 (0.4364)	batch 1.1888 (1.6083)	loss 3.5592 (3.5460)	grad_norm 0.4401 (0.4447)	mem 38886MB
Train: [9/180][100/625]	eta 0:12:10 lr 0.794899	data 0.0004 (0.2206)	batch 1.1564 (1.3909)	loss 3.6017 (3.5434)	grad_norm 0.4497 (0.4452)	mem 38886MB
Train: [9/180][150/625]	eta 0:10:25 lr 0.794810	data 0.0004 (0.1478)	batch 1.1378 (1.3168)	loss 3.7920 (3.5526)	grad_norm 0.4350 (0.4462)	mem 38886MB
Train: [9/180][200/625]	eta 0:09:04 lr 0.794720	data 0.0006 (0.1111)	batch 1.1612 (1.2800)	loss 3.4815 (3.5537)	grad_norm 0.4353 (0.4458)	mem 38886MB
Train: [9/180][250/625]	eta 0:07:51 lr 0.794629	data 0.0004 (0.0891)	batch 1.1137 (1.2573)	loss 3.5365 (3.5508)	grad_norm 0.4373 (0.4463)	mem 38886MB
Train: [9/180][300/625]	eta 0:06:43 lr 0.794538	data 0.0006 (0.0744)	batch 1.1555 (1.2430)	loss 3.5267 (3.5502)	grad_norm 0.4287 (0.4461)	mem 38886MB
Train: [9/180][350/625]	eta 0:05:38 lr 0.794445	data 0.0008 (0.0639)	batch 1.1957 (1.2323)	loss 3.3727 (3.5509)	grad_norm 0.4536 (0.4459)	mem 38886MB
Train: [9/180][400/625]	eta 0:04:35 lr 0.794352	data 0.0009 (0.0560)	batch 1.2026 (1.2249)	loss 3.5803 (3.5550)	grad_norm 0.4621 (0.4459)	mem 38886MB
Train: [9/180][450/625]	eta 0:03:33 lr 0.794258	data 0.0006 (0.0499)	batch 1.1289 (1.2185)	loss 3.5389 (3.5537)	grad_norm 0.4337 (0.4458)	mem 38886MB
Train: [9/180][500/625]	eta 0:02:31 lr 0.794163	data 0.0006 (0.0449)	batch 1.1577 (1.2137)	loss 3.4616 (3.5529)	grad_norm 0.4445 (0.4457)	mem 38886MB
Train: [9/180][550/625]	eta 0:01:30 lr 0.794068	data 0.0006 (0.0409)	batch 1.1480 (1.2095)	loss 3.3882 (3.5525)	grad_norm 0.4351 (0.4456)	mem 38886MB
Train: [9/180][600/625]	eta 0:00:30 lr 0.793972	data 0.0008 (0.0376)	batch 1.1517 (1.2065)	loss 3.2714 (3.5525)	grad_norm 0.4334 (0.4456)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 9 training takes 0:12:34
Test: [0/25]	Time 14.827 (14.827)	Loss 1.7061 (1.7061)	Acc@1 61.523 (61.523)	Acc@5 84.863 (84.863)	Mem 38886MB
 * Acc@1 50.904 Acc@5 75.418
Accuracy of the network on the 50000 test images: 50.90%
Max accuracy (after decay): 50.90%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [10/180][0/625]	eta 4:00:00 lr 0.793923	data 21.6291 (21.6291)	batch 23.0415 (23.0415)	loss 3.4582 (3.4582)	grad_norm 0.4390 (0.4390)	mem 38886MB
Train: [10/180][50/625]	eta 0:15:22 lr 0.793826	data 0.0006 (0.4249)	batch 1.1787 (1.6038)	loss 3.4708 (3.5273)	grad_norm 0.4441 (0.4438)	mem 38886MB
Train: [10/180][100/625]	eta 0:12:08 lr 0.793728	data 0.0005 (0.2149)	batch 1.1504 (1.3879)	loss 3.3914 (3.5119)	grad_norm 0.4289 (0.4439)	mem 38886MB
Train: [10/180][150/625]	eta 0:10:26 lr 0.793629	data 0.0005 (0.1439)	batch 1.1450 (1.3180)	loss 3.5077 (3.5152)	grad_norm 0.4435 (0.4445)	mem 38886MB
Train: [10/180][200/625]	eta 0:09:04 lr 0.793529	data 0.0005 (0.1083)	batch 1.1497 (1.2802)	loss 3.5522 (3.5173)	grad_norm 0.4339 (0.4450)	mem 38886MB
Train: [10/180][250/625]	eta 0:07:52 lr 0.793429	data 0.0005 (0.0868)	batch 1.1955 (1.2591)	loss 3.5822 (3.5152)	grad_norm 0.4356 (0.4450)	mem 38886MB
Train: [10/180][300/625]	eta 0:06:44 lr 0.793328	data 0.0005 (0.0725)	batch 1.1837 (1.2450)	loss 3.5409 (3.5088)	grad_norm 0.4410 (0.4443)	mem 38886MB
Train: [10/180][350/625]	eta 0:05:39 lr 0.793226	data 0.0006 (0.0622)	batch 1.2102 (1.2343)	loss 3.6001 (3.5112)	grad_norm 0.4475 (0.4448)	mem 38886MB
Train: [10/180][400/625]	eta 0:04:36 lr 0.793123	data 0.0005 (0.0545)	batch 1.1388 (1.2269)	loss 3.3128 (3.5093)	grad_norm 0.4346 (0.4447)	mem 38886MB
Train: [10/180][450/625]	eta 0:03:33 lr 0.793020	data 0.0007 (0.0486)	batch 1.1632 (1.2207)	loss 3.5085 (3.5088)	grad_norm 0.4666 (0.4449)	mem 38886MB
Train: [10/180][500/625]	eta 0:02:31 lr 0.792915	data 0.0005 (0.0438)	batch 1.1448 (1.2160)	loss 3.4018 (3.5123)	grad_norm 0.4350 (0.4445)	mem 38886MB
Train: [10/180][550/625]	eta 0:01:30 lr 0.792810	data 0.0005 (0.0398)	batch 1.1263 (1.2118)	loss 3.4837 (3.5089)	grad_norm 0.4388 (0.4442)	mem 38886MB
Train: [10/180][600/625]	eta 0:00:30 lr 0.792704	data 0.0006 (0.0366)	batch 1.1610 (1.2084)	loss 3.5077 (3.5076)	grad_norm 0.4458 (0.4442)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 10 training takes 0:12:35
Test: [0/25]	Time 15.083 (15.083)	Loss 1.6044 (1.6044)	Acc@1 64.648 (64.648)	Acc@5 85.498 (85.498)	Mem 38886MB
 * Acc@1 50.816 Acc@5 75.436
Accuracy of the network on the 50000 test images: 50.82%
Max accuracy (after decay): 50.90%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [11/180][0/625]	eta 4:04:45 lr 0.792651	data 22.2458 (22.2458)	batch 23.4974 (23.4974)	loss 3.5503 (3.5503)	grad_norm 0.4500 (0.4500)	mem 38886MB
Train: [11/180][50/625]	eta 0:15:18 lr 0.792544	data 0.0003 (0.4374)	batch 0.8724 (1.5973)	loss 3.4779 (3.4695)	grad_norm 0.4524 (0.4450)	mem 38886MB
Train: [11/180][100/625]	eta 0:11:04 lr 0.792437	data 0.0008 (0.2212)	batch 0.8958 (1.2663)	loss 3.4070 (3.4759)	grad_norm 0.4361 (0.4452)	mem 38886MB
Train: [11/180][150/625]	eta 0:09:05 lr 0.792328	data 0.0006 (0.1484)	batch 0.9204 (1.1481)	loss 3.4748 (3.4699)	grad_norm 0.4480 (0.4447)	mem 38886MB
Train: [11/180][200/625]	eta 0:07:42 lr 0.792219	data 0.0007 (0.1117)	batch 0.8866 (1.0885)	loss 3.4673 (3.4757)	grad_norm 0.4489 (0.4447)	mem 38886MB
Train: [11/180][250/625]	eta 0:06:34 lr 0.792109	data 0.0010 (0.0896)	batch 0.8959 (1.0522)	loss 3.5140 (3.4786)	grad_norm 0.4378 (0.4442)	mem 38886MB
Train: [11/180][300/625]	eta 0:05:34 lr 0.791998	data 0.0007 (0.0748)	batch 0.9086 (1.0283)	loss 3.5728 (3.4798)	grad_norm 0.4364 (0.4439)	mem 38886MB
Train: [11/180][350/625]	eta 0:04:37 lr 0.791887	data 0.0006 (0.0643)	batch 0.9480 (1.0098)	loss 3.4221 (3.4789)	grad_norm 0.4498 (0.4441)	mem 38886MB
Train: [11/180][400/625]	eta 0:03:44 lr 0.791774	data 0.0006 (0.0564)	batch 0.8997 (0.9976)	loss 3.3109 (3.4772)	grad_norm 0.4360 (0.4438)	mem 38886MB
Train: [11/180][450/625]	eta 0:02:52 lr 0.791661	data 0.0009 (0.0502)	batch 0.8992 (0.9875)	loss 3.4817 (3.4799)	grad_norm 0.4337 (0.4439)	mem 38886MB
Train: [11/180][500/625]	eta 0:02:02 lr 0.791547	data 0.0006 (0.0453)	batch 0.8973 (0.9791)	loss 3.4104 (3.4791)	grad_norm 0.4448 (0.4437)	mem 38886MB
Train: [11/180][550/625]	eta 0:01:12 lr 0.791433	data 0.0006 (0.0412)	batch 0.8860 (0.9723)	loss 3.5209 (3.4798)	grad_norm 0.4413 (0.4438)	mem 38886MB
Train: [11/180][600/625]	eta 0:00:24 lr 0.791317	data 0.0006 (0.0379)	batch 0.8900 (0.9664)	loss 3.4619 (3.4782)	grad_norm 0.4442 (0.4436)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 11 training takes 0:10:03
Test: [0/25]	Time 14.883 (14.883)	Loss 1.7994 (1.7994)	Acc@1 61.523 (61.523)	Acc@5 83.594 (83.594)	Mem 38886MB
 * Acc@1 52.144 Acc@5 76.578
Accuracy of the network on the 50000 test images: 52.14%
Max accuracy (after decay): 52.14%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [12/180][0/625]	eta 3:58:50 lr 0.791259	data 20.6901 (20.6901)	batch 22.9295 (22.9295)	loss 3.6255 (3.6255)	grad_norm 0.4345 (0.4345)	mem 38886MB
Train: [12/180][50/625]	eta 0:12:52 lr 0.791143	data 0.0007 (0.4064)	batch 0.8725 (1.3428)	loss 3.5330 (3.4275)	grad_norm 0.4801 (0.4432)	mem 38886MB
Train: [12/180][100/625]	eta 0:09:51 lr 0.791026	data 0.0006 (0.2056)	batch 0.8886 (1.1265)	loss 3.3736 (3.4398)	grad_norm 0.4470 (0.4422)	mem 38886MB
Train: [12/180][150/625]	eta 0:08:20 lr 0.790908	data 0.0007 (0.1377)	batch 0.8985 (1.0530)	loss 3.4284 (3.4454)	grad_norm 0.4447 (0.4426)	mem 38886MB
Train: [12/180][200/625]	eta 0:07:12 lr 0.790789	data 0.0006 (0.1037)	batch 0.8939 (1.0170)	loss 3.4623 (3.4464)	grad_norm 0.4523 (0.4433)	mem 38886MB
Train: [12/180][250/625]	eta 0:06:13 lr 0.790669	data 0.0006 (0.0832)	batch 0.9169 (0.9948)	loss 3.4419 (3.4443)	grad_norm 0.4458 (0.4432)	mem 38886MB
Train: [12/180][300/625]	eta 0:05:18 lr 0.790549	data 0.0008 (0.0695)	batch 0.8809 (0.9797)	loss 3.6230 (3.4431)	grad_norm 0.4469 (0.4433)	mem 38886MB
Train: [12/180][350/625]	eta 0:04:26 lr 0.790428	data 0.0005 (0.0597)	batch 0.8815 (0.9691)	loss 3.4472 (3.4439)	grad_norm 0.4356 (0.4430)	mem 38886MB
Train: [12/180][400/625]	eta 0:03:36 lr 0.790306	data 0.0006 (0.0523)	batch 0.9722 (0.9610)	loss 3.6287 (3.4444)	grad_norm 0.4467 (0.4427)	mem 38886MB
Train: [12/180][450/625]	eta 0:02:47 lr 0.790184	data 0.0006 (0.0466)	batch 0.9285 (0.9552)	loss 3.4825 (3.4461)	grad_norm 0.4499 (0.4428)	mem 38886MB
Train: [12/180][500/625]	eta 0:01:58 lr 0.790060	data 0.0008 (0.0420)	batch 0.9276 (0.9504)	loss 3.4433 (3.4465)	grad_norm 0.4443 (0.4431)	mem 38886MB
Train: [12/180][550/625]	eta 0:01:10 lr 0.789936	data 0.0005 (0.0383)	batch 0.9058 (0.9460)	loss 3.4023 (3.4489)	grad_norm 0.4633 (0.4429)	mem 38886MB
Train: [12/180][600/625]	eta 0:00:23 lr 0.789811	data 0.0005 (0.0352)	batch 0.8768 (0.9423)	loss 3.7172 (3.4498)	grad_norm 0.4561 (0.4428)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 12 training takes 0:09:49
Test: [0/25]	Time 14.660 (14.660)	Loss 1.5387 (1.5387)	Acc@1 64.355 (64.355)	Acc@5 86.279 (86.279)	Mem 38886MB
 * Acc@1 52.586 Acc@5 76.926
Accuracy of the network on the 50000 test images: 52.59%
Max accuracy (after decay): 52.59%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [13/180][0/625]	eta 4:00:36 lr 0.789749	data 20.8250 (20.8250)	batch 23.0988 (23.0988)	loss 3.3332 (3.3332)	grad_norm 0.4292 (0.4292)	mem 38886MB
Train: [13/180][50/625]	eta 0:12:52 lr 0.789623	data 0.0007 (0.4091)	batch 0.8542 (1.3434)	loss 3.3914 (3.4153)	grad_norm 0.4479 (0.4428)	mem 38886MB
Train: [13/180][100/625]	eta 0:09:50 lr 0.789496	data 0.0012 (0.2070)	batch 0.9096 (1.1249)	loss 3.3978 (3.4091)	grad_norm 0.4393 (0.4429)	mem 38886MB
Train: [13/180][150/625]	eta 0:08:20 lr 0.789368	data 0.0007 (0.1387)	batch 1.1773 (1.0538)	loss 3.3275 (3.3996)	grad_norm 0.4452 (0.4433)	mem 38886MB
Train: [13/180][200/625]	eta 0:07:12 lr 0.789240	data 0.0006 (0.1044)	batch 0.9035 (1.0174)	loss 3.4898 (3.4014)	grad_norm 0.4419 (0.4434)	mem 38886MB
Train: [13/180][250/625]	eta 0:06:13 lr 0.789111	data 0.0007 (0.0837)	batch 0.8995 (0.9947)	loss 3.2352 (3.4065)	grad_norm 0.4417 (0.4434)	mem 38886MB
Train: [13/180][300/625]	eta 0:05:18 lr 0.788981	data 0.0003 (0.0700)	batch 0.8892 (0.9806)	loss 3.6344 (3.4059)	grad_norm 0.4364 (0.4429)	mem 38886MB
Train: [13/180][350/625]	eta 0:04:26 lr 0.788851	data 0.0006 (0.0601)	batch 0.8673 (0.9693)	loss 3.4615 (3.4072)	grad_norm 0.4353 (0.4433)	mem 38886MB
Train: [13/180][400/625]	eta 0:03:36 lr 0.788719	data 0.0006 (0.0527)	batch 0.8993 (0.9613)	loss 3.5071 (3.4096)	grad_norm 0.4344 (0.4432)	mem 38886MB
Train: [13/180][450/625]	eta 0:02:47 lr 0.788587	data 0.0007 (0.0469)	batch 0.8678 (0.9552)	loss 3.3454 (3.4092)	grad_norm 0.4395 (0.4429)	mem 38886MB
Train: [13/180][500/625]	eta 0:01:58 lr 0.788454	data 0.0005 (0.0423)	batch 0.8774 (0.9496)	loss 3.4402 (3.4091)	grad_norm 0.4525 (0.4435)	mem 38886MB
Train: [13/180][550/625]	eta 0:01:10 lr 0.788321	data 0.0004 (0.0386)	batch 0.8666 (0.9453)	loss 3.5684 (3.4146)	grad_norm 0.4369 (0.4433)	mem 38886MB
Train: [13/180][600/625]	eta 0:00:23 lr 0.788186	data 0.0006 (0.0354)	batch 0.9282 (0.9418)	loss 3.4136 (3.4144)	grad_norm 0.4346 (0.4430)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 13 training takes 0:09:49
Test: [0/25]	Time 14.985 (14.985)	Loss 1.5739 (1.5739)	Acc@1 64.209 (64.209)	Acc@5 86.426 (86.426)	Mem 38886MB
 * Acc@1 53.146 Acc@5 77.132
Accuracy of the network on the 50000 test images: 53.15%
Max accuracy (after decay): 53.15%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [14/180][0/625]	eta 4:00:28 lr 0.788119	data 22.0659 (22.0659)	batch 23.0864 (23.0864)	loss 3.3497 (3.3497)	grad_norm 0.4372 (0.4372)	mem 38886MB
Train: [14/180][50/625]	eta 0:12:53 lr 0.787983	data 0.0010 (0.4334)	batch 0.9190 (1.3459)	loss 3.1341 (3.4000)	grad_norm 0.4261 (0.4415)	mem 38886MB
Train: [14/180][100/625]	eta 0:09:53 lr 0.787847	data 0.0006 (0.2191)	batch 0.8885 (1.1313)	loss 3.5252 (3.3803)	grad_norm 0.4539 (0.4422)	mem 38886MB
Train: [14/180][150/625]	eta 0:08:22 lr 0.787710	data 0.0007 (0.1468)	batch 0.8787 (1.0572)	loss 3.5540 (3.3852)	grad_norm 0.4544 (0.4431)	mem 38886MB
Train: [14/180][200/625]	eta 0:07:14 lr 0.787572	data 0.0005 (0.1105)	batch 0.9106 (1.0216)	loss 3.2430 (3.3850)	grad_norm 0.4400 (0.4431)	mem 38886MB
Train: [14/180][250/625]	eta 0:06:14 lr 0.787434	data 0.0010 (0.0886)	batch 0.9202 (0.9993)	loss 3.2143 (3.3834)	grad_norm 0.4359 (0.4429)	mem 38886MB
Train: [14/180][300/625]	eta 0:05:19 lr 0.787295	data 0.0005 (0.0740)	batch 0.8941 (0.9839)	loss 3.3278 (3.3836)	grad_norm 0.4441 (0.4434)	mem 38886MB
Train: [14/180][350/625]	eta 0:04:27 lr 0.787155	data 0.0008 (0.0636)	batch 0.8941 (0.9741)	loss 3.4270 (3.3891)	grad_norm 0.4482 (0.4437)	mem 38886MB
Train: [14/180][400/625]	eta 0:03:37 lr 0.787014	data 0.0005 (0.0557)	batch 0.9447 (0.9650)	loss 3.3936 (3.3913)	grad_norm 0.4401 (0.4436)	mem 38886MB
Train: [14/180][450/625]	eta 0:02:47 lr 0.786872	data 0.0008 (0.0496)	batch 0.9069 (0.9589)	loss 3.2467 (3.3890)	grad_norm 0.4507 (0.4433)	mem 38886MB
Train: [14/180][500/625]	eta 0:01:59 lr 0.786730	data 0.0006 (0.0447)	batch 0.8763 (0.9538)	loss 3.3361 (3.3870)	grad_norm 0.4314 (0.4430)	mem 38886MB
Train: [14/180][550/625]	eta 0:01:11 lr 0.786587	data 0.0006 (0.0407)	batch 0.9268 (0.9494)	loss 3.3570 (3.3887)	grad_norm 0.4274 (0.4430)	mem 38886MB
Train: [14/180][600/625]	eta 0:00:23 lr 0.786443	data 0.0005 (0.0374)	batch 0.8836 (0.9464)	loss 3.3698 (3.3886)	grad_norm 0.4504 (0.4428)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 14 training takes 0:09:52
Test: [0/25]	Time 14.947 (14.947)	Loss 1.5724 (1.5724)	Acc@1 65.381 (65.381)	Acc@5 86.035 (86.035)	Mem 38886MB
 * Acc@1 52.954 Acc@5 77.246
Accuracy of the network on the 50000 test images: 52.95%
Max accuracy (after decay): 53.15%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [15/180][0/625]	eta 3:56:28 lr 0.786371	data 21.1371 (21.1371)	batch 22.7014 (22.7014)	loss 3.2278 (3.2278)	grad_norm 0.4350 (0.4350)	mem 38886MB
Train: [15/180][50/625]	eta 0:12:48 lr 0.786226	data 0.0007 (0.4152)	batch 0.9199 (1.3374)	loss 3.2659 (3.3436)	grad_norm 0.4447 (0.4392)	mem 38886MB
Train: [15/180][100/625]	eta 0:09:52 lr 0.786080	data 0.0007 (0.2101)	batch 0.9039 (1.1284)	loss 3.3788 (3.3506)	grad_norm 0.4928 (0.4425)	mem 38886MB
Train: [15/180][150/625]	eta 0:08:20 lr 0.785934	data 0.0005 (0.1408)	batch 0.9349 (1.0536)	loss 3.2613 (3.3629)	grad_norm 0.4405 (0.4421)	mem 38886MB
Train: [15/180][200/625]	eta 0:07:12 lr 0.785787	data 0.0006 (0.1060)	batch 0.9413 (1.0172)	loss 3.5848 (3.3682)	grad_norm 0.4421 (0.4432)	mem 38886MB
Train: [15/180][250/625]	eta 0:06:13 lr 0.785639	data 0.0006 (0.0850)	batch 0.8803 (0.9948)	loss 3.3665 (3.3736)	grad_norm 0.4423 (0.4434)	mem 38886MB
Train: [15/180][300/625]	eta 0:05:18 lr 0.785490	data 0.0007 (0.0710)	batch 0.8799 (0.9789)	loss 3.1990 (3.3700)	grad_norm 0.4407 (0.4433)	mem 38886MB
Train: [15/180][350/625]	eta 0:04:26 lr 0.785341	data 0.0008 (0.0610)	batch 0.8828 (0.9687)	loss 3.3443 (3.3738)	grad_norm 0.4299 (0.4431)	mem 38886MB
Train: [15/180][400/625]	eta 0:03:36 lr 0.785191	data 0.0011 (0.0535)	batch 0.8821 (0.9611)	loss 3.5326 (3.3759)	grad_norm 0.4493 (0.4435)	mem 38886MB
Train: [15/180][450/625]	eta 0:02:47 lr 0.785040	data 0.0007 (0.0476)	batch 0.9029 (0.9557)	loss 3.7012 (3.3781)	grad_norm 0.4487 (0.4435)	mem 38886MB
Train: [15/180][500/625]	eta 0:01:58 lr 0.784888	data 0.0007 (0.0430)	batch 0.9220 (0.9510)	loss 3.5537 (3.3786)	grad_norm 0.4370 (0.4433)	mem 38886MB
Train: [15/180][550/625]	eta 0:01:11 lr 0.784736	data 0.0005 (0.0392)	batch 0.9248 (0.9469)	loss 3.2445 (3.3792)	grad_norm 0.4629 (0.4431)	mem 38886MB
Train: [15/180][600/625]	eta 0:00:23 lr 0.784582	data 0.0006 (0.0360)	batch 0.9189 (0.9434)	loss 3.4019 (3.3779)	grad_norm 0.4518 (0.4430)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 15 training takes 0:09:50
Test: [0/25]	Time 14.641 (14.641)	Loss 1.4399 (1.4399)	Acc@1 66.943 (66.943)	Acc@5 86.914 (86.914)	Mem 38886MB
 * Acc@1 54.664 Acc@5 78.610
Accuracy of the network on the 50000 test images: 54.66%
Max accuracy (after decay): 54.66%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [16/180][0/625]	eta 4:03:11 lr 0.784505	data 22.3118 (22.3118)	batch 23.3461 (23.3461)	loss 3.3130 (3.3130)	grad_norm 0.4273 (0.4273)	mem 38886MB
Train: [16/180][50/625]	eta 0:12:54 lr 0.784351	data 0.0011 (0.4382)	batch 0.9422 (1.3465)	loss 3.3837 (3.3447)	grad_norm 0.4515 (0.4417)	mem 38886MB
Train: [16/180][100/625]	eta 0:09:54 lr 0.784196	data 0.0013 (0.2217)	batch 0.8911 (1.1327)	loss 3.4882 (3.3548)	grad_norm 0.4319 (0.4416)	mem 38886MB
Train: [16/180][150/625]	eta 0:08:23 lr 0.784040	data 0.0012 (0.1485)	batch 1.1263 (1.0591)	loss 3.3811 (3.3620)	grad_norm 0.4467 (0.4412)	mem 38886MB
Train: [16/180][200/625]	eta 0:07:13 lr 0.783884	data 0.0005 (0.1118)	batch 0.9053 (1.0206)	loss 3.3357 (3.3654)	grad_norm 0.4335 (0.4414)	mem 38886MB
Train: [16/180][250/625]	eta 0:06:14 lr 0.783726	data 0.0006 (0.0896)	batch 0.9632 (0.9984)	loss 3.3931 (3.3689)	grad_norm 0.4356 (0.4420)	mem 38886MB
Train: [16/180][300/625]	eta 0:05:19 lr 0.783568	data 0.0005 (0.0749)	batch 0.9106 (0.9828)	loss 3.0913 (3.3645)	grad_norm 0.4414 (0.4419)	mem 38886MB
Train: [16/180][350/625]	eta 0:04:27 lr 0.783410	data 0.0009 (0.0643)	batch 0.8408 (0.9722)	loss 3.2772 (3.3661)	grad_norm 0.4371 (0.4420)	mem 38886MB
Train: [16/180][400/625]	eta 0:03:36 lr 0.783250	data 0.0008 (0.0564)	batch 0.9173 (0.9637)	loss 3.2583 (3.3650)	grad_norm 0.4387 (0.4420)	mem 38886MB
Train: [16/180][450/625]	eta 0:02:47 lr 0.783090	data 0.0006 (0.0502)	batch 0.9083 (0.9569)	loss 3.5096 (3.3630)	grad_norm 0.4490 (0.4422)	mem 38886MB
Train: [16/180][500/625]	eta 0:01:58 lr 0.782929	data 0.0008 (0.0453)	batch 0.8912 (0.9515)	loss 3.2141 (3.3601)	grad_norm 0.4715 (0.4427)	mem 38886MB
Train: [16/180][550/625]	eta 0:01:11 lr 0.782767	data 0.0007 (0.0413)	batch 0.8948 (0.9478)	loss 3.2713 (3.3602)	grad_norm 0.4348 (0.4425)	mem 38886MB
Train: [16/180][600/625]	eta 0:00:23 lr 0.782604	data 0.0007 (0.0379)	batch 0.8727 (0.9443)	loss 3.2102 (3.3599)	grad_norm 0.4464 (0.4425)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 16 training takes 0:09:50
Test: [0/25]	Time 14.868 (14.868)	Loss 1.5692 (1.5692)	Acc@1 64.941 (64.941)	Acc@5 85.596 (85.596)	Mem 38886MB
 * Acc@1 53.454 Acc@5 77.698
Accuracy of the network on the 50000 test images: 53.45%
Max accuracy (after decay): 54.66%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [17/180][0/625]	eta 3:52:34 lr 0.782523	data 20.8636 (20.8636)	batch 22.3275 (22.3275)	loss 3.4828 (3.4828)	grad_norm 0.4670 (0.4670)	mem 38886MB
Train: [17/180][50/625]	eta 0:12:46 lr 0.782359	data 0.0007 (0.4101)	batch 0.8972 (1.3331)	loss 3.3770 (3.3468)	grad_norm 0.4417 (0.4417)	mem 38886MB
Train: [17/180][100/625]	eta 0:09:50 lr 0.782195	data 0.0007 (0.2078)	batch 0.8978 (1.1248)	loss 3.3448 (3.3346)	grad_norm 0.4261 (0.4411)	mem 38886MB
Train: [17/180][150/625]	eta 0:08:19 lr 0.782030	data 0.0006 (0.1392)	batch 0.9191 (1.0507)	loss 3.2720 (3.3340)	grad_norm 0.4451 (0.4416)	mem 38886MB
Train: [17/180][200/625]	eta 0:07:11 lr 0.781864	data 0.0006 (0.1048)	batch 0.9388 (1.0144)	loss 3.4106 (3.3403)	grad_norm 0.4351 (0.4421)	mem 38886MB
Train: [17/180][250/625]	eta 0:06:12 lr 0.781697	data 0.0006 (0.0840)	batch 0.8845 (0.9923)	loss 3.1677 (3.3381)	grad_norm 0.4442 (0.4425)	mem 38886MB
Train: [17/180][300/625]	eta 0:05:17 lr 0.781530	data 0.0004 (0.0701)	batch 0.9412 (0.9782)	loss 3.2725 (3.3394)	grad_norm 0.4507 (0.4428)	mem 38886MB
Train: [17/180][350/625]	eta 0:04:26 lr 0.781362	data 0.0005 (0.0602)	batch 0.8990 (0.9677)	loss 3.3718 (3.3432)	grad_norm 0.4483 (0.4428)	mem 38886MB
Train: [17/180][400/625]	eta 0:03:36 lr 0.781193	data 0.0006 (0.0528)	batch 0.8928 (0.9603)	loss 3.3320 (3.3399)	grad_norm 0.4423 (0.4428)	mem 38886MB
Train: [17/180][450/625]	eta 0:02:47 lr 0.781023	data 0.0006 (0.0470)	batch 0.8907 (0.9543)	loss 3.2416 (3.3434)	grad_norm 0.4497 (0.4426)	mem 38886MB
Train: [17/180][500/625]	eta 0:01:58 lr 0.780853	data 0.0007 (0.0423)	batch 0.9294 (0.9487)	loss 3.3768 (3.3427)	grad_norm 0.4407 (0.4430)	mem 38886MB
Train: [17/180][550/625]	eta 0:01:10 lr 0.780682	data 0.0006 (0.0386)	batch 0.8941 (0.9442)	loss 3.6037 (3.3430)	grad_norm 0.4310 (0.4429)	mem 38886MB
Train: [17/180][600/625]	eta 0:00:23 lr 0.780510	data 0.0006 (0.0354)	batch 0.9378 (0.9413)	loss 3.2764 (3.3420)	grad_norm 0.4622 (0.4428)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 17 training takes 0:09:48
Test: [0/25]	Time 14.870 (14.870)	Loss 1.6129 (1.6129)	Acc@1 65.039 (65.039)	Acc@5 85.645 (85.645)	Mem 38886MB
 * Acc@1 54.490 Acc@5 78.354
Accuracy of the network on the 50000 test images: 54.49%
Max accuracy (after decay): 54.66%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [18/180][0/625]	eta 3:55:27 lr 0.780424	data 21.7388 (21.7388)	batch 22.6041 (22.6041)	loss 3.4954 (3.4954)	grad_norm 0.4367 (0.4367)	mem 38886MB
Train: [18/180][50/625]	eta 0:12:51 lr 0.780251	data 0.0006 (0.4271)	batch 0.9085 (1.3415)	loss 3.3959 (3.3161)	grad_norm 0.4468 (0.4415)	mem 38886MB
Train: [18/180][100/625]	eta 0:09:52 lr 0.780077	data 0.0005 (0.2159)	batch 0.9278 (1.1282)	loss 3.2219 (3.3122)	grad_norm 0.4439 (0.4431)	mem 38886MB
Train: [18/180][150/625]	eta 0:08:21 lr 0.779903	data 0.0006 (0.1446)	batch 0.9104 (1.0561)	loss 3.5801 (3.3165)	grad_norm 0.4413 (0.4440)	mem 38886MB
Train: [18/180][200/625]	eta 0:07:12 lr 0.779727	data 0.0004 (0.1088)	batch 0.9154 (1.0186)	loss 3.0739 (3.3133)	grad_norm 0.4290 (0.4435)	mem 38886MB
Train: [18/180][250/625]	eta 0:06:13 lr 0.779551	data 0.0006 (0.0872)	batch 0.8647 (0.9964)	loss 3.2673 (3.3143)	grad_norm 0.4468 (0.4436)	mem 38886MB
Train: [18/180][300/625]	eta 0:05:19 lr 0.779375	data 0.0005 (0.0728)	batch 0.8841 (0.9819)	loss 3.4716 (3.3147)	grad_norm 0.4386 (0.4435)	mem 38886MB
Train: [18/180][350/625]	eta 0:04:27 lr 0.779197	data 0.0005 (0.0625)	batch 0.9231 (0.9716)	loss 3.2895 (3.3133)	grad_norm 0.4346 (0.4436)	mem 38886MB
Train: [18/180][400/625]	eta 0:03:36 lr 0.779019	data 0.0005 (0.0548)	batch 0.9099 (0.9636)	loss 3.4468 (3.3133)	grad_norm 0.4417 (0.4434)	mem 38886MB
Train: [18/180][450/625]	eta 0:02:47 lr 0.778840	data 0.0004 (0.0488)	batch 0.8951 (0.9578)	loss 3.1601 (3.3165)	grad_norm 0.4336 (0.4433)	mem 38886MB
Train: [18/180][500/625]	eta 0:01:59 lr 0.778661	data 0.0005 (0.0440)	batch 0.8686 (0.9531)	loss 3.2147 (3.3179)	grad_norm 0.4436 (0.4432)	mem 38886MB
Train: [18/180][550/625]	eta 0:01:11 lr 0.778480	data 0.0004 (0.0400)	batch 0.8901 (0.9494)	loss 3.2306 (3.3179)	grad_norm 0.4427 (0.4431)	mem 38886MB
Train: [18/180][600/625]	eta 0:00:23 lr 0.778299	data 0.0007 (0.0367)	batch 0.9372 (0.9458)	loss 3.2771 (3.3182)	grad_norm 0.4571 (0.4430)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 18 training takes 0:09:51
Test: [0/25]	Time 14.828 (14.828)	Loss 1.4209 (1.4209)	Acc@1 67.480 (67.480)	Acc@5 87.256 (87.256)	Mem 38886MB
 * Acc@1 54.860 Acc@5 78.932
Accuracy of the network on the 50000 test images: 54.86%
Max accuracy (after decay): 54.86%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [19/180][0/625]	eta 3:57:00 lr 0.778209	data 21.1684 (21.1684)	batch 22.7536 (22.7536)	loss 3.2816 (3.2816)	grad_norm 0.4467 (0.4467)	mem 38886MB
Train: [19/180][50/625]	eta 0:12:46 lr 0.778026	data 0.0005 (0.4157)	batch 0.8870 (1.3334)	loss 3.2263 (3.2801)	grad_norm 0.4300 (0.4442)	mem 38886MB
Train: [19/180][100/625]	eta 0:09:48 lr 0.777843	data 0.0005 (0.2103)	batch 0.9004 (1.1205)	loss 3.2125 (3.2813)	grad_norm 0.4352 (0.4432)	mem 38886MB
Train: [19/180][150/625]	eta 0:08:18 lr 0.777660	data 0.0003 (0.1409)	batch 0.8915 (1.0492)	loss 3.2779 (3.2821)	grad_norm 0.4496 (0.4439)	mem 38886MB
Train: [19/180][200/625]	eta 0:07:11 lr 0.777475	data 0.0011 (0.1060)	batch 0.9345 (1.0154)	loss 3.5009 (3.2890)	grad_norm 0.4441 (0.4437)	mem 38886MB
Train: [19/180][250/625]	eta 0:06:12 lr 0.777290	data 0.0006 (0.0850)	batch 0.9059 (0.9933)	loss 3.4233 (3.2938)	grad_norm 0.4665 (0.4440)	mem 38886MB
Train: [19/180][300/625]	eta 0:05:17 lr 0.777104	data 0.0007 (0.0710)	batch 0.8646 (0.9779)	loss 3.1791 (3.2940)	grad_norm 0.4509 (0.4440)	mem 38886MB
Train: [19/180][350/625]	eta 0:04:26 lr 0.776918	data 0.0007 (0.0610)	batch 0.8995 (0.9685)	loss 3.2191 (3.2958)	grad_norm 0.4457 (0.4443)	mem 38886MB
Train: [19/180][400/625]	eta 0:03:36 lr 0.776730	data 0.0007 (0.0535)	batch 0.9000 (0.9612)	loss 3.1665 (3.2969)	grad_norm 0.4334 (0.4445)	mem 38886MB
Train: [19/180][450/625]	eta 0:02:47 lr 0.776542	data 0.0008 (0.0477)	batch 0.8995 (0.9562)	loss 3.2071 (3.2988)	grad_norm 0.4330 (0.4445)	mem 38886MB
Train: [19/180][500/625]	eta 0:01:58 lr 0.776353	data 0.0006 (0.0430)	batch 0.8985 (0.9515)	loss 3.3433 (3.3002)	grad_norm 0.4384 (0.4445)	mem 38886MB
Train: [19/180][550/625]	eta 0:01:11 lr 0.776164	data 0.0006 (0.0392)	batch 0.9287 (0.9470)	loss 3.2416 (3.2983)	grad_norm 0.4512 (0.4443)	mem 38886MB
Train: [19/180][600/625]	eta 0:00:23 lr 0.775974	data 0.0011 (0.0361)	batch 0.8620 (0.9442)	loss 3.4068 (3.2964)	grad_norm 0.4450 (0.4442)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 19 training takes 0:09:50
Test: [0/25]	Time 14.850 (14.850)	Loss 1.4754 (1.4754)	Acc@1 67.480 (67.480)	Acc@5 87.646 (87.646)	Mem 38886MB
 * Acc@1 54.922 Acc@5 78.678
Accuracy of the network on the 50000 test images: 54.92%
Max accuracy (after decay): 54.92%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [20/180][0/625]	eta 3:51:41 lr 0.775878	data 20.6430 (20.6430)	batch 22.2421 (22.2421)	loss 3.3308 (3.3308)	grad_norm 0.4543 (0.4543)	mem 38886MB
Train: [20/180][50/625]	eta 0:12:41 lr 0.775687	data 0.0008 (0.4059)	batch 0.8872 (1.3236)	loss 3.2857 (3.2833)	grad_norm 0.4424 (0.4447)	mem 38886MB
Train: [20/180][100/625]	eta 0:09:46 lr 0.775495	data 0.0014 (0.2054)	batch 0.8891 (1.1181)	loss 3.3727 (3.2810)	grad_norm 0.4450 (0.4441)	mem 38886MB
Train: [20/180][150/625]	eta 0:08:17 lr 0.775302	data 0.0007 (0.1376)	batch 0.8978 (1.0482)	loss 3.2174 (3.2856)	grad_norm 0.4425 (0.4435)	mem 38886MB
Train: [20/180][200/625]	eta 0:07:10 lr 0.775108	data 0.0006 (0.1040)	batch 0.8560 (1.0140)	loss 3.3301 (3.2889)	grad_norm 0.4333 (0.4441)	mem 38886MB
Train: [20/180][250/625]	eta 0:06:11 lr 0.774914	data 0.0006 (0.0834)	batch 0.9114 (0.9914)	loss 3.1832 (3.2873)	grad_norm 0.4446 (0.4441)	mem 38886MB
Train: [20/180][300/625]	eta 0:05:17 lr 0.774719	data 0.0007 (0.0697)	batch 0.9331 (0.9776)	loss 3.0818 (3.2918)	grad_norm 0.4582 (0.4442)	mem 38886MB
Train: [20/180][350/625]	eta 0:04:25 lr 0.774523	data 0.0012 (0.0599)	batch 0.9183 (0.9673)	loss 3.2899 (3.2908)	grad_norm 0.4334 (0.4439)	mem 38886MB
Train: [20/180][400/625]	eta 0:03:35 lr 0.774327	data 0.0007 (0.0525)	batch 0.9037 (0.9593)	loss 3.1549 (3.2905)	grad_norm 0.4596 (0.4441)	mem 38886MB
Train: [20/180][450/625]	eta 0:02:46 lr 0.774130	data 0.0008 (0.0468)	batch 0.9056 (0.9533)	loss 3.3578 (3.2902)	grad_norm 0.4424 (0.4441)	mem 38886MB
Train: [20/180][500/625]	eta 0:01:58 lr 0.773932	data 0.0006 (0.0422)	batch 0.9007 (0.9483)	loss 3.3483 (3.2896)	grad_norm 0.4355 (0.4440)	mem 38886MB
Train: [20/180][550/625]	eta 0:01:10 lr 0.773733	data 0.0007 (0.0384)	batch 0.8762 (0.9441)	loss 3.2468 (3.2921)	grad_norm 0.4389 (0.4439)	mem 38886MB
Train: [20/180][600/625]	eta 0:00:23 lr 0.773533	data 0.0008 (0.0353)	batch 0.8842 (0.9410)	loss 3.1667 (3.2934)	grad_norm 0.4332 (0.4437)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 20 training takes 0:09:48
Test: [0/25]	Time 14.948 (14.948)	Loss 1.3805 (1.3805)	Acc@1 68.408 (68.408)	Acc@5 89.062 (89.062)	Mem 38886MB
 * Acc@1 55.448 Acc@5 79.526
Accuracy of the network on the 50000 test images: 55.45%
Max accuracy (after decay): 55.45%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [21/180][0/625]	eta 3:58:46 lr 0.773433	data 22.0343 (22.0343)	batch 22.9220 (22.9220)	loss 3.2487 (3.2487)	grad_norm 0.4359 (0.4359)	mem 38886MB
Train: [21/180][50/625]	eta 0:12:52 lr 0.773233	data 0.0005 (0.4327)	batch 0.8984 (1.3431)	loss 3.2313 (3.3027)	grad_norm 0.4520 (0.4421)	mem 38886MB
Train: [21/180][100/625]	eta 0:09:51 lr 0.773032	data 0.0009 (0.2189)	batch 0.8864 (1.1263)	loss 3.3178 (3.2890)	grad_norm 0.4461 (0.4434)	mem 38886MB
Train: [21/180][150/625]	eta 0:08:19 lr 0.772830	data 0.0007 (0.1466)	batch 0.8690 (1.0507)	loss 3.5201 (3.2779)	grad_norm 0.4408 (0.4439)	mem 38886MB
Train: [21/180][200/625]	eta 0:07:11 lr 0.772627	data 0.0007 (0.1103)	batch 0.8883 (1.0156)	loss 3.1096 (3.2709)	grad_norm 0.4488 (0.4446)	mem 38886MB
Train: [21/180][250/625]	eta 0:06:12 lr 0.772424	data 0.0011 (0.0885)	batch 0.8896 (0.9942)	loss 3.4154 (3.2682)	grad_norm 0.4475 (0.4441)	mem 38886MB
Train: [21/180][300/625]	eta 0:05:18 lr 0.772220	data 0.0007 (0.0740)	batch 0.9196 (0.9794)	loss 3.1799 (3.2681)	grad_norm 0.4399 (0.4442)	mem 38886MB
Train: [21/180][350/625]	eta 0:04:26 lr 0.772015	data 0.0010 (0.0635)	batch 0.9099 (0.9692)	loss 3.2143 (3.2640)	grad_norm 0.4471 (0.4443)	mem 38886MB
Train: [21/180][400/625]	eta 0:03:36 lr 0.771809	data 0.0006 (0.0557)	batch 0.9002 (0.9601)	loss 3.0741 (3.2631)	grad_norm 0.4314 (0.4444)	mem 38886MB
Train: [21/180][450/625]	eta 0:02:47 lr 0.771603	data 0.0006 (0.0496)	batch 0.9141 (0.9547)	loss 3.5849 (3.2639)	grad_norm 0.4538 (0.4443)	mem 38886MB
Train: [21/180][500/625]	eta 0:01:58 lr 0.771396	data 0.0008 (0.0448)	batch 0.8990 (0.9496)	loss 3.2741 (3.2645)	grad_norm 0.4445 (0.4443)	mem 38886MB
Train: [21/180][550/625]	eta 0:01:10 lr 0.771188	data 0.0008 (0.0408)	batch 0.8765 (0.9456)	loss 3.2215 (3.2646)	grad_norm 0.4328 (0.4440)	mem 38886MB
Train: [21/180][600/625]	eta 0:00:23 lr 0.770980	data 0.0004 (0.0374)	batch 0.9189 (0.9425)	loss 3.2367 (3.2670)	grad_norm 0.4355 (0.4442)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 21 training takes 0:09:49
Test: [0/25]	Time 14.750 (14.750)	Loss 1.4960 (1.4960)	Acc@1 68.945 (68.945)	Acc@5 88.184 (88.184)	Mem 38886MB
 * Acc@1 56.322 Acc@5 79.858
Accuracy of the network on the 50000 test images: 56.32%
Max accuracy (after decay): 56.32%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [22/180][0/625]	eta 3:56:36 lr 0.770875	data 20.6567 (20.6567)	batch 22.7141 (22.7141)	loss 3.3447 (3.3447)	grad_norm 0.4408 (0.4408)	mem 38886MB
Train: [22/180][50/625]	eta 0:12:48 lr 0.770665	data 0.0006 (0.4060)	batch 0.9518 (1.3372)	loss 3.2478 (3.2583)	grad_norm 0.4366 (0.4409)	mem 38886MB
Train: [22/180][100/625]	eta 0:09:51 lr 0.770455	data 0.0010 (0.2054)	batch 0.9184 (1.1262)	loss 3.0733 (3.2668)	grad_norm 0.4314 (0.4417)	mem 38886MB
Train: [22/180][150/625]	eta 0:08:20 lr 0.770244	data 0.0012 (0.1376)	batch 0.8767 (1.0547)	loss 3.3556 (3.2598)	grad_norm 0.4410 (0.4422)	mem 38886MB
Train: [22/180][200/625]	eta 0:07:12 lr 0.770032	data 0.0006 (0.1036)	batch 0.8733 (1.0185)	loss 3.4382 (3.2605)	grad_norm 0.4485 (0.4437)	mem 38886MB
Train: [22/180][250/625]	eta 0:06:13 lr 0.769820	data 0.0016 (0.0831)	batch 0.8604 (0.9963)	loss 3.2881 (3.2604)	grad_norm 0.4424 (0.4438)	mem 38886MB
Train: [22/180][300/625]	eta 0:05:18 lr 0.769607	data 0.0007 (0.0695)	batch 0.9195 (0.9814)	loss 3.3392 (3.2638)	grad_norm 0.4324 (0.4438)	mem 38886MB
Train: [22/180][350/625]	eta 0:04:26 lr 0.769393	data 0.0007 (0.0597)	batch 0.8684 (0.9707)	loss 3.2834 (3.2607)	grad_norm 0.4563 (0.4438)	mem 38886MB
Train: [22/180][400/625]	eta 0:03:36 lr 0.769178	data 0.0007 (0.0524)	batch 0.8948 (0.9632)	loss 3.1742 (3.2632)	grad_norm 0.4495 (0.4438)	mem 38886MB
Train: [22/180][450/625]	eta 0:02:47 lr 0.768963	data 0.0006 (0.0467)	batch 0.8914 (0.9572)	loss 3.3513 (3.2624)	grad_norm 0.4621 (0.4438)	mem 38886MB
Train: [22/180][500/625]	eta 0:01:59 lr 0.768747	data 0.0005 (0.0421)	batch 0.9123 (0.9524)	loss 3.2567 (3.2628)	grad_norm 0.4443 (0.4438)	mem 38886MB
Train: [22/180][550/625]	eta 0:01:11 lr 0.768530	data 0.0005 (0.0383)	batch 0.8940 (0.9480)	loss 3.1105 (3.2633)	grad_norm 0.4691 (0.4439)	mem 38886MB
Train: [22/180][600/625]	eta 0:00:23 lr 0.768313	data 0.0004 (0.0352)	batch 0.9050 (0.9444)	loss 3.2103 (3.2648)	grad_norm 0.4409 (0.4438)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 22 training takes 0:09:50
Test: [0/25]	Time 14.812 (14.812)	Loss 1.4172 (1.4172)	Acc@1 67.920 (67.920)	Acc@5 87.891 (87.891)	Mem 38886MB
 * Acc@1 56.196 Acc@5 79.508
Accuracy of the network on the 50000 test images: 56.20%
Max accuracy (after decay): 56.32%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [23/180][0/625]	eta 4:00:24 lr 0.768204	data 21.6272 (21.6272)	batch 23.0785 (23.0785)	loss 3.1257 (3.1257)	grad_norm 0.4458 (0.4458)	mem 38886MB
Train: [23/180][50/625]	eta 0:12:52 lr 0.767985	data 0.0006 (0.4248)	batch 0.9042 (1.3428)	loss 3.3627 (3.2063)	grad_norm 0.4473 (0.4415)	mem 38886MB
Train: [23/180][100/625]	eta 0:09:52 lr 0.767766	data 0.0005 (0.2149)	batch 0.8921 (1.1284)	loss 3.1504 (3.2273)	grad_norm 0.4541 (0.4433)	mem 38886MB
Train: [23/180][150/625]	eta 0:08:20 lr 0.767546	data 0.0006 (0.1440)	batch 0.8815 (1.0528)	loss 3.3675 (3.2429)	grad_norm 0.4481 (0.4450)	mem 38886MB
Train: [23/180][200/625]	eta 0:07:11 lr 0.767325	data 0.0007 (0.1083)	batch 0.8414 (1.0147)	loss 3.1312 (3.2382)	grad_norm 0.4373 (0.4443)	mem 38886MB
Train: [23/180][250/625]	eta 0:06:12 lr 0.767103	data 0.0006 (0.0869)	batch 1.1294 (0.9944)	loss 3.3605 (3.2397)	grad_norm 0.4377 (0.4446)	mem 38886MB
Train: [23/180][300/625]	eta 0:05:18 lr 0.766881	data 0.0006 (0.0727)	batch 0.9341 (0.9793)	loss 3.2778 (3.2405)	grad_norm 0.4454 (0.4446)	mem 38886MB
Train: [23/180][350/625]	eta 0:04:26 lr 0.766658	data 0.0006 (0.0624)	batch 0.9058 (0.9682)	loss 3.2231 (3.2419)	grad_norm 0.4346 (0.4446)	mem 38886MB
Train: [23/180][400/625]	eta 0:03:36 lr 0.766435	data 0.0006 (0.0547)	batch 0.8993 (0.9600)	loss 3.1219 (3.2431)	grad_norm 0.4357 (0.4448)	mem 38886MB
Train: [23/180][450/625]	eta 0:02:46 lr 0.766211	data 0.0005 (0.0487)	batch 0.9093 (0.9540)	loss 3.2938 (3.2442)	grad_norm 0.4390 (0.4450)	mem 38886MB
Train: [23/180][500/625]	eta 0:01:58 lr 0.765986	data 0.0005 (0.0439)	batch 0.8961 (0.9489)	loss 3.0200 (3.2444)	grad_norm 0.4622 (0.4451)	mem 38886MB
Train: [23/180][550/625]	eta 0:01:10 lr 0.765760	data 0.0006 (0.0400)	batch 0.9146 (0.9450)	loss 3.3820 (3.2438)	grad_norm 0.4486 (0.4451)	mem 38886MB
Train: [23/180][600/625]	eta 0:00:23 lr 0.765533	data 0.0005 (0.0367)	batch 0.8986 (0.9414)	loss 3.4108 (3.2437)	grad_norm 0.4475 (0.4452)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 23 training takes 0:09:48
Test: [0/25]	Time 14.882 (14.882)	Loss 1.4340 (1.4340)	Acc@1 68.311 (68.311)	Acc@5 87.354 (87.354)	Mem 38886MB
 * Acc@1 56.850 Acc@5 80.128
Accuracy of the network on the 50000 test images: 56.85%
Max accuracy (after decay): 56.85%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [24/180][0/625]	eta 3:56:51 lr 0.765420	data 21.3463 (21.3463)	batch 22.7387 (22.7387)	loss 3.1649 (3.1649)	grad_norm 0.4441 (0.4441)	mem 38886MB
Train: [24/180][50/625]	eta 0:13:00 lr 0.765192	data 0.0006 (0.4194)	batch 0.9435 (1.3566)	loss 3.2054 (3.2300)	grad_norm 0.4449 (0.4425)	mem 38886MB
Train: [24/180][100/625]	eta 0:10:21 lr 0.764964	data 0.0006 (0.2128)	batch 1.1913 (1.1830)	loss 2.9990 (3.2234)	grad_norm 0.4357 (0.4437)	mem 38886MB
Train: [24/180][150/625]	eta 0:09:22 lr 0.764735	data 0.0005 (0.1426)	batch 1.2166 (1.1839)	loss 3.1354 (3.2295)	grad_norm 0.4455 (0.4451)	mem 38886MB
Train: [24/180][200/625]	eta 0:08:22 lr 0.764506	data 0.0008 (0.1074)	batch 1.2094 (1.1821)	loss 3.4249 (3.2370)	grad_norm 0.4457 (0.4459)	mem 38886MB
Train: [24/180][250/625]	eta 0:07:23 lr 0.764275	data 0.0005 (0.0861)	batch 1.1788 (1.1815)	loss 3.0693 (3.2394)	grad_norm 0.4696 (0.4459)	mem 38886MB
Train: [24/180][300/625]	eta 0:06:23 lr 0.764044	data 0.0007 (0.0719)	batch 1.1964 (1.1802)	loss 3.0521 (3.2371)	grad_norm 0.4428 (0.4459)	mem 38886MB
Train: [24/180][350/625]	eta 0:05:24 lr 0.763812	data 0.0008 (0.0618)	batch 1.1394 (1.1796)	loss 3.3278 (3.2341)	grad_norm 0.4398 (0.4460)	mem 38886MB
Train: [24/180][400/625]	eta 0:04:25 lr 0.763580	data 0.0006 (0.0542)	batch 1.1416 (1.1788)	loss 3.3443 (3.2375)	grad_norm 0.4398 (0.4460)	mem 38886MB
Train: [24/180][450/625]	eta 0:03:26 lr 0.763347	data 0.0006 (0.0482)	batch 1.1883 (1.1788)	loss 3.1229 (3.2383)	grad_norm 0.4503 (0.4458)	mem 38886MB
Train: [24/180][500/625]	eta 0:02:27 lr 0.763113	data 0.0006 (0.0435)	batch 1.0949 (1.1780)	loss 3.1718 (3.2392)	grad_norm 0.4609 (0.4458)	mem 38886MB
Train: [24/180][550/625]	eta 0:01:28 lr 0.762878	data 0.0005 (0.0396)	batch 1.1837 (1.1776)	loss 2.9890 (3.2391)	grad_norm 0.4395 (0.4459)	mem 38886MB
Train: [24/180][600/625]	eta 0:00:29 lr 0.762643	data 0.0006 (0.0363)	batch 1.1461 (1.1773)	loss 3.2935 (3.2408)	grad_norm 0.4357 (0.4458)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 24 training takes 0:12:16
Test: [0/25]	Time 14.782 (14.782)	Loss 1.3827 (1.3827)	Acc@1 69.189 (69.189)	Acc@5 88.965 (88.965)	Mem 38886MB
 * Acc@1 56.766 Acc@5 80.364
Accuracy of the network on the 50000 test images: 56.77%
Max accuracy (after decay): 56.85%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [25/180][0/625]	eta 4:06:53 lr 0.762525	data 22.1868 (22.1868)	batch 23.7022 (23.7022)	loss 3.2743 (3.2743)	grad_norm 0.4306 (0.4306)	mem 38886MB
Train: [25/180][50/625]	eta 0:15:31 lr 0.762289	data 0.0005 (0.4357)	batch 1.1652 (1.6204)	loss 3.2503 (3.2329)	grad_norm 0.4427 (0.4436)	mem 38886MB
Train: [25/180][100/625]	eta 0:11:50 lr 0.762052	data 0.0004 (0.2206)	batch 0.9203 (1.3538)	loss 3.2660 (3.2242)	grad_norm 0.4375 (0.4452)	mem 38886MB
Train: [25/180][150/625]	eta 0:09:32 lr 0.761814	data 0.0005 (0.1477)	batch 0.9353 (1.2054)	loss 3.1998 (3.2199)	grad_norm 0.4585 (0.4451)	mem 38886MB
Train: [25/180][200/625]	eta 0:08:01 lr 0.761575	data 0.0006 (0.1111)	batch 0.9360 (1.1333)	loss 3.1764 (3.2197)	grad_norm 0.4544 (0.4456)	mem 38886MB
Train: [25/180][250/625]	eta 0:06:48 lr 0.761336	data 0.0005 (0.0891)	batch 0.9638 (1.0889)	loss 3.2094 (3.2194)	grad_norm 0.4338 (0.4459)	mem 38886MB
Train: [25/180][300/625]	eta 0:05:44 lr 0.761096	data 0.0004 (0.0744)	batch 0.9330 (1.0590)	loss 3.1266 (3.2183)	grad_norm 0.4337 (0.4462)	mem 38886MB
Train: [25/180][350/625]	eta 0:04:45 lr 0.760856	data 0.0006 (0.0639)	batch 0.9172 (1.0377)	loss 3.2338 (3.2185)	grad_norm 0.4425 (0.4461)	mem 38886MB
Train: [25/180][400/625]	eta 0:03:49 lr 0.760614	data 0.0004 (0.0560)	batch 0.9055 (1.0216)	loss 3.2007 (3.2214)	grad_norm 0.4385 (0.4459)	mem 38886MB
Train: [25/180][450/625]	eta 0:02:56 lr 0.760372	data 0.0005 (0.0498)	batch 0.9126 (1.0091)	loss 3.0754 (3.2209)	grad_norm 0.4502 (0.4460)	mem 38886MB
Train: [25/180][500/625]	eta 0:02:04 lr 0.760130	data 0.0005 (0.0449)	batch 0.9001 (0.9990)	loss 3.4782 (3.2240)	grad_norm 0.4579 (0.4462)	mem 38886MB
Train: [25/180][550/625]	eta 0:01:14 lr 0.759886	data 0.0005 (0.0409)	batch 0.9080 (0.9905)	loss 3.2810 (3.2241)	grad_norm 0.4442 (0.4460)	mem 38886MB
Train: [25/180][600/625]	eta 0:00:24 lr 0.759642	data 0.0006 (0.0375)	batch 0.9294 (0.9836)	loss 3.2321 (3.2266)	grad_norm 0.4470 (0.4461)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 25 training takes 0:10:14
Test: [0/25]	Time 14.610 (14.610)	Loss 1.4061 (1.4061)	Acc@1 70.117 (70.117)	Acc@5 88.135 (88.135)	Mem 38886MB
 * Acc@1 57.050 Acc@5 80.330
Accuracy of the network on the 50000 test images: 57.05%
Max accuracy (after decay): 57.05%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [26/180][0/625]	eta 4:06:11 lr 0.759520	data 21.2696 (21.2696)	batch 23.6344 (23.6344)	loss 3.2701 (3.2701)	grad_norm 0.4546 (0.4546)	mem 38886MB
Train: [26/180][50/625]	eta 0:12:54 lr 0.759274	data 0.0005 (0.4176)	batch 0.8945 (1.3475)	loss 3.2608 (3.2099)	grad_norm 0.4467 (0.4436)	mem 38886MB
Train: [26/180][100/625]	eta 0:09:55 lr 0.759029	data 0.0006 (0.2111)	batch 0.9224 (1.1349)	loss 3.4168 (3.1968)	grad_norm 0.4532 (0.4460)	mem 38886MB
Train: [26/180][150/625]	eta 0:08:23 lr 0.758782	data 0.0004 (0.1414)	batch 0.9280 (1.0592)	loss 3.3632 (3.2024)	grad_norm 0.4512 (0.4458)	mem 38886MB
Train: [26/180][200/625]	eta 0:07:13 lr 0.758535	data 0.0004 (0.1063)	batch 0.9184 (1.0207)	loss 3.2917 (3.2093)	grad_norm 0.4489 (0.4461)	mem 38886MB
Train: [26/180][250/625]	eta 0:06:13 lr 0.758287	data 0.0005 (0.0853)	batch 0.8822 (0.9971)	loss 3.1360 (3.2072)	grad_norm 0.4496 (0.4460)	mem 38886MB
Train: [26/180][300/625]	eta 0:05:19 lr 0.758038	data 0.0005 (0.0712)	batch 0.8965 (0.9818)	loss 3.0527 (3.2080)	grad_norm 0.4472 (0.4459)	mem 38886MB
Train: [26/180][350/625]	eta 0:04:27 lr 0.757789	data 0.0006 (0.0611)	batch 0.8998 (0.9723)	loss 3.3450 (3.2116)	grad_norm 0.4471 (0.4460)	mem 38886MB
Train: [26/180][400/625]	eta 0:03:37 lr 0.757539	data 0.0005 (0.0536)	batch 0.9009 (0.9645)	loss 3.0516 (3.2092)	grad_norm 0.4455 (0.4463)	mem 38886MB
Train: [26/180][450/625]	eta 0:02:47 lr 0.757288	data 0.0005 (0.0477)	batch 0.9259 (0.9582)	loss 3.0618 (3.2120)	grad_norm 0.4344 (0.4462)	mem 38886MB
Train: [26/180][500/625]	eta 0:01:59 lr 0.757036	data 0.0005 (0.0430)	batch 0.9314 (0.9530)	loss 3.3110 (3.2139)	grad_norm 0.4542 (0.4459)	mem 38886MB
Train: [26/180][550/625]	eta 0:01:11 lr 0.756784	data 0.0005 (0.0391)	batch 0.8847 (0.9483)	loss 3.0691 (3.2159)	grad_norm 0.4433 (0.4460)	mem 38886MB
Train: [26/180][600/625]	eta 0:00:23 lr 0.756531	data 0.0004 (0.0359)	batch 0.9100 (0.9454)	loss 3.2479 (3.2153)	grad_norm 0.4397 (0.4459)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 26 training takes 0:09:51
Test: [0/25]	Time 14.931 (14.931)	Loss 1.4411 (1.4411)	Acc@1 68.115 (68.115)	Acc@5 88.086 (88.086)	Mem 38886MB
 * Acc@1 57.248 Acc@5 80.430
Accuracy of the network on the 50000 test images: 57.25%
Max accuracy (after decay): 57.25%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [27/180][0/625]	eta 3:57:32 lr 0.756405	data 21.3951 (21.3951)	batch 22.8037 (22.8037)	loss 3.2022 (3.2022)	grad_norm 0.4408 (0.4408)	mem 38886MB
Train: [27/180][50/625]	eta 0:12:48 lr 0.756151	data 0.0005 (0.4203)	batch 1.0576 (1.3360)	loss 3.3508 (3.1823)	grad_norm 0.4465 (0.4457)	mem 38886MB
Train: [27/180][100/625]	eta 0:09:49 lr 0.755896	data 0.0004 (0.2125)	batch 0.8957 (1.1231)	loss 3.0444 (3.1871)	grad_norm 0.4689 (0.4475)	mem 38886MB
Train: [27/180][150/625]	eta 0:08:18 lr 0.755641	data 0.0005 (0.1423)	batch 1.0769 (1.0499)	loss 3.1637 (3.1989)	grad_norm 0.4555 (0.4472)	mem 38886MB
Train: [27/180][200/625]	eta 0:07:13 lr 0.755385	data 0.0005 (0.1071)	batch 1.0082 (1.0204)	loss 3.3370 (3.1982)	grad_norm 0.4421 (0.4466)	mem 38886MB
Train: [27/180][250/625]	eta 0:06:22 lr 0.755128	data 0.0005 (0.0858)	batch 1.1730 (1.0197)	loss 3.1958 (3.1959)	grad_norm 0.4415 (0.4462)	mem 38886MB
Train: [27/180][300/625]	eta 0:05:37 lr 0.754871	data 0.0005 (0.0717)	batch 0.8713 (1.0370)	loss 3.0709 (3.1939)	grad_norm 0.4381 (0.4470)	mem 38886MB
Train: [27/180][350/625]	eta 0:04:40 lr 0.754613	data 0.0005 (0.0616)	batch 0.9087 (1.0185)	loss 3.2286 (3.1986)	grad_norm 0.4328 (0.4473)	mem 38886MB
Train: [27/180][400/625]	eta 0:03:46 lr 0.754354	data 0.0005 (0.0540)	batch 0.9287 (1.0047)	loss 3.0020 (3.1988)	grad_norm 0.4406 (0.4470)	mem 38886MB
Train: [27/180][450/625]	eta 0:02:53 lr 0.754095	data 0.0005 (0.0480)	batch 0.8887 (0.9938)	loss 3.3312 (3.1963)	grad_norm 0.4484 (0.4469)	mem 38886MB
Train: [27/180][500/625]	eta 0:02:03 lr 0.753835	data 0.0005 (0.0433)	batch 0.8638 (0.9856)	loss 3.0116 (3.1956)	grad_norm 0.4388 (0.4472)	mem 38886MB
Train: [27/180][550/625]	eta 0:01:13 lr 0.753574	data 0.0005 (0.0394)	batch 0.8741 (0.9784)	loss 3.1015 (3.1967)	grad_norm 0.4522 (0.4470)	mem 38886MB
Train: [27/180][600/625]	eta 0:00:24 lr 0.753312	data 0.0005 (0.0362)	batch 0.8949 (0.9729)	loss 3.2860 (3.1994)	grad_norm 0.4604 (0.4470)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 27 training takes 0:10:08
Test: [0/25]	Time 14.546 (14.546)	Loss 1.3413 (1.3413)	Acc@1 70.410 (70.410)	Acc@5 89.062 (89.062)	Mem 38886MB
 * Acc@1 57.328 Acc@5 80.772
Accuracy of the network on the 50000 test images: 57.33%
Max accuracy (after decay): 57.33%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [28/180][0/625]	eta 3:55:11 lr 0.753181	data 21.4490 (21.4490)	batch 22.5784 (22.5784)	loss 3.2489 (3.2489)	grad_norm 0.4395 (0.4395)	mem 38886MB
Train: [28/180][50/625]	eta 0:12:45 lr 0.752919	data 0.0005 (0.4211)	batch 0.9584 (1.3319)	loss 3.2079 (3.1779)	grad_norm 0.4567 (0.4457)	mem 38886MB
Train: [28/180][100/625]	eta 0:09:50 lr 0.752656	data 0.0005 (0.2129)	batch 0.8919 (1.1244)	loss 3.1274 (3.1827)	grad_norm 0.4505 (0.4467)	mem 38886MB
Train: [28/180][150/625]	eta 0:08:19 lr 0.752392	data 0.0006 (0.1426)	batch 0.9241 (1.0514)	loss 3.2381 (3.1899)	grad_norm 0.4569 (0.4474)	mem 38886MB
Train: [28/180][200/625]	eta 0:07:11 lr 0.752127	data 0.0005 (0.1073)	batch 0.9147 (1.0142)	loss 3.0647 (3.1922)	grad_norm 0.4382 (0.4477)	mem 38886MB
Train: [28/180][250/625]	eta 0:06:12 lr 0.751862	data 0.0006 (0.0860)	batch 0.8971 (0.9938)	loss 3.2092 (3.1936)	grad_norm 0.4469 (0.4476)	mem 38886MB
Train: [28/180][300/625]	eta 0:05:18 lr 0.751596	data 0.0004 (0.0718)	batch 0.8734 (0.9785)	loss 3.3466 (3.1944)	grad_norm 0.4563 (0.4475)	mem 38886MB
Train: [28/180][350/625]	eta 0:04:26 lr 0.751329	data 0.0005 (0.0616)	batch 0.9249 (0.9681)	loss 3.1298 (3.1961)	grad_norm 0.4503 (0.4474)	mem 38886MB
Train: [28/180][400/625]	eta 0:03:36 lr 0.751062	data 0.0005 (0.0540)	batch 0.8653 (0.9610)	loss 3.1616 (3.1985)	grad_norm 0.4475 (0.4475)	mem 38886MB
Train: [28/180][450/625]	eta 0:02:47 lr 0.750794	data 0.0005 (0.0481)	batch 0.8904 (0.9547)	loss 3.1718 (3.1989)	grad_norm 0.4752 (0.4472)	mem 38886MB
Train: [28/180][500/625]	eta 0:01:58 lr 0.750525	data 0.0005 (0.0433)	batch 0.9190 (0.9512)	loss 3.2739 (3.1982)	grad_norm 0.4555 (0.4476)	mem 38886MB
Train: [28/180][550/625]	eta 0:01:10 lr 0.750256	data 0.0004 (0.0395)	batch 0.9002 (0.9465)	loss 3.3186 (3.1969)	grad_norm 0.4592 (0.4479)	mem 38886MB
Train: [28/180][600/625]	eta 0:00:23 lr 0.749986	data 0.0004 (0.0362)	batch 0.8688 (0.9435)	loss 3.3637 (3.1971)	grad_norm 0.4376 (0.4478)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 28 training takes 0:09:49
Test: [0/25]	Time 14.963 (14.963)	Loss 1.4407 (1.4407)	Acc@1 69.141 (69.141)	Acc@5 87.695 (87.695)	Mem 38886MB
 * Acc@1 57.044 Acc@5 80.258
Accuracy of the network on the 50000 test images: 57.04%
Max accuracy (after decay): 57.33%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [29/180][0/625]	eta 3:56:04 lr 0.749850	data 21.7494 (21.7494)	batch 22.6632 (22.6632)	loss 3.1807 (3.1807)	grad_norm 0.4290 (0.4290)	mem 38886MB
Train: [29/180][50/625]	eta 0:12:46 lr 0.749579	data 0.0007 (0.4271)	batch 0.8702 (1.3339)	loss 3.2885 (3.1986)	grad_norm 0.4427 (0.4454)	mem 38886MB
Train: [29/180][100/625]	eta 0:09:48 lr 0.749308	data 0.0008 (0.2163)	batch 0.9208 (1.1201)	loss 3.0357 (3.1942)	grad_norm 0.4409 (0.4470)	mem 38886MB
Train: [29/180][150/625]	eta 0:08:19 lr 0.749035	data 0.0005 (0.1448)	batch 0.8540 (1.0512)	loss 3.1733 (3.1872)	grad_norm 0.4378 (0.4467)	mem 38886MB
Train: [29/180][200/625]	eta 0:07:10 lr 0.748762	data 0.0006 (0.1089)	batch 0.9514 (1.0137)	loss 3.0877 (3.1926)	grad_norm 0.4551 (0.4477)	mem 38886MB
Train: [29/180][250/625]	eta 0:06:11 lr 0.748488	data 0.0005 (0.0873)	batch 0.9358 (0.9905)	loss 3.4008 (3.1927)	grad_norm 0.4449 (0.4480)	mem 38886MB
Train: [29/180][300/625]	eta 0:05:17 lr 0.748214	data 0.0005 (0.0729)	batch 0.9427 (0.9758)	loss 3.0534 (3.1889)	grad_norm 0.4406 (0.4483)	mem 38886MB
Train: [29/180][350/625]	eta 0:04:25 lr 0.747938	data 0.0006 (0.0626)	batch 0.8893 (0.9667)	loss 3.2109 (3.1916)	grad_norm 0.4352 (0.4482)	mem 38886MB
Train: [29/180][400/625]	eta 0:03:35 lr 0.747663	data 0.0005 (0.0549)	batch 0.9107 (0.9586)	loss 3.1048 (3.1912)	grad_norm 0.4468 (0.4482)	mem 38886MB
Train: [29/180][450/625]	eta 0:02:47 lr 0.747386	data 0.0005 (0.0489)	batch 1.0132 (0.9545)	loss 2.9950 (3.1917)	grad_norm 0.4555 (0.4482)	mem 38886MB
Train: [29/180][500/625]	eta 0:02:00 lr 0.747109	data 0.0005 (0.0441)	batch 1.1287 (0.9626)	loss 3.2437 (3.1911)	grad_norm 0.4443 (0.4481)	mem 38886MB
Train: [29/180][550/625]	eta 0:01:13 lr 0.746831	data 0.0004 (0.0401)	batch 1.1973 (0.9814)	loss 3.0373 (3.1948)	grad_norm 0.4427 (0.4483)	mem 38886MB
Train: [29/180][600/625]	eta 0:00:24 lr 0.746552	data 0.0006 (0.0368)	batch 1.1580 (0.9967)	loss 3.1248 (3.1978)	grad_norm 0.4815 (0.4483)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 29 training takes 0:10:28
Test: [0/25]	Time 14.690 (14.690)	Loss 1.2987 (1.2987)	Acc@1 70.947 (70.947)	Acc@5 89.404 (89.404)	Mem 38886MB
 * Acc@1 57.244 Acc@5 80.670
Accuracy of the network on the 50000 test images: 57.24%
Max accuracy (after decay): 57.33%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [30/180][0/625]	eta 4:11:49 lr 0.746413	data 22.4313 (22.4313)	batch 24.1759 (24.1759)	loss 2.9282 (2.9282)	grad_norm 0.4557 (0.4557)	mem 38886MB
Train: [30/180][50/625]	eta 0:15:31 lr 0.746133	data 0.0006 (0.4405)	batch 1.1838 (1.6205)	loss 3.2772 (3.1440)	grad_norm 0.4518 (0.4463)	mem 38886MB
Train: [30/180][100/625]	eta 0:12:15 lr 0.745853	data 0.0006 (0.2227)	batch 1.1627 (1.4009)	loss 3.0948 (3.1567)	grad_norm 0.4466 (0.4470)	mem 38886MB
Train: [30/180][150/625]	eta 0:10:30 lr 0.745572	data 0.0005 (0.1491)	batch 1.2095 (1.3272)	loss 3.1152 (3.1617)	grad_norm 0.4360 (0.4470)	mem 38886MB
Train: [30/180][200/625]	eta 0:09:07 lr 0.745290	data 0.0005 (0.1122)	batch 1.1709 (1.2881)	loss 3.0607 (3.1678)	grad_norm 0.4540 (0.4482)	mem 38886MB
Train: [30/180][250/625]	eta 0:07:54 lr 0.745008	data 0.0005 (0.0900)	batch 1.1550 (1.2654)	loss 3.3641 (3.1693)	grad_norm 0.4479 (0.4479)	mem 38886MB
Train: [30/180][300/625]	eta 0:06:46 lr 0.744725	data 0.0005 (0.0751)	batch 1.1986 (1.2502)	loss 3.0749 (3.1708)	grad_norm 0.4373 (0.4479)	mem 38886MB
Train: [30/180][350/625]	eta 0:05:40 lr 0.744442	data 0.0005 (0.0645)	batch 1.1833 (1.2400)	loss 3.3469 (3.1719)	grad_norm 0.4491 (0.4480)	mem 38886MB
Train: [30/180][400/625]	eta 0:04:37 lr 0.744157	data 0.0006 (0.0565)	batch 1.1801 (1.2328)	loss 3.2180 (3.1779)	grad_norm 0.4504 (0.4482)	mem 38886MB
Train: [30/180][450/625]	eta 0:03:34 lr 0.743872	data 0.0005 (0.0503)	batch 1.1840 (1.2261)	loss 3.0261 (3.1803)	grad_norm 0.4408 (0.4483)	mem 38886MB
Train: [30/180][500/625]	eta 0:02:32 lr 0.743587	data 0.0007 (0.0454)	batch 1.1990 (1.2214)	loss 3.1338 (3.1794)	grad_norm 0.4362 (0.4482)	mem 38886MB
Train: [30/180][550/625]	eta 0:01:31 lr 0.743300	data 0.0005 (0.0413)	batch 1.2068 (1.2173)	loss 3.2956 (3.1796)	grad_norm 0.4468 (0.4480)	mem 38886MB
Train: [30/180][600/625]	eta 0:00:30 lr 0.743014	data 0.0005 (0.0379)	batch 1.1692 (1.2133)	loss 3.1578 (3.1797)	grad_norm 0.4444 (0.4479)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 30 training takes 0:12:38
Test: [0/25]	Time 14.960 (14.960)	Loss 1.3941 (1.3941)	Acc@1 69.385 (69.385)	Acc@5 88.037 (88.037)	Mem 38886MB
 * Acc@1 57.660 Acc@5 80.888
Accuracy of the network on the 50000 test images: 57.66%
Max accuracy (after decay): 57.66%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [31/180][0/625]	eta 4:01:28 lr 0.742870	data 21.5721 (21.5721)	batch 23.1814 (23.1814)	loss 3.3060 (3.3060)	grad_norm 0.4473 (0.4473)	mem 38886MB
Train: [31/180][50/625]	eta 0:15:24 lr 0.742582	data 0.0005 (0.4237)	batch 1.1773 (1.6075)	loss 2.9981 (3.1641)	grad_norm 0.4540 (0.4487)	mem 38886MB
Train: [31/180][100/625]	eta 0:12:12 lr 0.742293	data 0.0006 (0.2142)	batch 1.1937 (1.3944)	loss 3.2212 (3.1833)	grad_norm 0.4436 (0.4503)	mem 38886MB
Train: [31/180][150/625]	eta 0:10:28 lr 0.742004	data 0.0004 (0.1435)	batch 1.1889 (1.3225)	loss 3.2928 (3.1844)	grad_norm 0.4392 (0.4515)	mem 38886MB
Train: [31/180][200/625]	eta 0:09:06 lr 0.741714	data 0.0006 (0.1079)	batch 1.1709 (1.2866)	loss 3.0889 (3.1834)	grad_norm 0.4458 (0.4507)	mem 38886MB
Train: [31/180][250/625]	eta 0:07:54 lr 0.741423	data 0.0007 (0.0865)	batch 1.1980 (1.2646)	loss 3.0784 (3.1786)	grad_norm 0.4366 (0.4504)	mem 38886MB
Train: [31/180][300/625]	eta 0:06:46 lr 0.741132	data 0.0006 (0.0723)	batch 1.1903 (1.2512)	loss 3.0896 (3.1783)	grad_norm 0.4466 (0.4504)	mem 38886MB
Train: [31/180][350/625]	eta 0:05:41 lr 0.740840	data 0.0006 (0.0620)	batch 1.2005 (1.2408)	loss 3.3880 (3.1806)	grad_norm 0.4480 (0.4508)	mem 38886MB
Train: [31/180][400/625]	eta 0:04:37 lr 0.740547	data 0.0005 (0.0544)	batch 1.1595 (1.2330)	loss 3.2512 (3.1818)	grad_norm 0.4492 (0.4505)	mem 38886MB
Train: [31/180][450/625]	eta 0:03:34 lr 0.740254	data 0.0005 (0.0484)	batch 1.1240 (1.2254)	loss 3.3167 (3.1803)	grad_norm 0.4398 (0.4504)	mem 38886MB
Train: [31/180][500/625]	eta 0:02:32 lr 0.739960	data 0.0005 (0.0436)	batch 1.2683 (1.2198)	loss 3.2363 (3.1825)	grad_norm 0.4487 (0.4504)	mem 38886MB
Train: [31/180][550/625]	eta 0:01:31 lr 0.739665	data 0.0005 (0.0397)	batch 1.1049 (1.2153)	loss 2.9554 (3.1818)	grad_norm 0.4344 (0.4503)	mem 38886MB
Train: [31/180][600/625]	eta 0:00:30 lr 0.739370	data 0.0009 (0.0365)	batch 1.1959 (1.2117)	loss 3.0986 (3.1811)	grad_norm 0.4506 (0.4502)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 31 training takes 0:12:37
Test: [0/25]	Time 14.761 (14.761)	Loss 1.3482 (1.3482)	Acc@1 70.020 (70.020)	Acc@5 89.404 (89.404)	Mem 38886MB
 * Acc@1 58.558 Acc@5 81.500
Accuracy of the network on the 50000 test images: 58.56%
Max accuracy (after decay): 58.56%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [32/180][0/625]	eta 4:02:24 lr 0.739222	data 22.0932 (22.0932)	batch 23.2704 (23.2704)	loss 3.0479 (3.0479)	grad_norm 0.4395 (0.4395)	mem 38886MB
Train: [32/180][50/625]	eta 0:15:24 lr 0.738926	data 0.0007 (0.4339)	batch 1.1501 (1.6086)	loss 2.9055 (3.1236)	grad_norm 0.4454 (0.4500)	mem 38886MB
Train: [32/180][100/625]	eta 0:12:11 lr 0.738629	data 0.0005 (0.2194)	batch 1.1316 (1.3933)	loss 3.2106 (3.1314)	grad_norm 0.4547 (0.4502)	mem 38886MB
Train: [32/180][150/625]	eta 0:10:28 lr 0.738331	data 0.0005 (0.1470)	batch 1.2447 (1.3236)	loss 2.8915 (3.1288)	grad_norm 0.4390 (0.4504)	mem 38886MB
Train: [32/180][200/625]	eta 0:09:06 lr 0.738033	data 0.0006 (0.1106)	batch 1.1448 (1.2865)	loss 3.1308 (3.1359)	grad_norm 0.4395 (0.4502)	mem 38886MB
Train: [32/180][250/625]	eta 0:07:54 lr 0.737734	data 0.0006 (0.0887)	batch 1.1906 (1.2654)	loss 3.1417 (3.1405)	grad_norm 0.4813 (0.4502)	mem 38886MB
Train: [32/180][300/625]	eta 0:06:46 lr 0.737435	data 0.0006 (0.0740)	batch 1.1941 (1.2513)	loss 3.0824 (3.1473)	grad_norm 0.4457 (0.4504)	mem 38886MB
Train: [32/180][350/625]	eta 0:05:40 lr 0.737134	data 0.0006 (0.0636)	batch 1.1604 (1.2400)	loss 3.3387 (3.1532)	grad_norm 0.4564 (0.4498)	mem 38886MB
Train: [32/180][400/625]	eta 0:04:37 lr 0.736834	data 0.0005 (0.0557)	batch 1.1758 (1.2315)	loss 3.0546 (3.1562)	grad_norm 0.4454 (0.4496)	mem 38886MB
Train: [32/180][450/625]	eta 0:03:34 lr 0.736532	data 0.0006 (0.0496)	batch 1.1765 (1.2244)	loss 3.0891 (3.1580)	grad_norm 0.4455 (0.4495)	mem 38886MB
Train: [32/180][500/625]	eta 0:02:32 lr 0.736230	data 0.0005 (0.0447)	batch 1.1510 (1.2192)	loss 3.1224 (3.1621)	grad_norm 0.4492 (0.4495)	mem 38886MB
Train: [32/180][550/625]	eta 0:01:31 lr 0.735927	data 0.0005 (0.0407)	batch 1.2190 (1.2142)	loss 3.2873 (3.1623)	grad_norm 0.4587 (0.4494)	mem 38886MB
Train: [32/180][600/625]	eta 0:00:30 lr 0.735623	data 0.0004 (0.0374)	batch 1.1860 (1.2102)	loss 3.0699 (3.1640)	grad_norm 0.4678 (0.4496)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 32 training takes 0:12:36
Test: [0/25]	Time 14.842 (14.842)	Loss 1.2775 (1.2775)	Acc@1 71.631 (71.631)	Acc@5 89.746 (89.746)	Mem 38886MB
 * Acc@1 57.796 Acc@5 81.136
Accuracy of the network on the 50000 test images: 57.80%
Max accuracy (after decay): 58.56%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [33/180][0/625]	eta 4:02:20 lr 0.735471	data 21.6580 (21.6580)	batch 23.2646 (23.2646)	loss 3.4010 (3.4010)	grad_norm 0.4520 (0.4520)	mem 38886MB
Train: [33/180][50/625]	eta 0:15:19 lr 0.735167	data 0.0006 (0.4255)	batch 1.0665 (1.5988)	loss 3.0166 (3.1527)	grad_norm 0.4489 (0.4485)	mem 38886MB
Train: [33/180][100/625]	eta 0:12:07 lr 0.734862	data 0.0005 (0.2152)	batch 1.1966 (1.3861)	loss 3.2549 (3.1476)	grad_norm 0.4490 (0.4480)	mem 38886MB
Train: [33/180][150/625]	eta 0:10:25 lr 0.734556	data 0.0006 (0.1442)	batch 1.1817 (1.3171)	loss 3.1528 (3.1445)	grad_norm 0.4536 (0.4491)	mem 38886MB
Train: [33/180][200/625]	eta 0:09:04 lr 0.734250	data 0.0008 (0.1085)	batch 1.1642 (1.2821)	loss 3.0572 (3.1435)	grad_norm 0.4378 (0.4487)	mem 38886MB
Train: [33/180][250/625]	eta 0:07:52 lr 0.733942	data 0.0008 (0.0871)	batch 1.1882 (1.2596)	loss 3.2547 (3.1470)	grad_norm 0.4468 (0.4489)	mem 38886MB
Train: [33/180][300/625]	eta 0:06:44 lr 0.733635	data 0.0007 (0.0727)	batch 1.1822 (1.2457)	loss 2.8856 (3.1472)	grad_norm 0.4457 (0.4493)	mem 38886MB
Train: [33/180][350/625]	eta 0:05:39 lr 0.733326	data 0.0005 (0.0625)	batch 1.1668 (1.2352)	loss 3.1579 (3.1500)	grad_norm 0.4523 (0.4499)	mem 38886MB
Train: [33/180][400/625]	eta 0:04:36 lr 0.733017	data 0.0008 (0.0547)	batch 1.1561 (1.2282)	loss 3.1024 (3.1508)	grad_norm 0.4458 (0.4499)	mem 38886MB
Train: [33/180][450/625]	eta 0:03:33 lr 0.732708	data 0.0007 (0.0488)	batch 1.1200 (1.2216)	loss 2.9960 (3.1513)	grad_norm 0.4702 (0.4502)	mem 38886MB
Train: [33/180][500/625]	eta 0:02:32 lr 0.732397	data 0.0005 (0.0439)	batch 1.1363 (1.2165)	loss 3.2482 (3.1537)	grad_norm 0.4449 (0.4502)	mem 38886MB
Train: [33/180][550/625]	eta 0:01:30 lr 0.732086	data 0.0005 (0.0400)	batch 1.1780 (1.2123)	loss 3.0115 (3.1540)	grad_norm 0.4419 (0.4500)	mem 38886MB
Train: [33/180][600/625]	eta 0:00:30 lr 0.731775	data 0.0006 (0.0367)	batch 1.1041 (1.2078)	loss 3.1633 (3.1543)	grad_norm 0.4513 (0.4503)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 33 training takes 0:12:35
Test: [0/25]	Time 15.447 (15.447)	Loss 1.4164 (1.4164)	Acc@1 69.727 (69.727)	Acc@5 88.135 (88.135)	Mem 38886MB
 * Acc@1 58.418 Acc@5 81.714
Accuracy of the network on the 50000 test images: 58.42%
Max accuracy (after decay): 58.56%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [34/180][0/625]	eta 4:05:15 lr 0.731618	data 22.1500 (22.1500)	batch 23.5453 (23.5453)	loss 3.1981 (3.1981)	grad_norm 0.4489 (0.4489)	mem 38886MB
Train: [34/180][50/625]	eta 0:15:25 lr 0.731306	data 0.0006 (0.4351)	batch 1.1568 (1.6088)	loss 3.1765 (3.1573)	grad_norm 0.4439 (0.4471)	mem 38886MB
Train: [34/180][100/625]	eta 0:12:09 lr 0.730993	data 0.0006 (0.2200)	batch 1.2007 (1.3891)	loss 3.1845 (3.1432)	grad_norm 0.4575 (0.4476)	mem 38886MB
Train: [34/180][150/625]	eta 0:10:25 lr 0.730679	data 0.0005 (0.1474)	batch 1.2125 (1.3179)	loss 3.0675 (3.1496)	grad_norm 0.4680 (0.4498)	mem 38886MB
Train: [34/180][200/625]	eta 0:09:04 lr 0.730364	data 0.0005 (0.1108)	batch 1.1478 (1.2801)	loss 3.0264 (3.1556)	grad_norm 0.4469 (0.4506)	mem 38886MB
Train: [34/180][250/625]	eta 0:07:51 lr 0.730049	data 0.0005 (0.0889)	batch 1.1550 (1.2575)	loss 3.1904 (3.1543)	grad_norm 0.4522 (0.4507)	mem 38886MB
Train: [34/180][300/625]	eta 0:06:44 lr 0.729733	data 0.0005 (0.0742)	batch 1.1495 (1.2439)	loss 3.2709 (3.1569)	grad_norm 0.4624 (0.4509)	mem 38886MB
Train: [34/180][350/625]	eta 0:05:39 lr 0.729417	data 0.0005 (0.0637)	batch 1.1670 (1.2329)	loss 3.0790 (3.1551)	grad_norm 0.4459 (0.4510)	mem 38886MB
Train: [34/180][400/625]	eta 0:04:35 lr 0.729099	data 0.0005 (0.0558)	batch 1.2013 (1.2251)	loss 3.1024 (3.1534)	grad_norm 0.4572 (0.4512)	mem 38886MB
Train: [34/180][450/625]	eta 0:03:33 lr 0.728782	data 0.0004 (0.0497)	batch 1.1913 (1.2190)	loss 3.0816 (3.1508)	grad_norm 0.4479 (0.4514)	mem 38886MB
Train: [34/180][500/625]	eta 0:02:31 lr 0.728463	data 0.0005 (0.0448)	batch 1.1769 (1.2147)	loss 3.1319 (3.1481)	grad_norm 0.4675 (0.4513)	mem 38886MB
Train: [34/180][550/625]	eta 0:01:30 lr 0.728144	data 0.0006 (0.0408)	batch 1.1955 (1.2103)	loss 2.9392 (3.1465)	grad_norm 0.4392 (0.4511)	mem 38886MB
Train: [34/180][600/625]	eta 0:00:30 lr 0.727825	data 0.0005 (0.0374)	batch 1.0826 (1.2062)	loss 3.3258 (3.1459)	grad_norm 0.4622 (0.4512)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 34 training takes 0:12:34
Test: [0/25]	Time 15.153 (15.153)	Loss 1.2973 (1.2973)	Acc@1 71.289 (71.289)	Acc@5 89.893 (89.893)	Mem 38886MB
 * Acc@1 58.316 Acc@5 81.474
Accuracy of the network on the 50000 test images: 58.32%
Max accuracy (after decay): 58.56%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [35/180][0/625]	eta 4:09:05 lr 0.727664	data 22.0396 (22.0396)	batch 23.9128 (23.9128)	loss 3.0228 (3.0228)	grad_norm 0.4756 (0.4756)	mem 38886MB
Train: [35/180][50/625]	eta 0:14:25 lr 0.727344	data 0.0005 (0.4330)	batch 0.8974 (1.5054)	loss 3.1539 (3.1201)	grad_norm 0.4629 (0.4515)	mem 38886MB
Train: [35/180][100/625]	eta 0:10:51 lr 0.727022	data 0.0005 (0.2189)	batch 1.0615 (1.2415)	loss 2.9983 (3.1133)	grad_norm 0.4577 (0.4515)	mem 38886MB
Train: [35/180][150/625]	eta 0:09:07 lr 0.726701	data 0.0005 (0.1466)	batch 0.8853 (1.1528)	loss 3.4036 (3.1270)	grad_norm 0.4599 (0.4518)	mem 38886MB
Train: [35/180][200/625]	eta 0:07:44 lr 0.726378	data 0.0005 (0.1103)	batch 0.8953 (1.0924)	loss 3.1446 (3.1267)	grad_norm 0.4560 (0.4520)	mem 38886MB
Train: [35/180][250/625]	eta 0:06:35 lr 0.726055	data 0.0007 (0.0884)	batch 0.8777 (1.0543)	loss 2.9879 (3.1279)	grad_norm 0.4534 (0.4520)	mem 38886MB
Train: [35/180][300/625]	eta 0:05:35 lr 0.725731	data 0.0004 (0.0738)	batch 0.8960 (1.0317)	loss 3.1392 (3.1282)	grad_norm 0.4544 (0.4524)	mem 38886MB
Train: [35/180][350/625]	eta 0:04:38 lr 0.725407	data 0.0005 (0.0634)	batch 0.8849 (1.0134)	loss 3.0997 (3.1294)	grad_norm 0.4457 (0.4521)	mem 38886MB
Train: [35/180][400/625]	eta 0:03:44 lr 0.725081	data 0.0005 (0.0555)	batch 0.9086 (1.0000)	loss 3.3721 (3.1319)	grad_norm 0.4794 (0.4522)	mem 38886MB
Train: [35/180][450/625]	eta 0:02:53 lr 0.724756	data 0.0005 (0.0494)	batch 0.8681 (0.9889)	loss 3.0251 (3.1333)	grad_norm 0.4492 (0.4525)	mem 38886MB
Train: [35/180][500/625]	eta 0:02:02 lr 0.724429	data 0.0005 (0.0445)	batch 0.8850 (0.9799)	loss 3.1724 (3.1357)	grad_norm 0.4566 (0.4523)	mem 38886MB
Train: [35/180][550/625]	eta 0:01:12 lr 0.724102	data 0.0005 (0.0405)	batch 0.8499 (0.9732)	loss 3.2794 (3.1347)	grad_norm 0.4470 (0.4522)	mem 38886MB
Train: [35/180][600/625]	eta 0:00:24 lr 0.723775	data 0.0007 (0.0372)	batch 0.8689 (0.9667)	loss 3.0582 (3.1370)	grad_norm 0.4535 (0.4526)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 35 training takes 0:10:04
Test: [0/25]	Time 15.042 (15.042)	Loss 1.3266 (1.3266)	Acc@1 70.264 (70.264)	Acc@5 89.697 (89.697)	Mem 38886MB
 * Acc@1 58.914 Acc@5 82.144
Accuracy of the network on the 50000 test images: 58.91%
Max accuracy (after decay): 58.91%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [36/180][0/625]	eta 4:06:39 lr 0.723611	data 21.1486 (21.1486)	batch 23.6795 (23.6795)	loss 3.1562 (3.1562)	grad_norm 0.4344 (0.4344)	mem 38886MB
Train: [36/180][50/625]	eta 0:13:01 lr 0.723282	data 0.0005 (0.4152)	batch 0.8795 (1.3598)	loss 2.9782 (3.1267)	grad_norm 0.4592 (0.4489)	mem 38886MB
Train: [36/180][100/625]	eta 0:09:54 lr 0.722953	data 0.0005 (0.2099)	batch 0.8908 (1.1330)	loss 3.0717 (3.1158)	grad_norm 0.4517 (0.4514)	mem 38886MB
Train: [36/180][150/625]	eta 0:08:22 lr 0.722623	data 0.0005 (0.1406)	batch 0.8931 (1.0572)	loss 2.9981 (3.1151)	grad_norm 0.4534 (0.4521)	mem 38886MB
Train: [36/180][200/625]	eta 0:07:13 lr 0.722293	data 0.0005 (0.1057)	batch 0.8617 (1.0199)	loss 2.8780 (3.1234)	grad_norm 0.4383 (0.4526)	mem 38886MB
Train: [36/180][250/625]	eta 0:06:13 lr 0.721961	data 0.0004 (0.0848)	batch 0.8854 (0.9967)	loss 3.2419 (3.1275)	grad_norm 0.4481 (0.4523)	mem 38886MB
Train: [36/180][300/625]	eta 0:05:19 lr 0.721630	data 0.0005 (0.0708)	batch 0.9396 (0.9827)	loss 3.1222 (3.1311)	grad_norm 0.4610 (0.4527)	mem 38886MB
Train: [36/180][350/625]	eta 0:04:27 lr 0.721297	data 0.0006 (0.0608)	batch 0.9029 (0.9711)	loss 3.2174 (3.1284)	grad_norm 0.4492 (0.4528)	mem 38886MB
Train: [36/180][400/625]	eta 0:03:36 lr 0.720964	data 0.0004 (0.0533)	batch 0.9220 (0.9635)	loss 3.1422 (3.1288)	grad_norm 0.4420 (0.4528)	mem 38886MB
Train: [36/180][450/625]	eta 0:02:47 lr 0.720631	data 0.0004 (0.0474)	batch 0.8953 (0.9564)	loss 3.1705 (3.1309)	grad_norm 0.4404 (0.4526)	mem 38886MB
Train: [36/180][500/625]	eta 0:01:58 lr 0.720297	data 0.0005 (0.0427)	batch 0.8845 (0.9507)	loss 3.2537 (3.1336)	grad_norm 0.4534 (0.4529)	mem 38886MB
Train: [36/180][550/625]	eta 0:01:10 lr 0.719962	data 0.0007 (0.0389)	batch 0.8748 (0.9464)	loss 3.3411 (3.1367)	grad_norm 0.4517 (0.4529)	mem 38886MB
Train: [36/180][600/625]	eta 0:00:23 lr 0.719626	data 0.0005 (0.0357)	batch 0.9371 (0.9422)	loss 2.9461 (3.1376)	grad_norm 0.4598 (0.4526)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 36 training takes 0:09:49
Test: [0/25]	Time 14.904 (14.904)	Loss 1.3125 (1.3125)	Acc@1 70.117 (70.117)	Acc@5 88.965 (88.965)	Mem 38886MB
 * Acc@1 59.416 Acc@5 82.144
Accuracy of the network on the 50000 test images: 59.42%
Max accuracy (after decay): 59.42%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [37/180][0/625]	eta 4:06:01 lr 0.719458	data 21.2322 (21.2322)	batch 23.6177 (23.6177)	loss 3.1532 (3.1532)	grad_norm 0.4419 (0.4419)	mem 38886MB
Train: [37/180][50/625]	eta 0:12:59 lr 0.719122	data 0.0005 (0.4169)	batch 0.9097 (1.3560)	loss 3.0896 (3.1091)	grad_norm 0.4531 (0.4484)	mem 38886MB
Train: [37/180][100/625]	eta 0:09:54 lr 0.718785	data 0.0004 (0.2108)	batch 0.9168 (1.1326)	loss 3.1074 (3.1012)	grad_norm 0.4612 (0.4519)	mem 38886MB
Train: [37/180][150/625]	eta 0:08:21 lr 0.718447	data 0.0003 (0.1412)	batch 0.8992 (1.0557)	loss 2.9990 (3.1068)	grad_norm 0.4505 (0.4523)	mem 38886MB
Train: [37/180][200/625]	eta 0:07:12 lr 0.718109	data 0.0005 (0.1062)	batch 0.8902 (1.0182)	loss 3.3252 (3.1136)	grad_norm 0.4426 (0.4526)	mem 38886MB
Train: [37/180][250/625]	eta 0:06:13 lr 0.717770	data 0.0005 (0.0851)	batch 0.8705 (0.9956)	loss 3.2783 (3.1133)	grad_norm 0.4546 (0.4530)	mem 38886MB
Train: [37/180][300/625]	eta 0:05:18 lr 0.717430	data 0.0004 (0.0711)	batch 0.8926 (0.9811)	loss 3.3299 (3.1200)	grad_norm 0.4569 (0.4531)	mem 38886MB
Train: [37/180][350/625]	eta 0:04:26 lr 0.717090	data 0.0006 (0.0610)	batch 0.8728 (0.9702)	loss 3.3089 (3.1236)	grad_norm 0.4547 (0.4531)	mem 38886MB
Train: [37/180][400/625]	eta 0:03:36 lr 0.716750	data 0.0005 (0.0535)	batch 0.9253 (0.9617)	loss 3.0805 (3.1228)	grad_norm 0.4491 (0.4530)	mem 38886MB
Train: [37/180][450/625]	eta 0:02:47 lr 0.716408	data 0.0005 (0.0476)	batch 0.9086 (0.9545)	loss 3.1305 (3.1225)	grad_norm 0.4473 (0.4528)	mem 38886MB
Train: [37/180][500/625]	eta 0:01:58 lr 0.716066	data 0.0006 (0.0429)	batch 0.9166 (0.9493)	loss 3.1147 (3.1253)	grad_norm 0.4454 (0.4529)	mem 38886MB
Train: [37/180][550/625]	eta 0:01:10 lr 0.715724	data 0.0005 (0.0391)	batch 0.9463 (0.9460)	loss 3.0430 (3.1278)	grad_norm 0.4462 (0.4530)	mem 38886MB
Train: [37/180][600/625]	eta 0:00:23 lr 0.715380	data 0.0045 (0.0359)	batch 0.8836 (0.9420)	loss 3.0942 (3.1288)	grad_norm 0.4476 (0.4530)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 37 training takes 0:09:49
Test: [0/25]	Time 14.865 (14.865)	Loss 1.3193 (1.3193)	Acc@1 70.410 (70.410)	Acc@5 89.453 (89.453)	Mem 38886MB
 * Acc@1 58.716 Acc@5 81.892
Accuracy of the network on the 50000 test images: 58.72%
Max accuracy (after decay): 59.42%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [38/180][0/625]	eta 3:56:09 lr 0.715209	data 20.8927 (20.8927)	batch 22.6710 (22.6710)	loss 3.2346 (3.2346)	grad_norm 0.4513 (0.4513)	mem 38886MB
Train: [38/180][50/625]	eta 0:12:47 lr 0.714864	data 0.0007 (0.4109)	batch 0.8881 (1.3356)	loss 3.0478 (3.1289)	grad_norm 0.4510 (0.4535)	mem 38886MB
Train: [38/180][100/625]	eta 0:09:52 lr 0.714520	data 0.0011 (0.2078)	batch 0.8713 (1.1279)	loss 3.4736 (3.1221)	grad_norm 0.4514 (0.4535)	mem 38886MB
Train: [38/180][150/625]	eta 0:08:21 lr 0.714174	data 0.0006 (0.1395)	batch 0.9115 (1.0552)	loss 2.8483 (3.1208)	grad_norm 0.4452 (0.4541)	mem 38886MB
Train: [38/180][200/625]	eta 0:07:12 lr 0.713828	data 0.0006 (0.1050)	batch 0.9207 (1.0175)	loss 3.3823 (3.1219)	grad_norm 0.4844 (0.4552)	mem 38886MB
Train: [38/180][250/625]	eta 0:06:13 lr 0.713482	data 0.0005 (0.0842)	batch 0.8988 (0.9960)	loss 2.9472 (3.1222)	grad_norm 0.4605 (0.4550)	mem 38886MB
Train: [38/180][300/625]	eta 0:05:18 lr 0.713135	data 0.0006 (0.0703)	batch 0.8695 (0.9811)	loss 3.1392 (3.1252)	grad_norm 0.4652 (0.4551)	mem 38886MB
Train: [38/180][350/625]	eta 0:04:26 lr 0.712787	data 0.0007 (0.0604)	batch 0.9694 (0.9704)	loss 3.3714 (3.1242)	grad_norm 0.4537 (0.4549)	mem 38886MB
Train: [38/180][400/625]	eta 0:03:36 lr 0.712438	data 0.0007 (0.0529)	batch 0.8843 (0.9626)	loss 3.1519 (3.1283)	grad_norm 0.4500 (0.4555)	mem 38886MB
Train: [38/180][450/625]	eta 0:02:47 lr 0.712089	data 0.0005 (0.0471)	batch 0.9056 (0.9561)	loss 3.1566 (3.1249)	grad_norm 0.4508 (0.4555)	mem 38886MB
Train: [38/180][500/625]	eta 0:01:58 lr 0.711740	data 0.0008 (0.0425)	batch 0.8929 (0.9510)	loss 3.0265 (3.1258)	grad_norm 0.4581 (0.4554)	mem 38886MB
Train: [38/180][550/625]	eta 0:01:11 lr 0.711389	data 0.0008 (0.0387)	batch 0.8913 (0.9480)	loss 3.2380 (3.1280)	grad_norm 0.4476 (0.4552)	mem 38886MB
Train: [38/180][600/625]	eta 0:00:23 lr 0.711038	data 0.0009 (0.0356)	batch 0.9157 (0.9442)	loss 3.1047 (3.1295)	grad_norm 0.4461 (0.4551)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 38 training takes 0:09:50
Test: [0/25]	Time 15.089 (15.089)	Loss 1.4108 (1.4108)	Acc@1 68.604 (68.604)	Acc@5 88.818 (88.818)	Mem 38886MB
 * Acc@1 58.820 Acc@5 81.606
Accuracy of the network on the 50000 test images: 58.82%
Max accuracy (after decay): 59.42%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [39/180][0/625]	eta 3:53:45 lr 0.710863	data 21.2995 (21.2995)	batch 22.4411 (22.4411)	loss 2.9249 (2.9249)	grad_norm 0.4418 (0.4418)	mem 38886MB
Train: [39/180][50/625]	eta 0:12:46 lr 0.710511	data 0.0005 (0.4184)	batch 0.8860 (1.3325)	loss 3.2106 (3.1091)	grad_norm 0.4468 (0.4558)	mem 38886MB
Train: [39/180][100/625]	eta 0:09:48 lr 0.710159	data 0.0005 (0.2116)	batch 0.9042 (1.1205)	loss 3.1307 (3.1159)	grad_norm 0.4522 (0.4545)	mem 38886MB
Train: [39/180][150/625]	eta 0:08:19 lr 0.709806	data 0.0005 (0.1417)	batch 0.9242 (1.0509)	loss 2.8872 (3.1055)	grad_norm 0.4573 (0.4541)	mem 38886MB
Train: [39/180][200/625]	eta 0:07:11 lr 0.709452	data 0.0005 (0.1066)	batch 0.8949 (1.0154)	loss 3.0457 (3.1025)	grad_norm 0.4537 (0.4548)	mem 38886MB
Train: [39/180][250/625]	eta 0:06:12 lr 0.709098	data 0.0006 (0.0855)	batch 0.9172 (0.9945)	loss 3.3152 (3.1032)	grad_norm 0.4957 (0.4555)	mem 38886MB
Train: [39/180][300/625]	eta 0:05:18 lr 0.708743	data 0.0005 (0.0714)	batch 0.8966 (0.9811)	loss 3.2207 (3.1038)	grad_norm 0.4683 (0.4556)	mem 38886MB
Train: [39/180][350/625]	eta 0:04:26 lr 0.708388	data 0.0005 (0.0613)	batch 0.8903 (0.9695)	loss 3.1160 (3.1099)	grad_norm 0.4773 (0.4560)	mem 38886MB
Train: [39/180][400/625]	eta 0:03:36 lr 0.708032	data 0.0004 (0.0537)	batch 0.8871 (0.9609)	loss 3.1598 (3.1119)	grad_norm 0.4487 (0.4559)	mem 38886MB
Train: [39/180][450/625]	eta 0:02:47 lr 0.707675	data 0.0005 (0.0478)	batch 0.8765 (0.9548)	loss 3.1134 (3.1162)	grad_norm 0.4532 (0.4557)	mem 38886MB
Train: [39/180][500/625]	eta 0:01:58 lr 0.707318	data 0.0005 (0.0431)	batch 0.9124 (0.9492)	loss 3.1650 (3.1164)	grad_norm 0.4461 (0.4558)	mem 38886MB
Train: [39/180][550/625]	eta 0:01:10 lr 0.706960	data 0.0005 (0.0392)	batch 0.8773 (0.9455)	loss 3.1064 (3.1200)	grad_norm 0.4523 (0.4558)	mem 38886MB
Train: [39/180][600/625]	eta 0:00:23 lr 0.706602	data 0.0005 (0.0361)	batch 0.8982 (0.9437)	loss 3.1524 (3.1179)	grad_norm 0.4682 (0.4558)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 39 training takes 0:09:50
Test: [0/25]	Time 15.102 (15.102)	Loss 1.3096 (1.3096)	Acc@1 70.801 (70.801)	Acc@5 90.186 (90.186)	Mem 38886MB
 * Acc@1 59.468 Acc@5 82.206
Accuracy of the network on the 50000 test images: 59.47%
Max accuracy (after decay): 59.47%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [40/180][0/625]	eta 3:57:36 lr 0.706422	data 21.2711 (21.2711)	batch 22.8101 (22.8101)	loss 3.1764 (3.1764)	grad_norm 0.4471 (0.4471)	mem 38886MB
Train: [40/180][50/625]	eta 0:12:51 lr 0.706063	data 0.0004 (0.4181)	batch 0.8995 (1.3420)	loss 3.1461 (3.0938)	grad_norm 0.4445 (0.4520)	mem 38886MB
Train: [40/180][100/625]	eta 0:09:51 lr 0.705703	data 0.0008 (0.2115)	batch 0.9983 (1.1263)	loss 3.0528 (3.0982)	grad_norm 0.4501 (0.4529)	mem 38886MB
Train: [40/180][150/625]	eta 0:08:21 lr 0.705343	data 0.0004 (0.1417)	batch 0.9098 (1.0551)	loss 3.2056 (3.0981)	grad_norm 0.4529 (0.4553)	mem 38886MB
Train: [40/180][200/625]	eta 0:07:12 lr 0.704982	data 0.0006 (0.1066)	batch 0.9609 (1.0186)	loss 3.0352 (3.0995)	grad_norm 0.4546 (0.4552)	mem 38886MB
Train: [40/180][250/625]	eta 0:06:13 lr 0.704620	data 0.0005 (0.0855)	batch 0.8796 (0.9966)	loss 2.9828 (3.1011)	grad_norm 0.4528 (0.4554)	mem 38886MB
Train: [40/180][300/625]	eta 0:05:19 lr 0.704258	data 0.0005 (0.0714)	batch 0.8856 (0.9821)	loss 3.1488 (3.0996)	grad_norm 0.4702 (0.4556)	mem 38886MB
Train: [40/180][350/625]	eta 0:04:27 lr 0.703895	data 0.0006 (0.0613)	batch 0.9018 (0.9712)	loss 3.2526 (3.1004)	grad_norm 0.4525 (0.4555)	mem 38886MB
Train: [40/180][400/625]	eta 0:03:36 lr 0.703532	data 0.0005 (0.0537)	batch 0.9501 (0.9640)	loss 3.1204 (3.1019)	grad_norm 0.4615 (0.4562)	mem 38886MB
Train: [40/180][450/625]	eta 0:02:47 lr 0.703168	data 0.0005 (0.0478)	batch 0.8957 (0.9581)	loss 3.0246 (3.1034)	grad_norm 0.4554 (0.4561)	mem 38886MB
Train: [40/180][500/625]	eta 0:01:59 lr 0.702803	data 0.0005 (0.0431)	batch 0.9843 (0.9528)	loss 3.0475 (3.1052)	grad_norm 0.4408 (0.4561)	mem 38886MB
Train: [40/180][550/625]	eta 0:01:11 lr 0.702438	data 0.0006 (0.0392)	batch 0.8502 (0.9487)	loss 3.3072 (3.1087)	grad_norm 0.4577 (0.4562)	mem 38886MB
Train: [40/180][600/625]	eta 0:00:23 lr 0.702072	data 0.0005 (0.0360)	batch 0.8952 (0.9452)	loss 3.0896 (3.1108)	grad_norm 0.4528 (0.4562)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 40 training takes 0:09:51
Test: [0/25]	Time 14.754 (14.754)	Loss 1.3129 (1.3129)	Acc@1 70.654 (70.654)	Acc@5 89.160 (89.160)	Mem 38886MB
 * Acc@1 59.448 Acc@5 82.356
Accuracy of the network on the 50000 test images: 59.45%
Max accuracy (after decay): 59.47%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [41/180][0/625]	eta 3:58:10 lr 0.701889	data 21.3170 (21.3170)	batch 22.8644 (22.8644)	loss 3.0547 (3.0547)	grad_norm 0.4725 (0.4725)	mem 38886MB
Train: [41/180][50/625]	eta 0:12:54 lr 0.701522	data 0.0016 (0.4188)	batch 0.9526 (1.3473)	loss 2.9425 (3.0765)	grad_norm 0.4678 (0.4553)	mem 38886MB
Train: [41/180][100/625]	eta 0:09:52 lr 0.701155	data 0.0005 (0.2118)	batch 0.8949 (1.1280)	loss 3.0504 (3.0774)	grad_norm 0.4561 (0.4543)	mem 38886MB
Train: [41/180][150/625]	eta 0:08:21 lr 0.700787	data 0.0005 (0.1418)	batch 0.8674 (1.0555)	loss 3.1232 (3.0787)	grad_norm 0.4641 (0.4546)	mem 38886MB
Train: [41/180][200/625]	eta 0:07:12 lr 0.700418	data 0.0006 (0.1067)	batch 0.8917 (1.0187)	loss 3.1842 (3.0809)	grad_norm 0.4554 (0.4557)	mem 38886MB
Train: [41/180][250/625]	eta 0:06:13 lr 0.700049	data 0.0004 (0.0855)	batch 0.9041 (0.9961)	loss 3.0829 (3.0848)	grad_norm 0.4550 (0.4558)	mem 38886MB
Train: [41/180][300/625]	eta 0:05:19 lr 0.699680	data 0.0004 (0.0714)	batch 0.8694 (0.9821)	loss 3.1242 (3.0877)	grad_norm 0.4518 (0.4558)	mem 38886MB
Train: [41/180][350/625]	eta 0:04:27 lr 0.699310	data 0.0006 (0.0613)	batch 0.8919 (0.9711)	loss 3.1330 (3.0897)	grad_norm 0.4679 (0.4563)	mem 38886MB
Train: [41/180][400/625]	eta 0:03:36 lr 0.698939	data 0.0005 (0.0537)	batch 0.8815 (0.9623)	loss 3.1357 (3.0924)	grad_norm 0.4503 (0.4562)	mem 38886MB
Train: [41/180][450/625]	eta 0:02:47 lr 0.698567	data 0.0005 (0.0478)	batch 0.8893 (0.9559)	loss 3.0714 (3.0931)	grad_norm 0.4437 (0.4563)	mem 38886MB
Train: [41/180][500/625]	eta 0:01:58 lr 0.698195	data 0.0005 (0.0432)	batch 0.9031 (0.9507)	loss 3.1798 (3.0963)	grad_norm 0.4662 (0.4565)	mem 38886MB
Train: [41/180][550/625]	eta 0:01:11 lr 0.697823	data 0.0005 (0.0393)	batch 0.8753 (0.9470)	loss 3.1956 (3.0996)	grad_norm 0.4539 (0.4568)	mem 38886MB
Train: [41/180][600/625]	eta 0:00:23 lr 0.697450	data 0.0005 (0.0361)	batch 0.8939 (0.9435)	loss 3.0954 (3.1027)	grad_norm 0.4635 (0.4568)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 41 training takes 0:09:50
Test: [0/25]	Time 14.782 (14.782)	Loss 1.3254 (1.3254)	Acc@1 70.264 (70.264)	Acc@5 89.648 (89.648)	Mem 38886MB
 * Acc@1 59.276 Acc@5 81.880
Accuracy of the network on the 50000 test images: 59.28%
Max accuracy (after decay): 59.47%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [42/180][0/625]	eta 4:00:56 lr 0.697263	data 20.0266 (20.0266)	batch 23.1296 (23.1296)	loss 3.1393 (3.1393)	grad_norm 0.4578 (0.4578)	mem 38886MB
Train: [42/180][50/625]	eta 0:12:55 lr 0.696889	data 0.0006 (0.3933)	batch 0.9002 (1.3484)	loss 2.9117 (3.0851)	grad_norm 0.4551 (0.4540)	mem 38886MB
Train: [42/180][100/625]	eta 0:09:51 lr 0.696515	data 0.0007 (0.1989)	batch 0.9378 (1.1266)	loss 3.0171 (3.0845)	grad_norm 0.4418 (0.4553)	mem 38886MB
Train: [42/180][150/625]	eta 0:08:19 lr 0.696139	data 0.0005 (0.1332)	batch 0.9006 (1.0521)	loss 3.1690 (3.0898)	grad_norm 0.4653 (0.4568)	mem 38886MB
Train: [42/180][200/625]	eta 0:07:11 lr 0.695764	data 0.0004 (0.1002)	batch 0.9277 (1.0159)	loss 3.1745 (3.0885)	grad_norm 0.4408 (0.4564)	mem 38886MB
Train: [42/180][250/625]	eta 0:06:13 lr 0.695387	data 0.0007 (0.0803)	batch 0.9015 (0.9956)	loss 3.0050 (3.0882)	grad_norm 0.4517 (0.4568)	mem 38886MB
Train: [42/180][300/625]	eta 0:05:18 lr 0.695010	data 0.0008 (0.0671)	batch 0.8889 (0.9812)	loss 3.0569 (3.0909)	grad_norm 0.4465 (0.4570)	mem 38886MB
Train: [42/180][350/625]	eta 0:04:26 lr 0.694633	data 0.0015 (0.0576)	batch 0.9461 (0.9708)	loss 3.0022 (3.0915)	grad_norm 0.4655 (0.4570)	mem 38886MB
Train: [42/180][400/625]	eta 0:03:36 lr 0.694255	data 0.0007 (0.0505)	batch 0.9095 (0.9620)	loss 3.0352 (3.0939)	grad_norm 0.4543 (0.4576)	mem 38886MB
Train: [42/180][450/625]	eta 0:02:47 lr 0.693876	data 0.0006 (0.0450)	batch 0.9037 (0.9559)	loss 3.1894 (3.0950)	grad_norm 0.4766 (0.4575)	mem 38886MB
Train: [42/180][500/625]	eta 0:01:58 lr 0.693497	data 0.0006 (0.0405)	batch 0.8834 (0.9508)	loss 3.2372 (3.0956)	grad_norm 0.4455 (0.4574)	mem 38886MB
Train: [42/180][550/625]	eta 0:01:11 lr 0.693118	data 0.0006 (0.0370)	batch 0.8597 (0.9473)	loss 2.9610 (3.0951)	grad_norm 0.4559 (0.4573)	mem 38886MB
Train: [42/180][600/625]	eta 0:00:23 lr 0.692737	data 0.0006 (0.0340)	batch 0.8861 (0.9433)	loss 3.0557 (3.0971)	grad_norm 0.4481 (0.4575)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 42 training takes 0:09:50
Test: [0/25]	Time 15.054 (15.054)	Loss 1.3993 (1.3993)	Acc@1 70.605 (70.605)	Acc@5 88.281 (88.281)	Mem 38886MB
 * Acc@1 59.818 Acc@5 82.438
Accuracy of the network on the 50000 test images: 59.82%
Max accuracy (after decay): 59.82%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [43/180][0/625]	eta 4:04:13 lr 0.692547	data 21.1317 (21.1317)	batch 23.4461 (23.4461)	loss 3.0219 (3.0219)	grad_norm 0.4488 (0.4488)	mem 38886MB
Train: [43/180][50/625]	eta 0:12:58 lr 0.692166	data 0.0005 (0.4149)	batch 0.9105 (1.3535)	loss 2.7654 (3.0704)	grad_norm 0.4580 (0.4568)	mem 38886MB
Train: [43/180][100/625]	eta 0:09:54 lr 0.691784	data 0.0004 (0.2102)	batch 0.9112 (1.1327)	loss 3.1943 (3.0888)	grad_norm 0.4534 (0.4573)	mem 38886MB
Train: [43/180][150/625]	eta 0:08:22 lr 0.691402	data 0.0005 (0.1408)	batch 0.8906 (1.0575)	loss 3.1913 (3.0874)	grad_norm 0.4610 (0.4585)	mem 38886MB
Train: [43/180][200/625]	eta 0:07:13 lr 0.691019	data 0.0005 (0.1059)	batch 0.8867 (1.0206)	loss 3.1442 (3.0881)	grad_norm 0.4639 (0.4581)	mem 38886MB
Train: [43/180][250/625]	eta 0:06:14 lr 0.690635	data 0.0006 (0.0849)	batch 0.8837 (0.9979)	loss 3.0238 (3.0909)	grad_norm 0.4736 (0.4580)	mem 38886MB
Train: [43/180][300/625]	eta 0:05:19 lr 0.690251	data 0.0007 (0.0709)	batch 0.8680 (0.9827)	loss 3.2448 (3.0872)	grad_norm 0.4612 (0.4583)	mem 38886MB
Train: [43/180][350/625]	eta 0:04:27 lr 0.689867	data 0.0009 (0.0609)	batch 0.9080 (0.9713)	loss 3.2266 (3.0921)	grad_norm 0.4762 (0.4585)	mem 38886MB
Train: [43/180][400/625]	eta 0:03:36 lr 0.689482	data 0.0005 (0.0534)	batch 0.9156 (0.9633)	loss 3.1899 (3.0928)	grad_norm 0.4492 (0.4585)	mem 38886MB
Train: [43/180][450/625]	eta 0:02:47 lr 0.689096	data 0.0005 (0.0475)	batch 0.8761 (0.9565)	loss 2.9334 (3.0893)	grad_norm 0.4460 (0.4585)	mem 38886MB
Train: [43/180][500/625]	eta 0:01:58 lr 0.688710	data 0.0005 (0.0428)	batch 0.9258 (0.9507)	loss 3.3242 (3.0909)	grad_norm 0.4545 (0.4583)	mem 38886MB
Train: [43/180][550/625]	eta 0:01:11 lr 0.688323	data 0.0005 (0.0390)	batch 0.9572 (0.9475)	loss 2.9347 (3.0908)	grad_norm 0.4538 (0.4582)	mem 38886MB
Train: [43/180][600/625]	eta 0:00:23 lr 0.687935	data 0.0005 (0.0358)	batch 0.8630 (0.9437)	loss 3.1901 (3.0921)	grad_norm 0.4528 (0.4583)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 43 training takes 0:09:50
Test: [0/25]	Time 14.760 (14.760)	Loss 1.2084 (1.2084)	Acc@1 72.363 (72.363)	Acc@5 89.990 (89.990)	Mem 38886MB
 * Acc@1 60.038 Acc@5 82.806
Accuracy of the network on the 50000 test images: 60.04%
Max accuracy (after decay): 60.04%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [44/180][0/625]	eta 3:55:18 lr 0.687742	data 21.6546 (21.6546)	batch 22.5895 (22.5895)	loss 2.9001 (2.9001)	grad_norm 0.4530 (0.4530)	mem 38886MB
Train: [44/180][50/625]	eta 0:12:49 lr 0.687353	data 0.0005 (0.4253)	batch 0.9490 (1.3383)	loss 3.0013 (3.0223)	grad_norm 0.4476 (0.4564)	mem 38886MB
Train: [44/180][100/625]	eta 0:09:50 lr 0.686965	data 0.0005 (0.2150)	batch 0.8557 (1.1246)	loss 2.9104 (3.0512)	grad_norm 0.4499 (0.4576)	mem 38886MB
Train: [44/180][150/625]	eta 0:08:20 lr 0.686575	data 0.0004 (0.1440)	batch 0.9296 (1.0527)	loss 2.9487 (3.0546)	grad_norm 0.4658 (0.4586)	mem 38886MB
Train: [44/180][200/625]	eta 0:07:12 lr 0.686185	data 0.0005 (0.1083)	batch 0.8953 (1.0165)	loss 3.0500 (3.0647)	grad_norm 0.4565 (0.4585)	mem 38886MB
Train: [44/180][250/625]	eta 0:06:12 lr 0.685795	data 0.0006 (0.0868)	batch 0.9085 (0.9932)	loss 3.1890 (3.0673)	grad_norm 0.4656 (0.4593)	mem 38886MB
Train: [44/180][300/625]	eta 0:05:17 lr 0.685404	data 0.0006 (0.0725)	batch 0.9009 (0.9783)	loss 3.1932 (3.0696)	grad_norm 0.4683 (0.4595)	mem 38886MB
Train: [44/180][350/625]	eta 0:04:26 lr 0.685012	data 0.0005 (0.0622)	batch 0.8953 (0.9680)	loss 2.9928 (3.0743)	grad_norm 0.4534 (0.4597)	mem 38886MB
Train: [44/180][400/625]	eta 0:03:36 lr 0.684620	data 0.0005 (0.0545)	batch 0.8866 (0.9605)	loss 3.1945 (3.0747)	grad_norm 0.4506 (0.4598)	mem 38886MB
Train: [44/180][450/625]	eta 0:02:47 lr 0.684227	data 0.0006 (0.0486)	batch 0.9405 (0.9552)	loss 3.2816 (3.0771)	grad_norm 0.4517 (0.4600)	mem 38886MB
Train: [44/180][500/625]	eta 0:01:58 lr 0.683834	data 0.0004 (0.0438)	batch 0.9370 (0.9496)	loss 3.0802 (3.0767)	grad_norm 0.4532 (0.4597)	mem 38886MB
Train: [44/180][550/625]	eta 0:01:10 lr 0.683440	data 0.0007 (0.0398)	batch 0.8626 (0.9453)	loss 2.7929 (3.0799)	grad_norm 0.4495 (0.4595)	mem 38886MB
Train: [44/180][600/625]	eta 0:00:23 lr 0.683046	data 0.0005 (0.0366)	batch 0.8930 (0.9425)	loss 3.1107 (3.0804)	grad_norm 0.4690 (0.4594)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 44 training takes 0:09:49
Test: [0/25]	Time 15.201 (15.201)	Loss 1.3772 (1.3772)	Acc@1 70.703 (70.703)	Acc@5 88.867 (88.867)	Mem 38886MB
 * Acc@1 59.980 Acc@5 82.776
Accuracy of the network on the 50000 test images: 59.98%
Max accuracy (after decay): 60.04%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [45/180][0/625]	eta 3:58:51 lr 0.682849	data 21.3147 (21.3147)	batch 22.9311 (22.9311)	loss 3.1023 (3.1023)	grad_norm 0.4584 (0.4584)	mem 38886MB
Train: [45/180][50/625]	eta 0:12:53 lr 0.682453	data 0.0006 (0.4187)	batch 0.8825 (1.3451)	loss 3.1080 (3.0723)	grad_norm 0.4476 (0.4574)	mem 38886MB
Train: [45/180][100/625]	eta 0:09:52 lr 0.682058	data 0.0009 (0.2117)	batch 0.9578 (1.1278)	loss 3.0299 (3.0763)	grad_norm 0.4478 (0.4590)	mem 38886MB
Train: [45/180][150/625]	eta 0:08:21 lr 0.681661	data 0.0010 (0.1418)	batch 0.9887 (1.0551)	loss 3.0631 (3.0766)	grad_norm 0.4774 (0.4595)	mem 38886MB
Train: [45/180][200/625]	eta 0:07:12 lr 0.681265	data 0.0004 (0.1067)	batch 0.8882 (1.0187)	loss 3.0978 (3.0751)	grad_norm 0.4617 (0.4594)	mem 38886MB
Train: [45/180][250/625]	eta 0:06:13 lr 0.680867	data 0.0004 (0.0855)	batch 0.9122 (0.9956)	loss 3.3273 (3.0801)	grad_norm 0.4762 (0.4602)	mem 38886MB
Train: [45/180][300/625]	eta 0:05:18 lr 0.680469	data 0.0005 (0.0714)	batch 0.9291 (0.9804)	loss 2.9374 (3.0773)	grad_norm 0.4648 (0.4603)	mem 38886MB
Train: [45/180][350/625]	eta 0:04:26 lr 0.680071	data 0.0005 (0.0613)	batch 0.9095 (0.9694)	loss 3.2435 (3.0774)	grad_norm 0.4598 (0.4604)	mem 38886MB
Train: [45/180][400/625]	eta 0:03:36 lr 0.679672	data 0.0006 (0.0537)	batch 0.9136 (0.9619)	loss 3.0151 (3.0781)	grad_norm 0.4578 (0.4608)	mem 38886MB
Train: [45/180][450/625]	eta 0:02:47 lr 0.679272	data 0.0004 (0.0479)	batch 0.8856 (0.9557)	loss 3.2335 (3.0813)	grad_norm 0.4584 (0.4608)	mem 38886MB
Train: [45/180][500/625]	eta 0:01:58 lr 0.678872	data 0.0005 (0.0432)	batch 0.9075 (0.9499)	loss 3.1229 (3.0827)	grad_norm 0.4627 (0.4604)	mem 38886MB
Train: [45/180][550/625]	eta 0:01:10 lr 0.678471	data 0.0009 (0.0393)	batch 0.9296 (0.9455)	loss 3.1517 (3.0829)	grad_norm 0.4605 (0.4604)	mem 38886MB
Train: [45/180][600/625]	eta 0:00:23 lr 0.678070	data 0.0005 (0.0361)	batch 0.9236 (0.9423)	loss 3.1480 (3.0826)	grad_norm 0.4657 (0.4604)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 45 training takes 0:09:49
Test: [0/25]	Time 14.933 (14.933)	Loss 1.2200 (1.2200)	Acc@1 72.559 (72.559)	Acc@5 90.723 (90.723)	Mem 38886MB
 * Acc@1 59.578 Acc@5 82.506
Accuracy of the network on the 50000 test images: 59.58%
Max accuracy (after decay): 60.04%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [46/180][0/625]	eta 3:58:56 lr 0.677869	data 20.0869 (20.0869)	batch 22.9378 (22.9378)	loss 3.0917 (3.0917)	grad_norm 0.4528 (0.4528)	mem 38886MB
Train: [46/180][50/625]	eta 0:12:52 lr 0.677467	data 0.0004 (0.3946)	batch 0.8919 (1.3436)	loss 3.1496 (3.0676)	grad_norm 0.4597 (0.4603)	mem 38886MB
Train: [46/180][100/625]	eta 0:09:52 lr 0.677065	data 0.0005 (0.1996)	batch 0.8696 (1.1293)	loss 3.1211 (3.0769)	grad_norm 0.4696 (0.4623)	mem 38886MB
Train: [46/180][150/625]	eta 0:08:21 lr 0.676662	data 0.0005 (0.1337)	batch 0.9048 (1.0565)	loss 3.1313 (3.0780)	grad_norm 0.4481 (0.4625)	mem 38886MB
Train: [46/180][200/625]	eta 0:07:13 lr 0.676258	data 0.0005 (0.1005)	batch 0.9102 (1.0199)	loss 3.1369 (3.0752)	grad_norm 0.4663 (0.4622)	mem 38886MB
Train: [46/180][250/625]	eta 0:06:14 lr 0.675854	data 0.0003 (0.0806)	batch 1.0269 (0.9987)	loss 2.9980 (3.0770)	grad_norm 0.4569 (0.4621)	mem 38886MB
Train: [46/180][300/625]	eta 0:05:19 lr 0.675449	data 0.0005 (0.0673)	batch 0.9097 (0.9838)	loss 3.0584 (3.0749)	grad_norm 0.4634 (0.4616)	mem 38886MB
Train: [46/180][350/625]	eta 0:04:27 lr 0.675044	data 0.0005 (0.0578)	batch 0.9375 (0.9720)	loss 3.0229 (3.0734)	grad_norm 0.4439 (0.4614)	mem 38886MB
Train: [46/180][400/625]	eta 0:03:36 lr 0.674638	data 0.0005 (0.0508)	batch 0.8946 (0.9638)	loss 2.9950 (3.0759)	grad_norm 0.4546 (0.4613)	mem 38886MB
Train: [46/180][450/625]	eta 0:02:47 lr 0.674232	data 0.0005 (0.0452)	batch 0.8815 (0.9573)	loss 3.1956 (3.0799)	grad_norm 0.4727 (0.4614)	mem 38886MB
Train: [46/180][500/625]	eta 0:01:59 lr 0.673825	data 0.0004 (0.0407)	batch 0.9044 (0.9520)	loss 3.1146 (3.0806)	grad_norm 0.4632 (0.4613)	mem 38886MB
Train: [46/180][550/625]	eta 0:01:11 lr 0.673418	data 0.0004 (0.0371)	batch 0.8629 (0.9479)	loss 3.0739 (3.0846)	grad_norm 0.4565 (0.4616)	mem 38886MB
Train: [46/180][600/625]	eta 0:00:23 lr 0.673010	data 0.0004 (0.0340)	batch 0.9357 (0.9443)	loss 3.0045 (3.0871)	grad_norm 0.4669 (0.4618)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 46 training takes 0:09:50
Test: [0/25]	Time 15.211 (15.211)	Loss 1.2639 (1.2639)	Acc@1 71.143 (71.143)	Acc@5 89.111 (89.111)	Mem 38886MB
 * Acc@1 60.504 Acc@5 82.984
Accuracy of the network on the 50000 test images: 60.50%
Max accuracy (after decay): 60.50%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [47/180][0/625]	eta 4:03:12 lr 0.672806	data 20.3865 (20.3865)	batch 23.3486 (23.3486)	loss 2.9601 (2.9601)	grad_norm 0.4456 (0.4456)	mem 38886MB
Train: [47/180][50/625]	eta 0:12:58 lr 0.672397	data 0.0006 (0.4008)	batch 0.8717 (1.3537)	loss 3.2349 (3.0421)	grad_norm 0.4715 (0.4615)	mem 38886MB
Train: [47/180][100/625]	eta 0:09:55 lr 0.671988	data 0.0006 (0.2027)	batch 0.8711 (1.1336)	loss 3.1485 (3.0605)	grad_norm 0.4773 (0.4602)	mem 38886MB
Train: [47/180][150/625]	eta 0:08:23 lr 0.671578	data 0.0007 (0.1358)	batch 0.9042 (1.0595)	loss 3.1011 (3.0629)	grad_norm 0.4586 (0.4607)	mem 38886MB
Train: [47/180][200/625]	eta 0:07:13 lr 0.671168	data 0.0007 (0.1021)	batch 0.8942 (1.0202)	loss 3.0109 (3.0630)	grad_norm 0.4550 (0.4616)	mem 38886MB
Train: [47/180][250/625]	eta 0:06:14 lr 0.670757	data 0.0003 (0.0819)	batch 0.9018 (0.9974)	loss 2.9792 (3.0641)	grad_norm 0.4750 (0.4612)	mem 38886MB
Train: [47/180][300/625]	eta 0:05:19 lr 0.670345	data 0.0004 (0.0685)	batch 0.9092 (0.9833)	loss 3.1104 (3.0694)	grad_norm 0.4543 (0.4618)	mem 38886MB
Train: [47/180][350/625]	eta 0:04:27 lr 0.669934	data 0.0005 (0.0589)	batch 0.8955 (0.9724)	loss 3.0297 (3.0713)	grad_norm 0.4748 (0.4617)	mem 38886MB
Train: [47/180][400/625]	eta 0:03:36 lr 0.669521	data 0.0005 (0.0516)	batch 0.8613 (0.9637)	loss 3.0508 (3.0735)	grad_norm 0.4544 (0.4615)	mem 38886MB
Train: [47/180][450/625]	eta 0:02:47 lr 0.669108	data 0.0005 (0.0459)	batch 0.8658 (0.9573)	loss 3.1860 (3.0730)	grad_norm 0.4540 (0.4617)	mem 38886MB
Train: [47/180][500/625]	eta 0:01:58 lr 0.668695	data 0.0007 (0.0414)	batch 0.8882 (0.9520)	loss 3.2508 (3.0753)	grad_norm 0.4733 (0.4618)	mem 38886MB
Train: [47/180][550/625]	eta 0:01:11 lr 0.668281	data 0.0005 (0.0377)	batch 0.9255 (0.9477)	loss 2.9006 (3.0750)	grad_norm 0.4564 (0.4620)	mem 38886MB
Train: [47/180][600/625]	eta 0:00:23 lr 0.667866	data 0.0008 (0.0347)	batch 0.8842 (0.9439)	loss 3.1013 (3.0740)	grad_norm 0.4652 (0.4621)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 47 training takes 0:09:50
Test: [0/25]	Time 14.569 (14.569)	Loss 1.3038 (1.3038)	Acc@1 70.850 (70.850)	Acc@5 88.818 (88.818)	Mem 38886MB
 * Acc@1 59.998 Acc@5 82.898
Accuracy of the network on the 50000 test images: 60.00%
Max accuracy (after decay): 60.50%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [48/180][0/625]	eta 4:01:26 lr 0.667659	data 21.3384 (21.3384)	batch 23.1787 (23.1787)	loss 3.1558 (3.1558)	grad_norm 0.4513 (0.4513)	mem 38886MB
Train: [48/180][50/625]	eta 0:12:53 lr 0.667244	data 0.0006 (0.4192)	batch 0.9102 (1.3451)	loss 2.9433 (3.0534)	grad_norm 0.4615 (0.4604)	mem 38886MB
Train: [48/180][100/625]	eta 0:09:54 lr 0.666828	data 0.0006 (0.2120)	batch 0.9278 (1.1315)	loss 3.1638 (3.0552)	grad_norm 0.4742 (0.4614)	mem 38886MB
Train: [48/180][150/625]	eta 0:08:21 lr 0.666411	data 0.0006 (0.1420)	batch 0.9231 (1.0566)	loss 3.0108 (3.0540)	grad_norm 0.4610 (0.4625)	mem 38886MB
Train: [48/180][200/625]	eta 0:07:13 lr 0.665995	data 0.0006 (0.1068)	batch 0.8910 (1.0208)	loss 2.8985 (3.0553)	grad_norm 0.4744 (0.4630)	mem 38886MB
Train: [48/180][250/625]	eta 0:06:14 lr 0.665577	data 0.0006 (0.0856)	batch 0.9273 (0.9978)	loss 3.0190 (3.0538)	grad_norm 0.4512 (0.4627)	mem 38886MB
Train: [48/180][300/625]	eta 0:05:19 lr 0.665159	data 0.0003 (0.0715)	batch 0.9083 (0.9827)	loss 3.1521 (3.0527)	grad_norm 0.4649 (0.4631)	mem 38886MB
Train: [48/180][350/625]	eta 0:04:27 lr 0.664741	data 0.0007 (0.0614)	batch 0.8664 (0.9725)	loss 3.1633 (3.0544)	grad_norm 0.4805 (0.4632)	mem 38886MB
Train: [48/180][400/625]	eta 0:03:36 lr 0.664322	data 0.0006 (0.0538)	batch 0.9502 (0.9644)	loss 3.1076 (3.0597)	grad_norm 0.4653 (0.4637)	mem 38886MB
Train: [48/180][450/625]	eta 0:02:47 lr 0.663903	data 0.0005 (0.0479)	batch 0.9260 (0.9581)	loss 3.0335 (3.0604)	grad_norm 0.4723 (0.4638)	mem 38886MB
Train: [48/180][500/625]	eta 0:01:59 lr 0.663483	data 0.0004 (0.0432)	batch 0.8716 (0.9525)	loss 2.9433 (3.0612)	grad_norm 0.4791 (0.4635)	mem 38886MB
Train: [48/180][550/625]	eta 0:01:11 lr 0.663062	data 0.0006 (0.0393)	batch 0.8837 (0.9486)	loss 3.1637 (3.0648)	grad_norm 0.4640 (0.4632)	mem 38886MB
Train: [48/180][600/625]	eta 0:00:23 lr 0.662641	data 0.0006 (0.0361)	batch 0.8742 (0.9452)	loss 3.1711 (3.0664)	grad_norm 0.4597 (0.4635)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 48 training takes 0:09:51
Test: [0/25]	Time 14.962 (14.962)	Loss 1.2901 (1.2901)	Acc@1 72.559 (72.559)	Acc@5 89.648 (89.648)	Mem 38886MB
 * Acc@1 60.692 Acc@5 83.158
Accuracy of the network on the 50000 test images: 60.69%
Max accuracy (after decay): 60.69%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [49/180][0/625]	eta 3:57:39 lr 0.662430	data 20.7441 (20.7441)	batch 22.8144 (22.8144)	loss 2.8884 (2.8884)	grad_norm 0.4468 (0.4468)	mem 38886MB
Train: [49/180][50/625]	eta 0:12:52 lr 0.662009	data 0.0005 (0.4074)	batch 0.9014 (1.3441)	loss 2.9029 (3.0468)	grad_norm 0.4537 (0.4615)	mem 38886MB
Train: [49/180][100/625]	eta 0:09:53 lr 0.661586	data 0.0007 (0.2060)	batch 0.9533 (1.1299)	loss 3.0404 (3.0395)	grad_norm 0.4615 (0.4610)	mem 38886MB
Train: [49/180][150/625]	eta 0:08:21 lr 0.661164	data 0.0005 (0.1380)	batch 0.9233 (1.0556)	loss 2.9170 (3.0532)	grad_norm 0.4576 (0.4626)	mem 38886MB
Train: [49/180][200/625]	eta 0:07:13 lr 0.660740	data 0.0005 (0.1038)	batch 0.9282 (1.0194)	loss 2.9759 (3.0535)	grad_norm 0.4604 (0.4629)	mem 38886MB
Train: [49/180][250/625]	eta 0:06:13 lr 0.660317	data 0.0005 (0.0832)	batch 0.8753 (0.9967)	loss 3.0894 (3.0573)	grad_norm 0.4549 (0.4631)	mem 38886MB
Train: [49/180][300/625]	eta 0:05:19 lr 0.659892	data 0.0005 (0.0695)	batch 0.9432 (0.9821)	loss 3.1477 (3.0599)	grad_norm 0.4620 (0.4636)	mem 38886MB
Train: [49/180][350/625]	eta 0:04:27 lr 0.659468	data 0.0005 (0.0597)	batch 0.8911 (0.9713)	loss 2.9687 (3.0576)	grad_norm 0.4700 (0.4635)	mem 38886MB
Train: [49/180][400/625]	eta 0:03:36 lr 0.659042	data 0.0005 (0.0523)	batch 0.8884 (0.9635)	loss 2.9866 (3.0604)	grad_norm 0.4513 (0.4639)	mem 38886MB
Train: [49/180][450/625]	eta 0:02:47 lr 0.658616	data 0.0005 (0.0466)	batch 0.8976 (0.9581)	loss 3.1726 (3.0623)	grad_norm 0.4689 (0.4638)	mem 38886MB
Train: [49/180][500/625]	eta 0:01:59 lr 0.658190	data 0.0005 (0.0420)	batch 0.9259 (0.9532)	loss 3.0374 (3.0672)	grad_norm 0.4571 (0.4639)	mem 38886MB
Train: [49/180][550/625]	eta 0:01:11 lr 0.657763	data 0.0005 (0.0382)	batch 0.9393 (0.9495)	loss 3.0653 (3.0652)	grad_norm 0.4803 (0.4642)	mem 38886MB
Train: [49/180][600/625]	eta 0:00:23 lr 0.657336	data 0.0006 (0.0351)	batch 0.8979 (0.9458)	loss 3.1166 (3.0671)	grad_norm 0.4654 (0.4640)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 49 training takes 0:09:51
Test: [0/25]	Time 14.659 (14.659)	Loss 1.3154 (1.3154)	Acc@1 72.412 (72.412)	Acc@5 89.795 (89.795)	Mem 38886MB
 * Acc@1 60.150 Acc@5 82.766
Accuracy of the network on the 50000 test images: 60.15%
Max accuracy (after decay): 60.69%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [50/180][0/625]	eta 3:55:32 lr 0.657122	data 21.6364 (21.6364)	batch 22.6127 (22.6127)	loss 2.8774 (2.8774)	grad_norm 0.4602 (0.4602)	mem 38886MB
Train: [50/180][50/625]	eta 0:12:44 lr 0.656694	data 0.0005 (0.4249)	batch 0.8790 (1.3300)	loss 2.8068 (3.0316)	grad_norm 0.4447 (0.4624)	mem 38886MB
Train: [50/180][100/625]	eta 0:09:49 lr 0.656266	data 0.0004 (0.2148)	batch 0.9001 (1.1233)	loss 2.8578 (3.0524)	grad_norm 0.4585 (0.4631)	mem 38886MB
Train: [50/180][150/625]	eta 0:08:19 lr 0.655836	data 0.0006 (0.1439)	batch 0.9361 (1.0516)	loss 3.1347 (3.0499)	grad_norm 0.4710 (0.4634)	mem 38886MB
Train: [50/180][200/625]	eta 0:07:12 lr 0.655407	data 0.0005 (0.1084)	batch 0.8778 (1.0175)	loss 2.8709 (3.0496)	grad_norm 0.4615 (0.4641)	mem 38886MB
Train: [50/180][250/625]	eta 0:06:13 lr 0.654977	data 0.0005 (0.0869)	batch 0.9140 (0.9956)	loss 3.1548 (3.0501)	grad_norm 0.4630 (0.4643)	mem 38886MB
Train: [50/180][300/625]	eta 0:05:19 lr 0.654546	data 0.0004 (0.0726)	batch 0.9260 (0.9817)	loss 3.0982 (3.0522)	grad_norm 0.4744 (0.4645)	mem 38886MB
Train: [50/180][350/625]	eta 0:04:27 lr 0.654115	data 0.0006 (0.0623)	batch 0.9181 (0.9714)	loss 2.9978 (3.0533)	grad_norm 0.4674 (0.4647)	mem 38886MB
Train: [50/180][400/625]	eta 0:03:36 lr 0.653684	data 0.0004 (0.0546)	batch 0.9332 (0.9630)	loss 3.0551 (3.0563)	grad_norm 0.4838 (0.4647)	mem 38886MB
Train: [50/180][450/625]	eta 0:02:47 lr 0.653252	data 0.0005 (0.0486)	batch 0.8997 (0.9571)	loss 2.8811 (3.0585)	grad_norm 0.4562 (0.4650)	mem 38886MB
Train: [50/180][500/625]	eta 0:01:58 lr 0.652819	data 0.0005 (0.0439)	batch 0.9124 (0.9519)	loss 3.1748 (3.0570)	grad_norm 0.4707 (0.4649)	mem 38886MB
Train: [50/180][550/625]	eta 0:01:11 lr 0.652386	data 0.0006 (0.0400)	batch 0.8728 (0.9480)	loss 3.2788 (3.0554)	grad_norm 0.4559 (0.4649)	mem 38886MB
Train: [50/180][600/625]	eta 0:00:23 lr 0.651953	data 0.0005 (0.0367)	batch 0.9068 (0.9448)	loss 3.0735 (3.0591)	grad_norm 0.4761 (0.4651)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 50 training takes 0:09:51
Test: [0/25]	Time 15.253 (15.253)	Loss 1.2746 (1.2746)	Acc@1 71.143 (71.143)	Acc@5 90.332 (90.332)	Mem 38886MB
 * Acc@1 60.032 Acc@5 82.912
Accuracy of the network on the 50000 test images: 60.03%
Max accuracy (after decay): 60.69%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [51/180][0/625]	eta 3:55:27 lr 0.651736	data 21.3100 (21.3100)	batch 22.6037 (22.6037)	loss 2.9090 (2.9090)	grad_norm 0.4593 (0.4593)	mem 38886MB
Train: [51/180][50/625]	eta 0:12:48 lr 0.651301	data 0.0006 (0.4186)	batch 0.8773 (1.3362)	loss 2.7450 (3.0135)	grad_norm 0.4612 (0.4650)	mem 38886MB
Train: [51/180][100/625]	eta 0:09:49 lr 0.650867	data 0.0007 (0.2117)	batch 0.9101 (1.1231)	loss 2.9262 (3.0421)	grad_norm 0.4863 (0.4652)	mem 38886MB
Train: [51/180][150/625]	eta 0:08:19 lr 0.650431	data 0.0005 (0.1418)	batch 0.9118 (1.0510)	loss 3.0439 (3.0445)	grad_norm 0.4738 (0.4662)	mem 38886MB
Train: [51/180][200/625]	eta 0:07:11 lr 0.649996	data 0.0003 (0.1067)	batch 0.8756 (1.0149)	loss 3.0962 (3.0487)	grad_norm 0.4642 (0.4668)	mem 38886MB
Train: [51/180][250/625]	eta 0:06:12 lr 0.649559	data 0.0005 (0.0856)	batch 0.9035 (0.9927)	loss 3.1143 (3.0522)	grad_norm 0.4548 (0.4670)	mem 38886MB
Train: [51/180][300/625]	eta 0:05:18 lr 0.649123	data 0.0005 (0.0714)	batch 0.9230 (0.9785)	loss 3.1201 (3.0561)	grad_norm 0.4650 (0.4665)	mem 38886MB
Train: [51/180][350/625]	eta 0:04:26 lr 0.648685	data 0.0005 (0.0613)	batch 0.9197 (0.9683)	loss 3.2551 (3.0584)	grad_norm 0.4703 (0.4665)	mem 38886MB
Train: [51/180][400/625]	eta 0:03:35 lr 0.648248	data 0.0005 (0.0538)	batch 0.9261 (0.9599)	loss 2.9643 (3.0562)	grad_norm 0.4693 (0.4663)	mem 38886MB
Train: [51/180][450/625]	eta 0:02:46 lr 0.647810	data 0.0005 (0.0479)	batch 0.8991 (0.9541)	loss 2.9236 (3.0569)	grad_norm 0.4628 (0.4663)	mem 38886MB
Train: [51/180][500/625]	eta 0:01:58 lr 0.647371	data 0.0006 (0.0431)	batch 0.8991 (0.9490)	loss 2.9280 (3.0550)	grad_norm 0.4832 (0.4661)	mem 38886MB
Train: [51/180][550/625]	eta 0:01:10 lr 0.646932	data 0.0006 (0.0393)	batch 0.9010 (0.9455)	loss 2.9999 (3.0514)	grad_norm 0.4611 (0.4661)	mem 38886MB
Train: [51/180][600/625]	eta 0:00:23 lr 0.646492	data 0.0005 (0.0360)	batch 0.8922 (0.9416)	loss 3.0824 (3.0515)	grad_norm 0.4742 (0.4662)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 51 training takes 0:09:49
Test: [0/25]	Time 14.954 (14.954)	Loss 1.2864 (1.2864)	Acc@1 72.070 (72.070)	Acc@5 90.479 (90.479)	Mem 38886MB
 * Acc@1 60.170 Acc@5 82.816
Accuracy of the network on the 50000 test images: 60.17%
Max accuracy (after decay): 60.69%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [52/180][0/625]	eta 3:58:10 lr 0.646272	data 21.9539 (21.9539)	batch 22.8651 (22.8651)	loss 3.0470 (3.0470)	grad_norm 0.4871 (0.4871)	mem 38886MB
Train: [52/180][50/625]	eta 0:12:52 lr 0.645832	data 0.0006 (0.4312)	batch 0.9036 (1.3439)	loss 2.7934 (3.0258)	grad_norm 0.4631 (0.4647)	mem 38886MB
Train: [52/180][100/625]	eta 0:09:53 lr 0.645391	data 0.0011 (0.2181)	batch 0.8728 (1.1298)	loss 2.8793 (3.0309)	grad_norm 0.4851 (0.4662)	mem 38886MB
Train: [52/180][150/625]	eta 0:08:21 lr 0.644950	data 0.0006 (0.1461)	batch 0.9140 (1.0559)	loss 3.0648 (3.0367)	grad_norm 0.4792 (0.4655)	mem 38886MB
Train: [52/180][200/625]	eta 0:07:13 lr 0.644508	data 0.0006 (0.1100)	batch 0.8915 (1.0192)	loss 2.8975 (3.0375)	grad_norm 0.4575 (0.4655)	mem 38886MB
Train: [52/180][250/625]	eta 0:06:13 lr 0.644066	data 0.0009 (0.0882)	batch 0.8770 (0.9969)	loss 2.9762 (3.0412)	grad_norm 0.4681 (0.4666)	mem 38886MB
Train: [52/180][300/625]	eta 0:05:19 lr 0.643623	data 0.0008 (0.0738)	batch 0.8969 (0.9820)	loss 3.0462 (3.0495)	grad_norm 0.4623 (0.4671)	mem 38886MB
Train: [52/180][350/625]	eta 0:04:27 lr 0.643180	data 0.0005 (0.0634)	batch 0.9374 (0.9716)	loss 2.8684 (3.0506)	grad_norm 0.4520 (0.4669)	mem 38886MB
Train: [52/180][400/625]	eta 0:03:36 lr 0.642736	data 0.0010 (0.0556)	batch 0.9298 (0.9642)	loss 3.1345 (3.0501)	grad_norm 0.4772 (0.4672)	mem 38886MB
Train: [52/180][450/625]	eta 0:02:47 lr 0.642292	data 0.0006 (0.0495)	batch 0.9327 (0.9580)	loss 2.9220 (3.0486)	grad_norm 0.4606 (0.4670)	mem 38886MB
Train: [52/180][500/625]	eta 0:01:59 lr 0.641848	data 0.0010 (0.0446)	batch 0.8619 (0.9532)	loss 3.1239 (3.0496)	grad_norm 0.4598 (0.4671)	mem 38886MB
Train: [52/180][550/625]	eta 0:01:11 lr 0.641402	data 0.0006 (0.0406)	batch 0.8797 (0.9492)	loss 2.7191 (3.0489)	grad_norm 0.4617 (0.4675)	mem 38886MB
Train: [52/180][600/625]	eta 0:00:23 lr 0.640957	data 0.0005 (0.0373)	batch 0.9373 (0.9454)	loss 3.0533 (3.0498)	grad_norm 0.4832 (0.4674)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 52 training takes 0:09:51
Test: [0/25]	Time 14.516 (14.516)	Loss 1.2977 (1.2977)	Acc@1 70.996 (70.996)	Acc@5 89.893 (89.893)	Mem 38886MB
 * Acc@1 60.628 Acc@5 82.946
Accuracy of the network on the 50000 test images: 60.63%
Max accuracy (after decay): 60.69%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [53/180][0/625]	eta 3:57:35 lr 0.640734	data 21.6961 (21.6961)	batch 22.8092 (22.8092)	loss 3.0581 (3.0581)	grad_norm 0.4526 (0.4526)	mem 38886MB
Train: [53/180][50/625]	eta 0:12:49 lr 0.640288	data 0.0006 (0.4262)	batch 0.8919 (1.3389)	loss 3.0378 (3.0208)	grad_norm 0.4688 (0.4656)	mem 38886MB
Train: [53/180][100/625]	eta 0:09:50 lr 0.639841	data 0.0005 (0.2156)	batch 0.8741 (1.1252)	loss 2.6904 (3.0260)	grad_norm 0.4572 (0.4663)	mem 38886MB
Train: [53/180][150/625]	eta 0:08:20 lr 0.639394	data 0.0004 (0.1444)	batch 0.8813 (1.0547)	loss 2.9478 (3.0323)	grad_norm 0.4541 (0.4664)	mem 38886MB
Train: [53/180][200/625]	eta 0:07:12 lr 0.638946	data 0.0005 (0.1087)	batch 0.9329 (1.0187)	loss 2.8757 (3.0346)	grad_norm 0.4714 (0.4666)	mem 38886MB
Train: [53/180][250/625]	eta 0:06:13 lr 0.638498	data 0.0006 (0.0871)	batch 0.9186 (0.9967)	loss 3.0434 (3.0347)	grad_norm 0.4713 (0.4669)	mem 38886MB
Train: [53/180][300/625]	eta 0:05:19 lr 0.638049	data 0.0005 (0.0728)	batch 0.9704 (0.9825)	loss 2.8537 (3.0357)	grad_norm 0.4514 (0.4671)	mem 38886MB
Train: [53/180][350/625]	eta 0:04:27 lr 0.637600	data 0.0006 (0.0625)	batch 0.9680 (0.9712)	loss 2.8733 (3.0379)	grad_norm 0.4622 (0.4674)	mem 38886MB
Train: [53/180][400/625]	eta 0:03:36 lr 0.637151	data 0.0005 (0.0548)	batch 0.9050 (0.9636)	loss 2.9733 (3.0428)	grad_norm 0.4708 (0.4674)	mem 38886MB
Train: [53/180][450/625]	eta 0:02:47 lr 0.636701	data 0.0007 (0.0488)	batch 0.8861 (0.9580)	loss 3.0609 (3.0402)	grad_norm 0.4718 (0.4676)	mem 38886MB
Train: [53/180][500/625]	eta 0:01:59 lr 0.636250	data 0.0007 (0.0440)	batch 0.8805 (0.9534)	loss 2.9266 (3.0392)	grad_norm 0.4578 (0.4675)	mem 38886MB
Train: [53/180][550/625]	eta 0:01:11 lr 0.635800	data 0.0005 (0.0401)	batch 0.9658 (0.9499)	loss 3.0453 (3.0417)	grad_norm 0.4674 (0.4675)	mem 38886MB
Train: [53/180][600/625]	eta 0:00:23 lr 0.635348	data 0.0006 (0.0368)	batch 0.9477 (0.9463)	loss 3.2911 (3.0437)	grad_norm 0.4717 (0.4676)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 53 training takes 0:09:51
Test: [0/25]	Time 15.006 (15.006)	Loss 1.2744 (1.2744)	Acc@1 71.729 (71.729)	Acc@5 89.160 (89.160)	Mem 38886MB
 * Acc@1 60.804 Acc@5 83.178
Accuracy of the network on the 50000 test images: 60.80%
Max accuracy (after decay): 60.80%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [54/180][0/625]	eta 3:58:09 lr 0.635122	data 21.4448 (21.4448)	batch 22.8626 (22.8626)	loss 3.1593 (3.1593)	grad_norm 0.4775 (0.4775)	mem 38886MB
Train: [54/180][50/625]	eta 0:12:52 lr 0.634670	data 0.0006 (0.4215)	batch 0.9253 (1.3435)	loss 3.0824 (3.0279)	grad_norm 0.4735 (0.4706)	mem 38886MB
Train: [54/180][100/625]	eta 0:09:52 lr 0.634218	data 0.0010 (0.2132)	batch 0.9320 (1.1280)	loss 2.7767 (3.0244)	grad_norm 0.4731 (0.4694)	mem 38886MB
Train: [54/180][150/625]	eta 0:08:21 lr 0.633765	data 0.0007 (0.1429)	batch 0.8818 (1.0562)	loss 3.0205 (3.0248)	grad_norm 0.4621 (0.4694)	mem 38886MB
Train: [54/180][200/625]	eta 0:07:13 lr 0.633311	data 0.0007 (0.1075)	batch 0.9150 (1.0205)	loss 2.8907 (3.0356)	grad_norm 0.4606 (0.4698)	mem 38886MB
Train: [54/180][250/625]	eta 0:06:14 lr 0.632858	data 0.0006 (0.0864)	batch 0.8956 (0.9990)	loss 2.9451 (3.0363)	grad_norm 0.4635 (0.4701)	mem 38886MB
Train: [54/180][300/625]	eta 0:05:19 lr 0.632403	data 0.0006 (0.0722)	batch 0.8946 (0.9838)	loss 3.1093 (3.0364)	grad_norm 0.4671 (0.4698)	mem 38886MB
Train: [54/180][350/625]	eta 0:04:27 lr 0.631948	data 0.0009 (0.0620)	batch 0.8838 (0.9729)	loss 3.1367 (3.0378)	grad_norm 0.4683 (0.4694)	mem 38886MB
Train: [54/180][400/625]	eta 0:03:36 lr 0.631493	data 0.0006 (0.0544)	batch 0.9230 (0.9640)	loss 3.2887 (3.0411)	grad_norm 0.4681 (0.4691)	mem 38886MB
Train: [54/180][450/625]	eta 0:02:47 lr 0.631038	data 0.0008 (0.0484)	batch 0.8643 (0.9587)	loss 3.1202 (3.0390)	grad_norm 0.4727 (0.4695)	mem 38886MB
Train: [54/180][500/625]	eta 0:01:59 lr 0.630581	data 0.0008 (0.0437)	batch 0.9041 (0.9533)	loss 2.9981 (3.0391)	grad_norm 0.4855 (0.4696)	mem 38886MB
Train: [54/180][550/625]	eta 0:01:11 lr 0.630125	data 0.0005 (0.0398)	batch 0.8979 (0.9492)	loss 3.0447 (3.0392)	grad_norm 0.4574 (0.4693)	mem 38886MB
Train: [54/180][600/625]	eta 0:00:23 lr 0.629668	data 0.0004 (0.0365)	batch 0.9460 (0.9455)	loss 2.8613 (3.0410)	grad_norm 0.4722 (0.4692)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 54 training takes 0:09:51
Test: [0/25]	Time 13.961 (13.961)	Loss 1.2473 (1.2473)	Acc@1 72.412 (72.412)	Acc@5 89.941 (89.941)	Mem 38886MB
 * Acc@1 60.864 Acc@5 83.238
Accuracy of the network on the 50000 test images: 60.86%
Max accuracy (after decay): 60.86%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [55/180][0/625]	eta 4:08:03 lr 0.629439	data 22.3607 (22.3607)	batch 23.8131 (23.8131)	loss 3.1651 (3.1651)	grad_norm 0.4693 (0.4693)	mem 38886MB
Train: [55/180][50/625]	eta 0:13:00 lr 0.628981	data 0.0006 (0.4394)	batch 0.8680 (1.3578)	loss 3.0615 (3.0196)	grad_norm 0.4774 (0.4710)	mem 38886MB
Train: [55/180][100/625]	eta 0:09:58 lr 0.628523	data 0.0005 (0.2222)	batch 0.9941 (1.1408)	loss 2.9350 (3.0299)	grad_norm 0.4744 (0.4710)	mem 38886MB
Train: [55/180][150/625]	eta 0:08:25 lr 0.628065	data 0.0008 (0.1489)	batch 0.9368 (1.0647)	loss 2.9823 (3.0309)	grad_norm 0.4821 (0.4709)	mem 38886MB
Train: [55/180][200/625]	eta 0:07:16 lr 0.627606	data 0.0008 (0.1121)	batch 0.8770 (1.0263)	loss 2.8754 (3.0264)	grad_norm 0.4650 (0.4712)	mem 38886MB
Train: [55/180][250/625]	eta 0:06:15 lr 0.627146	data 0.0010 (0.0899)	batch 0.8735 (1.0026)	loss 3.1239 (3.0272)	grad_norm 0.4832 (0.4711)	mem 38886MB
Train: [55/180][300/625]	eta 0:05:20 lr 0.626686	data 0.0006 (0.0751)	batch 0.8858 (0.9871)	loss 3.1907 (3.0324)	grad_norm 0.5009 (0.4713)	mem 38886MB
Train: [55/180][350/625]	eta 0:04:28 lr 0.626226	data 0.0006 (0.0645)	batch 0.9290 (0.9764)	loss 2.9459 (3.0284)	grad_norm 0.4564 (0.4711)	mem 38886MB
Train: [55/180][400/625]	eta 0:03:37 lr 0.625765	data 0.0008 (0.0566)	batch 0.9294 (0.9682)	loss 2.9696 (3.0280)	grad_norm 0.4674 (0.4711)	mem 38886MB
Train: [55/180][450/625]	eta 0:02:48 lr 0.625304	data 0.0006 (0.0504)	batch 0.8829 (0.9612)	loss 3.1833 (3.0290)	grad_norm 0.4718 (0.4712)	mem 38886MB
Train: [55/180][500/625]	eta 0:01:59 lr 0.624842	data 0.0007 (0.0454)	batch 0.8829 (0.9556)	loss 3.0694 (3.0313)	grad_norm 0.4620 (0.4710)	mem 38886MB
Train: [55/180][550/625]	eta 0:01:11 lr 0.624380	data 0.0005 (0.0414)	batch 0.8965 (0.9512)	loss 3.0254 (3.0317)	grad_norm 0.4512 (0.4707)	mem 38886MB
Train: [55/180][600/625]	eta 0:00:23 lr 0.623917	data 0.0008 (0.0380)	batch 0.8669 (0.9474)	loss 3.0507 (3.0318)	grad_norm 0.4782 (0.4706)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 55 training takes 0:09:52
Test: [0/25]	Time 14.456 (14.456)	Loss 1.2235 (1.2235)	Acc@1 72.754 (72.754)	Acc@5 90.283 (90.283)	Mem 38886MB
 * Acc@1 61.152 Acc@5 83.488
Accuracy of the network on the 50000 test images: 61.15%
Max accuracy (after decay): 61.15%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [56/180][0/625]	eta 3:55:12 lr 0.623686	data 21.3720 (21.3720)	batch 22.5806 (22.5806)	loss 3.1261 (3.1261)	grad_norm 0.4667 (0.4667)	mem 38886MB
Train: [56/180][50/625]	eta 0:12:49 lr 0.623223	data 0.0006 (0.4198)	batch 0.8785 (1.3384)	loss 3.0007 (3.0287)	grad_norm 0.4678 (0.4700)	mem 38886MB
Train: [56/180][100/625]	eta 0:09:51 lr 0.622759	data 0.0013 (0.2123)	batch 0.9270 (1.1258)	loss 2.9845 (3.0289)	grad_norm 0.4714 (0.4720)	mem 38886MB
Train: [56/180][150/625]	eta 0:08:20 lr 0.622295	data 0.0006 (0.1423)	batch 0.8881 (1.0540)	loss 3.2125 (3.0270)	grad_norm 0.4764 (0.4718)	mem 38886MB
Train: [56/180][200/625]	eta 0:07:12 lr 0.621831	data 0.0006 (0.1070)	batch 0.9149 (1.0185)	loss 2.9241 (3.0265)	grad_norm 0.4717 (0.4717)	mem 38886MB
Train: [56/180][250/625]	eta 0:06:13 lr 0.621366	data 0.0007 (0.0858)	batch 0.8797 (0.9964)	loss 3.0596 (3.0244)	grad_norm 0.4816 (0.4719)	mem 38886MB
Train: [56/180][300/625]	eta 0:05:18 lr 0.620900	data 0.0006 (0.0717)	batch 0.8836 (0.9813)	loss 3.3200 (3.0217)	grad_norm 0.4767 (0.4725)	mem 38886MB
Train: [56/180][350/625]	eta 0:04:27 lr 0.620434	data 0.0007 (0.0616)	batch 0.8732 (0.9712)	loss 2.8428 (3.0191)	grad_norm 0.4753 (0.4723)	mem 38886MB
Train: [56/180][400/625]	eta 0:03:36 lr 0.619968	data 0.0006 (0.0540)	batch 0.9006 (0.9633)	loss 3.1269 (3.0208)	grad_norm 0.4661 (0.4728)	mem 38886MB
Train: [56/180][450/625]	eta 0:02:47 lr 0.619501	data 0.0006 (0.0481)	batch 0.9235 (0.9570)	loss 3.0194 (3.0192)	grad_norm 0.4708 (0.4724)	mem 38886MB
Train: [56/180][500/625]	eta 0:01:58 lr 0.619034	data 0.0006 (0.0434)	batch 0.8776 (0.9517)	loss 2.9623 (3.0219)	grad_norm 0.4713 (0.4724)	mem 38886MB
Train: [56/180][550/625]	eta 0:01:11 lr 0.618567	data 0.0009 (0.0396)	batch 0.8945 (0.9476)	loss 3.0061 (3.0256)	grad_norm 0.4908 (0.4725)	mem 38886MB
Train: [56/180][600/625]	eta 0:00:23 lr 0.618099	data 0.0005 (0.0364)	batch 0.9368 (0.9439)	loss 3.2118 (3.0293)	grad_norm 0.4790 (0.4727)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 56 training takes 0:09:50
Test: [0/25]	Time 14.414 (14.414)	Loss 1.1816 (1.1816)	Acc@1 73.486 (73.486)	Acc@5 91.260 (91.260)	Mem 38886MB
 * Acc@1 61.094 Acc@5 83.580
Accuracy of the network on the 50000 test images: 61.09%
Max accuracy (after decay): 61.15%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [57/180][0/625]	eta 3:54:48 lr 0.617865	data 21.3524 (21.3524)	batch 22.5412 (22.5412)	loss 2.8795 (2.8795)	grad_norm 0.4615 (0.4615)	mem 38886MB
Train: [57/180][50/625]	eta 0:12:51 lr 0.617396	data 0.0007 (0.4199)	batch 0.9036 (1.3416)	loss 3.0074 (3.0352)	grad_norm 0.4654 (0.4700)	mem 38886MB
Train: [57/180][100/625]	eta 0:09:51 lr 0.616927	data 0.0006 (0.2123)	batch 0.8946 (1.1265)	loss 2.8224 (3.0246)	grad_norm 0.4781 (0.4699)	mem 38886MB
Train: [57/180][150/625]	eta 0:08:21 lr 0.616458	data 0.0008 (0.1423)	batch 0.9001 (1.0555)	loss 2.9133 (3.0196)	grad_norm 0.4714 (0.4712)	mem 38886MB
Train: [57/180][200/625]	eta 0:07:12 lr 0.615988	data 0.0007 (0.1071)	batch 0.8427 (1.0185)	loss 3.1307 (3.0227)	grad_norm 0.4885 (0.4714)	mem 38886MB
Train: [57/180][250/625]	eta 0:06:13 lr 0.615518	data 0.0006 (0.0859)	batch 0.8906 (0.9958)	loss 3.0521 (3.0243)	grad_norm 0.4577 (0.4716)	mem 38886MB
Train: [57/180][300/625]	eta 0:05:18 lr 0.615047	data 0.0007 (0.0717)	batch 0.8994 (0.9813)	loss 2.8862 (3.0276)	grad_norm 0.4778 (0.4721)	mem 38886MB
Train: [57/180][350/625]	eta 0:04:26 lr 0.614576	data 0.0009 (0.0616)	batch 0.9011 (0.9703)	loss 3.1039 (3.0308)	grad_norm 0.4609 (0.4720)	mem 38886MB
Train: [57/180][400/625]	eta 0:03:36 lr 0.614104	data 0.0006 (0.0540)	batch 0.8965 (0.9631)	loss 2.8828 (3.0245)	grad_norm 0.4608 (0.4721)	mem 38886MB
Train: [57/180][450/625]	eta 0:02:47 lr 0.613632	data 0.0006 (0.0481)	batch 0.9128 (0.9573)	loss 2.9988 (3.0243)	grad_norm 0.5497 (0.4723)	mem 38886MB
Train: [57/180][500/625]	eta 0:01:58 lr 0.613160	data 0.0007 (0.0434)	batch 0.8925 (0.9519)	loss 3.0577 (3.0269)	grad_norm 0.4787 (0.4727)	mem 38886MB
Train: [57/180][550/625]	eta 0:01:11 lr 0.612687	data 0.0007 (0.0395)	batch 0.9213 (0.9478)	loss 3.0845 (3.0300)	grad_norm 0.4863 (0.4729)	mem 38886MB
Train: [57/180][600/625]	eta 0:00:23 lr 0.612214	data 0.0008 (0.0363)	batch 0.8690 (0.9440)	loss 2.9368 (3.0317)	grad_norm 0.4776 (0.4730)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 57 training takes 0:09:50
Test: [0/25]	Time 14.721 (14.721)	Loss 1.2369 (1.2369)	Acc@1 72.217 (72.217)	Acc@5 89.697 (89.697)	Mem 38886MB
 * Acc@1 61.052 Acc@5 83.468
Accuracy of the network on the 50000 test images: 61.05%
Max accuracy (after decay): 61.15%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [58/180][0/625]	eta 3:57:46 lr 0.611977	data 20.9789 (20.9789)	batch 22.8264 (22.8264)	loss 2.9317 (2.9317)	grad_norm 0.4654 (0.4654)	mem 38886MB
Train: [58/180][50/625]	eta 0:12:47 lr 0.611503	data 0.0006 (0.4120)	batch 0.8840 (1.3349)	loss 3.0321 (3.0228)	grad_norm 0.4725 (0.4722)	mem 38886MB
Train: [58/180][100/625]	eta 0:09:49 lr 0.611029	data 0.0006 (0.2084)	batch 0.9075 (1.1228)	loss 3.0824 (3.0168)	grad_norm 0.4671 (0.4719)	mem 38886MB
Train: [58/180][150/625]	eta 0:08:20 lr 0.610554	data 0.0005 (0.1396)	batch 0.8723 (1.0535)	loss 3.1086 (3.0220)	grad_norm 0.4731 (0.4726)	mem 38886MB
Train: [58/180][200/625]	eta 0:07:12 lr 0.610079	data 0.0007 (0.1050)	batch 0.8810 (1.0182)	loss 2.9756 (3.0234)	grad_norm 0.4782 (0.4727)	mem 38886MB
Train: [58/180][250/625]	eta 0:06:14 lr 0.609604	data 0.0010 (0.0842)	batch 0.9036 (0.9980)	loss 3.1435 (3.0286)	grad_norm 0.4719 (0.4729)	mem 38886MB
Train: [58/180][300/625]	eta 0:05:19 lr 0.609128	data 0.0006 (0.0703)	batch 0.8962 (0.9825)	loss 3.0405 (3.0331)	grad_norm 0.4650 (0.4729)	mem 38886MB
Train: [58/180][350/625]	eta 0:04:27 lr 0.608652	data 0.0005 (0.0604)	batch 0.9236 (0.9723)	loss 2.9838 (3.0317)	grad_norm 0.4727 (0.4730)	mem 38886MB
Train: [58/180][400/625]	eta 0:03:37 lr 0.608175	data 0.0005 (0.0529)	batch 0.9397 (0.9656)	loss 2.9564 (3.0300)	grad_norm 0.4823 (0.4733)	mem 38886MB
Train: [58/180][450/625]	eta 0:02:47 lr 0.607698	data 0.0011 (0.0471)	batch 0.8929 (0.9594)	loss 3.0126 (3.0302)	grad_norm 0.4734 (0.4733)	mem 38886MB
Train: [58/180][500/625]	eta 0:01:59 lr 0.607220	data 0.0007 (0.0425)	batch 0.9068 (0.9546)	loss 2.9644 (3.0282)	grad_norm 0.4572 (0.4731)	mem 38886MB
Train: [58/180][550/625]	eta 0:01:11 lr 0.606743	data 0.0005 (0.0387)	batch 0.8927 (0.9504)	loss 2.9325 (3.0273)	grad_norm 0.4699 (0.4731)	mem 38886MB
Train: [58/180][600/625]	eta 0:00:23 lr 0.606264	data 0.0006 (0.0356)	batch 0.8991 (0.9468)	loss 3.0325 (3.0296)	grad_norm 0.4678 (0.4731)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 58 training takes 0:09:52
Test: [0/25]	Time 14.863 (14.863)	Loss 1.2411 (1.2411)	Acc@1 72.168 (72.168)	Acc@5 90.137 (90.137)	Mem 38886MB
 * Acc@1 61.578 Acc@5 83.768
Accuracy of the network on the 50000 test images: 61.58%
Max accuracy (after decay): 61.58%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [59/180][0/625]	eta 3:56:16 lr 0.606025	data 21.1438 (21.1438)	batch 22.6817 (22.6817)	loss 3.1772 (3.1772)	grad_norm 0.4686 (0.4686)	mem 38886MB
Train: [59/180][50/625]	eta 0:12:47 lr 0.605546	data 0.0004 (0.4152)	batch 0.8947 (1.3346)	loss 2.8823 (3.0178)	grad_norm 0.4703 (0.4719)	mem 38886MB
Train: [59/180][100/625]	eta 0:09:49 lr 0.605067	data 0.0006 (0.2100)	batch 0.8696 (1.1229)	loss 2.9460 (3.0172)	grad_norm 0.4983 (0.4739)	mem 38886MB
Train: [59/180][150/625]	eta 0:08:20 lr 0.604587	data 0.0007 (0.1407)	batch 0.8858 (1.0536)	loss 2.9057 (3.0148)	grad_norm 0.4647 (0.4748)	mem 38886MB
Train: [59/180][200/625]	eta 0:07:12 lr 0.604107	data 0.0007 (0.1058)	batch 0.9063 (1.0178)	loss 2.6993 (3.0098)	grad_norm 0.4740 (0.4745)	mem 38886MB
Train: [59/180][250/625]	eta 0:06:13 lr 0.603626	data 0.0006 (0.0849)	batch 0.9457 (0.9964)	loss 2.9688 (3.0120)	grad_norm 0.4649 (0.4747)	mem 38886MB
Train: [59/180][300/625]	eta 0:05:19 lr 0.603145	data 0.0005 (0.0709)	batch 0.8904 (0.9818)	loss 3.1269 (3.0143)	grad_norm 0.4721 (0.4747)	mem 38886MB
Train: [59/180][350/625]	eta 0:04:27 lr 0.602664	data 0.0006 (0.0609)	batch 0.8645 (0.9719)	loss 2.9167 (3.0151)	grad_norm 0.4845 (0.4751)	mem 38886MB
Train: [59/180][400/625]	eta 0:03:37 lr 0.602182	data 0.0007 (0.0534)	batch 0.8880 (0.9646)	loss 3.1888 (3.0170)	grad_norm 0.4622 (0.4754)	mem 38886MB
Train: [59/180][450/625]	eta 0:02:47 lr 0.601700	data 0.0006 (0.0475)	batch 0.9100 (0.9579)	loss 3.1898 (3.0215)	grad_norm 0.4700 (0.4756)	mem 38886MB
Train: [59/180][500/625]	eta 0:01:59 lr 0.601218	data 0.0006 (0.0429)	batch 0.8928 (0.9523)	loss 3.1109 (3.0200)	grad_norm 0.4910 (0.4753)	mem 38886MB
Train: [59/180][550/625]	eta 0:01:11 lr 0.600735	data 0.0006 (0.0391)	batch 0.9393 (0.9482)	loss 3.0960 (3.0204)	grad_norm 0.4803 (0.4752)	mem 38886MB
Train: [59/180][600/625]	eta 0:00:23 lr 0.600252	data 0.0014 (0.0360)	batch 0.9069 (0.9449)	loss 2.7997 (3.0188)	grad_norm 0.4530 (0.4751)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 59 training takes 0:09:50
Test: [0/25]	Time 14.982 (14.982)	Loss 1.1965 (1.1965)	Acc@1 72.998 (72.998)	Acc@5 90.625 (90.625)	Mem 38886MB
 * Acc@1 61.136 Acc@5 83.574
Accuracy of the network on the 50000 test images: 61.14%
Max accuracy (after decay): 61.58%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [60/180][0/625]	eta 3:59:48 lr 0.600010	data 20.6617 (20.6617)	batch 23.0222 (23.0222)	loss 2.9110 (2.9110)	grad_norm 0.4701 (0.4701)	mem 38886MB
Train: [60/180][50/625]	eta 0:12:51 lr 0.599526	data 0.0007 (0.4059)	batch 0.9081 (1.3418)	loss 3.0141 (3.0054)	grad_norm 0.4739 (0.4728)	mem 38886MB
Train: [60/180][100/625]	eta 0:09:50 lr 0.599042	data 0.0007 (0.2053)	batch 0.9263 (1.1239)	loss 2.9122 (3.0068)	grad_norm 0.4627 (0.4740)	mem 38886MB
Train: [60/180][150/625]	eta 0:08:20 lr 0.598557	data 0.0007 (0.1376)	batch 0.8664 (1.0533)	loss 3.0920 (3.0119)	grad_norm 0.4808 (0.4758)	mem 38886MB
Train: [60/180][200/625]	eta 0:07:12 lr 0.598072	data 0.0007 (0.1035)	batch 0.8861 (1.0165)	loss 2.9595 (3.0083)	grad_norm 0.4903 (0.4755)	mem 38886MB
Train: [60/180][250/625]	eta 0:06:13 lr 0.597587	data 0.0005 (0.0831)	batch 0.9332 (0.9952)	loss 3.2025 (3.0118)	grad_norm 0.4724 (0.4762)	mem 38886MB
Train: [60/180][300/625]	eta 0:05:18 lr 0.597101	data 0.0006 (0.0694)	batch 0.8948 (0.9799)	loss 3.0444 (3.0168)	grad_norm 0.4916 (0.4764)	mem 38886MB
Train: [60/180][350/625]	eta 0:04:26 lr 0.596615	data 0.0007 (0.0596)	batch 0.8879 (0.9699)	loss 3.0273 (3.0165)	grad_norm 0.4701 (0.4764)	mem 38886MB
Train: [60/180][400/625]	eta 0:03:36 lr 0.596128	data 0.0010 (0.0523)	batch 0.9088 (0.9618)	loss 3.0105 (3.0172)	grad_norm 0.4882 (0.4764)	mem 38886MB
Train: [60/180][450/625]	eta 0:02:47 lr 0.595641	data 0.0006 (0.0465)	batch 0.8734 (0.9554)	loss 3.0227 (3.0174)	grad_norm 0.4894 (0.4762)	mem 38886MB
Train: [60/180][500/625]	eta 0:01:58 lr 0.595154	data 0.0011 (0.0420)	batch 0.9148 (0.9501)	loss 2.8733 (3.0201)	grad_norm 0.4552 (0.4762)	mem 38886MB
Train: [60/180][550/625]	eta 0:01:10 lr 0.594666	data 0.0006 (0.0382)	batch 0.9215 (0.9459)	loss 3.0756 (3.0206)	grad_norm 0.4702 (0.4762)	mem 38886MB
Train: [60/180][600/625]	eta 0:00:23 lr 0.594178	data 0.0007 (0.0351)	batch 1.0645 (0.9428)	loss 2.9818 (3.0205)	grad_norm 0.4688 (0.4763)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 60 training takes 0:09:49
Test: [0/25]	Time 14.877 (14.877)	Loss 1.2672 (1.2672)	Acc@1 72.314 (72.314)	Acc@5 90.137 (90.137)	Mem 38886MB
 * Acc@1 61.782 Acc@5 83.918
Accuracy of the network on the 50000 test images: 61.78%
Max accuracy (after decay): 61.78%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [61/180][0/625]	eta 4:02:08 lr 0.593934	data 21.4936 (21.4936)	batch 23.2451 (23.2451)	loss 3.0491 (3.0491)	grad_norm 0.4749 (0.4749)	mem 38886MB
Train: [61/180][50/625]	eta 0:12:55 lr 0.593446	data 0.0008 (0.4223)	batch 0.8778 (1.3495)	loss 3.0683 (2.9959)	grad_norm 0.4745 (0.4733)	mem 38886MB
Train: [61/180][100/625]	eta 0:09:54 lr 0.592956	data 0.0009 (0.2136)	batch 0.9128 (1.1315)	loss 2.9590 (3.0154)	grad_norm 0.4624 (0.4747)	mem 38886MB
Train: [61/180][150/625]	eta 0:08:22 lr 0.592467	data 0.0003 (0.1431)	batch 0.9093 (1.0578)	loss 3.1198 (3.0082)	grad_norm 0.4912 (0.4754)	mem 38886MB
Train: [61/180][200/625]	eta 0:07:14 lr 0.591977	data 0.0004 (0.1077)	batch 0.9064 (1.0217)	loss 3.0897 (3.0117)	grad_norm 0.4867 (0.4758)	mem 38886MB
Train: [61/180][250/625]	eta 0:06:14 lr 0.591487	data 0.0012 (0.0864)	batch 0.9454 (0.9998)	loss 2.8020 (3.0122)	grad_norm 0.4825 (0.4754)	mem 38886MB
Train: [61/180][300/625]	eta 0:05:19 lr 0.590997	data 0.0008 (0.0721)	batch 0.9267 (0.9846)	loss 2.9266 (3.0097)	grad_norm 0.4802 (0.4759)	mem 38886MB
Train: [61/180][350/625]	eta 0:04:27 lr 0.590506	data 0.0008 (0.0620)	batch 0.9391 (0.9734)	loss 2.9784 (3.0130)	grad_norm 0.4764 (0.4765)	mem 38886MB
Train: [61/180][400/625]	eta 0:03:37 lr 0.590014	data 0.0006 (0.0543)	batch 0.9099 (0.9657)	loss 3.0652 (3.0141)	grad_norm 0.4852 (0.4766)	mem 38886MB
Train: [61/180][450/625]	eta 0:02:47 lr 0.589523	data 0.0012 (0.0484)	batch 0.9100 (0.9598)	loss 3.1388 (3.0113)	grad_norm 0.4791 (0.4766)	mem 38886MB
Train: [61/180][500/625]	eta 0:01:59 lr 0.589031	data 0.0010 (0.0437)	batch 0.8921 (0.9545)	loss 3.0379 (3.0150)	grad_norm 0.4727 (0.4766)	mem 38886MB
Train: [61/180][550/625]	eta 0:01:11 lr 0.588538	data 0.0014 (0.0398)	batch 0.8825 (0.9502)	loss 3.0791 (3.0154)	grad_norm 0.4829 (0.4767)	mem 38886MB
Train: [61/180][600/625]	eta 0:00:23 lr 0.588046	data 0.0010 (0.0365)	batch 0.8938 (0.9464)	loss 3.0306 (3.0157)	grad_norm 0.4687 (0.4768)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 61 training takes 0:09:51
Test: [0/25]	Time 14.737 (14.737)	Loss 1.2024 (1.2024)	Acc@1 73.047 (73.047)	Acc@5 90.137 (90.137)	Mem 38886MB
 * Acc@1 61.108 Acc@5 83.622
Accuracy of the network on the 50000 test images: 61.11%
Max accuracy (after decay): 61.78%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [62/180][0/625]	eta 3:59:24 lr 0.587799	data 21.8797 (21.8797)	batch 22.9834 (22.9834)	loss 2.9416 (2.9416)	grad_norm 0.4810 (0.4810)	mem 38886MB
Train: [62/180][50/625]	eta 0:12:55 lr 0.587306	data 0.0011 (0.4297)	batch 0.8812 (1.3487)	loss 3.1913 (2.9824)	grad_norm 0.4688 (0.4768)	mem 38886MB
Train: [62/180][100/625]	eta 0:09:52 lr 0.586812	data 0.0009 (0.2173)	batch 0.9623 (1.1283)	loss 2.9283 (2.9937)	grad_norm 0.4883 (0.4766)	mem 38886MB
Train: [62/180][150/625]	eta 0:08:21 lr 0.586318	data 0.0007 (0.1456)	batch 0.8955 (1.0558)	loss 2.9938 (2.9975)	grad_norm 0.4766 (0.4772)	mem 38886MB
Train: [62/180][200/625]	eta 0:07:13 lr 0.585824	data 0.0006 (0.1095)	batch 0.9479 (1.0191)	loss 2.9625 (2.9994)	grad_norm 0.4849 (0.4766)	mem 38886MB
Train: [62/180][250/625]	eta 0:06:13 lr 0.585329	data 0.0007 (0.0879)	batch 0.9128 (0.9960)	loss 2.9749 (2.9981)	grad_norm 0.4753 (0.4777)	mem 38886MB
Train: [62/180][300/625]	eta 0:05:19 lr 0.584834	data 0.0005 (0.0734)	batch 0.9464 (0.9817)	loss 3.0519 (3.0035)	grad_norm 0.4854 (0.4780)	mem 38886MB
Train: [62/180][350/625]	eta 0:04:27 lr 0.584339	data 0.0007 (0.0630)	batch 0.9807 (0.9709)	loss 3.1335 (3.0048)	grad_norm 0.5057 (0.4785)	mem 38886MB
Train: [62/180][400/625]	eta 0:03:36 lr 0.583843	data 0.0008 (0.0553)	batch 0.9616 (0.9631)	loss 2.8751 (3.0043)	grad_norm 0.4810 (0.4786)	mem 38886MB
Train: [62/180][450/625]	eta 0:02:47 lr 0.583347	data 0.0010 (0.0492)	batch 0.9428 (0.9573)	loss 2.9069 (3.0034)	grad_norm 0.4750 (0.4785)	mem 38886MB
Train: [62/180][500/625]	eta 0:01:59 lr 0.582850	data 0.0007 (0.0444)	batch 0.8870 (0.9524)	loss 3.1338 (3.0028)	grad_norm 0.4856 (0.4787)	mem 38886MB
Train: [62/180][550/625]	eta 0:01:11 lr 0.582353	data 0.0007 (0.0404)	batch 0.8629 (0.9481)	loss 3.0964 (3.0043)	grad_norm 0.4844 (0.4786)	mem 38886MB
Train: [62/180][600/625]	eta 0:00:23 lr 0.581856	data 0.0003 (0.0371)	batch 0.9178 (0.9445)	loss 2.8690 (3.0049)	grad_norm 0.4797 (0.4785)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 62 training takes 0:09:50
Test: [0/25]	Time 15.077 (15.077)	Loss 1.3016 (1.3016)	Acc@1 72.705 (72.705)	Acc@5 89.307 (89.307)	Mem 38886MB
 * Acc@1 61.348 Acc@5 83.634
Accuracy of the network on the 50000 test images: 61.35%
Max accuracy (after decay): 61.78%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [63/180][0/625]	eta 4:01:00 lr 0.581607	data 21.8036 (21.8036)	batch 23.1375 (23.1375)	loss 2.9077 (2.9077)	grad_norm 0.4717 (0.4717)	mem 38886MB
Train: [63/180][50/625]	eta 0:12:48 lr 0.581109	data 0.0012 (0.4286)	batch 0.8971 (1.3360)	loss 3.0189 (2.9815)	grad_norm 0.4773 (0.4764)	mem 38886MB
Train: [63/180][100/625]	eta 0:09:49 lr 0.580611	data 0.0008 (0.2168)	batch 0.9594 (1.1232)	loss 2.8438 (2.9954)	grad_norm 0.4990 (0.4777)	mem 38886MB
Train: [63/180][150/625]	eta 0:08:20 lr 0.580113	data 0.0006 (0.1453)	batch 0.8829 (1.0535)	loss 3.0246 (2.9897)	grad_norm 0.4752 (0.4787)	mem 38886MB
Train: [63/180][200/625]	eta 0:07:12 lr 0.579614	data 0.0015 (0.1094)	batch 0.9166 (1.0179)	loss 3.0280 (2.9904)	grad_norm 0.4731 (0.4796)	mem 38886MB
Train: [63/180][250/625]	eta 0:06:13 lr 0.579115	data 0.0007 (0.0877)	batch 0.8904 (0.9951)	loss 3.0489 (2.9884)	grad_norm 0.4853 (0.4798)	mem 38886MB
Train: [63/180][300/625]	eta 0:05:18 lr 0.578615	data 0.0005 (0.0733)	batch 0.9381 (0.9807)	loss 2.8350 (2.9927)	grad_norm 0.4978 (0.4799)	mem 38886MB
Train: [63/180][350/625]	eta 0:04:26 lr 0.578115	data 0.0007 (0.0630)	batch 0.9462 (0.9702)	loss 2.8273 (2.9919)	grad_norm 0.4748 (0.4795)	mem 38886MB
Train: [63/180][400/625]	eta 0:03:36 lr 0.577615	data 0.0008 (0.0552)	batch 0.8639 (0.9624)	loss 3.0383 (2.9912)	grad_norm 0.4826 (0.4794)	mem 38886MB
Train: [63/180][450/625]	eta 0:02:47 lr 0.577114	data 0.0008 (0.0492)	batch 0.8883 (0.9562)	loss 3.0269 (2.9931)	grad_norm 0.4793 (0.4795)	mem 38886MB
Train: [63/180][500/625]	eta 0:01:58 lr 0.576614	data 0.0009 (0.0443)	batch 0.8948 (0.9509)	loss 3.1182 (2.9926)	grad_norm 0.4846 (0.4798)	mem 38886MB
Train: [63/180][550/625]	eta 0:01:10 lr 0.576112	data 0.0004 (0.0403)	batch 0.9203 (0.9467)	loss 3.0148 (2.9946)	grad_norm 0.4737 (0.4800)	mem 38886MB
Train: [63/180][600/625]	eta 0:00:23 lr 0.575611	data 0.0005 (0.0370)	batch 0.8921 (0.9428)	loss 2.8861 (2.9953)	grad_norm 0.4970 (0.4800)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 63 training takes 0:09:49
Test: [0/25]	Time 14.927 (14.927)	Loss 1.1967 (1.1967)	Acc@1 73.682 (73.682)	Acc@5 91.113 (91.113)	Mem 38886MB
 * Acc@1 61.844 Acc@5 83.988
Accuracy of the network on the 50000 test images: 61.84%
Max accuracy (after decay): 61.84%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [64/180][0/625]	eta 3:58:16 lr 0.575360	data 20.7426 (20.7426)	batch 22.8738 (22.8738)	loss 2.8579 (2.8579)	grad_norm 0.4810 (0.4810)	mem 38886MB
Train: [64/180][50/625]	eta 0:12:52 lr 0.574858	data 0.0005 (0.4074)	batch 0.9112 (1.3434)	loss 2.9632 (3.0086)	grad_norm 0.4689 (0.4774)	mem 38886MB
Train: [64/180][100/625]	eta 0:09:51 lr 0.574355	data 0.0005 (0.2060)	batch 0.9299 (1.1266)	loss 3.0108 (3.0001)	grad_norm 0.4816 (0.4800)	mem 38886MB
Train: [64/180][150/625]	eta 0:08:19 lr 0.573852	data 0.0006 (0.1380)	batch 0.9044 (1.0522)	loss 3.0362 (2.9998)	grad_norm 0.4752 (0.4801)	mem 38886MB
Train: [64/180][200/625]	eta 0:07:11 lr 0.573349	data 0.0005 (0.1038)	batch 0.8979 (1.0150)	loss 2.8921 (3.0055)	grad_norm 0.4709 (0.4809)	mem 38886MB
Train: [64/180][250/625]	eta 0:06:12 lr 0.572846	data 0.0006 (0.0832)	batch 0.8704 (0.9923)	loss 2.9742 (3.0035)	grad_norm 0.5036 (0.4815)	mem 38886MB
Train: [64/180][300/625]	eta 0:05:17 lr 0.572342	data 0.0004 (0.0695)	batch 0.9053 (0.9783)	loss 3.0605 (3.0053)	grad_norm 0.4744 (0.4814)	mem 38886MB
Train: [64/180][350/625]	eta 0:04:26 lr 0.571838	data 0.0006 (0.0597)	batch 0.8819 (0.9682)	loss 3.1515 (3.0058)	grad_norm 0.4826 (0.4814)	mem 38886MB
Train: [64/180][400/625]	eta 0:03:36 lr 0.571333	data 0.0005 (0.0524)	batch 0.9078 (0.9608)	loss 2.9383 (3.0051)	grad_norm 0.4935 (0.4812)	mem 38886MB
Train: [64/180][450/625]	eta 0:02:47 lr 0.570828	data 0.0007 (0.0467)	batch 0.8693 (0.9544)	loss 2.9254 (3.0045)	grad_norm 0.4728 (0.4812)	mem 38886MB
Train: [64/180][500/625]	eta 0:01:58 lr 0.570323	data 0.0004 (0.0420)	batch 0.9056 (0.9492)	loss 2.8104 (3.0019)	grad_norm 0.5120 (0.4818)	mem 38886MB
Train: [64/180][550/625]	eta 0:01:10 lr 0.569818	data 0.0005 (0.0383)	batch 0.9121 (0.9454)	loss 2.8972 (3.0023)	grad_norm 0.4649 (0.4815)	mem 38886MB
Train: [64/180][600/625]	eta 0:00:23 lr 0.569312	data 0.0006 (0.0351)	batch 0.8619 (0.9420)	loss 3.0144 (3.0025)	grad_norm 0.4884 (0.4815)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 64 training takes 0:09:49
Test: [0/25]	Time 14.860 (14.860)	Loss 1.2575 (1.2575)	Acc@1 72.803 (72.803)	Acc@5 90.869 (90.869)	Mem 38886MB
 * Acc@1 61.534 Acc@5 83.602
Accuracy of the network on the 50000 test images: 61.53%
Max accuracy (after decay): 61.84%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [65/180][0/625]	eta 3:53:37 lr 0.569059	data 20.8941 (20.8941)	batch 22.4273 (22.4273)	loss 2.8036 (2.8036)	grad_norm 0.4625 (0.4625)	mem 38886MB
Train: [65/180][50/625]	eta 0:12:43 lr 0.568553	data 0.0005 (0.4104)	batch 0.8582 (1.3284)	loss 2.8073 (2.9800)	grad_norm 0.4782 (0.4825)	mem 38886MB
Train: [65/180][100/625]	eta 0:09:48 lr 0.568046	data 0.0007 (0.2076)	batch 0.9213 (1.1211)	loss 2.9447 (2.9827)	grad_norm 0.4733 (0.4818)	mem 38886MB
Train: [65/180][150/625]	eta 0:08:18 lr 0.567539	data 0.0007 (0.1391)	batch 0.9354 (1.0498)	loss 3.0727 (2.9946)	grad_norm 0.4895 (0.4819)	mem 38886MB
Train: [65/180][200/625]	eta 0:07:11 lr 0.567032	data 0.0007 (0.1046)	batch 0.9128 (1.0150)	loss 2.8528 (2.9937)	grad_norm 0.4891 (0.4820)	mem 38886MB
Train: [65/180][250/625]	eta 0:06:11 lr 0.566524	data 0.0007 (0.0839)	batch 0.8677 (0.9919)	loss 2.9829 (2.9950)	grad_norm 0.4866 (0.4825)	mem 38886MB
Train: [65/180][300/625]	eta 0:05:18 lr 0.566016	data 0.0006 (0.0701)	batch 0.9849 (0.9790)	loss 2.8622 (2.9949)	grad_norm 0.4795 (0.4825)	mem 38886MB
Train: [65/180][350/625]	eta 0:04:26 lr 0.565508	data 0.0005 (0.0602)	batch 0.8735 (0.9684)	loss 2.7757 (2.9937)	grad_norm 0.4704 (0.4825)	mem 38886MB
Train: [65/180][400/625]	eta 0:03:36 lr 0.564999	data 0.0005 (0.0527)	batch 0.9629 (0.9604)	loss 3.0475 (2.9906)	grad_norm 0.4967 (0.4825)	mem 38886MB
Train: [65/180][450/625]	eta 0:02:46 lr 0.564490	data 0.0005 (0.0469)	batch 0.8957 (0.9538)	loss 3.0216 (2.9942)	grad_norm 0.4866 (0.4822)	mem 38886MB
Train: [65/180][500/625]	eta 0:01:58 lr 0.563981	data 0.0005 (0.0423)	batch 0.9063 (0.9489)	loss 2.9020 (2.9952)	grad_norm 0.4799 (0.4824)	mem 38886MB
Train: [65/180][550/625]	eta 0:01:10 lr 0.563471	data 0.0006 (0.0385)	batch 0.9345 (0.9452)	loss 3.0024 (3.0001)	grad_norm 0.4836 (0.4824)	mem 38886MB
Train: [65/180][600/625]	eta 0:00:23 lr 0.562962	data 0.0005 (0.0354)	batch 0.9060 (0.9421)	loss 3.1109 (3.0024)	grad_norm 0.4790 (0.4822)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 65 training takes 0:09:49
Test: [0/25]	Time 14.815 (14.815)	Loss 1.2079 (1.2079)	Acc@1 72.656 (72.656)	Acc@5 90.576 (90.576)	Mem 38886MB
 * Acc@1 62.326 Acc@5 84.298
Accuracy of the network on the 50000 test images: 62.33%
Max accuracy (after decay): 62.33%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [66/180][0/625]	eta 3:54:07 lr 0.562707	data 21.2315 (21.2315)	batch 22.4753 (22.4753)	loss 2.8770 (2.8770)	grad_norm 0.4674 (0.4674)	mem 38886MB
Train: [66/180][50/625]	eta 0:12:47 lr 0.562196	data 0.0005 (0.4169)	batch 0.8799 (1.3344)	loss 2.9736 (2.9847)	grad_norm 0.4743 (0.4830)	mem 38886MB
Train: [66/180][100/625]	eta 0:09:50 lr 0.561686	data 0.0005 (0.2108)	batch 0.8991 (1.1241)	loss 2.9773 (2.9915)	grad_norm 0.4882 (0.4843)	mem 38886MB
Train: [66/180][150/625]	eta 0:08:19 lr 0.561175	data 0.0005 (0.1412)	batch 0.8590 (1.0520)	loss 2.9892 (2.9875)	grad_norm 0.4908 (0.4839)	mem 38886MB
Train: [66/180][200/625]	eta 0:07:12 lr 0.560663	data 0.0005 (0.1062)	batch 0.9226 (1.0167)	loss 2.8212 (2.9906)	grad_norm 0.4899 (0.4848)	mem 38886MB
Train: [66/180][250/625]	eta 0:06:13 lr 0.560152	data 0.0007 (0.0852)	batch 0.9160 (0.9957)	loss 3.0406 (2.9887)	grad_norm 0.4792 (0.4842)	mem 38886MB
Train: [66/180][300/625]	eta 0:05:19 lr 0.559640	data 0.0005 (0.0711)	batch 0.9052 (0.9818)	loss 3.1639 (2.9932)	grad_norm 0.4879 (0.4841)	mem 38886MB
Train: [66/180][350/625]	eta 0:04:27 lr 0.559127	data 0.0006 (0.0612)	batch 0.8733 (0.9714)	loss 2.9533 (2.9931)	grad_norm 0.4817 (0.4842)	mem 38886MB
Train: [66/180][400/625]	eta 0:03:36 lr 0.558615	data 0.0005 (0.0536)	batch 0.8796 (0.9631)	loss 3.0251 (2.9938)	grad_norm 0.4749 (0.4843)	mem 38886MB
Train: [66/180][450/625]	eta 0:02:47 lr 0.558102	data 0.0005 (0.0478)	batch 0.9283 (0.9572)	loss 3.0884 (2.9945)	grad_norm 0.4691 (0.4842)	mem 38886MB
Train: [66/180][500/625]	eta 0:01:59 lr 0.557589	data 0.0005 (0.0430)	batch 0.9115 (0.9528)	loss 2.7813 (2.9946)	grad_norm 0.4869 (0.4843)	mem 38886MB
Train: [66/180][550/625]	eta 0:01:11 lr 0.557075	data 0.0006 (0.0392)	batch 0.8718 (0.9487)	loss 2.7762 (2.9935)	grad_norm 0.4966 (0.4844)	mem 38886MB
Train: [66/180][600/625]	eta 0:00:23 lr 0.556562	data 0.0006 (0.0360)	batch 1.1802 (0.9454)	loss 2.9631 (2.9930)	grad_norm 0.4755 (0.4845)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 66 training takes 0:09:51
Test: [0/25]	Time 14.801 (14.801)	Loss 1.1845 (1.1845)	Acc@1 72.900 (72.900)	Acc@5 90.674 (90.674)	Mem 38886MB
 * Acc@1 61.824 Acc@5 84.018
Accuracy of the network on the 50000 test images: 61.82%
Max accuracy (after decay): 62.33%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [67/180][0/625]	eta 4:02:27 lr 0.556305	data 20.9107 (20.9107)	batch 23.2765 (23.2765)	loss 2.9514 (2.9514)	grad_norm 0.4756 (0.4756)	mem 38886MB
Train: [67/180][50/625]	eta 0:12:55 lr 0.555790	data 0.0006 (0.4108)	batch 0.8876 (1.3484)	loss 3.2009 (2.9747)	grad_norm 0.4877 (0.4819)	mem 38886MB
Train: [67/180][100/625]	eta 0:09:55 lr 0.555276	data 0.0005 (0.2077)	batch 0.9080 (1.1342)	loss 2.9946 (2.9727)	grad_norm 0.4741 (0.4828)	mem 38886MB
Train: [67/180][150/625]	eta 0:08:22 lr 0.554761	data 0.0007 (0.1391)	batch 0.8548 (1.0582)	loss 2.9650 (2.9724)	grad_norm 0.4927 (0.4839)	mem 38886MB
Train: [67/180][200/625]	eta 0:07:14 lr 0.554246	data 0.0004 (0.1047)	batch 0.9389 (1.0217)	loss 3.0665 (2.9752)	grad_norm 0.4907 (0.4852)	mem 38886MB
Train: [67/180][250/625]	eta 0:06:14 lr 0.553730	data 0.0005 (0.0839)	batch 0.8964 (0.9999)	loss 2.9520 (2.9726)	grad_norm 0.4796 (0.4851)	mem 38886MB
Train: [67/180][300/625]	eta 0:05:20 lr 0.553215	data 0.0005 (0.0701)	batch 0.9518 (0.9847)	loss 3.0540 (2.9731)	grad_norm 0.4879 (0.4854)	mem 38886MB
Train: [67/180][350/625]	eta 0:04:27 lr 0.552699	data 0.0004 (0.0602)	batch 0.9081 (0.9737)	loss 2.8296 (2.9747)	grad_norm 0.4756 (0.4853)	mem 38886MB
Train: [67/180][400/625]	eta 0:03:37 lr 0.552182	data 0.0006 (0.0527)	batch 0.8650 (0.9652)	loss 3.0061 (2.9779)	grad_norm 0.4886 (0.4851)	mem 38886MB
Train: [67/180][450/625]	eta 0:02:47 lr 0.551666	data 0.0005 (0.0470)	batch 0.9107 (0.9589)	loss 2.9977 (2.9808)	grad_norm 0.4833 (0.4849)	mem 38886MB
Train: [67/180][500/625]	eta 0:01:59 lr 0.551149	data 0.0005 (0.0424)	batch 0.9080 (0.9542)	loss 2.9589 (2.9860)	grad_norm 0.4893 (0.4852)	mem 38886MB
Train: [67/180][550/625]	eta 0:01:11 lr 0.550632	data 0.0004 (0.0386)	batch 0.8984 (0.9494)	loss 2.9941 (2.9909)	grad_norm 0.4873 (0.4852)	mem 38886MB
Train: [67/180][600/625]	eta 0:00:23 lr 0.550114	data 0.0005 (0.0354)	batch 0.9129 (0.9460)	loss 3.1051 (2.9908)	grad_norm 0.4938 (0.4854)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 67 training takes 0:09:51
Test: [0/25]	Time 14.774 (14.774)	Loss 1.2276 (1.2276)	Acc@1 71.875 (71.875)	Acc@5 89.893 (89.893)	Mem 38886MB
 * Acc@1 61.674 Acc@5 83.850
Accuracy of the network on the 50000 test images: 61.67%
Max accuracy (after decay): 62.33%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [68/180][0/625]	eta 3:54:44 lr 0.549855	data 21.5359 (21.5359)	batch 22.5353 (22.5353)	loss 2.9451 (2.9451)	grad_norm 0.4912 (0.4912)	mem 38886MB
Train: [68/180][50/625]	eta 0:12:46 lr 0.549337	data 0.0005 (0.4231)	batch 0.9380 (1.3338)	loss 2.9751 (2.9416)	grad_norm 0.4735 (0.4844)	mem 38886MB
Train: [68/180][100/625]	eta 0:09:49 lr 0.548819	data 0.0004 (0.2139)	batch 0.9193 (1.1235)	loss 3.0425 (2.9528)	grad_norm 0.4912 (0.4858)	mem 38886MB
Train: [68/180][150/625]	eta 0:08:19 lr 0.548300	data 0.0006 (0.1435)	batch 0.8484 (1.0517)	loss 2.9400 (2.9579)	grad_norm 0.4852 (0.4863)	mem 38886MB
Train: [68/180][200/625]	eta 0:07:11 lr 0.547782	data 0.0005 (0.1080)	batch 0.9647 (1.0164)	loss 2.7966 (2.9617)	grad_norm 0.4995 (0.4870)	mem 38886MB
Train: [68/180][250/625]	eta 0:06:13 lr 0.547262	data 0.0006 (0.0866)	batch 0.8591 (0.9954)	loss 3.0681 (2.9649)	grad_norm 0.5490 (0.4874)	mem 38886MB
Train: [68/180][300/625]	eta 0:05:18 lr 0.546743	data 0.0005 (0.0725)	batch 0.9010 (0.9813)	loss 2.9155 (2.9674)	grad_norm 0.4838 (0.4872)	mem 38886MB
Train: [68/180][350/625]	eta 0:04:26 lr 0.546223	data 0.0005 (0.0622)	batch 0.8859 (0.9707)	loss 3.0411 (2.9708)	grad_norm 0.4741 (0.4870)	mem 38886MB
Train: [68/180][400/625]	eta 0:03:36 lr 0.545703	data 0.0006 (0.0545)	batch 0.9282 (0.9633)	loss 3.1905 (2.9729)	grad_norm 0.4923 (0.4873)	mem 38886MB
Train: [68/180][450/625]	eta 0:02:47 lr 0.545183	data 0.0006 (0.0485)	batch 0.8944 (0.9573)	loss 3.2770 (2.9786)	grad_norm 0.4886 (0.4873)	mem 38886MB
Train: [68/180][500/625]	eta 0:01:59 lr 0.544663	data 0.0004 (0.0437)	batch 0.8871 (0.9523)	loss 2.9268 (2.9791)	grad_norm 0.4802 (0.4874)	mem 38886MB
Train: [68/180][550/625]	eta 0:01:11 lr 0.544142	data 0.0005 (0.0398)	batch 0.9327 (0.9482)	loss 2.9669 (2.9821)	grad_norm 0.4893 (0.4875)	mem 38886MB
Train: [68/180][600/625]	eta 0:00:23 lr 0.543621	data 0.0005 (0.0366)	batch 0.9117 (0.9447)	loss 3.0171 (2.9842)	grad_norm 0.4812 (0.4875)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 68 training takes 0:09:50
Test: [0/25]	Time 15.102 (15.102)	Loss 1.1991 (1.1991)	Acc@1 74.268 (74.268)	Acc@5 90.527 (90.527)	Mem 38886MB
 * Acc@1 62.472 Acc@5 84.504
Accuracy of the network on the 50000 test images: 62.47%
Max accuracy (after decay): 62.47%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [69/180][0/625]	eta 3:56:37 lr 0.543360	data 20.8426 (20.8426)	batch 22.7158 (22.7158)	loss 2.7935 (2.7935)	grad_norm 0.4883 (0.4883)	mem 38886MB
Train: [69/180][50/625]	eta 0:12:48 lr 0.542838	data 0.0005 (0.4094)	batch 0.9248 (1.3367)	loss 3.1415 (2.9609)	grad_norm 0.4901 (0.4871)	mem 38886MB
Train: [69/180][100/625]	eta 0:09:51 lr 0.542317	data 0.0006 (0.2070)	batch 0.9322 (1.1263)	loss 3.0381 (2.9599)	grad_norm 0.4940 (0.4870)	mem 38886MB
Train: [69/180][150/625]	eta 0:08:21 lr 0.541795	data 0.0005 (0.1387)	batch 0.9214 (1.0560)	loss 2.9096 (2.9568)	grad_norm 0.4918 (0.4876)	mem 38886MB
Train: [69/180][200/625]	eta 0:07:13 lr 0.541272	data 0.0005 (0.1043)	batch 0.8955 (1.0207)	loss 2.9748 (2.9589)	grad_norm 0.4926 (0.4880)	mem 38886MB
Train: [69/180][250/625]	eta 0:06:14 lr 0.540750	data 0.0004 (0.0836)	batch 0.9396 (0.9982)	loss 2.9959 (2.9569)	grad_norm 0.4846 (0.4875)	mem 38886MB
Train: [69/180][300/625]	eta 0:05:19 lr 0.540227	data 0.0005 (0.0698)	batch 0.8822 (0.9825)	loss 2.8485 (2.9604)	grad_norm 0.4952 (0.4878)	mem 38886MB
Train: [69/180][350/625]	eta 0:04:26 lr 0.539704	data 0.0004 (0.0600)	batch 0.9097 (0.9704)	loss 2.8386 (2.9652)	grad_norm 0.4968 (0.4878)	mem 38886MB
Train: [69/180][400/625]	eta 0:03:36 lr 0.539180	data 0.0004 (0.0526)	batch 0.9570 (0.9622)	loss 2.9602 (2.9681)	grad_norm 0.4863 (0.4882)	mem 38886MB
Train: [69/180][450/625]	eta 0:02:47 lr 0.538656	data 0.0005 (0.0468)	batch 0.9101 (0.9559)	loss 2.9097 (2.9710)	grad_norm 0.4891 (0.4882)	mem 38886MB
Train: [69/180][500/625]	eta 0:01:58 lr 0.538132	data 0.0005 (0.0422)	batch 1.1088 (0.9516)	loss 3.1038 (2.9738)	grad_norm 0.4862 (0.4885)	mem 38886MB
Train: [69/180][550/625]	eta 0:01:10 lr 0.537608	data 0.0005 (0.0384)	batch 0.9164 (0.9464)	loss 3.0647 (2.9763)	grad_norm 0.5035 (0.4886)	mem 38886MB
Train: [69/180][600/625]	eta 0:00:23 lr 0.537084	data 0.0005 (0.0352)	batch 0.9444 (0.9436)	loss 3.0795 (2.9800)	grad_norm 0.4850 (0.4886)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 69 training takes 0:09:49
Test: [0/25]	Time 14.846 (14.846)	Loss 1.2334 (1.2334)	Acc@1 73.291 (73.291)	Acc@5 90.918 (90.918)	Mem 38886MB
 * Acc@1 61.870 Acc@5 83.970
Accuracy of the network on the 50000 test images: 61.87%
Max accuracy (after decay): 62.47%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [70/180][0/625]	eta 3:56:48 lr 0.536821	data 21.6856 (21.6856)	batch 22.7334 (22.7334)	loss 2.9365 (2.9365)	grad_norm 0.4738 (0.4738)	mem 38886MB
Train: [70/180][50/625]	eta 0:12:49 lr 0.536296	data 0.0007 (0.4272)	batch 0.8786 (1.3388)	loss 3.0351 (2.9660)	grad_norm 0.4994 (0.4882)	mem 38886MB
Train: [70/180][100/625]	eta 0:09:49 lr 0.535771	data 0.0006 (0.2161)	batch 0.8998 (1.1230)	loss 2.8132 (2.9633)	grad_norm 0.4749 (0.4886)	mem 38886MB
Train: [70/180][150/625]	eta 0:08:19 lr 0.535246	data 0.0006 (0.1451)	batch 0.9331 (1.0521)	loss 2.9071 (2.9727)	grad_norm 0.4885 (0.4885)	mem 38886MB
Train: [70/180][200/625]	eta 0:07:11 lr 0.534720	data 0.0005 (0.1092)	batch 1.0511 (1.0158)	loss 3.0353 (2.9678)	grad_norm 0.4882 (0.4887)	mem 38886MB
Train: [70/180][250/625]	eta 0:06:12 lr 0.534194	data 0.0009 (0.0876)	batch 0.8777 (0.9943)	loss 2.8160 (2.9708)	grad_norm 0.4856 (0.4889)	mem 38886MB
Train: [70/180][300/625]	eta 0:05:18 lr 0.533668	data 0.0008 (0.0732)	batch 0.9166 (0.9802)	loss 2.8090 (2.9678)	grad_norm 0.4792 (0.4891)	mem 38886MB
Train: [70/180][350/625]	eta 0:04:26 lr 0.533141	data 0.0005 (0.0629)	batch 0.9033 (0.9697)	loss 2.9881 (2.9730)	grad_norm 0.4934 (0.4895)	mem 38886MB
Train: [70/180][400/625]	eta 0:03:36 lr 0.532614	data 0.0008 (0.0551)	batch 0.8798 (0.9624)	loss 2.9858 (2.9749)	grad_norm 0.5087 (0.4896)	mem 38886MB
Train: [70/180][450/625]	eta 0:02:47 lr 0.532087	data 0.0007 (0.0491)	batch 0.9128 (0.9561)	loss 2.8569 (2.9752)	grad_norm 0.4887 (0.4899)	mem 38886MB
Train: [70/180][500/625]	eta 0:01:58 lr 0.531560	data 0.0006 (0.0443)	batch 0.8996 (0.9505)	loss 2.8659 (2.9747)	grad_norm 0.5067 (0.4897)	mem 38886MB
Train: [70/180][550/625]	eta 0:01:11 lr 0.531033	data 0.0006 (0.0403)	batch 0.9399 (0.9467)	loss 2.8841 (2.9760)	grad_norm 0.4890 (0.4897)	mem 38886MB
Train: [70/180][600/625]	eta 0:00:23 lr 0.530505	data 0.0010 (0.0370)	batch 0.8879 (0.9432)	loss 2.9569 (2.9752)	grad_norm 0.5085 (0.4897)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 70 training takes 0:09:50
Test: [0/25]	Time 14.793 (14.793)	Loss 1.1241 (1.1241)	Acc@1 74.951 (74.951)	Acc@5 91.113 (91.113)	Mem 38886MB
 * Acc@1 61.954 Acc@5 84.158
Accuracy of the network on the 50000 test images: 61.95%
Max accuracy (after decay): 62.47%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [71/180][0/625]	eta 3:59:13 lr 0.530241	data 21.3022 (21.3022)	batch 22.9651 (22.9651)	loss 2.8428 (2.8428)	grad_norm 0.4633 (0.4633)	mem 38886MB
Train: [71/180][50/625]	eta 0:12:52 lr 0.529713	data 0.0007 (0.4184)	batch 0.9154 (1.3427)	loss 3.0110 (2.9134)	grad_norm 0.4858 (0.4883)	mem 38886MB
Train: [71/180][100/625]	eta 0:09:52 lr 0.529184	data 0.0013 (0.2116)	batch 0.9133 (1.1293)	loss 2.8023 (2.9401)	grad_norm 0.5119 (0.4924)	mem 38886MB
Train: [71/180][150/625]	eta 0:08:21 lr 0.528655	data 0.0006 (0.1418)	batch 1.0598 (1.0551)	loss 3.2677 (2.9391)	grad_norm 0.5781 (0.4916)	mem 38886MB
Train: [71/180][200/625]	eta 0:07:12 lr 0.528127	data 0.0006 (0.1067)	batch 0.8890 (1.0171)	loss 2.9491 (2.9501)	grad_norm 0.4749 (0.4913)	mem 38886MB
Train: [71/180][250/625]	eta 0:06:13 lr 0.527597	data 0.0006 (0.0856)	batch 0.9176 (0.9964)	loss 2.9607 (2.9530)	grad_norm 0.4841 (0.4918)	mem 38886MB
Train: [71/180][300/625]	eta 0:05:19 lr 0.527068	data 0.0005 (0.0714)	batch 0.9000 (0.9824)	loss 2.9488 (2.9560)	grad_norm 0.4941 (0.4915)	mem 38886MB
Train: [71/180][350/625]	eta 0:04:27 lr 0.526538	data 0.0008 (0.0613)	batch 0.9173 (0.9715)	loss 2.9485 (2.9614)	grad_norm 0.4857 (0.4915)	mem 38886MB
Train: [71/180][400/625]	eta 0:03:36 lr 0.526008	data 0.0004 (0.0538)	batch 0.9178 (0.9639)	loss 3.1560 (2.9593)	grad_norm 0.5017 (0.4916)	mem 38886MB
Train: [71/180][450/625]	eta 0:02:47 lr 0.525478	data 0.0004 (0.0479)	batch 0.9245 (0.9571)	loss 2.9023 (2.9626)	grad_norm 0.4898 (0.4914)	mem 38886MB
Train: [71/180][500/625]	eta 0:01:59 lr 0.524948	data 0.0005 (0.0431)	batch 0.9013 (0.9526)	loss 2.9983 (2.9627)	grad_norm 0.4849 (0.4914)	mem 38886MB
Train: [71/180][550/625]	eta 0:01:11 lr 0.524417	data 0.0005 (0.0393)	batch 0.9013 (0.9483)	loss 2.9718 (2.9626)	grad_norm 0.4945 (0.4916)	mem 38886MB
Train: [71/180][600/625]	eta 0:00:23 lr 0.523886	data 0.0003 (0.0360)	batch 0.8975 (0.9452)	loss 3.1177 (2.9644)	grad_norm 0.5096 (0.4917)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 71 training takes 0:09:51
Test: [0/25]	Time 14.719 (14.719)	Loss 1.2024 (1.2024)	Acc@1 74.268 (74.268)	Acc@5 91.748 (91.748)	Mem 38886MB
 * Acc@1 61.932 Acc@5 83.980
Accuracy of the network on the 50000 test images: 61.93%
Max accuracy (after decay): 62.47%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [72/180][0/625]	eta 3:58:58 lr 0.523621	data 22.0301 (22.0301)	batch 22.9412 (22.9412)	loss 2.9474 (2.9474)	grad_norm 0.5012 (0.5012)	mem 38886MB
Train: [72/180][50/625]	eta 0:12:49 lr 0.523089	data 0.0005 (0.4326)	batch 0.9129 (1.3386)	loss 2.6374 (2.9495)	grad_norm 0.4676 (0.4903)	mem 38886MB
Train: [72/180][100/625]	eta 0:09:52 lr 0.522558	data 0.0004 (0.2187)	batch 0.9432 (1.1290)	loss 3.0473 (2.9427)	grad_norm 0.4876 (0.4908)	mem 38886MB
Train: [72/180][150/625]	eta 0:08:21 lr 0.522026	data 0.0004 (0.1465)	batch 0.8942 (1.0548)	loss 3.0202 (2.9377)	grad_norm 0.4947 (0.4917)	mem 38886MB
Train: [72/180][200/625]	eta 0:07:12 lr 0.521494	data 0.0006 (0.1102)	batch 0.8791 (1.0182)	loss 2.9358 (2.9372)	grad_norm 0.4846 (0.4919)	mem 38886MB
Train: [72/180][250/625]	eta 0:06:13 lr 0.520962	data 0.0006 (0.0883)	batch 0.9159 (0.9965)	loss 2.9113 (2.9455)	grad_norm 0.4733 (0.4921)	mem 38886MB
Train: [72/180][300/625]	eta 0:05:18 lr 0.520429	data 0.0006 (0.0737)	batch 0.8839 (0.9813)	loss 3.1287 (2.9535)	grad_norm 0.4852 (0.4920)	mem 38886MB
Train: [72/180][350/625]	eta 0:04:27 lr 0.519897	data 0.0005 (0.0633)	batch 1.0499 (0.9712)	loss 2.8665 (2.9587)	grad_norm 0.4942 (0.4918)	mem 38886MB
Train: [72/180][400/625]	eta 0:03:36 lr 0.519364	data 0.0004 (0.0555)	batch 0.9022 (0.9635)	loss 2.9604 (2.9607)	grad_norm 0.4884 (0.4916)	mem 38886MB
Train: [72/180][450/625]	eta 0:02:47 lr 0.518831	data 0.0005 (0.0494)	batch 0.8763 (0.9572)	loss 2.9217 (2.9617)	grad_norm 0.4930 (0.4917)	mem 38886MB
Train: [72/180][500/625]	eta 0:01:59 lr 0.518297	data 0.0006 (0.0445)	batch 0.9321 (0.9527)	loss 2.8965 (2.9615)	grad_norm 0.4956 (0.4919)	mem 38886MB
Train: [72/180][550/625]	eta 0:01:11 lr 0.517764	data 0.0005 (0.0405)	batch 0.9073 (0.9485)	loss 3.1591 (2.9646)	grad_norm 0.5028 (0.4921)	mem 38886MB
Train: [72/180][600/625]	eta 0:00:23 lr 0.517230	data 0.0006 (0.0372)	batch 0.9094 (0.9452)	loss 2.8974 (2.9658)	grad_norm 0.4795 (0.4920)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 72 training takes 0:09:51
Test: [0/25]	Time 14.712 (14.712)	Loss 1.1596 (1.1596)	Acc@1 74.561 (74.561)	Acc@5 91.064 (91.064)	Mem 38886MB
 * Acc@1 62.394 Acc@5 84.514
Accuracy of the network on the 50000 test images: 62.39%
Max accuracy (after decay): 62.47%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [73/180][0/625]	eta 4:02:07 lr 0.516963	data 21.9680 (21.9680)	batch 23.2445 (23.2445)	loss 3.1127 (3.1127)	grad_norm 0.4965 (0.4965)	mem 38886MB
Train: [73/180][50/625]	eta 0:12:53 lr 0.516429	data 0.0005 (0.4314)	batch 0.9005 (1.3449)	loss 3.0021 (2.9369)	grad_norm 0.4871 (0.4909)	mem 38886MB
Train: [73/180][100/625]	eta 0:09:53 lr 0.515894	data 0.0006 (0.2181)	batch 0.9673 (1.1313)	loss 2.9358 (2.9444)	grad_norm 0.4928 (0.4919)	mem 38886MB
Train: [73/180][150/625]	eta 0:08:22 lr 0.515360	data 0.0007 (0.1461)	batch 0.8722 (1.0572)	loss 2.9248 (2.9476)	grad_norm 0.4841 (0.4932)	mem 38886MB
Train: [73/180][200/625]	eta 0:07:13 lr 0.514825	data 0.0005 (0.1099)	batch 0.9147 (1.0204)	loss 3.0215 (2.9465)	grad_norm 0.4896 (0.4932)	mem 38886MB
Train: [73/180][250/625]	eta 0:06:14 lr 0.514290	data 0.0008 (0.0881)	batch 1.0243 (0.9996)	loss 2.9010 (2.9495)	grad_norm 0.4927 (0.4936)	mem 38886MB
Train: [73/180][300/625]	eta 0:05:19 lr 0.513754	data 0.0004 (0.0735)	batch 0.8814 (0.9842)	loss 2.9436 (2.9502)	grad_norm 0.4865 (0.4935)	mem 38886MB
Train: [73/180][350/625]	eta 0:04:27 lr 0.513219	data 0.0005 (0.0631)	batch 0.9274 (0.9733)	loss 2.9226 (2.9514)	grad_norm 0.4934 (0.4938)	mem 38886MB
Train: [73/180][400/625]	eta 0:03:37 lr 0.512683	data 0.0005 (0.0553)	batch 0.9003 (0.9654)	loss 3.1773 (2.9551)	grad_norm 0.4962 (0.4942)	mem 38886MB
Train: [73/180][450/625]	eta 0:02:47 lr 0.512147	data 0.0005 (0.0493)	batch 0.8947 (0.9587)	loss 2.9140 (2.9568)	grad_norm 0.4929 (0.4942)	mem 38886MB
Train: [73/180][500/625]	eta 0:01:59 lr 0.511611	data 0.0005 (0.0444)	batch 0.9287 (0.9541)	loss 2.8660 (2.9564)	grad_norm 0.5050 (0.4941)	mem 38886MB
Train: [73/180][550/625]	eta 0:01:11 lr 0.511074	data 0.0006 (0.0404)	batch 0.9120 (0.9497)	loss 2.9077 (2.9576)	grad_norm 0.4943 (0.4943)	mem 38886MB
Train: [73/180][600/625]	eta 0:00:23 lr 0.510538	data 0.0005 (0.0371)	batch 0.9157 (0.9461)	loss 3.0454 (2.9583)	grad_norm 0.4967 (0.4942)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 73 training takes 0:09:51
Test: [0/25]	Time 15.043 (15.043)	Loss 1.2259 (1.2259)	Acc@1 72.412 (72.412)	Acc@5 90.039 (90.039)	Mem 38886MB
 * Acc@1 62.104 Acc@5 84.288
Accuracy of the network on the 50000 test images: 62.10%
Max accuracy (after decay): 62.47%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [74/180][0/625]	eta 3:57:14 lr 0.510269	data 21.6166 (21.6166)	batch 22.7746 (22.7746)	loss 2.8171 (2.8171)	grad_norm 0.4820 (0.4820)	mem 38886MB
Train: [74/180][50/625]	eta 0:12:50 lr 0.509732	data 0.0007 (0.4250)	batch 0.9106 (1.3399)	loss 2.9561 (2.9656)	grad_norm 0.4938 (0.4944)	mem 38886MB
Train: [74/180][100/625]	eta 0:09:52 lr 0.509195	data 0.0006 (0.2149)	batch 0.8933 (1.1281)	loss 3.1405 (2.9831)	grad_norm 0.5002 (0.4945)	mem 38886MB
Train: [74/180][150/625]	eta 0:08:21 lr 0.508658	data 0.0005 (0.1439)	batch 0.8971 (1.0561)	loss 2.9371 (2.9653)	grad_norm 0.5218 (0.4959)	mem 38886MB
Train: [74/180][200/625]	eta 0:07:12 lr 0.508120	data 0.0005 (0.1083)	batch 0.9390 (1.0185)	loss 2.9001 (2.9672)	grad_norm 0.5262 (0.4960)	mem 38886MB
Train: [74/180][250/625]	eta 0:06:14 lr 0.507583	data 0.0004 (0.0868)	batch 0.9006 (0.9974)	loss 3.1076 (2.9719)	grad_norm 0.4999 (0.4961)	mem 38886MB
Train: [74/180][300/625]	eta 0:05:19 lr 0.507045	data 0.0006 (0.0725)	batch 0.9350 (0.9830)	loss 2.8781 (2.9694)	grad_norm 0.5022 (0.4960)	mem 38886MB
Train: [74/180][350/625]	eta 0:04:27 lr 0.506506	data 0.0004 (0.0622)	batch 0.9098 (0.9716)	loss 3.1400 (2.9695)	grad_norm 0.4893 (0.4961)	mem 38886MB
Train: [74/180][400/625]	eta 0:03:37 lr 0.505968	data 0.0005 (0.0545)	batch 0.8868 (0.9653)	loss 2.8730 (2.9689)	grad_norm 0.4801 (0.4968)	mem 38886MB
Train: [74/180][450/625]	eta 0:02:47 lr 0.505429	data 0.0006 (0.0485)	batch 0.8860 (0.9586)	loss 3.0238 (2.9675)	grad_norm 0.5056 (0.4968)	mem 38886MB
Train: [74/180][500/625]	eta 0:01:59 lr 0.504890	data 0.0005 (0.0438)	batch 0.9508 (0.9541)	loss 2.9857 (2.9671)	grad_norm 0.5010 (0.4968)	mem 38886MB
Train: [74/180][550/625]	eta 0:01:11 lr 0.504351	data 0.0007 (0.0398)	batch 0.9084 (0.9503)	loss 2.9797 (2.9666)	grad_norm 0.5150 (0.4971)	mem 38886MB
Train: [74/180][600/625]	eta 0:00:23 lr 0.503812	data 0.0004 (0.0366)	batch 0.8761 (0.9465)	loss 3.0964 (2.9662)	grad_norm 0.4964 (0.4972)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 74 training takes 0:09:52
Test: [0/25]	Time 14.890 (14.890)	Loss 1.1747 (1.1747)	Acc@1 74.951 (74.951)	Acc@5 90.771 (90.771)	Mem 38886MB
 * Acc@1 62.400 Acc@5 84.324
Accuracy of the network on the 50000 test images: 62.40%
Max accuracy (after decay): 62.47%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [75/180][0/625]	eta 3:55:26 lr 0.503542	data 21.0429 (21.0429)	batch 22.6019 (22.6019)	loss 2.8082 (2.8082)	grad_norm 0.4852 (0.4852)	mem 38886MB
Train: [75/180][50/625]	eta 0:12:50 lr 0.503003	data 0.0006 (0.4133)	batch 0.9062 (1.3399)	loss 2.9807 (2.9271)	grad_norm 0.5111 (0.4950)	mem 38886MB
Train: [75/180][100/625]	eta 0:09:49 lr 0.502463	data 0.0007 (0.2091)	batch 0.8943 (1.1228)	loss 2.9439 (2.9277)	grad_norm 0.5002 (0.4959)	mem 38886MB
Train: [75/180][150/625]	eta 0:08:19 lr 0.501923	data 0.0006 (0.1401)	batch 0.9087 (1.0516)	loss 2.7908 (2.9310)	grad_norm 0.5075 (0.4966)	mem 38886MB
Train: [75/180][200/625]	eta 0:07:10 lr 0.501383	data 0.0006 (0.1054)	batch 0.8809 (1.0141)	loss 3.0081 (2.9363)	grad_norm 0.5008 (0.4969)	mem 38886MB
Train: [75/180][250/625]	eta 0:06:12 lr 0.500843	data 0.0006 (0.0846)	batch 0.9196 (0.9930)	loss 2.9665 (2.9427)	grad_norm 0.5023 (0.4969)	mem 38886MB
Train: [75/180][300/625]	eta 0:05:18 lr 0.500302	data 0.0014 (0.0708)	batch 0.8614 (0.9785)	loss 2.8474 (2.9417)	grad_norm 0.4909 (0.4972)	mem 38886MB
Train: [75/180][350/625]	eta 0:04:26 lr 0.499761	data 0.0009 (0.0608)	batch 0.9012 (0.9676)	loss 2.8975 (2.9415)	grad_norm 0.4778 (0.4973)	mem 38886MB
Train: [75/180][400/625]	eta 0:03:36 lr 0.499220	data 0.0005 (0.0533)	batch 0.8880 (0.9604)	loss 2.8132 (2.9448)	grad_norm 0.4926 (0.4974)	mem 38886MB
Train: [75/180][450/625]	eta 0:02:46 lr 0.498679	data 0.0005 (0.0475)	batch 0.9293 (0.9542)	loss 2.7096 (2.9457)	grad_norm 0.5088 (0.4975)	mem 38886MB
Train: [75/180][500/625]	eta 0:01:58 lr 0.498138	data 0.0013 (0.0428)	batch 0.8990 (0.9493)	loss 2.8367 (2.9468)	grad_norm 0.5008 (0.4980)	mem 38886MB
Train: [75/180][550/625]	eta 0:01:10 lr 0.497597	data 0.0014 (0.0390)	batch 0.8596 (0.9457)	loss 2.8468 (2.9533)	grad_norm 0.4914 (0.4982)	mem 38886MB
Train: [75/180][600/625]	eta 0:00:23 lr 0.497055	data 0.0005 (0.0358)	batch 0.9275 (0.9424)	loss 2.8036 (2.9550)	grad_norm 0.4949 (0.4980)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 75 training takes 0:09:49
Test: [0/25]	Time 14.550 (14.550)	Loss 1.1682 (1.1682)	Acc@1 74.316 (74.316)	Acc@5 90.918 (90.918)	Mem 38886MB
 * Acc@1 62.978 Acc@5 84.614
Accuracy of the network on the 50000 test images: 62.98%
Max accuracy (after decay): 62.98%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [76/180][0/625]	eta 3:55:00 lr 0.496784	data 20.6787 (20.6787)	batch 22.5603 (22.5603)	loss 3.0334 (3.0334)	grad_norm 0.4995 (0.4995)	mem 38886MB
Train: [76/180][50/625]	eta 0:12:44 lr 0.496242	data 0.0005 (0.4064)	batch 0.9175 (1.3297)	loss 2.9763 (2.9392)	grad_norm 0.4822 (0.4992)	mem 38886MB
Train: [76/180][100/625]	eta 0:09:47 lr 0.495700	data 0.0007 (0.2055)	batch 0.9475 (1.1189)	loss 2.8414 (2.9471)	grad_norm 0.5015 (0.4981)	mem 38886MB
Train: [76/180][150/625]	eta 0:08:18 lr 0.495157	data 0.0004 (0.1376)	batch 0.8894 (1.0496)	loss 3.0855 (2.9442)	grad_norm 0.4964 (0.4983)	mem 38886MB
Train: [76/180][200/625]	eta 0:07:11 lr 0.494615	data 0.0005 (0.1035)	batch 0.9262 (1.0156)	loss 2.9367 (2.9448)	grad_norm 0.4967 (0.4996)	mem 38886MB
Train: [76/180][250/625]	eta 0:06:12 lr 0.494072	data 0.0005 (0.0830)	batch 0.9190 (0.9935)	loss 2.8678 (2.9480)	grad_norm 0.5091 (0.4995)	mem 38886MB
Train: [76/180][300/625]	eta 0:05:18 lr 0.493529	data 0.0005 (0.0693)	batch 0.9263 (0.9788)	loss 2.9724 (2.9506)	grad_norm 0.4864 (0.4993)	mem 38886MB
Train: [76/180][350/625]	eta 0:04:26 lr 0.492986	data 0.0006 (0.0595)	batch 0.8696 (0.9680)	loss 2.8402 (2.9495)	grad_norm 0.4891 (0.4996)	mem 38886MB
Train: [76/180][400/625]	eta 0:03:36 lr 0.492443	data 0.0006 (0.0522)	batch 0.8865 (0.9611)	loss 2.8510 (2.9519)	grad_norm 0.4897 (0.5000)	mem 38886MB
Train: [76/180][450/625]	eta 0:02:47 lr 0.491899	data 0.0003 (0.0464)	batch 0.8914 (0.9554)	loss 2.8724 (2.9543)	grad_norm 0.4914 (0.4996)	mem 38886MB
Train: [76/180][500/625]	eta 0:01:58 lr 0.491356	data 0.0006 (0.0419)	batch 0.8954 (0.9505)	loss 3.0814 (2.9548)	grad_norm 0.4893 (0.4995)	mem 38886MB
Train: [76/180][550/625]	eta 0:01:10 lr 0.490812	data 0.0006 (0.0381)	batch 0.8849 (0.9463)	loss 2.7408 (2.9554)	grad_norm 0.4997 (0.4996)	mem 38886MB
Train: [76/180][600/625]	eta 0:00:23 lr 0.490268	data 0.0004 (0.0350)	batch 0.8768 (0.9432)	loss 2.9561 (2.9557)	grad_norm 0.4957 (0.4995)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 76 training takes 0:09:50
Test: [0/25]	Time 14.936 (14.936)	Loss 1.1773 (1.1773)	Acc@1 74.463 (74.463)	Acc@5 90.918 (90.918)	Mem 38886MB
 * Acc@1 62.364 Acc@5 84.548
Accuracy of the network on the 50000 test images: 62.36%
Max accuracy (after decay): 62.98%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [77/180][0/625]	eta 3:57:28 lr 0.489996	data 21.2575 (21.2575)	batch 22.7969 (22.7969)	loss 2.7436 (2.7436)	grad_norm 0.4908 (0.4908)	mem 38886MB
Train: [77/180][50/625]	eta 0:12:53 lr 0.489452	data 0.0005 (0.4176)	batch 0.9248 (1.3446)	loss 3.1387 (2.9393)	grad_norm 0.5064 (0.4994)	mem 38886MB
Train: [77/180][100/625]	eta 0:09:51 lr 0.488907	data 0.0007 (0.2112)	batch 0.9231 (1.1269)	loss 3.1052 (2.9333)	grad_norm 0.4952 (0.4990)	mem 38886MB
Train: [77/180][150/625]	eta 0:08:22 lr 0.488363	data 0.0007 (0.1415)	batch 0.9506 (1.0581)	loss 3.1323 (2.9358)	grad_norm 0.4865 (0.4994)	mem 38886MB
Train: [77/180][200/625]	eta 0:07:13 lr 0.487818	data 0.0007 (0.1065)	batch 0.8651 (1.0211)	loss 2.9693 (2.9410)	grad_norm 0.4913 (0.4996)	mem 38886MB
Train: [77/180][250/625]	eta 0:06:14 lr 0.487273	data 0.0008 (0.0854)	batch 0.9084 (0.9986)	loss 3.0519 (2.9406)	grad_norm 0.4969 (0.4998)	mem 38886MB
Train: [77/180][300/625]	eta 0:05:19 lr 0.486728	data 0.0014 (0.0714)	batch 0.9076 (0.9834)	loss 2.8753 (2.9389)	grad_norm 0.5008 (0.4997)	mem 38886MB
Train: [77/180][350/625]	eta 0:04:27 lr 0.486183	data 0.0007 (0.0613)	batch 0.9019 (0.9716)	loss 2.9613 (2.9394)	grad_norm 0.4934 (0.5002)	mem 38886MB
Train: [77/180][400/625]	eta 0:03:36 lr 0.485637	data 0.0007 (0.0538)	batch 0.8784 (0.9638)	loss 2.9882 (2.9364)	grad_norm 0.5026 (0.5005)	mem 38886MB
Train: [77/180][450/625]	eta 0:02:47 lr 0.485091	data 0.0006 (0.0479)	batch 0.8895 (0.9577)	loss 3.1256 (2.9377)	grad_norm 0.5088 (0.5005)	mem 38886MB
Train: [77/180][500/625]	eta 0:01:59 lr 0.484546	data 0.0011 (0.0432)	batch 0.8860 (0.9525)	loss 2.7984 (2.9380)	grad_norm 0.5064 (0.5005)	mem 38886MB
Train: [77/180][550/625]	eta 0:01:11 lr 0.484000	data 0.0006 (0.0393)	batch 0.8930 (0.9486)	loss 3.0402 (2.9420)	grad_norm 0.5100 (0.5009)	mem 38886MB
Train: [77/180][600/625]	eta 0:00:23 lr 0.483454	data 0.0007 (0.0361)	batch 0.9120 (0.9448)	loss 3.0305 (2.9446)	grad_norm 0.4873 (0.5008)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 77 training takes 0:09:50
Test: [0/25]	Time 14.795 (14.795)	Loss 1.2089 (1.2089)	Acc@1 72.510 (72.510)	Acc@5 90.820 (90.820)	Mem 38886MB
 * Acc@1 62.622 Acc@5 84.602
Accuracy of the network on the 50000 test images: 62.62%
Max accuracy (after decay): 62.98%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [78/180][0/625]	eta 3:56:36 lr 0.483181	data 21.8338 (21.8338)	batch 22.7147 (22.7147)	loss 2.9362 (2.9362)	grad_norm 0.5037 (0.5037)	mem 38886MB
Train: [78/180][50/625]	eta 0:12:48 lr 0.482634	data 0.0007 (0.4292)	batch 0.8949 (1.3371)	loss 2.9807 (2.9124)	grad_norm 0.4976 (0.4996)	mem 38886MB
Train: [78/180][100/625]	eta 0:09:50 lr 0.482088	data 0.0006 (0.2170)	batch 0.9507 (1.1250)	loss 2.7648 (2.9279)	grad_norm 0.5190 (0.5003)	mem 38886MB
Train: [78/180][150/625]	eta 0:08:19 lr 0.481541	data 0.0005 (0.1454)	batch 0.8971 (1.0525)	loss 3.0184 (2.9253)	grad_norm 0.5037 (0.5015)	mem 38886MB
Train: [78/180][200/625]	eta 0:07:11 lr 0.480994	data 0.0006 (0.1093)	batch 0.9743 (1.0162)	loss 2.7197 (2.9321)	grad_norm 0.4986 (0.5012)	mem 38886MB
Train: [78/180][250/625]	eta 0:06:12 lr 0.480447	data 0.0006 (0.0878)	batch 0.8938 (0.9938)	loss 2.8223 (2.9380)	grad_norm 0.4952 (0.5015)	mem 38886MB
Train: [78/180][300/625]	eta 0:05:18 lr 0.479900	data 0.0005 (0.0733)	batch 0.9254 (0.9788)	loss 3.1156 (2.9394)	grad_norm 0.5027 (0.5015)	mem 38886MB
Train: [78/180][350/625]	eta 0:04:26 lr 0.479353	data 0.0004 (0.0630)	batch 0.8821 (0.9689)	loss 2.7539 (2.9391)	grad_norm 0.5110 (0.5018)	mem 38886MB
Train: [78/180][400/625]	eta 0:03:36 lr 0.478805	data 0.0006 (0.0552)	batch 0.9407 (0.9612)	loss 2.8966 (2.9405)	grad_norm 0.5283 (0.5023)	mem 38886MB
Train: [78/180][450/625]	eta 0:02:47 lr 0.478258	data 0.0005 (0.0491)	batch 0.9123 (0.9550)	loss 3.0785 (2.9406)	grad_norm 0.5193 (0.5023)	mem 38886MB
Train: [78/180][500/625]	eta 0:01:58 lr 0.477710	data 0.0005 (0.0443)	batch 0.8961 (0.9499)	loss 2.9784 (2.9416)	grad_norm 0.5014 (0.5022)	mem 38886MB
Train: [78/180][550/625]	eta 0:01:10 lr 0.477162	data 0.0005 (0.0403)	batch 0.9011 (0.9460)	loss 2.9237 (2.9408)	grad_norm 0.5138 (0.5026)	mem 38886MB
Train: [78/180][600/625]	eta 0:00:23 lr 0.476614	data 0.0007 (0.0370)	batch 0.9370 (0.9427)	loss 2.7569 (2.9432)	grad_norm 0.5120 (0.5027)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 78 training takes 0:09:49
Test: [0/25]	Time 14.823 (14.823)	Loss 1.1530 (1.1530)	Acc@1 73.291 (73.291)	Acc@5 91.309 (91.309)	Mem 38886MB
 * Acc@1 62.596 Acc@5 84.748
Accuracy of the network on the 50000 test images: 62.60%
Max accuracy (after decay): 62.98%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [79/180][0/625]	eta 3:56:33 lr 0.476340	data 21.2806 (21.2806)	batch 22.7101 (22.7101)	loss 2.9567 (2.9567)	grad_norm 0.4973 (0.4973)	mem 38886MB
Train: [79/180][50/625]	eta 0:12:51 lr 0.475791	data 0.0005 (0.4180)	batch 0.9794 (1.3411)	loss 2.8777 (2.9104)	grad_norm 0.4962 (0.5010)	mem 38886MB
Train: [79/180][100/625]	eta 0:09:50 lr 0.475243	data 0.0004 (0.2113)	batch 0.9313 (1.1256)	loss 2.8771 (2.9195)	grad_norm 0.5008 (0.5029)	mem 38886MB
Train: [79/180][150/625]	eta 0:08:20 lr 0.474694	data 0.0005 (0.1415)	batch 0.9029 (1.0536)	loss 2.8783 (2.9216)	grad_norm 0.4889 (0.5029)	mem 38886MB
Train: [79/180][200/625]	eta 0:07:12 lr 0.474146	data 0.0005 (0.1065)	batch 0.9039 (1.0169)	loss 2.8920 (2.9216)	grad_norm 0.5180 (0.5032)	mem 38886MB
Train: [79/180][250/625]	eta 0:06:13 lr 0.473597	data 0.0006 (0.0854)	batch 1.0289 (0.9962)	loss 3.0177 (2.9253)	grad_norm 0.4974 (0.5041)	mem 38886MB
Train: [79/180][300/625]	eta 0:05:19 lr 0.473048	data 0.0005 (0.0713)	batch 0.8870 (0.9819)	loss 2.9280 (2.9325)	grad_norm 0.5052 (0.5043)	mem 38886MB
Train: [79/180][350/625]	eta 0:04:27 lr 0.472499	data 0.0005 (0.0612)	batch 0.8811 (0.9716)	loss 2.9439 (2.9322)	grad_norm 0.4948 (0.5046)	mem 38886MB
Train: [79/180][400/625]	eta 0:03:36 lr 0.471949	data 0.0006 (0.0536)	batch 0.8697 (0.9630)	loss 2.9835 (2.9319)	grad_norm 0.4989 (0.5043)	mem 38886MB
Train: [79/180][450/625]	eta 0:02:47 lr 0.471400	data 0.0005 (0.0478)	batch 0.9515 (0.9572)	loss 2.9406 (2.9325)	grad_norm 0.5135 (0.5042)	mem 38886MB
Train: [79/180][500/625]	eta 0:01:58 lr 0.470850	data 0.0005 (0.0430)	batch 0.9050 (0.9516)	loss 2.8400 (2.9308)	grad_norm 0.4988 (0.5043)	mem 38886MB
Train: [79/180][550/625]	eta 0:01:11 lr 0.470301	data 0.0004 (0.0392)	batch 0.9464 (0.9476)	loss 2.9714 (2.9332)	grad_norm 0.5124 (0.5045)	mem 38886MB
Train: [79/180][600/625]	eta 0:00:23 lr 0.469751	data 0.0004 (0.0360)	batch 1.0297 (0.9438)	loss 3.0829 (2.9348)	grad_norm 0.5001 (0.5045)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 79 training takes 0:09:50
Test: [0/25]	Time 14.788 (14.788)	Loss 1.1356 (1.1356)	Acc@1 75.488 (75.488)	Acc@5 91.064 (91.064)	Mem 38886MB
 * Acc@1 63.162 Acc@5 84.954
Accuracy of the network on the 50000 test images: 63.16%
Max accuracy (after decay): 63.16%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [80/180][0/625]	eta 3:58:02 lr 0.469476	data 20.8024 (20.8024)	batch 22.8520 (22.8520)	loss 2.9064 (2.9064)	grad_norm 0.5045 (0.5045)	mem 38886MB
Train: [80/180][50/625]	eta 0:12:50 lr 0.468926	data 0.0005 (0.4087)	batch 0.8729 (1.3397)	loss 2.9468 (2.8934)	grad_norm 0.5000 (0.5023)	mem 38886MB
Train: [80/180][100/625]	eta 0:09:50 lr 0.468376	data 0.0006 (0.2067)	batch 0.8697 (1.1251)	loss 2.9468 (2.9046)	grad_norm 0.5013 (0.5028)	mem 38886MB
Train: [80/180][150/625]	eta 0:08:19 lr 0.467825	data 0.0007 (0.1384)	batch 0.9023 (1.0524)	loss 2.8350 (2.9108)	grad_norm 0.5080 (0.5045)	mem 38886MB
Train: [80/180][200/625]	eta 0:07:11 lr 0.467275	data 0.0006 (0.1041)	batch 0.9119 (1.0160)	loss 3.0300 (2.9162)	grad_norm 0.4995 (0.5044)	mem 38886MB
Train: [80/180][250/625]	eta 0:06:13 lr 0.466724	data 0.0004 (0.0835)	batch 0.8931 (0.9953)	loss 2.8771 (2.9140)	grad_norm 0.5013 (0.5042)	mem 38886MB
Train: [80/180][300/625]	eta 0:05:18 lr 0.466173	data 0.0005 (0.0697)	batch 0.9380 (0.9803)	loss 2.9227 (2.9146)	grad_norm 0.5064 (0.5048)	mem 38886MB
Train: [80/180][350/625]	eta 0:04:26 lr 0.465623	data 0.0006 (0.0599)	batch 0.9352 (0.9702)	loss 2.9723 (2.9154)	grad_norm 0.5195 (0.5055)	mem 38886MB
Train: [80/180][400/625]	eta 0:03:36 lr 0.465072	data 0.0005 (0.0525)	batch 0.9074 (0.9619)	loss 2.9530 (2.9215)	grad_norm 0.4983 (0.5058)	mem 38886MB
Train: [80/180][450/625]	eta 0:02:47 lr 0.464521	data 0.0007 (0.0467)	batch 0.9179 (0.9558)	loss 2.9522 (2.9257)	grad_norm 0.4992 (0.5059)	mem 38886MB
Train: [80/180][500/625]	eta 0:01:58 lr 0.463969	data 0.0008 (0.0421)	batch 0.9386 (0.9514)	loss 2.8184 (2.9272)	grad_norm 0.4931 (0.5061)	mem 38886MB
Train: [80/180][550/625]	eta 0:01:11 lr 0.463418	data 0.0006 (0.0384)	batch 0.8661 (0.9475)	loss 2.8519 (2.9279)	grad_norm 0.5199 (0.5065)	mem 38886MB
Train: [80/180][600/625]	eta 0:00:23 lr 0.462866	data 0.0005 (0.0352)	batch 0.9550 (0.9448)	loss 3.0357 (2.9300)	grad_norm 0.5155 (0.5066)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 80 training takes 0:09:50
Test: [0/25]	Time 15.007 (15.007)	Loss 1.1378 (1.1378)	Acc@1 75.781 (75.781)	Acc@5 91.162 (91.162)	Mem 38886MB
 * Acc@1 63.040 Acc@5 84.824
Accuracy of the network on the 50000 test images: 63.04%
Max accuracy (after decay): 63.16%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [81/180][0/625]	eta 3:54:00 lr 0.462591	data 21.5427 (21.5427)	batch 22.4655 (22.4655)	loss 3.1702 (3.1702)	grad_norm 0.4865 (0.4865)	mem 38886MB
Train: [81/180][50/625]	eta 0:12:48 lr 0.462039	data 0.0008 (0.4234)	batch 0.9767 (1.3357)	loss 2.9844 (2.9425)	grad_norm 0.4938 (0.5042)	mem 38886MB
Train: [81/180][100/625]	eta 0:09:48 lr 0.461487	data 0.0005 (0.2142)	batch 0.8798 (1.1217)	loss 2.8515 (2.9301)	grad_norm 0.5058 (0.5054)	mem 38886MB
Train: [81/180][150/625]	eta 0:08:18 lr 0.460935	data 0.0007 (0.1435)	batch 0.8564 (1.0503)	loss 2.8158 (2.9279)	grad_norm 0.4936 (0.5059)	mem 38886MB
Train: [81/180][200/625]	eta 0:07:11 lr 0.460383	data 0.0008 (0.1081)	batch 0.8918 (1.0156)	loss 2.8295 (2.9254)	grad_norm 0.5117 (0.5063)	mem 38886MB
Train: [81/180][250/625]	eta 0:06:12 lr 0.459831	data 0.0007 (0.0867)	batch 0.8975 (0.9930)	loss 3.0735 (2.9281)	grad_norm 0.5256 (0.5073)	mem 38886MB
Train: [81/180][300/625]	eta 0:05:18 lr 0.459279	data 0.0005 (0.0724)	batch 0.9050 (0.9790)	loss 2.9331 (2.9308)	grad_norm 0.5049 (0.5077)	mem 38886MB
Train: [81/180][350/625]	eta 0:04:26 lr 0.458727	data 0.0004 (0.0622)	batch 0.9177 (0.9693)	loss 2.9903 (2.9317)	grad_norm 0.4964 (0.5075)	mem 38886MB
Train: [81/180][400/625]	eta 0:03:36 lr 0.458174	data 0.0004 (0.0545)	batch 0.8975 (0.9608)	loss 2.9799 (2.9279)	grad_norm 0.5090 (0.5074)	mem 38886MB
Train: [81/180][450/625]	eta 0:02:47 lr 0.457621	data 0.0007 (0.0485)	batch 0.8884 (0.9552)	loss 2.9979 (2.9296)	grad_norm 0.5142 (0.5073)	mem 38886MB
Train: [81/180][500/625]	eta 0:01:58 lr 0.457069	data 0.0006 (0.0437)	batch 0.9060 (0.9507)	loss 2.9878 (2.9289)	grad_norm 0.5023 (0.5075)	mem 38886MB
Train: [81/180][550/625]	eta 0:01:11 lr 0.456516	data 0.0005 (0.0399)	batch 0.8843 (0.9467)	loss 2.8999 (2.9283)	grad_norm 0.5205 (0.5076)	mem 38886MB
Train: [81/180][600/625]	eta 0:00:23 lr 0.455963	data 0.0004 (0.0366)	batch 0.9160 (0.9438)	loss 2.7767 (2.9311)	grad_norm 0.5060 (0.5077)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 81 training takes 0:09:50
Test: [0/25]	Time 14.903 (14.903)	Loss 1.1471 (1.1471)	Acc@1 74.658 (74.658)	Acc@5 91.406 (91.406)	Mem 38886MB
 * Acc@1 63.398 Acc@5 85.006
Accuracy of the network on the 50000 test images: 63.40%
Max accuracy (after decay): 63.40%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [82/180][0/625]	eta 4:03:22 lr 0.455686	data 22.4697 (22.4697)	batch 23.3633 (23.3633)	loss 2.9158 (2.9158)	grad_norm 0.4949 (0.4949)	mem 38886MB
Train: [82/180][50/625]	eta 0:12:59 lr 0.455133	data 0.0333 (0.4419)	batch 0.9026 (1.3554)	loss 2.7970 (2.8953)	grad_norm 0.5229 (0.5079)	mem 38886MB
Train: [82/180][100/625]	eta 0:09:54 lr 0.454580	data 0.0006 (0.2235)	batch 0.8499 (1.1325)	loss 2.9422 (2.9034)	grad_norm 0.5265 (0.5083)	mem 38886MB
Train: [82/180][150/625]	eta 0:08:22 lr 0.454027	data 0.0007 (0.1498)	batch 0.9001 (1.0580)	loss 2.7735 (2.8922)	grad_norm 0.4937 (0.5075)	mem 38886MB
Train: [82/180][200/625]	eta 0:07:14 lr 0.453473	data 0.0005 (0.1127)	batch 0.8761 (1.0217)	loss 2.8727 (2.9019)	grad_norm 0.4966 (0.5078)	mem 38886MB
Train: [82/180][250/625]	eta 0:06:14 lr 0.452920	data 0.0009 (0.0904)	batch 0.9314 (0.9989)	loss 2.7100 (2.9093)	grad_norm 0.5221 (0.5079)	mem 38886MB
Train: [82/180][300/625]	eta 0:05:19 lr 0.452366	data 0.0006 (0.0755)	batch 0.8947 (0.9843)	loss 2.9968 (2.9108)	grad_norm 0.5167 (0.5080)	mem 38886MB
Train: [82/180][350/625]	eta 0:04:27 lr 0.451813	data 0.0005 (0.0649)	batch 0.9446 (0.9730)	loss 3.0377 (2.9143)	grad_norm 0.5073 (0.5081)	mem 38886MB
Train: [82/180][400/625]	eta 0:03:36 lr 0.451259	data 0.0007 (0.0569)	batch 0.8535 (0.9642)	loss 2.7591 (2.9151)	grad_norm 0.5082 (0.5082)	mem 38886MB
Train: [82/180][450/625]	eta 0:02:47 lr 0.450705	data 0.0006 (0.0506)	batch 0.8854 (0.9577)	loss 2.9548 (2.9212)	grad_norm 0.5139 (0.5084)	mem 38886MB
Train: [82/180][500/625]	eta 0:01:59 lr 0.450151	data 0.0008 (0.0457)	batch 0.9265 (0.9532)	loss 2.9942 (2.9197)	grad_norm 0.4984 (0.5089)	mem 38886MB
Train: [82/180][550/625]	eta 0:01:11 lr 0.449597	data 0.0009 (0.0416)	batch 1.0039 (0.9490)	loss 2.8817 (2.9204)	grad_norm 0.4996 (0.5089)	mem 38886MB
Train: [82/180][600/625]	eta 0:00:23 lr 0.449042	data 0.0007 (0.0382)	batch 0.8789 (0.9457)	loss 3.0527 (2.9245)	grad_norm 0.5145 (0.5091)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 82 training takes 0:09:51
Test: [0/25]	Time 14.761 (14.761)	Loss 1.1532 (1.1532)	Acc@1 74.365 (74.365)	Acc@5 91.162 (91.162)	Mem 38886MB
 * Acc@1 63.102 Acc@5 84.722
Accuracy of the network on the 50000 test images: 63.10%
Max accuracy (after decay): 63.40%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [83/180][0/625]	eta 3:59:03 lr 0.448765	data 21.2417 (21.2417)	batch 22.9500 (22.9500)	loss 2.8862 (2.8862)	grad_norm 0.5055 (0.5055)	mem 38886MB
Train: [83/180][50/625]	eta 0:12:50 lr 0.448211	data 0.0006 (0.4176)	batch 0.9462 (1.3407)	loss 2.8639 (2.9252)	grad_norm 0.5059 (0.5089)	mem 38886MB
Train: [83/180][100/625]	eta 0:09:53 lr 0.447656	data 0.0006 (0.2112)	batch 0.9476 (1.1305)	loss 2.8252 (2.9096)	grad_norm 0.4984 (0.5082)	mem 38886MB
Train: [83/180][150/625]	eta 0:08:21 lr 0.447102	data 0.0006 (0.1415)	batch 0.8483 (1.0565)	loss 2.8496 (2.9139)	grad_norm 0.5069 (0.5095)	mem 38886MB
Train: [83/180][200/625]	eta 0:07:13 lr 0.446547	data 0.0005 (0.1064)	batch 0.9010 (1.0198)	loss 2.9389 (2.9163)	grad_norm 0.5039 (0.5109)	mem 38886MB
Train: [83/180][250/625]	eta 0:06:14 lr 0.445993	data 0.0005 (0.0854)	batch 0.8875 (0.9975)	loss 2.9151 (2.9125)	grad_norm 0.5195 (0.5105)	mem 38886MB
Train: [83/180][300/625]	eta 0:05:19 lr 0.445438	data 0.0006 (0.0713)	batch 0.8985 (0.9823)	loss 3.1540 (2.9179)	grad_norm 0.5141 (0.5110)	mem 38886MB
Train: [83/180][350/625]	eta 0:04:27 lr 0.444883	data 0.0006 (0.0613)	batch 0.9058 (0.9731)	loss 3.0560 (2.9193)	grad_norm 0.5029 (0.5110)	mem 38886MB
Train: [83/180][400/625]	eta 0:03:37 lr 0.444328	data 0.0007 (0.0538)	batch 0.8805 (0.9652)	loss 2.8290 (2.9209)	grad_norm 0.5089 (0.5111)	mem 38886MB
Train: [83/180][450/625]	eta 0:02:47 lr 0.443773	data 0.0009 (0.0479)	batch 0.9256 (0.9592)	loss 2.8283 (2.9211)	grad_norm 0.5074 (0.5112)	mem 38886MB
Train: [83/180][500/625]	eta 0:01:59 lr 0.443218	data 0.0005 (0.0432)	batch 0.8816 (0.9543)	loss 2.8200 (2.9221)	grad_norm 0.5027 (0.5113)	mem 38886MB
Train: [83/180][550/625]	eta 0:01:11 lr 0.442662	data 0.0005 (0.0393)	batch 0.9246 (0.9501)	loss 2.9297 (2.9241)	grad_norm 0.5230 (0.5114)	mem 38886MB
Train: [83/180][600/625]	eta 0:00:23 lr 0.442107	data 0.0005 (0.0361)	batch 0.8854 (0.9466)	loss 2.8588 (2.9255)	grad_norm 0.5081 (0.5115)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 83 training takes 0:09:51
Test: [0/25]	Time 14.463 (14.463)	Loss 1.1345 (1.1345)	Acc@1 74.121 (74.121)	Acc@5 91.895 (91.895)	Mem 38886MB
 * Acc@1 63.336 Acc@5 84.976
Accuracy of the network on the 50000 test images: 63.34%
Max accuracy (after decay): 63.40%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [84/180][0/625]	eta 3:54:12 lr 0.441829	data 20.5806 (20.5806)	batch 22.4842 (22.4842)	loss 2.9821 (2.9821)	grad_norm 0.5301 (0.5301)	mem 38886MB
Train: [84/180][50/625]	eta 0:12:45 lr 0.441274	data 0.0011 (0.4042)	batch 0.8683 (1.3320)	loss 2.6832 (2.9156)	grad_norm 0.5124 (0.5082)	mem 38886MB
Train: [84/180][100/625]	eta 0:09:48 lr 0.440718	data 0.0005 (0.2044)	batch 0.9164 (1.1205)	loss 2.8346 (2.9064)	grad_norm 0.5446 (0.5119)	mem 38886MB
Train: [84/180][150/625]	eta 0:08:19 lr 0.440163	data 0.0007 (0.1370)	batch 0.9474 (1.0523)	loss 3.0394 (2.9147)	grad_norm 0.5159 (0.5112)	mem 38886MB
Train: [84/180][200/625]	eta 0:07:12 lr 0.439607	data 0.0008 (0.1031)	batch 0.9006 (1.0185)	loss 2.9742 (2.9050)	grad_norm 0.5046 (0.5120)	mem 38886MB
Train: [84/180][250/625]	eta 0:06:13 lr 0.439051	data 0.0006 (0.0827)	batch 0.9593 (0.9968)	loss 2.8793 (2.9037)	grad_norm 0.4996 (0.5125)	mem 38886MB
Train: [84/180][300/625]	eta 0:05:18 lr 0.438495	data 0.0005 (0.0691)	batch 0.8825 (0.9811)	loss 2.8683 (2.9036)	grad_norm 0.4999 (0.5133)	mem 38886MB
Train: [84/180][350/625]	eta 0:04:26 lr 0.437939	data 0.0004 (0.0593)	batch 0.9333 (0.9700)	loss 2.8632 (2.9072)	grad_norm 0.5129 (0.5134)	mem 38886MB
Train: [84/180][400/625]	eta 0:03:36 lr 0.437383	data 0.0010 (0.0520)	batch 0.9322 (0.9626)	loss 2.9100 (2.9098)	grad_norm 0.5092 (0.5138)	mem 38886MB
Train: [84/180][450/625]	eta 0:02:47 lr 0.436827	data 0.0005 (0.0463)	batch 0.9062 (0.9570)	loss 2.8114 (2.9137)	grad_norm 0.5200 (0.5138)	mem 38886MB
Train: [84/180][500/625]	eta 0:01:58 lr 0.436271	data 0.0005 (0.0418)	batch 0.8921 (0.9514)	loss 2.9121 (2.9129)	grad_norm 0.5140 (0.5140)	mem 38886MB
Train: [84/180][550/625]	eta 0:01:11 lr 0.435715	data 0.0006 (0.0381)	batch 0.8329 (0.9473)	loss 2.9366 (2.9132)	grad_norm 0.5071 (0.5142)	mem 38886MB
Train: [84/180][600/625]	eta 0:00:23 lr 0.435159	data 0.0006 (0.0350)	batch 0.9240 (0.9441)	loss 2.8819 (2.9166)	grad_norm 0.5353 (0.5141)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 84 training takes 0:09:50
Test: [0/25]	Time 14.863 (14.863)	Loss 1.1552 (1.1552)	Acc@1 73.877 (73.877)	Acc@5 91.357 (91.357)	Mem 38886MB
 * Acc@1 63.020 Acc@5 84.974
Accuracy of the network on the 50000 test images: 63.02%
Max accuracy (after decay): 63.40%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [85/180][0/625]	eta 3:54:25 lr 0.434881	data 21.0017 (21.0017)	batch 22.5041 (22.5041)	loss 2.7380 (2.7380)	grad_norm 0.5177 (0.5177)	mem 38886MB
Train: [85/180][50/625]	eta 0:12:47 lr 0.434324	data 0.0008 (0.4124)	batch 0.9481 (1.3342)	loss 2.8426 (2.8788)	grad_norm 0.5172 (0.5128)	mem 38886MB
Train: [85/180][100/625]	eta 0:09:52 lr 0.433768	data 0.0006 (0.2086)	batch 0.9083 (1.1289)	loss 3.1359 (2.8883)	grad_norm 0.5174 (0.5143)	mem 38886MB
Train: [85/180][150/625]	eta 0:08:20 lr 0.433211	data 0.0006 (0.1397)	batch 0.8947 (1.0544)	loss 2.7128 (2.8929)	grad_norm 0.5043 (0.5144)	mem 38886MB
Train: [85/180][200/625]	eta 0:07:12 lr 0.432655	data 0.0005 (0.1051)	batch 0.8847 (1.0180)	loss 2.9062 (2.8877)	grad_norm 0.5194 (0.5141)	mem 38886MB
Train: [85/180][250/625]	eta 0:06:13 lr 0.432098	data 0.0537 (0.0846)	batch 0.9141 (0.9958)	loss 2.9292 (2.8954)	grad_norm 0.5318 (0.5141)	mem 38886MB
Train: [85/180][300/625]	eta 0:05:18 lr 0.431541	data 0.0006 (0.0706)	batch 0.9312 (0.9802)	loss 2.8684 (2.8997)	grad_norm 0.5035 (0.5146)	mem 38886MB
Train: [85/180][350/625]	eta 0:04:26 lr 0.430984	data 0.0005 (0.0607)	batch 0.9512 (0.9696)	loss 2.8299 (2.9038)	grad_norm 0.5034 (0.5152)	mem 38886MB
Train: [85/180][400/625]	eta 0:03:36 lr 0.430428	data 0.0005 (0.0532)	batch 0.9034 (0.9612)	loss 2.9666 (2.9022)	grad_norm 0.5153 (0.5152)	mem 38886MB
Train: [85/180][450/625]	eta 0:02:47 lr 0.429871	data 0.0005 (0.0473)	batch 0.9291 (0.9550)	loss 2.9791 (2.9052)	grad_norm 0.5034 (0.5152)	mem 38886MB
Train: [85/180][500/625]	eta 0:01:58 lr 0.429314	data 0.0007 (0.0427)	batch 0.9050 (0.9506)	loss 3.1314 (2.9079)	grad_norm 0.5134 (0.5151)	mem 38886MB
Train: [85/180][550/625]	eta 0:01:11 lr 0.428757	data 0.0006 (0.0389)	batch 0.9095 (0.9469)	loss 2.7498 (2.9079)	grad_norm 0.5200 (0.5154)	mem 38886MB
Train: [85/180][600/625]	eta 0:00:23 lr 0.428200	data 0.0006 (0.0357)	batch 0.9011 (0.9434)	loss 3.1387 (2.9089)	grad_norm 0.5169 (0.5154)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 85 training takes 0:09:50
Test: [0/25]	Time 14.996 (14.996)	Loss 1.1443 (1.1443)	Acc@1 74.170 (74.170)	Acc@5 92.236 (92.236)	Mem 38886MB
 * Acc@1 63.282 Acc@5 85.112
Accuracy of the network on the 50000 test images: 63.28%
Max accuracy (after decay): 63.40%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [86/180][0/625]	eta 4:02:35 lr 0.427921	data 21.7812 (21.7812)	batch 23.2891 (23.2891)	loss 2.6510 (2.6510)	grad_norm 0.4989 (0.4989)	mem 38886MB
Train: [86/180][50/625]	eta 0:12:51 lr 0.427364	data 0.0007 (0.4278)	batch 0.9242 (1.3419)	loss 2.8519 (2.8935)	grad_norm 0.4988 (0.5129)	mem 38886MB
Train: [86/180][100/625]	eta 0:09:52 lr 0.426807	data 0.0008 (0.2163)	batch 0.8783 (1.1280)	loss 2.8979 (2.9025)	grad_norm 0.5277 (0.5164)	mem 38886MB
Train: [86/180][150/625]	eta 0:08:20 lr 0.426250	data 0.0005 (0.1449)	batch 0.8531 (1.0542)	loss 2.9033 (2.9133)	grad_norm 0.5163 (0.5164)	mem 38886MB
Train: [86/180][200/625]	eta 0:07:12 lr 0.425692	data 0.0007 (0.1090)	batch 0.8915 (1.0181)	loss 3.0323 (2.9070)	grad_norm 0.5133 (0.5164)	mem 38886MB
Train: [86/180][250/625]	eta 0:06:13 lr 0.425135	data 0.0004 (0.0874)	batch 0.9142 (0.9959)	loss 2.8629 (2.9080)	grad_norm 0.5099 (0.5163)	mem 38886MB
Train: [86/180][300/625]	eta 0:05:19 lr 0.424578	data 0.0005 (0.0730)	batch 0.8912 (0.9820)	loss 2.9652 (2.9100)	grad_norm 0.5156 (0.5169)	mem 38886MB
Train: [86/180][350/625]	eta 0:04:27 lr 0.424020	data 0.0005 (0.0627)	batch 1.1058 (0.9720)	loss 2.9144 (2.9106)	grad_norm 0.5251 (0.5168)	mem 38886MB
Train: [86/180][400/625]	eta 0:03:36 lr 0.423463	data 0.0005 (0.0549)	batch 0.8732 (0.9636)	loss 2.8112 (2.9126)	grad_norm 0.5079 (0.5168)	mem 38886MB
Train: [86/180][450/625]	eta 0:02:47 lr 0.422905	data 0.0004 (0.0489)	batch 0.9048 (0.9569)	loss 3.2252 (2.9129)	grad_norm 0.5254 (0.5167)	mem 38886MB
Train: [86/180][500/625]	eta 0:01:59 lr 0.422347	data 0.0004 (0.0441)	batch 0.9082 (0.9522)	loss 3.0840 (2.9132)	grad_norm 0.5220 (0.5171)	mem 38886MB
Train: [86/180][550/625]	eta 0:01:11 lr 0.421790	data 0.0005 (0.0401)	batch 0.8878 (0.9483)	loss 2.8353 (2.9128)	grad_norm 0.5121 (0.5172)	mem 38886MB
Train: [86/180][600/625]	eta 0:00:23 lr 0.421232	data 0.0006 (0.0368)	batch 0.8885 (0.9459)	loss 2.8573 (2.9160)	grad_norm 0.5143 (0.5175)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 86 training takes 0:09:51
Test: [0/25]	Time 14.890 (14.890)	Loss 1.1682 (1.1682)	Acc@1 74.707 (74.707)	Acc@5 91.016 (91.016)	Mem 38886MB
 * Acc@1 63.530 Acc@5 85.054
Accuracy of the network on the 50000 test images: 63.53%
Max accuracy (after decay): 63.53%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [87/180][0/625]	eta 3:58:24 lr 0.420953	data 21.1127 (21.1127)	batch 22.8875 (22.8875)	loss 2.6017 (2.6017)	grad_norm 0.4990 (0.4990)	mem 38886MB
Train: [87/180][50/625]	eta 0:12:51 lr 0.420396	data 0.0004 (0.4147)	batch 0.9211 (1.3410)	loss 2.8020 (2.8621)	grad_norm 0.5142 (0.5183)	mem 38886MB
Train: [87/180][100/625]	eta 0:09:52 lr 0.419838	data 0.0005 (0.2097)	batch 0.9168 (1.1289)	loss 3.0368 (2.8692)	grad_norm 0.5096 (0.5182)	mem 38886MB
Train: [87/180][150/625]	eta 0:08:22 lr 0.419280	data 0.0005 (0.1404)	batch 1.0730 (1.0576)	loss 3.0666 (2.8801)	grad_norm 0.5342 (0.5182)	mem 38886MB
Train: [87/180][200/625]	eta 0:07:14 lr 0.418722	data 0.0004 (0.1056)	batch 0.9105 (1.0216)	loss 2.8140 (2.8823)	grad_norm 0.5147 (0.5179)	mem 38886MB
Train: [87/180][250/625]	eta 0:06:14 lr 0.418164	data 0.0005 (0.0847)	batch 0.9376 (0.9988)	loss 2.8456 (2.8846)	grad_norm 0.5163 (0.5173)	mem 38886MB
Train: [87/180][300/625]	eta 0:05:19 lr 0.417606	data 0.0005 (0.0707)	batch 0.8849 (0.9837)	loss 3.1293 (2.8888)	grad_norm 0.5174 (0.5177)	mem 38886MB
Train: [87/180][350/625]	eta 0:04:27 lr 0.417048	data 0.0006 (0.0607)	batch 0.8894 (0.9739)	loss 2.9811 (2.8903)	grad_norm 0.5171 (0.5184)	mem 38886MB
Train: [87/180][400/625]	eta 0:03:37 lr 0.416490	data 0.0005 (0.0532)	batch 0.8897 (0.9656)	loss 3.0188 (2.8906)	grad_norm 0.5144 (0.5187)	mem 38886MB
Train: [87/180][450/625]	eta 0:02:47 lr 0.415932	data 0.0007 (0.0474)	batch 0.8811 (0.9592)	loss 3.0192 (2.8902)	grad_norm 0.5278 (0.5190)	mem 38886MB
Train: [87/180][500/625]	eta 0:01:59 lr 0.415374	data 0.0005 (0.0427)	batch 0.9559 (0.9543)	loss 2.7656 (2.8918)	grad_norm 0.5345 (0.5193)	mem 38886MB
Train: [87/180][550/625]	eta 0:01:11 lr 0.414816	data 0.0003 (0.0389)	batch 0.8714 (0.9499)	loss 2.6161 (2.8929)	grad_norm 0.5099 (0.5194)	mem 38886MB
Train: [87/180][600/625]	eta 0:00:23 lr 0.414258	data 0.0006 (0.0357)	batch 0.8990 (0.9460)	loss 2.9899 (2.8938)	grad_norm 0.5373 (0.5194)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 87 training takes 0:09:51
Test: [0/25]	Time 15.125 (15.125)	Loss 1.1424 (1.1424)	Acc@1 75.000 (75.000)	Acc@5 91.846 (91.846)	Mem 38886MB
 * Acc@1 63.022 Acc@5 84.936
Accuracy of the network on the 50000 test images: 63.02%
Max accuracy (after decay): 63.53%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [88/180][0/625]	eta 3:57:41 lr 0.413979	data 21.8645 (21.8645)	batch 22.8185 (22.8185)	loss 2.8647 (2.8647)	grad_norm 0.5218 (0.5218)	mem 38886MB
Train: [88/180][50/625]	eta 0:12:51 lr 0.413421	data 0.0005 (0.4297)	batch 0.8905 (1.3417)	loss 2.8631 (2.8393)	grad_norm 0.5190 (0.5197)	mem 38886MB
Train: [88/180][100/625]	eta 0:09:49 lr 0.412863	data 0.0005 (0.2172)	batch 0.9032 (1.1234)	loss 2.9673 (2.8753)	grad_norm 0.5182 (0.5201)	mem 38886MB
Train: [88/180][150/625]	eta 0:08:19 lr 0.412305	data 0.0004 (0.1455)	batch 0.9160 (1.0516)	loss 2.9090 (2.8878)	grad_norm 0.5127 (0.5203)	mem 38886MB
Train: [88/180][200/625]	eta 0:07:11 lr 0.411746	data 0.0005 (0.1094)	batch 0.8445 (1.0158)	loss 3.0145 (2.8960)	grad_norm 0.5286 (0.5204)	mem 38886MB
Train: [88/180][250/625]	eta 0:06:12 lr 0.411188	data 0.0005 (0.0877)	batch 0.9315 (0.9945)	loss 3.0306 (2.8991)	grad_norm 0.4987 (0.5207)	mem 38886MB
Train: [88/180][300/625]	eta 0:05:18 lr 0.410630	data 0.0006 (0.0732)	batch 0.8433 (0.9797)	loss 2.9102 (2.8991)	grad_norm 0.5250 (0.5208)	mem 38886MB
Train: [88/180][350/625]	eta 0:04:26 lr 0.410072	data 0.0006 (0.0629)	batch 0.9083 (0.9702)	loss 2.9040 (2.9006)	grad_norm 0.5231 (0.5215)	mem 38886MB
Train: [88/180][400/625]	eta 0:03:36 lr 0.409513	data 0.0012 (0.0551)	batch 0.8851 (0.9619)	loss 3.0145 (2.8999)	grad_norm 0.5163 (0.5215)	mem 38886MB
Train: [88/180][450/625]	eta 0:02:47 lr 0.408955	data 0.0005 (0.0491)	batch 0.9419 (0.9557)	loss 3.0243 (2.9031)	grad_norm 0.5338 (0.5213)	mem 38886MB
Train: [88/180][500/625]	eta 0:01:58 lr 0.408397	data 0.0005 (0.0442)	batch 0.9221 (0.9507)	loss 2.7728 (2.9023)	grad_norm 0.5264 (0.5213)	mem 38886MB
Train: [88/180][550/625]	eta 0:01:11 lr 0.407838	data 0.0005 (0.0403)	batch 0.8743 (0.9469)	loss 2.7582 (2.9029)	grad_norm 0.5195 (0.5215)	mem 38886MB
Train: [88/180][600/625]	eta 0:00:23 lr 0.407280	data 0.0004 (0.0370)	batch 0.9596 (0.9435)	loss 3.0018 (2.9040)	grad_norm 0.5229 (0.5217)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 88 training takes 0:09:50
Test: [0/25]	Time 14.514 (14.514)	Loss 1.1485 (1.1485)	Acc@1 74.561 (74.561)	Acc@5 91.504 (91.504)	Mem 38886MB
 * Acc@1 63.756 Acc@5 85.268
Accuracy of the network on the 50000 test images: 63.76%
Max accuracy (after decay): 63.76%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [89/180][0/625]	eta 3:58:49 lr 0.407001	data 21.3798 (21.3798)	batch 22.9278 (22.9278)	loss 2.8319 (2.8319)	grad_norm 0.5307 (0.5307)	mem 38886MB
Train: [89/180][50/625]	eta 0:12:53 lr 0.406442	data 0.0006 (0.4198)	batch 0.9080 (1.3450)	loss 2.7522 (2.8776)	grad_norm 0.5182 (0.5232)	mem 38886MB
Train: [89/180][100/625]	eta 0:09:53 lr 0.405884	data 0.0007 (0.2129)	batch 0.8752 (1.1302)	loss 2.9665 (2.8820)	grad_norm 0.5278 (0.5219)	mem 38886MB
Train: [89/180][150/625]	eta 0:08:22 lr 0.405325	data 0.0006 (0.1426)	batch 0.9007 (1.0572)	loss 2.6493 (2.8814)	grad_norm 0.5118 (0.5211)	mem 38886MB
Train: [89/180][200/625]	eta 0:07:13 lr 0.404767	data 0.0005 (0.1073)	batch 0.8901 (1.0201)	loss 2.9682 (2.8894)	grad_norm 0.5405 (0.5220)	mem 38886MB
Train: [89/180][250/625]	eta 0:06:14 lr 0.404209	data 0.0007 (0.0860)	batch 0.9448 (0.9985)	loss 2.9456 (2.8930)	grad_norm 0.5139 (0.5222)	mem 38886MB
Train: [89/180][300/625]	eta 0:05:19 lr 0.403650	data 0.0005 (0.0719)	batch 0.8956 (0.9843)	loss 2.7506 (2.8926)	grad_norm 0.5370 (0.5221)	mem 38886MB
Train: [89/180][350/625]	eta 0:04:27 lr 0.403092	data 0.0004 (0.0617)	batch 0.9026 (0.9735)	loss 2.8422 (2.8905)	grad_norm 0.5379 (0.5228)	mem 38886MB
Train: [89/180][400/625]	eta 0:03:37 lr 0.402533	data 0.0007 (0.0541)	batch 0.8649 (0.9663)	loss 2.8681 (2.8925)	grad_norm 0.5191 (0.5231)	mem 38886MB
Train: [89/180][450/625]	eta 0:02:47 lr 0.401975	data 0.0005 (0.0482)	batch 0.9202 (0.9594)	loss 2.9023 (2.8949)	grad_norm 0.5253 (0.5229)	mem 38886MB
Train: [89/180][500/625]	eta 0:01:59 lr 0.401416	data 0.0008 (0.0434)	batch 0.8942 (0.9537)	loss 2.8194 (2.8950)	grad_norm 0.5054 (0.5229)	mem 38886MB
Train: [89/180][550/625]	eta 0:01:11 lr 0.400858	data 0.0004 (0.0395)	batch 0.9035 (0.9492)	loss 3.2508 (2.8966)	grad_norm 0.5305 (0.5232)	mem 38886MB
Train: [89/180][600/625]	eta 0:00:23 lr 0.400299	data 0.0007 (0.0363)	batch 0.9258 (0.9462)	loss 2.9673 (2.8995)	grad_norm 0.5309 (0.5233)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 89 training takes 0:09:51
Test: [0/25]	Time 15.153 (15.153)	Loss 1.1309 (1.1309)	Acc@1 75.879 (75.879)	Acc@5 92.041 (92.041)	Mem 38886MB
 * Acc@1 63.682 Acc@5 85.130
Accuracy of the network on the 50000 test images: 63.68%
Max accuracy (after decay): 63.76%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [90/180][0/625]	eta 3:56:02 lr 0.400020	data 19.9293 (19.9293)	batch 22.6594 (22.6594)	loss 3.0309 (3.0309)	grad_norm 0.5317 (0.5317)	mem 38886MB
Train: [90/180][50/625]	eta 0:12:49 lr 0.399462	data 0.0004 (0.3916)	batch 0.9123 (1.3384)	loss 3.0295 (2.8683)	grad_norm 0.5614 (0.5239)	mem 38886MB
Train: [90/180][100/625]	eta 0:09:52 lr 0.398903	data 0.0005 (0.1980)	batch 0.9031 (1.1284)	loss 2.8160 (2.8790)	grad_norm 0.5226 (0.5250)	mem 38886MB
Train: [90/180][150/625]	eta 0:08:22 lr 0.398345	data 0.0008 (0.1326)	batch 0.8534 (1.0580)	loss 2.9409 (2.8744)	grad_norm 0.5232 (0.5246)	mem 38886MB
Train: [90/180][200/625]	eta 0:07:13 lr 0.397786	data 0.0006 (0.0997)	batch 0.9075 (1.0205)	loss 2.7224 (2.8767)	grad_norm 0.5124 (0.5245)	mem 38886MB
Train: [90/180][250/625]	eta 0:06:14 lr 0.397228	data 0.0005 (0.0800)	batch 0.9130 (0.9994)	loss 2.7817 (2.8832)	grad_norm 0.5325 (0.5252)	mem 38886MB
Train: [90/180][300/625]	eta 0:05:19 lr 0.396669	data 0.0005 (0.0668)	batch 0.8843 (0.9843)	loss 2.9728 (2.8863)	grad_norm 0.5264 (0.5254)	mem 38886MB
Train: [90/180][350/625]	eta 0:04:27 lr 0.396111	data 0.0005 (0.0573)	batch 0.8740 (0.9730)	loss 2.5698 (2.8882)	grad_norm 0.5108 (0.5261)	mem 38886MB
Train: [90/180][400/625]	eta 0:03:37 lr 0.395552	data 0.0005 (0.0504)	batch 0.8883 (0.9654)	loss 2.7813 (2.8877)	grad_norm 0.5297 (0.5257)	mem 38886MB
Train: [90/180][450/625]	eta 0:02:47 lr 0.394994	data 0.0004 (0.0448)	batch 0.8888 (0.9590)	loss 3.0586 (2.8905)	grad_norm 0.5338 (0.5261)	mem 38886MB
Train: [90/180][500/625]	eta 0:01:59 lr 0.394435	data 0.0005 (0.0404)	batch 0.9275 (0.9546)	loss 3.0376 (2.8920)	grad_norm 0.5240 (0.5260)	mem 38886MB
Train: [90/180][550/625]	eta 0:01:11 lr 0.393877	data 0.0005 (0.0368)	batch 0.9059 (0.9502)	loss 2.8541 (2.8948)	grad_norm 0.5247 (0.5260)	mem 38886MB
Train: [90/180][600/625]	eta 0:00:23 lr 0.393319	data 0.0006 (0.0338)	batch 0.8619 (0.9466)	loss 3.1522 (2.8973)	grad_norm 0.5236 (0.5260)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 90 training takes 0:09:52
Test: [0/25]	Time 14.653 (14.653)	Loss 1.1741 (1.1741)	Acc@1 74.268 (74.268)	Acc@5 91.553 (91.553)	Mem 38886MB
 * Acc@1 63.580 Acc@5 85.188
Accuracy of the network on the 50000 test images: 63.58%
Max accuracy (after decay): 63.76%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [91/180][0/625]	eta 3:58:33 lr 0.393039	data 20.6277 (20.6277)	batch 22.9014 (22.9014)	loss 2.9109 (2.9109)	grad_norm 0.5259 (0.5259)	mem 38886MB
Train: [91/180][50/625]	eta 0:12:49 lr 0.392481	data 0.0005 (0.4050)	batch 0.8713 (1.3385)	loss 2.7720 (2.8693)	grad_norm 0.5121 (0.5254)	mem 38886MB
Train: [91/180][100/625]	eta 0:09:50 lr 0.391923	data 0.0005 (0.2048)	batch 0.9134 (1.1245)	loss 2.9281 (2.8667)	grad_norm 0.5050 (0.5261)	mem 38886MB
Train: [91/180][150/625]	eta 0:08:20 lr 0.391364	data 0.0005 (0.1371)	batch 0.8819 (1.0527)	loss 2.8900 (2.8708)	grad_norm 0.5144 (0.5259)	mem 38886MB
Train: [91/180][200/625]	eta 0:07:11 lr 0.390806	data 0.0005 (0.1032)	batch 0.9041 (1.0164)	loss 2.8669 (2.8745)	grad_norm 0.5271 (0.5257)	mem 38886MB
Train: [91/180][250/625]	eta 0:06:12 lr 0.390248	data 0.0005 (0.0827)	batch 0.8678 (0.9946)	loss 2.8275 (2.8764)	grad_norm 0.5303 (0.5262)	mem 38886MB
Train: [91/180][300/625]	eta 0:05:18 lr 0.389689	data 0.0005 (0.0692)	batch 0.9183 (0.9798)	loss 2.9575 (2.8778)	grad_norm 0.5287 (0.5266)	mem 38886MB
Train: [91/180][350/625]	eta 0:04:26 lr 0.389131	data 0.0005 (0.0594)	batch 0.9150 (0.9690)	loss 2.9713 (2.8816)	grad_norm 0.5352 (0.5266)	mem 38886MB
Train: [91/180][400/625]	eta 0:03:36 lr 0.388573	data 0.0004 (0.0521)	batch 1.0397 (0.9617)	loss 2.6363 (2.8826)	grad_norm 0.5334 (0.5271)	mem 38886MB
Train: [91/180][450/625]	eta 0:02:47 lr 0.388015	data 0.0005 (0.0463)	batch 0.8910 (0.9552)	loss 2.7213 (2.8841)	grad_norm 0.5252 (0.5272)	mem 38886MB
Train: [91/180][500/625]	eta 0:01:58 lr 0.387456	data 0.0006 (0.0418)	batch 0.8674 (0.9502)	loss 2.8970 (2.8842)	grad_norm 0.5323 (0.5273)	mem 38886MB
Train: [91/180][550/625]	eta 0:01:11 lr 0.386898	data 0.0004 (0.0381)	batch 0.9991 (0.9471)	loss 2.8569 (2.8851)	grad_norm 0.5287 (0.5274)	mem 38886MB
Train: [91/180][600/625]	eta 0:00:23 lr 0.386340	data 0.0005 (0.0350)	batch 0.9078 (0.9435)	loss 2.7224 (2.8873)	grad_norm 0.5148 (0.5277)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 91 training takes 0:09:50
Test: [0/25]	Time 14.712 (14.712)	Loss 1.1636 (1.1636)	Acc@1 73.682 (73.682)	Acc@5 91.211 (91.211)	Mem 38886MB
 * Acc@1 63.938 Acc@5 85.356
Accuracy of the network on the 50000 test images: 63.94%
Max accuracy (after decay): 63.94%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [92/180][0/625]	eta 3:56:47 lr 0.386061	data 20.1982 (20.1982)	batch 22.7314 (22.7314)	loss 2.9686 (2.9686)	grad_norm 0.5321 (0.5321)	mem 38886MB
Train: [92/180][50/625]	eta 0:12:48 lr 0.385503	data 0.0005 (0.3966)	batch 0.8803 (1.3370)	loss 3.0741 (2.8807)	grad_norm 0.5325 (0.5263)	mem 38886MB
Train: [92/180][100/625]	eta 0:09:50 lr 0.384945	data 0.0005 (0.2005)	batch 0.8675 (1.1253)	loss 2.8205 (2.8858)	grad_norm 0.5233 (0.5277)	mem 38886MB
Train: [92/180][150/625]	eta 0:08:20 lr 0.384387	data 0.0004 (0.1343)	batch 0.9143 (1.0529)	loss 2.8163 (2.8843)	grad_norm 0.5313 (0.5275)	mem 38886MB
Train: [92/180][200/625]	eta 0:07:11 lr 0.383829	data 0.0005 (0.1010)	batch 0.8871 (1.0151)	loss 2.8614 (2.8786)	grad_norm 0.5147 (0.5287)	mem 38886MB
Train: [92/180][250/625]	eta 0:06:11 lr 0.383271	data 0.0004 (0.0810)	batch 0.9195 (0.9919)	loss 2.8794 (2.8855)	grad_norm 0.5120 (0.5289)	mem 38886MB
Train: [92/180][300/625]	eta 0:05:17 lr 0.382713	data 0.0005 (0.0676)	batch 0.9175 (0.9775)	loss 3.0765 (2.8933)	grad_norm 0.5398 (0.5294)	mem 38886MB
Train: [92/180][350/625]	eta 0:04:26 lr 0.382155	data 0.0005 (0.0581)	batch 0.8988 (0.9675)	loss 2.8906 (2.8922)	grad_norm 0.5306 (0.5295)	mem 38886MB
Train: [92/180][400/625]	eta 0:03:35 lr 0.381597	data 0.0006 (0.0509)	batch 0.9261 (0.9600)	loss 2.8053 (2.8949)	grad_norm 0.5368 (0.5297)	mem 38886MB
Train: [92/180][450/625]	eta 0:02:46 lr 0.381039	data 0.0005 (0.0453)	batch 0.9048 (0.9535)	loss 2.9856 (2.8952)	grad_norm 0.5394 (0.5299)	mem 38886MB
Train: [92/180][500/625]	eta 0:01:58 lr 0.380481	data 0.0005 (0.0408)	batch 0.8828 (0.9485)	loss 2.8093 (2.8942)	grad_norm 0.5583 (0.5302)	mem 38886MB
Train: [92/180][550/625]	eta 0:01:10 lr 0.379923	data 0.0004 (0.0372)	batch 0.9330 (0.9443)	loss 2.7566 (2.8943)	grad_norm 0.5341 (0.5304)	mem 38886MB
Train: [92/180][600/625]	eta 0:00:23 lr 0.379366	data 0.0007 (0.0342)	batch 0.8896 (0.9409)	loss 2.9526 (2.8940)	grad_norm 0.5283 (0.5303)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 92 training takes 0:09:48
Test: [0/25]	Time 15.049 (15.049)	Loss 1.1469 (1.1469)	Acc@1 75.537 (75.537)	Acc@5 91.748 (91.748)	Mem 38886MB
 * Acc@1 64.192 Acc@5 85.408
Accuracy of the network on the 50000 test images: 64.19%
Max accuracy (after decay): 64.19%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [93/180][0/625]	eta 3:55:57 lr 0.379087	data 21.0875 (21.0875)	batch 22.6518 (22.6518)	loss 2.8486 (2.8486)	grad_norm 0.5324 (0.5324)	mem 38886MB
Train: [93/180][50/625]	eta 0:12:52 lr 0.378529	data 0.0007 (0.4142)	batch 0.8861 (1.3431)	loss 2.7387 (2.8524)	grad_norm 0.5163 (0.5281)	mem 38886MB
Train: [93/180][100/625]	eta 0:09:51 lr 0.377971	data 0.0010 (0.2095)	batch 0.8965 (1.1260)	loss 2.9290 (2.8658)	grad_norm 0.5521 (0.5298)	mem 38886MB
Train: [93/180][150/625]	eta 0:08:20 lr 0.377414	data 0.0006 (0.1403)	batch 0.8920 (1.0537)	loss 2.8115 (2.8662)	grad_norm 0.5337 (0.5295)	mem 38886MB
Train: [93/180][200/625]	eta 0:07:11 lr 0.376856	data 0.0005 (0.1055)	batch 0.9362 (1.0163)	loss 2.9550 (2.8780)	grad_norm 0.5364 (0.5302)	mem 38886MB
Train: [93/180][250/625]	eta 0:06:13 lr 0.376299	data 0.0005 (0.0846)	batch 0.8840 (0.9948)	loss 2.6771 (2.8779)	grad_norm 0.5495 (0.5300)	mem 38886MB
Train: [93/180][300/625]	eta 0:05:18 lr 0.375741	data 0.0004 (0.0706)	batch 0.8924 (0.9801)	loss 2.8244 (2.8721)	grad_norm 0.5392 (0.5310)	mem 38886MB
Train: [93/180][350/625]	eta 0:04:26 lr 0.375184	data 0.0005 (0.0607)	batch 0.9012 (0.9689)	loss 2.9149 (2.8735)	grad_norm 0.5243 (0.5314)	mem 38886MB
Train: [93/180][400/625]	eta 0:03:36 lr 0.374626	data 0.0005 (0.0532)	batch 0.9128 (0.9616)	loss 3.0242 (2.8719)	grad_norm 0.5364 (0.5318)	mem 38886MB
Train: [93/180][450/625]	eta 0:02:47 lr 0.374069	data 0.0006 (0.0473)	batch 0.8392 (0.9555)	loss 2.9770 (2.8737)	grad_norm 0.5435 (0.5319)	mem 38886MB
Train: [93/180][500/625]	eta 0:01:58 lr 0.373512	data 0.0007 (0.0427)	batch 0.8983 (0.9511)	loss 3.0225 (2.8766)	grad_norm 0.5203 (0.5323)	mem 38886MB
Train: [93/180][550/625]	eta 0:01:11 lr 0.372955	data 0.0006 (0.0388)	batch 0.8724 (0.9473)	loss 3.0632 (2.8799)	grad_norm 0.5319 (0.5325)	mem 38886MB
Train: [93/180][600/625]	eta 0:00:23 lr 0.372397	data 0.0005 (0.0356)	batch 0.8865 (0.9440)	loss 2.7956 (2.8807)	grad_norm 0.5441 (0.5323)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 93 training takes 0:09:50
Test: [0/25]	Time 14.928 (14.928)	Loss 1.1440 (1.1440)	Acc@1 74.414 (74.414)	Acc@5 92.188 (92.188)	Mem 38886MB
 * Acc@1 63.738 Acc@5 85.508
Accuracy of the network on the 50000 test images: 63.74%
Max accuracy (after decay): 64.19%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [94/180][0/625]	eta 3:58:17 lr 0.372119	data 21.1724 (21.1724)	batch 22.8763 (22.8763)	loss 3.0435 (3.0435)	grad_norm 0.5348 (0.5348)	mem 38886MB
Train: [94/180][50/625]	eta 0:12:48 lr 0.371562	data 0.0006 (0.4157)	batch 0.8791 (1.3358)	loss 2.7151 (2.8355)	grad_norm 0.5318 (0.5336)	mem 38886MB
Train: [94/180][100/625]	eta 0:09:49 lr 0.371005	data 0.0005 (0.2102)	batch 0.9700 (1.1219)	loss 2.8255 (2.8476)	grad_norm 0.5156 (0.5324)	mem 38886MB
Train: [94/180][150/625]	eta 0:08:19 lr 0.370448	data 0.0004 (0.1408)	batch 0.8985 (1.0508)	loss 2.9334 (2.8585)	grad_norm 0.5350 (0.5333)	mem 38886MB
Train: [94/180][200/625]	eta 0:07:10 lr 0.369891	data 0.0005 (0.1059)	batch 0.9029 (1.0131)	loss 2.8428 (2.8598)	grad_norm 0.5474 (0.5342)	mem 38886MB
Train: [94/180][250/625]	eta 0:06:11 lr 0.369334	data 0.0006 (0.0849)	batch 0.9251 (0.9900)	loss 2.9197 (2.8599)	grad_norm 0.5419 (0.5345)	mem 38886MB
Train: [94/180][300/625]	eta 0:05:17 lr 0.368777	data 0.0005 (0.0709)	batch 0.9191 (0.9760)	loss 2.9699 (2.8651)	grad_norm 0.5500 (0.5345)	mem 38886MB
Train: [94/180][350/625]	eta 0:04:25 lr 0.368220	data 0.0007 (0.0609)	batch 0.9641 (0.9666)	loss 2.8126 (2.8661)	grad_norm 0.5265 (0.5342)	mem 38886MB
Train: [94/180][400/625]	eta 0:03:35 lr 0.367664	data 0.0005 (0.0534)	batch 0.8697 (0.9587)	loss 2.8361 (2.8670)	grad_norm 0.5219 (0.5344)	mem 38886MB
Train: [94/180][450/625]	eta 0:02:46 lr 0.367107	data 0.0011 (0.0476)	batch 0.8620 (0.9526)	loss 2.8252 (2.8681)	grad_norm 0.5277 (0.5345)	mem 38886MB
Train: [94/180][500/625]	eta 0:01:58 lr 0.366551	data 0.0004 (0.0429)	batch 0.9136 (0.9475)	loss 2.7375 (2.8733)	grad_norm 0.5445 (0.5348)	mem 38886MB
Train: [94/180][550/625]	eta 0:01:10 lr 0.365994	data 0.0006 (0.0390)	batch 0.8693 (0.9435)	loss 3.1027 (2.8752)	grad_norm 0.5328 (0.5349)	mem 38886MB
Train: [94/180][600/625]	eta 0:00:23 lr 0.365438	data 0.0005 (0.0358)	batch 0.8999 (0.9401)	loss 3.0793 (2.8774)	grad_norm 0.5240 (0.5351)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 94 training takes 0:09:48
Test: [0/25]	Time 14.431 (14.431)	Loss 1.1784 (1.1784)	Acc@1 74.072 (74.072)	Acc@5 91.357 (91.357)	Mem 38886MB
 * Acc@1 63.924 Acc@5 85.420
Accuracy of the network on the 50000 test images: 63.92%
Max accuracy (after decay): 64.19%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [95/180][0/625]	eta 3:55:18 lr 0.365159	data 21.3078 (21.3078)	batch 22.5902 (22.5902)	loss 2.6567 (2.6567)	grad_norm 0.5154 (0.5154)	mem 38886MB
Train: [95/180][50/625]	eta 0:12:49 lr 0.364603	data 0.0004 (0.4185)	batch 0.8967 (1.3380)	loss 2.8715 (2.8633)	grad_norm 0.5260 (0.5332)	mem 38886MB
Train: [95/180][100/625]	eta 0:09:50 lr 0.364047	data 0.0004 (0.2116)	batch 0.8885 (1.1238)	loss 2.8620 (2.8661)	grad_norm 0.5260 (0.5346)	mem 38886MB
Train: [95/180][150/625]	eta 0:08:20 lr 0.363491	data 0.0006 (0.1417)	batch 0.8484 (1.0535)	loss 2.7948 (2.8651)	grad_norm 0.5315 (0.5337)	mem 38886MB
Train: [95/180][200/625]	eta 0:07:12 lr 0.362935	data 0.0006 (0.1066)	batch 0.8892 (1.0173)	loss 3.0509 (2.8633)	grad_norm 0.5311 (0.5345)	mem 38886MB
Train: [95/180][250/625]	eta 0:06:13 lr 0.362379	data 0.0005 (0.0855)	batch 0.9021 (0.9947)	loss 2.9775 (2.8739)	grad_norm 0.5454 (0.5355)	mem 38886MB
Train: [95/180][300/625]	eta 0:05:18 lr 0.361823	data 0.0006 (0.0714)	batch 0.8953 (0.9801)	loss 2.7190 (2.8716)	grad_norm 0.5608 (0.5357)	mem 38886MB
Train: [95/180][350/625]	eta 0:04:26 lr 0.361267	data 0.0008 (0.0613)	batch 0.8912 (0.9692)	loss 2.8841 (2.8713)	grad_norm 0.5241 (0.5359)	mem 38886MB
Train: [95/180][400/625]	eta 0:03:36 lr 0.360711	data 0.0005 (0.0537)	batch 0.8633 (0.9617)	loss 2.8600 (2.8761)	grad_norm 0.5266 (0.5362)	mem 38886MB
Train: [95/180][450/625]	eta 0:02:47 lr 0.360155	data 0.0006 (0.0478)	batch 0.9254 (0.9562)	loss 3.0096 (2.8760)	grad_norm 0.5613 (0.5362)	mem 38886MB
Train: [95/180][500/625]	eta 0:01:58 lr 0.359600	data 0.0006 (0.0431)	batch 0.9507 (0.9515)	loss 2.7682 (2.8764)	grad_norm 0.5372 (0.5362)	mem 38886MB
Train: [95/180][550/625]	eta 0:01:11 lr 0.359044	data 0.0005 (0.0392)	batch 0.8782 (0.9473)	loss 2.8538 (2.8797)	grad_norm 0.5366 (0.5363)	mem 38886MB
Train: [95/180][600/625]	eta 0:00:23 lr 0.358488	data 0.0006 (0.0360)	batch 0.8631 (0.9435)	loss 2.8317 (2.8794)	grad_norm 0.5290 (0.5364)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 95 training takes 0:09:50
Test: [0/25]	Time 14.518 (14.518)	Loss 1.1004 (1.1004)	Acc@1 74.756 (74.756)	Acc@5 92.725 (92.725)	Mem 38886MB
 * Acc@1 64.290 Acc@5 85.772
Accuracy of the network on the 50000 test images: 64.29%
Max accuracy (after decay): 64.29%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [96/180][0/625]	eta 4:05:03 lr 0.358211	data 20.4473 (20.4473)	batch 23.5257 (23.5257)	loss 2.9907 (2.9907)	grad_norm 0.5300 (0.5300)	mem 38886MB
Train: [96/180][50/625]	eta 0:12:56 lr 0.357655	data 0.0005 (0.4024)	batch 0.9434 (1.3505)	loss 2.8140 (2.8531)	grad_norm 0.5451 (0.5367)	mem 38886MB
Train: [96/180][100/625]	eta 0:09:53 lr 0.357100	data 0.0005 (0.2035)	batch 0.9263 (1.1305)	loss 2.8650 (2.8526)	grad_norm 0.5478 (0.5374)	mem 38886MB
Train: [96/180][150/625]	eta 0:08:22 lr 0.356545	data 0.0005 (0.1363)	batch 0.9003 (1.0576)	loss 2.8405 (2.8635)	grad_norm 0.5446 (0.5384)	mem 38886MB
Train: [96/180][200/625]	eta 0:07:13 lr 0.355990	data 0.0007 (0.1025)	batch 0.8958 (1.0199)	loss 2.9556 (2.8627)	grad_norm 0.5382 (0.5384)	mem 38886MB
Train: [96/180][250/625]	eta 0:06:13 lr 0.355435	data 0.0005 (0.0822)	batch 0.8653 (0.9967)	loss 2.7528 (2.8702)	grad_norm 0.5288 (0.5382)	mem 38886MB
Train: [96/180][300/625]	eta 0:05:19 lr 0.354880	data 0.0005 (0.0686)	batch 0.9072 (0.9822)	loss 2.9230 (2.8694)	grad_norm 0.5489 (0.5380)	mem 38886MB
Train: [96/180][350/625]	eta 0:04:26 lr 0.354325	data 0.0004 (0.0589)	batch 0.9026 (0.9706)	loss 2.9047 (2.8693)	grad_norm 0.5519 (0.5382)	mem 38886MB
Train: [96/180][400/625]	eta 0:03:36 lr 0.353770	data 0.0004 (0.0516)	batch 0.8907 (0.9639)	loss 2.8471 (2.8681)	grad_norm 0.5311 (0.5384)	mem 38886MB
Train: [96/180][450/625]	eta 0:02:47 lr 0.353215	data 0.0005 (0.0460)	batch 0.8657 (0.9567)	loss 2.9560 (2.8689)	grad_norm 0.5497 (0.5384)	mem 38886MB
Train: [96/180][500/625]	eta 0:01:58 lr 0.352661	data 0.0023 (0.0414)	batch 0.8936 (0.9515)	loss 2.9795 (2.8676)	grad_norm 0.5335 (0.5385)	mem 38886MB
Train: [96/180][550/625]	eta 0:01:11 lr 0.352106	data 0.0005 (0.0377)	batch 0.9570 (0.9470)	loss 2.9136 (2.8704)	grad_norm 0.5437 (0.5386)	mem 38886MB
Train: [96/180][600/625]	eta 0:00:23 lr 0.351552	data 0.0004 (0.0346)	batch 0.9279 (0.9435)	loss 2.7424 (2.8730)	grad_norm 0.5380 (0.5388)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 96 training takes 0:09:50
Test: [0/25]	Time 14.921 (14.921)	Loss 1.1045 (1.1045)	Acc@1 75.977 (75.977)	Acc@5 91.992 (91.992)	Mem 38886MB
 * Acc@1 64.274 Acc@5 85.648
Accuracy of the network on the 50000 test images: 64.27%
Max accuracy (after decay): 64.29%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [97/180][0/625]	eta 4:00:57 lr 0.351275	data 20.7738 (20.7738)	batch 23.1320 (23.1320)	loss 2.7291 (2.7291)	grad_norm 0.5260 (0.5260)	mem 38886MB
Train: [97/180][50/625]	eta 0:12:51 lr 0.350720	data 0.0006 (0.4081)	batch 0.8575 (1.3413)	loss 2.8231 (2.8546)	grad_norm 0.5455 (0.5372)	mem 38886MB
Train: [97/180][100/625]	eta 0:09:51 lr 0.350166	data 0.0005 (0.2064)	batch 0.8811 (1.1270)	loss 2.8885 (2.8478)	grad_norm 0.5385 (0.5384)	mem 38886MB
Train: [97/180][150/625]	eta 0:08:20 lr 0.349612	data 0.0006 (0.1382)	batch 0.8603 (1.0540)	loss 2.7500 (2.8566)	grad_norm 0.5358 (0.5390)	mem 38886MB
Train: [97/180][200/625]	eta 0:07:12 lr 0.349058	data 0.0006 (0.1040)	batch 0.8758 (1.0166)	loss 2.9008 (2.8625)	grad_norm 0.5418 (0.5400)	mem 38886MB
Train: [97/180][250/625]	eta 0:06:12 lr 0.348504	data 0.0005 (0.0834)	batch 0.8913 (0.9944)	loss 2.9376 (2.8624)	grad_norm 0.5438 (0.5400)	mem 38886MB
Train: [97/180][300/625]	eta 0:05:18 lr 0.347951	data 0.0004 (0.0696)	batch 0.8957 (0.9787)	loss 2.7640 (2.8614)	grad_norm 0.5386 (0.5400)	mem 38886MB
Train: [97/180][350/625]	eta 0:04:26 lr 0.347397	data 0.0005 (0.0598)	batch 0.8872 (0.9681)	loss 3.0362 (2.8642)	grad_norm 0.5494 (0.5405)	mem 38886MB
Train: [97/180][400/625]	eta 0:03:36 lr 0.346843	data 0.0005 (0.0524)	batch 0.8762 (0.9605)	loss 2.9703 (2.8645)	grad_norm 0.5344 (0.5406)	mem 38886MB
Train: [97/180][450/625]	eta 0:02:47 lr 0.346290	data 0.0006 (0.0466)	batch 0.8587 (0.9545)	loss 2.9207 (2.8641)	grad_norm 0.5384 (0.5406)	mem 38886MB
Train: [97/180][500/625]	eta 0:01:58 lr 0.345736	data 0.0005 (0.0420)	batch 0.9194 (0.9502)	loss 3.0728 (2.8682)	grad_norm 0.5434 (0.5408)	mem 38886MB
Train: [97/180][550/625]	eta 0:01:10 lr 0.345183	data 0.0006 (0.0383)	batch 0.9207 (0.9458)	loss 2.6602 (2.8671)	grad_norm 0.5348 (0.5409)	mem 38886MB
Train: [97/180][600/625]	eta 0:00:23 lr 0.344630	data 0.0005 (0.0351)	batch 0.9054 (0.9424)	loss 2.7173 (2.8690)	grad_norm 0.5393 (0.5410)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 97 training takes 0:09:49
Test: [0/25]	Time 15.104 (15.104)	Loss 1.1375 (1.1375)	Acc@1 74.414 (74.414)	Acc@5 91.699 (91.699)	Mem 38886MB
 * Acc@1 64.052 Acc@5 85.696
Accuracy of the network on the 50000 test images: 64.05%
Max accuracy (after decay): 64.29%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [98/180][0/625]	eta 4:01:45 lr 0.344354	data 21.5201 (21.5201)	batch 23.2087 (23.2087)	loss 2.5631 (2.5631)	grad_norm 0.5310 (0.5310)	mem 38886MB
Train: [98/180][50/625]	eta 0:12:58 lr 0.343801	data 0.0004 (0.4227)	batch 0.8923 (1.3534)	loss 2.9118 (2.8669)	grad_norm 0.5529 (0.5422)	mem 38886MB
Train: [98/180][100/625]	eta 0:09:54 lr 0.343248	data 0.0007 (0.2138)	batch 0.8710 (1.1323)	loss 2.7139 (2.8587)	grad_norm 0.5489 (0.5412)	mem 38886MB
Train: [98/180][150/625]	eta 0:08:23 lr 0.342695	data 0.0005 (0.1432)	batch 0.9446 (1.0596)	loss 2.9873 (2.8587)	grad_norm 0.5517 (0.5423)	mem 38886MB
Train: [98/180][200/625]	eta 0:07:14 lr 0.342142	data 0.0006 (0.1077)	batch 0.9071 (1.0217)	loss 2.9245 (2.8589)	grad_norm 0.5561 (0.5418)	mem 38886MB
Train: [98/180][250/625]	eta 0:06:14 lr 0.341590	data 0.0004 (0.0863)	batch 0.8998 (0.9996)	loss 2.8875 (2.8603)	grad_norm 0.5299 (0.5422)	mem 38886MB
Train: [98/180][300/625]	eta 0:05:20 lr 0.341037	data 0.0006 (0.0721)	batch 0.9194 (0.9853)	loss 2.6517 (2.8603)	grad_norm 0.5405 (0.5426)	mem 38886MB
Train: [98/180][350/625]	eta 0:04:27 lr 0.340485	data 0.0012 (0.0619)	batch 0.9019 (0.9745)	loss 2.7887 (2.8562)	grad_norm 0.5491 (0.5430)	mem 38886MB
Train: [98/180][400/625]	eta 0:03:37 lr 0.339933	data 0.0005 (0.0543)	batch 0.9443 (0.9670)	loss 2.8066 (2.8535)	grad_norm 0.5360 (0.5430)	mem 38886MB
Train: [98/180][450/625]	eta 0:02:47 lr 0.339381	data 0.0005 (0.0483)	batch 0.9561 (0.9599)	loss 2.9269 (2.8553)	grad_norm 0.5426 (0.5431)	mem 38886MB
Train: [98/180][500/625]	eta 0:01:59 lr 0.338829	data 0.0008 (0.0435)	batch 0.8790 (0.9548)	loss 2.8412 (2.8588)	grad_norm 0.5829 (0.5432)	mem 38886MB
Train: [98/180][550/625]	eta 0:01:11 lr 0.338277	data 0.0005 (0.0396)	batch 0.9060 (0.9508)	loss 3.0190 (2.8586)	grad_norm 0.5481 (0.5434)	mem 38886MB
Train: [98/180][600/625]	eta 0:00:23 lr 0.337725	data 0.0006 (0.0364)	batch 0.8932 (0.9471)	loss 2.8601 (2.8613)	grad_norm 0.5418 (0.5436)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 98 training takes 0:09:52
Test: [0/25]	Time 14.875 (14.875)	Loss 1.1452 (1.1452)	Acc@1 75.439 (75.439)	Acc@5 91.797 (91.797)	Mem 38886MB
 * Acc@1 64.004 Acc@5 85.662
Accuracy of the network on the 50000 test images: 64.00%
Max accuracy (after decay): 64.29%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [99/180][0/625]	eta 4:03:21 lr 0.337449	data 22.3739 (22.3739)	batch 23.3618 (23.3618)	loss 2.6843 (2.6843)	grad_norm 0.5512 (0.5512)	mem 38886MB
Train: [99/180][50/625]	eta 0:12:53 lr 0.336898	data 0.0006 (0.4393)	batch 0.8937 (1.3456)	loss 2.8268 (2.8234)	grad_norm 0.5366 (0.5448)	mem 38886MB
Train: [99/180][100/625]	eta 0:09:52 lr 0.336346	data 0.0006 (0.2221)	batch 1.1777 (1.1289)	loss 2.9472 (2.8367)	grad_norm 0.5779 (0.5455)	mem 38886MB
Train: [99/180][150/625]	eta 0:08:21 lr 0.335795	data 0.0006 (0.1487)	batch 0.9383 (1.0561)	loss 2.8311 (2.8422)	grad_norm 0.5536 (0.5464)	mem 38886MB
Train: [99/180][200/625]	eta 0:07:12 lr 0.335244	data 0.0006 (0.1119)	batch 0.8829 (1.0188)	loss 2.7317 (2.8443)	grad_norm 0.5679 (0.5467)	mem 38886MB
Train: [99/180][250/625]	eta 0:06:13 lr 0.334693	data 0.0007 (0.0897)	batch 0.8956 (0.9970)	loss 2.7819 (2.8471)	grad_norm 0.5498 (0.5469)	mem 38886MB
Train: [99/180][300/625]	eta 0:05:19 lr 0.334142	data 0.0004 (0.0749)	batch 0.9232 (0.9826)	loss 2.7232 (2.8507)	grad_norm 0.5433 (0.5474)	mem 38886MB
Train: [99/180][350/625]	eta 0:04:27 lr 0.333591	data 0.0007 (0.0643)	batch 0.8870 (0.9721)	loss 2.9860 (2.8544)	grad_norm 0.5388 (0.5472)	mem 38886MB
Train: [99/180][400/625]	eta 0:03:37 lr 0.333041	data 0.0005 (0.0564)	batch 0.9325 (0.9647)	loss 2.7657 (2.8552)	grad_norm 0.5424 (0.5471)	mem 38886MB
Train: [99/180][450/625]	eta 0:02:47 lr 0.332490	data 0.0006 (0.0502)	batch 0.8931 (0.9585)	loss 2.8923 (2.8545)	grad_norm 0.5491 (0.5472)	mem 38886MB
Train: [99/180][500/625]	eta 0:01:59 lr 0.331940	data 0.0004 (0.0453)	batch 0.9106 (0.9531)	loss 2.8284 (2.8564)	grad_norm 0.5437 (0.5474)	mem 38886MB
Train: [99/180][550/625]	eta 0:01:11 lr 0.331389	data 0.0006 (0.0413)	batch 0.8714 (0.9497)	loss 2.8953 (2.8575)	grad_norm 0.5420 (0.5474)	mem 38886MB
Train: [99/180][600/625]	eta 0:00:23 lr 0.330839	data 0.0005 (0.0379)	batch 0.9283 (0.9460)	loss 2.8526 (2.8585)	grad_norm 0.5587 (0.5476)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 99 training takes 0:09:51
Test: [0/25]	Time 14.847 (14.847)	Loss 1.0878 (1.0878)	Acc@1 76.562 (76.562)	Acc@5 92.236 (92.236)	Mem 38886MB
 * Acc@1 64.412 Acc@5 85.496
Accuracy of the network on the 50000 test images: 64.41%
Max accuracy (after decay): 64.41%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [100/180][0/625]	eta 3:56:38 lr 0.330564	data 20.8489 (20.8489)	batch 22.7171 (22.7171)	loss 2.7071 (2.7071)	grad_norm 0.5295 (0.5295)	mem 38886MB
Train: [100/180][50/625]	eta 0:12:49 lr 0.330014	data 0.0003 (0.4094)	batch 0.8840 (1.3374)	loss 2.8138 (2.8239)	grad_norm 0.5489 (0.5484)	mem 38886MB
Train: [100/180][100/625]	eta 0:09:51 lr 0.329464	data 0.0005 (0.2070)	batch 0.9248 (1.1259)	loss 2.8381 (2.8398)	grad_norm 0.5461 (0.5497)	mem 38886MB
Train: [100/180][150/625]	eta 0:08:21 lr 0.328915	data 0.0006 (0.1386)	batch 0.9072 (1.0559)	loss 2.6659 (2.8437)	grad_norm 0.5358 (0.5499)	mem 38886MB
Train: [100/180][200/625]	eta 0:07:13 lr 0.328365	data 0.0007 (0.1043)	batch 0.9085 (1.0197)	loss 2.8141 (2.8378)	grad_norm 0.5562 (0.5499)	mem 38886MB
Train: [100/180][250/625]	eta 0:06:13 lr 0.327816	data 0.0005 (0.0836)	batch 0.9048 (0.9961)	loss 2.7427 (2.8415)	grad_norm 0.5586 (0.5498)	mem 38886MB
Train: [100/180][300/625]	eta 0:05:18 lr 0.327267	data 0.0006 (0.0698)	batch 0.8831 (0.9807)	loss 2.8121 (2.8412)	grad_norm 0.5377 (0.5489)	mem 38886MB
Train: [100/180][350/625]	eta 0:04:26 lr 0.326718	data 0.0006 (0.0599)	batch 0.9420 (0.9699)	loss 2.7396 (2.8437)	grad_norm 0.5470 (0.5490)	mem 38886MB
Train: [100/180][400/625]	eta 0:03:36 lr 0.326169	data 0.0005 (0.0525)	batch 0.8967 (0.9626)	loss 2.8535 (2.8463)	grad_norm 0.5506 (0.5491)	mem 38886MB
Train: [100/180][450/625]	eta 0:02:47 lr 0.325620	data 0.0006 (0.0468)	batch 0.8808 (0.9567)	loss 2.8451 (2.8520)	grad_norm 0.5408 (0.5493)	mem 38886MB
Train: [100/180][500/625]	eta 0:01:58 lr 0.325071	data 0.0005 (0.0422)	batch 0.8935 (0.9513)	loss 2.8136 (2.8527)	grad_norm 0.5494 (0.5493)	mem 38886MB
Train: [100/180][550/625]	eta 0:01:11 lr 0.324523	data 0.0006 (0.0384)	batch 0.8691 (0.9476)	loss 2.8843 (2.8561)	grad_norm 0.5394 (0.5496)	mem 38886MB
Train: [100/180][600/625]	eta 0:00:23 lr 0.323974	data 0.0006 (0.0352)	batch 0.9369 (0.9444)	loss 2.6620 (2.8551)	grad_norm 0.5429 (0.5497)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 100 training takes 0:09:50
Test: [0/25]	Time 14.711 (14.711)	Loss 1.0882 (1.0882)	Acc@1 76.074 (76.074)	Acc@5 91.699 (91.699)	Mem 38886MB
 * Acc@1 64.554 Acc@5 85.864
Accuracy of the network on the 50000 test images: 64.55%
Max accuracy (after decay): 64.55%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [101/180][0/625]	eta 4:01:02 lr 0.323700	data 22.2494 (22.2494)	batch 23.1395 (23.1395)	loss 2.7889 (2.7889)	grad_norm 0.5494 (0.5494)	mem 38886MB
Train: [101/180][50/625]	eta 0:12:56 lr 0.323152	data 0.0008 (0.4370)	batch 0.8652 (1.3512)	loss 2.9660 (2.8333)	grad_norm 0.5471 (0.5462)	mem 38886MB
Train: [101/180][100/625]	eta 0:09:51 lr 0.322604	data 0.0007 (0.2210)	batch 0.8433 (1.1274)	loss 2.8418 (2.8337)	grad_norm 0.5706 (0.5493)	mem 38886MB
Train: [101/180][150/625]	eta 0:08:19 lr 0.322056	data 0.0005 (0.1480)	batch 0.8722 (1.0520)	loss 2.6226 (2.8322)	grad_norm 0.5384 (0.5493)	mem 38886MB
Train: [101/180][200/625]	eta 0:07:11 lr 0.321509	data 0.0005 (0.1113)	batch 0.9318 (1.0160)	loss 2.8428 (2.8278)	grad_norm 0.5440 (0.5486)	mem 38886MB
Train: [101/180][250/625]	eta 0:06:12 lr 0.320961	data 0.0006 (0.0892)	batch 0.8800 (0.9926)	loss 2.8630 (2.8292)	grad_norm 0.5480 (0.5488)	mem 38886MB
Train: [101/180][300/625]	eta 0:05:18 lr 0.320414	data 0.0004 (0.0745)	batch 0.8961 (0.9795)	loss 2.8242 (2.8331)	grad_norm 0.5506 (0.5493)	mem 38886MB
Train: [101/180][350/625]	eta 0:04:26 lr 0.319866	data 0.0006 (0.0639)	batch 0.8966 (0.9693)	loss 2.7690 (2.8360)	grad_norm 0.5484 (0.5495)	mem 38886MB
Train: [101/180][400/625]	eta 0:03:36 lr 0.319319	data 0.0005 (0.0560)	batch 0.8756 (0.9619)	loss 2.8373 (2.8418)	grad_norm 0.5525 (0.5498)	mem 38886MB
Train: [101/180][450/625]	eta 0:02:47 lr 0.318772	data 0.0005 (0.0500)	batch 0.9419 (0.9551)	loss 2.8135 (2.8428)	grad_norm 0.5402 (0.5502)	mem 38886MB
Train: [101/180][500/625]	eta 0:01:58 lr 0.318226	data 0.0005 (0.0450)	batch 0.9404 (0.9497)	loss 2.7349 (2.8464)	grad_norm 0.5648 (0.5507)	mem 38886MB
Train: [101/180][550/625]	eta 0:01:10 lr 0.317679	data 0.0005 (0.0410)	batch 0.8990 (0.9457)	loss 2.7178 (2.8452)	grad_norm 0.5501 (0.5507)	mem 38886MB
Train: [101/180][600/625]	eta 0:00:23 lr 0.317133	data 0.0007 (0.0376)	batch 0.8690 (0.9420)	loss 2.8396 (2.8449)	grad_norm 0.5622 (0.5507)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 101 training takes 0:09:49
Test: [0/25]	Time 15.401 (15.401)	Loss 1.0939 (1.0939)	Acc@1 75.488 (75.488)	Acc@5 91.602 (91.602)	Mem 38886MB
 * Acc@1 64.572 Acc@5 85.934
Accuracy of the network on the 50000 test images: 64.57%
Max accuracy (after decay): 64.57%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [102/180][0/625]	eta 3:57:53 lr 0.316859	data 21.3372 (21.3372)	batch 22.8374 (22.8374)	loss 2.7550 (2.7550)	grad_norm 0.5544 (0.5544)	mem 38886MB
Train: [102/180][50/625]	eta 0:12:53 lr 0.316313	data 0.0005 (0.4189)	batch 0.8902 (1.3453)	loss 2.9110 (2.8125)	grad_norm 0.5456 (0.5480)	mem 38886MB
Train: [102/180][100/625]	eta 0:09:52 lr 0.315767	data 0.0005 (0.2118)	batch 0.9167 (1.1285)	loss 3.0880 (2.8205)	grad_norm 0.5661 (0.5496)	mem 38886MB
Train: [102/180][150/625]	eta 0:08:21 lr 0.315221	data 0.0005 (0.1418)	batch 0.9303 (1.0550)	loss 2.7065 (2.8248)	grad_norm 0.5361 (0.5502)	mem 38886MB
Train: [102/180][200/625]	eta 0:07:13 lr 0.314676	data 0.0004 (0.1067)	batch 0.8863 (1.0198)	loss 3.0364 (2.8325)	grad_norm 0.5613 (0.5507)	mem 38886MB
Train: [102/180][250/625]	eta 0:06:13 lr 0.314130	data 0.0005 (0.0855)	batch 0.8918 (0.9966)	loss 3.0822 (2.8387)	grad_norm 0.5569 (0.5516)	mem 38886MB
Train: [102/180][300/625]	eta 0:05:19 lr 0.313585	data 0.0004 (0.0714)	batch 0.9466 (0.9837)	loss 2.9164 (2.8406)	grad_norm 0.5507 (0.5520)	mem 38886MB
Train: [102/180][350/625]	eta 0:04:27 lr 0.313040	data 0.0005 (0.0613)	batch 0.8720 (0.9723)	loss 2.7617 (2.8419)	grad_norm 0.5624 (0.5523)	mem 38886MB
Train: [102/180][400/625]	eta 0:03:36 lr 0.312495	data 0.0005 (0.0537)	batch 0.8875 (0.9635)	loss 2.6253 (2.8450)	grad_norm 0.5369 (0.5529)	mem 38886MB
Train: [102/180][450/625]	eta 0:02:47 lr 0.311950	data 0.0005 (0.0478)	batch 0.9425 (0.9576)	loss 2.9499 (2.8474)	grad_norm 0.5577 (0.5531)	mem 38886MB
Train: [102/180][500/625]	eta 0:01:59 lr 0.311405	data 0.0005 (0.0431)	batch 0.9091 (0.9523)	loss 3.0592 (2.8471)	grad_norm 0.5517 (0.5531)	mem 38886MB
Train: [102/180][550/625]	eta 0:01:11 lr 0.310861	data 0.0004 (0.0392)	batch 1.0697 (0.9489)	loss 3.0707 (2.8481)	grad_norm 0.5604 (0.5531)	mem 38886MB
Train: [102/180][600/625]	eta 0:00:23 lr 0.310316	data 0.0004 (0.0360)	batch 0.8746 (0.9453)	loss 2.8194 (2.8456)	grad_norm 0.5597 (0.5531)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 102 training takes 0:09:51
Test: [0/25]	Time 14.712 (14.712)	Loss 1.0688 (1.0688)	Acc@1 76.465 (76.465)	Acc@5 92.236 (92.236)	Mem 38886MB
 * Acc@1 64.724 Acc@5 86.148
Accuracy of the network on the 50000 test images: 64.72%
Max accuracy (after decay): 64.72%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [103/180][0/625]	eta 4:03:14 lr 0.310044	data 21.8071 (21.8071)	batch 23.3517 (23.3517)	loss 2.8099 (2.8099)	grad_norm 0.5498 (0.5498)	mem 38886MB
Train: [103/180][50/625]	eta 0:12:57 lr 0.309500	data 0.0005 (0.4282)	batch 0.9103 (1.3525)	loss 2.7057 (2.8103)	grad_norm 0.5601 (0.5503)	mem 38886MB
Train: [103/180][100/625]	eta 0:09:54 lr 0.308956	data 0.0004 (0.2165)	batch 0.9137 (1.1318)	loss 2.9156 (2.8156)	grad_norm 0.5481 (0.5514)	mem 38886MB
Train: [103/180][150/625]	eta 0:08:22 lr 0.308412	data 0.0006 (0.1450)	batch 0.9009 (1.0571)	loss 2.9072 (2.8257)	grad_norm 0.5630 (0.5539)	mem 38886MB
Train: [103/180][200/625]	eta 0:07:14 lr 0.307869	data 0.0005 (0.1090)	batch 0.9705 (1.0216)	loss 2.8998 (2.8338)	grad_norm 0.5521 (0.5547)	mem 38886MB
Train: [103/180][250/625]	eta 0:06:14 lr 0.307325	data 0.0005 (0.0874)	batch 0.8955 (0.9985)	loss 2.7926 (2.8358)	grad_norm 0.5527 (0.5546)	mem 38886MB
Train: [103/180][300/625]	eta 0:05:19 lr 0.306782	data 0.0005 (0.0730)	batch 0.8766 (0.9825)	loss 2.8958 (2.8413)	grad_norm 0.5310 (0.5553)	mem 38886MB
Train: [103/180][350/625]	eta 0:04:27 lr 0.306239	data 0.0005 (0.0627)	batch 0.8787 (0.9713)	loss 2.7025 (2.8410)	grad_norm 0.5625 (0.5553)	mem 38886MB
Train: [103/180][400/625]	eta 0:03:36 lr 0.305696	data 0.0004 (0.0549)	batch 0.8940 (0.9634)	loss 3.0039 (2.8404)	grad_norm 0.5480 (0.5559)	mem 38886MB
Train: [103/180][450/625]	eta 0:02:47 lr 0.305154	data 0.0005 (0.0489)	batch 0.9369 (0.9579)	loss 2.7138 (2.8394)	grad_norm 0.5499 (0.5565)	mem 38886MB
Train: [103/180][500/625]	eta 0:01:59 lr 0.304611	data 0.0006 (0.0441)	batch 0.8897 (0.9525)	loss 2.8049 (2.8400)	grad_norm 0.5603 (0.5566)	mem 38886MB
Train: [103/180][550/625]	eta 0:01:11 lr 0.304069	data 0.0005 (0.0401)	batch 0.9190 (0.9485)	loss 2.7871 (2.8397)	grad_norm 0.5550 (0.5566)	mem 38886MB
Train: [103/180][600/625]	eta 0:00:23 lr 0.303527	data 0.0006 (0.0368)	batch 0.9301 (0.9454)	loss 2.7082 (2.8384)	grad_norm 0.5685 (0.5568)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 103 training takes 0:09:51
Test: [0/25]	Time 14.787 (14.787)	Loss 1.1048 (1.1048)	Acc@1 75.537 (75.537)	Acc@5 91.943 (91.943)	Mem 38886MB
 * Acc@1 64.456 Acc@5 85.824
Accuracy of the network on the 50000 test images: 64.46%
Max accuracy (after decay): 64.72%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [104/180][0/625]	eta 3:55:31 lr 0.303256	data 20.9355 (20.9355)	batch 22.6107 (22.6107)	loss 3.1608 (3.1608)	grad_norm 0.5707 (0.5707)	mem 38886MB
Train: [104/180][50/625]	eta 0:12:50 lr 0.302714	data 0.0006 (0.4118)	batch 0.8890 (1.3406)	loss 2.7854 (2.8315)	grad_norm 0.5441 (0.5561)	mem 38886MB
Train: [104/180][100/625]	eta 0:09:53 lr 0.302173	data 0.0005 (0.2088)	batch 0.9258 (1.1297)	loss 3.0906 (2.8279)	grad_norm 0.5595 (0.5570)	mem 38886MB
Train: [104/180][150/625]	eta 0:08:20 lr 0.301631	data 0.0004 (0.1398)	batch 0.9165 (1.0542)	loss 3.0054 (2.8250)	grad_norm 0.5586 (0.5574)	mem 38886MB
Train: [104/180][200/625]	eta 0:07:12 lr 0.301090	data 0.0010 (0.1052)	batch 0.9083 (1.0176)	loss 2.8012 (2.8256)	grad_norm 0.5595 (0.5573)	mem 38886MB
Train: [104/180][250/625]	eta 0:06:13 lr 0.300549	data 0.0008 (0.0846)	batch 0.8641 (0.9958)	loss 2.6629 (2.8260)	grad_norm 0.5427 (0.5572)	mem 38886MB
Train: [104/180][300/625]	eta 0:05:18 lr 0.300008	data 0.0008 (0.0707)	batch 0.8906 (0.9810)	loss 2.7791 (2.8288)	grad_norm 0.5692 (0.5578)	mem 38886MB
Train: [104/180][350/625]	eta 0:04:26 lr 0.299468	data 0.0009 (0.0607)	batch 0.9070 (0.9703)	loss 2.8186 (2.8301)	grad_norm 0.5701 (0.5578)	mem 38886MB
Train: [104/180][400/625]	eta 0:03:36 lr 0.298927	data 0.0007 (0.0533)	batch 0.8835 (0.9626)	loss 2.7730 (2.8344)	grad_norm 0.5329 (0.5578)	mem 38886MB
Train: [104/180][450/625]	eta 0:02:47 lr 0.298387	data 0.0005 (0.0474)	batch 0.8830 (0.9564)	loss 2.7566 (2.8374)	grad_norm 0.5720 (0.5580)	mem 38886MB
Train: [104/180][500/625]	eta 0:01:58 lr 0.297847	data 0.0006 (0.0427)	batch 0.9251 (0.9512)	loss 2.7964 (2.8375)	grad_norm 0.5523 (0.5581)	mem 38886MB
Train: [104/180][550/625]	eta 0:01:11 lr 0.297307	data 0.0007 (0.0389)	batch 0.9267 (0.9469)	loss 2.9915 (2.8377)	grad_norm 0.5647 (0.5583)	mem 38886MB
Train: [104/180][600/625]	eta 0:00:23 lr 0.296767	data 0.0005 (0.0357)	batch 0.9097 (0.9435)	loss 2.8256 (2.8390)	grad_norm 0.5552 (0.5587)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 104 training takes 0:09:50
Test: [0/25]	Time 14.932 (14.932)	Loss 1.1162 (1.1162)	Acc@1 75.098 (75.098)	Acc@5 91.650 (91.650)	Mem 38886MB
 * Acc@1 64.850 Acc@5 86.100
Accuracy of the network on the 50000 test images: 64.85%
Max accuracy (after decay): 64.85%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [105/180][0/625]	eta 4:04:21 lr 0.296498	data 21.0933 (21.0933)	batch 23.4578 (23.4578)	loss 2.7200 (2.7200)	grad_norm 0.5480 (0.5480)	mem 38886MB
Train: [105/180][50/625]	eta 0:12:58 lr 0.295958	data 0.0006 (0.4144)	batch 0.9345 (1.3535)	loss 2.7724 (2.8249)	grad_norm 0.5516 (0.5569)	mem 38886MB
Train: [105/180][100/625]	eta 0:09:56 lr 0.295419	data 0.0007 (0.2096)	batch 0.8726 (1.1358)	loss 2.9626 (2.8173)	grad_norm 0.5625 (0.5595)	mem 38886MB
Train: [105/180][150/625]	eta 0:08:22 lr 0.294880	data 0.0006 (0.1405)	batch 0.9381 (1.0587)	loss 2.8146 (2.8179)	grad_norm 0.5608 (0.5597)	mem 38886MB
Train: [105/180][200/625]	eta 0:07:14 lr 0.294341	data 0.0012 (0.1057)	batch 0.9261 (1.0218)	loss 2.8749 (2.8272)	grad_norm 0.5510 (0.5599)	mem 38886MB
Train: [105/180][250/625]	eta 0:06:14 lr 0.293803	data 0.0006 (0.0848)	batch 0.8808 (0.9975)	loss 2.7367 (2.8289)	grad_norm 0.5740 (0.5597)	mem 38886MB
Train: [105/180][300/625]	eta 0:05:19 lr 0.293265	data 0.0015 (0.0709)	batch 0.9074 (0.9827)	loss 2.8049 (2.8314)	grad_norm 0.5613 (0.5601)	mem 38886MB
Train: [105/180][350/625]	eta 0:04:27 lr 0.292726	data 0.0010 (0.0609)	batch 0.8953 (0.9715)	loss 2.8059 (2.8313)	grad_norm 0.5780 (0.5603)	mem 38886MB
Train: [105/180][400/625]	eta 0:03:36 lr 0.292189	data 0.0006 (0.0534)	batch 0.8795 (0.9628)	loss 2.8937 (2.8316)	grad_norm 0.5742 (0.5604)	mem 38886MB
Train: [105/180][450/625]	eta 0:02:47 lr 0.291651	data 0.0006 (0.0476)	batch 0.9131 (0.9565)	loss 2.9325 (2.8337)	grad_norm 0.5955 (0.5607)	mem 38886MB
Train: [105/180][500/625]	eta 0:01:58 lr 0.291113	data 0.0006 (0.0429)	batch 0.8863 (0.9511)	loss 2.7452 (2.8325)	grad_norm 0.5661 (0.5610)	mem 38886MB
Train: [105/180][550/625]	eta 0:01:11 lr 0.290576	data 0.0004 (0.0391)	batch 0.9762 (0.9474)	loss 2.8697 (2.8326)	grad_norm 0.5691 (0.5611)	mem 38886MB
Train: [105/180][600/625]	eta 0:00:23 lr 0.290039	data 0.0008 (0.0359)	batch 0.8753 (0.9437)	loss 2.8648 (2.8336)	grad_norm 0.5621 (0.5611)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 105 training takes 0:09:50
Test: [0/25]	Time 14.990 (14.990)	Loss 1.0650 (1.0650)	Acc@1 76.318 (76.318)	Acc@5 92.432 (92.432)	Mem 38886MB
 * Acc@1 65.260 Acc@5 86.366
Accuracy of the network on the 50000 test images: 65.26%
Max accuracy (after decay): 65.26%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [106/180][0/625]	eta 4:05:24 lr 0.289771	data 21.6584 (21.6584)	batch 23.5588 (23.5588)	loss 2.6576 (2.6576)	grad_norm 0.5576 (0.5576)	mem 38886MB
Train: [106/180][50/625]	eta 0:12:57 lr 0.289234	data 0.0006 (0.4253)	batch 0.9174 (1.3522)	loss 2.9469 (2.8068)	grad_norm 0.5675 (0.5611)	mem 38886MB
Train: [106/180][100/625]	eta 0:09:54 lr 0.288697	data 0.0008 (0.2152)	batch 0.9071 (1.1316)	loss 2.8620 (2.8172)	grad_norm 0.5593 (0.5618)	mem 38886MB
Train: [106/180][150/625]	eta 0:08:23 lr 0.288161	data 0.0012 (0.1442)	batch 0.9313 (1.0595)	loss 2.8000 (2.8256)	grad_norm 0.5683 (0.5623)	mem 38886MB
Train: [106/180][200/625]	eta 0:07:14 lr 0.287625	data 0.0007 (0.1085)	batch 0.8642 (1.0230)	loss 2.9579 (2.8233)	grad_norm 0.5550 (0.5619)	mem 38886MB
Train: [106/180][250/625]	eta 0:06:15 lr 0.287089	data 0.0006 (0.0871)	batch 0.8580 (1.0004)	loss 2.7723 (2.8227)	grad_norm 0.5645 (0.5629)	mem 38886MB
Train: [106/180][300/625]	eta 0:05:19 lr 0.286553	data 0.0007 (0.0727)	batch 0.8764 (0.9834)	loss 2.7123 (2.8196)	grad_norm 0.5612 (0.5630)	mem 38886MB
Train: [106/180][350/625]	eta 0:04:27 lr 0.286018	data 0.0007 (0.0625)	batch 0.8854 (0.9716)	loss 2.7081 (2.8176)	grad_norm 0.5486 (0.5629)	mem 38886MB
Train: [106/180][400/625]	eta 0:03:36 lr 0.285483	data 0.0006 (0.0548)	batch 0.9093 (0.9631)	loss 2.7536 (2.8213)	grad_norm 0.5538 (0.5631)	mem 38886MB
Train: [106/180][450/625]	eta 0:02:47 lr 0.284948	data 0.0008 (0.0488)	batch 0.9195 (0.9569)	loss 2.9555 (2.8229)	grad_norm 0.5764 (0.5629)	mem 38886MB
Train: [106/180][500/625]	eta 0:01:58 lr 0.284413	data 0.0008 (0.0440)	batch 0.9038 (0.9517)	loss 2.9636 (2.8242)	grad_norm 0.5690 (0.5633)	mem 38886MB
Train: [106/180][550/625]	eta 0:01:11 lr 0.283879	data 0.0012 (0.0401)	batch 0.9000 (0.9476)	loss 2.9531 (2.8259)	grad_norm 0.5868 (0.5636)	mem 38886MB
Train: [106/180][600/625]	eta 0:00:23 lr 0.283344	data 0.0005 (0.0368)	batch 0.9142 (0.9439)	loss 2.8836 (2.8253)	grad_norm 0.5608 (0.5637)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 106 training takes 0:09:50
Test: [0/25]	Time 14.687 (14.687)	Loss 1.0689 (1.0689)	Acc@1 76.221 (76.221)	Acc@5 92.285 (92.285)	Mem 38886MB
 * Acc@1 64.790 Acc@5 86.202
Accuracy of the network on the 50000 test images: 64.79%
Max accuracy (after decay): 65.26%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [107/180][0/625]	eta 3:57:44 lr 0.283077	data 21.1347 (21.1347)	batch 22.8236 (22.8236)	loss 2.8398 (2.8398)	grad_norm 0.5580 (0.5580)	mem 38886MB
Train: [107/180][50/625]	eta 0:12:52 lr 0.282543	data 0.0008 (0.4153)	batch 0.9289 (1.3428)	loss 2.6496 (2.8126)	grad_norm 0.5581 (0.5640)	mem 38886MB
Train: [107/180][100/625]	eta 0:09:51 lr 0.282009	data 0.0006 (0.2106)	batch 0.9813 (1.1268)	loss 2.5847 (2.8225)	grad_norm 0.5585 (0.5646)	mem 38886MB
Train: [107/180][150/625]	eta 0:08:21 lr 0.281476	data 0.0006 (0.1411)	batch 0.8794 (1.0548)	loss 2.8947 (2.8153)	grad_norm 0.5824 (0.5646)	mem 38886MB
Train: [107/180][200/625]	eta 0:07:13 lr 0.280943	data 0.0007 (0.1062)	batch 1.0362 (1.0189)	loss 2.8085 (2.8215)	grad_norm 0.5626 (0.5658)	mem 38886MB
Train: [107/180][250/625]	eta 0:06:13 lr 0.280410	data 0.0013 (0.0852)	batch 0.8797 (0.9972)	loss 2.8344 (2.8214)	grad_norm 0.5685 (0.5661)	mem 38886MB
Train: [107/180][300/625]	eta 0:05:19 lr 0.279877	data 0.0006 (0.0712)	batch 0.8880 (0.9825)	loss 2.7069 (2.8225)	grad_norm 0.5348 (0.5661)	mem 38886MB
Train: [107/180][350/625]	eta 0:04:27 lr 0.279344	data 0.0007 (0.0611)	batch 0.8878 (0.9722)	loss 3.0475 (2.8254)	grad_norm 0.5731 (0.5664)	mem 38886MB
Train: [107/180][400/625]	eta 0:03:37 lr 0.278812	data 0.0006 (0.0536)	batch 1.0353 (0.9653)	loss 2.7126 (2.8241)	grad_norm 0.5657 (0.5664)	mem 38886MB
Train: [107/180][450/625]	eta 0:02:47 lr 0.278280	data 0.0006 (0.0478)	batch 0.9242 (0.9586)	loss 2.8544 (2.8274)	grad_norm 0.5738 (0.5669)	mem 38886MB
Train: [107/180][500/625]	eta 0:01:59 lr 0.277748	data 0.0009 (0.0431)	batch 0.8705 (0.9537)	loss 3.1475 (2.8296)	grad_norm 0.5744 (0.5669)	mem 38886MB
Train: [107/180][550/625]	eta 0:01:11 lr 0.277216	data 0.0006 (0.0393)	batch 0.8857 (0.9495)	loss 2.7777 (2.8294)	grad_norm 0.5749 (0.5671)	mem 38886MB
Train: [107/180][600/625]	eta 0:00:23 lr 0.276685	data 0.0006 (0.0361)	batch 0.9093 (0.9456)	loss 2.6939 (2.8257)	grad_norm 0.5541 (0.5671)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 107 training takes 0:09:51
Test: [0/25]	Time 14.586 (14.586)	Loss 1.0930 (1.0930)	Acc@1 77.002 (77.002)	Acc@5 92.480 (92.480)	Mem 38886MB
 * Acc@1 65.134 Acc@5 86.256
Accuracy of the network on the 50000 test images: 65.13%
Max accuracy (after decay): 65.26%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [108/180][0/625]	eta 3:59:55 lr 0.276419	data 21.5051 (21.5051)	batch 23.0325 (23.0325)	loss 2.8521 (2.8521)	grad_norm 0.5620 (0.5620)	mem 38886MB
Train: [108/180][50/625]	eta 0:12:58 lr 0.275888	data 0.0017 (0.4229)	batch 0.8950 (1.3543)	loss 2.8049 (2.8136)	grad_norm 0.5845 (0.5689)	mem 38886MB
Train: [108/180][100/625]	eta 0:09:56 lr 0.275358	data 0.0010 (0.2139)	batch 0.8950 (1.1364)	loss 2.8357 (2.8198)	grad_norm 0.5573 (0.5690)	mem 38886MB
Train: [108/180][150/625]	eta 0:08:24 lr 0.274827	data 0.0005 (0.1433)	batch 0.9249 (1.0627)	loss 2.8950 (2.8179)	grad_norm 0.5710 (0.5679)	mem 38886MB
Train: [108/180][200/625]	eta 0:07:14 lr 0.274297	data 0.0006 (0.1078)	batch 0.9061 (1.0232)	loss 2.7495 (2.8224)	grad_norm 0.5789 (0.5680)	mem 38886MB
Train: [108/180][250/625]	eta 0:06:15 lr 0.273767	data 0.0006 (0.0865)	batch 0.9204 (1.0002)	loss 2.6883 (2.8227)	grad_norm 0.5662 (0.5689)	mem 38886MB
Train: [108/180][300/625]	eta 0:05:20 lr 0.273237	data 0.0006 (0.0722)	batch 0.8912 (0.9858)	loss 2.8298 (2.8193)	grad_norm 0.5667 (0.5690)	mem 38886MB
Train: [108/180][350/625]	eta 0:04:28 lr 0.272707	data 0.0009 (0.0620)	batch 0.9138 (0.9751)	loss 2.7516 (2.8191)	grad_norm 0.5643 (0.5692)	mem 38886MB
Train: [108/180][400/625]	eta 0:03:37 lr 0.272178	data 0.0007 (0.0544)	batch 0.9421 (0.9665)	loss 2.7415 (2.8219)	grad_norm 0.5637 (0.5695)	mem 38886MB
Train: [108/180][450/625]	eta 0:02:47 lr 0.271649	data 0.0005 (0.0484)	batch 0.8662 (0.9595)	loss 2.6183 (2.8207)	grad_norm 0.5867 (0.5697)	mem 38886MB
Train: [108/180][500/625]	eta 0:01:59 lr 0.271120	data 0.0003 (0.0437)	batch 0.8808 (0.9541)	loss 2.7083 (2.8193)	grad_norm 0.5574 (0.5697)	mem 38886MB
Train: [108/180][550/625]	eta 0:01:11 lr 0.270592	data 0.0005 (0.0398)	batch 0.9454 (0.9498)	loss 2.7572 (2.8201)	grad_norm 0.5772 (0.5697)	mem 38886MB
Train: [108/180][600/625]	eta 0:00:23 lr 0.270063	data 0.0004 (0.0365)	batch 0.8965 (0.9460)	loss 2.7203 (2.8209)	grad_norm 0.5820 (0.5699)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 108 training takes 0:09:51
Test: [0/25]	Time 15.027 (15.027)	Loss 1.0503 (1.0503)	Acc@1 76.758 (76.758)	Acc@5 92.822 (92.822)	Mem 38886MB
 * Acc@1 65.094 Acc@5 86.276
Accuracy of the network on the 50000 test images: 65.09%
Max accuracy (after decay): 65.26%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [109/180][0/625]	eta 4:03:22 lr 0.269799	data 22.1671 (22.1671)	batch 23.3647 (23.3647)	loss 2.5186 (2.5186)	grad_norm 0.5574 (0.5574)	mem 38886MB
Train: [109/180][50/625]	eta 0:12:54 lr 0.269271	data 0.0005 (0.4352)	batch 0.9209 (1.3476)	loss 2.6719 (2.7923)	grad_norm 0.5476 (0.5711)	mem 38886MB
Train: [109/180][100/625]	eta 0:09:52 lr 0.268744	data 0.0005 (0.2200)	batch 0.9448 (1.1276)	loss 3.0519 (2.7960)	grad_norm 0.5770 (0.5690)	mem 38886MB
Train: [109/180][150/625]	eta 0:08:20 lr 0.268216	data 0.0005 (0.1474)	batch 0.9211 (1.0528)	loss 2.6875 (2.7955)	grad_norm 0.5651 (0.5693)	mem 38886MB
Train: [109/180][200/625]	eta 0:07:11 lr 0.267689	data 0.0005 (0.1108)	batch 0.8781 (1.0161)	loss 2.8934 (2.7980)	grad_norm 0.5859 (0.5699)	mem 38886MB
Train: [109/180][250/625]	eta 0:06:12 lr 0.267162	data 0.0005 (0.0889)	batch 0.8838 (0.9942)	loss 2.6782 (2.7998)	grad_norm 0.5644 (0.5708)	mem 38886MB
Train: [109/180][300/625]	eta 0:05:18 lr 0.266636	data 0.0005 (0.0742)	batch 0.8895 (0.9812)	loss 2.7848 (2.8068)	grad_norm 0.5604 (0.5714)	mem 38886MB
Train: [109/180][350/625]	eta 0:04:26 lr 0.266109	data 0.0005 (0.0637)	batch 0.9683 (0.9706)	loss 2.9264 (2.8068)	grad_norm 0.5651 (0.5714)	mem 38886MB
Train: [109/180][400/625]	eta 0:03:36 lr 0.265583	data 0.0006 (0.0558)	batch 0.9560 (0.9622)	loss 2.9263 (2.8085)	grad_norm 0.5872 (0.5717)	mem 38886MB
Train: [109/180][450/625]	eta 0:02:47 lr 0.265057	data 0.0004 (0.0497)	batch 0.8788 (0.9559)	loss 2.9128 (2.8084)	grad_norm 0.5761 (0.5717)	mem 38886MB
Train: [109/180][500/625]	eta 0:01:58 lr 0.264532	data 0.0004 (0.0448)	batch 0.9010 (0.9506)	loss 2.8094 (2.8088)	grad_norm 0.5795 (0.5722)	mem 38886MB
Train: [109/180][550/625]	eta 0:01:11 lr 0.264006	data 0.0006 (0.0408)	batch 1.0222 (0.9468)	loss 2.9877 (2.8104)	grad_norm 0.5782 (0.5727)	mem 38886MB
Train: [109/180][600/625]	eta 0:00:23 lr 0.263481	data 0.0005 (0.0375)	batch 0.8821 (0.9432)	loss 2.7353 (2.8117)	grad_norm 0.5810 (0.5728)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 109 training takes 0:09:49
Test: [0/25]	Time 15.121 (15.121)	Loss 1.0787 (1.0787)	Acc@1 77.100 (77.100)	Acc@5 92.871 (92.871)	Mem 38886MB
 * Acc@1 65.084 Acc@5 86.136
Accuracy of the network on the 50000 test images: 65.08%
Max accuracy (after decay): 65.26%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [110/180][0/625]	eta 3:57:37 lr 0.263219	data 21.4587 (21.4587)	batch 22.8115 (22.8115)	loss 3.0124 (3.0124)	grad_norm 0.5694 (0.5694)	mem 38886MB
Train: [110/180][50/625]	eta 0:12:53 lr 0.262694	data 0.0005 (0.4213)	batch 0.8822 (1.3449)	loss 2.8602 (2.7981)	grad_norm 0.5826 (0.5738)	mem 38886MB
Train: [110/180][100/625]	eta 0:09:51 lr 0.262170	data 0.0005 (0.2130)	batch 0.9054 (1.1276)	loss 2.7445 (2.7950)	grad_norm 0.5772 (0.5743)	mem 38886MB
Train: [110/180][150/625]	eta 0:08:21 lr 0.261646	data 0.0007 (0.1427)	batch 0.8837 (1.0548)	loss 2.8709 (2.8063)	grad_norm 0.5654 (0.5747)	mem 38886MB
Train: [110/180][200/625]	eta 0:07:13 lr 0.261122	data 0.0005 (0.1073)	batch 0.9068 (1.0189)	loss 2.9546 (2.8134)	grad_norm 0.5866 (0.5749)	mem 38886MB
Train: [110/180][250/625]	eta 0:06:14 lr 0.260598	data 0.0003 (0.0861)	batch 0.9135 (0.9975)	loss 2.8465 (2.8104)	grad_norm 0.5779 (0.5748)	mem 38886MB
Train: [110/180][300/625]	eta 0:05:19 lr 0.260075	data 0.0006 (0.0719)	batch 0.8576 (0.9832)	loss 2.8004 (2.8155)	grad_norm 0.5675 (0.5746)	mem 38886MB
Train: [110/180][350/625]	eta 0:04:27 lr 0.259552	data 0.0008 (0.0617)	batch 0.8974 (0.9725)	loss 2.6997 (2.8134)	grad_norm 0.5786 (0.5749)	mem 38886MB
Train: [110/180][400/625]	eta 0:03:36 lr 0.259029	data 0.0005 (0.0541)	batch 0.9374 (0.9644)	loss 2.7430 (2.8123)	grad_norm 0.5680 (0.5751)	mem 38886MB
Train: [110/180][450/625]	eta 0:02:47 lr 0.258507	data 0.0005 (0.0482)	batch 0.8999 (0.9585)	loss 2.8761 (2.8138)	grad_norm 0.5864 (0.5753)	mem 38886MB
Train: [110/180][500/625]	eta 0:01:59 lr 0.257984	data 0.0005 (0.0434)	batch 0.9193 (0.9528)	loss 2.9325 (2.8135)	grad_norm 0.5894 (0.5754)	mem 38886MB
Train: [110/180][550/625]	eta 0:01:11 lr 0.257462	data 0.0007 (0.0395)	batch 0.8931 (0.9496)	loss 2.7728 (2.8167)	grad_norm 0.5926 (0.5754)	mem 38886MB
Train: [110/180][600/625]	eta 0:00:23 lr 0.256941	data 0.0006 (0.0363)	batch 0.9163 (0.9465)	loss 2.9659 (2.8163)	grad_norm 0.5824 (0.5756)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 110 training takes 0:09:52
Test: [0/25]	Time 15.014 (15.014)	Loss 1.0836 (1.0836)	Acc@1 76.367 (76.367)	Acc@5 91.943 (91.943)	Mem 38886MB
 * Acc@1 65.224 Acc@5 86.378
Accuracy of the network on the 50000 test images: 65.22%
Max accuracy (after decay): 65.26%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [111/180][0/625]	eta 4:00:24 lr 0.256680	data 21.8465 (21.8465)	batch 23.0791 (23.0791)	loss 2.9450 (2.9450)	grad_norm 0.5772 (0.5772)	mem 38886MB
Train: [111/180][50/625]	eta 0:12:51 lr 0.256159	data 0.0005 (0.4292)	batch 0.9174 (1.3416)	loss 2.8159 (2.7871)	grad_norm 0.5742 (0.5763)	mem 38886MB
Train: [111/180][100/625]	eta 0:09:51 lr 0.255638	data 0.0005 (0.2170)	batch 0.8855 (1.1267)	loss 2.9498 (2.7899)	grad_norm 0.5895 (0.5764)	mem 38886MB
Train: [111/180][150/625]	eta 0:08:20 lr 0.255117	data 0.0006 (0.1453)	batch 0.8951 (1.0536)	loss 3.0779 (2.8017)	grad_norm 0.5942 (0.5775)	mem 38886MB
Train: [111/180][200/625]	eta 0:07:12 lr 0.254597	data 0.0006 (0.1094)	batch 0.8451 (1.0177)	loss 2.9497 (2.8021)	grad_norm 0.5684 (0.5777)	mem 38886MB
Train: [111/180][250/625]	eta 0:06:13 lr 0.254077	data 0.0008 (0.0877)	batch 0.8834 (0.9958)	loss 2.9047 (2.8014)	grad_norm 0.6058 (0.5778)	mem 38886MB
Train: [111/180][300/625]	eta 0:05:18 lr 0.253557	data 0.0010 (0.0733)	batch 0.9027 (0.9809)	loss 2.7616 (2.8023)	grad_norm 0.5668 (0.5783)	mem 38886MB
Train: [111/180][350/625]	eta 0:04:27 lr 0.253037	data 0.0008 (0.0631)	batch 0.9762 (0.9713)	loss 2.8534 (2.8063)	grad_norm 0.5835 (0.5784)	mem 38886MB
Train: [111/180][400/625]	eta 0:03:36 lr 0.252518	data 0.0006 (0.0553)	batch 0.9555 (0.9633)	loss 2.6690 (2.8078)	grad_norm 0.5747 (0.5784)	mem 38886MB
Train: [111/180][450/625]	eta 0:02:47 lr 0.251999	data 0.0006 (0.0493)	batch 0.8920 (0.9567)	loss 2.9131 (2.8094)	grad_norm 0.5570 (0.5788)	mem 38886MB
Train: [111/180][500/625]	eta 0:01:59 lr 0.251480	data 0.0004 (0.0444)	batch 0.9405 (0.9522)	loss 2.7464 (2.8107)	grad_norm 0.5941 (0.5792)	mem 38886MB
Train: [111/180][550/625]	eta 0:01:11 lr 0.250962	data 0.0009 (0.0404)	batch 0.8955 (0.9479)	loss 2.7854 (2.8110)	grad_norm 0.5834 (0.5792)	mem 38886MB
Train: [111/180][600/625]	eta 0:00:23 lr 0.250444	data 0.0006 (0.0371)	batch 0.9142 (0.9446)	loss 2.8727 (2.8114)	grad_norm 0.5847 (0.5789)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 111 training takes 0:09:50
Test: [0/25]	Time 14.679 (14.679)	Loss 1.0678 (1.0678)	Acc@1 76.514 (76.514)	Acc@5 92.676 (92.676)	Mem 38886MB
 * Acc@1 65.158 Acc@5 86.284
Accuracy of the network on the 50000 test images: 65.16%
Max accuracy (after decay): 65.26%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [112/180][0/625]	eta 4:00:12 lr 0.250185	data 20.9585 (20.9585)	batch 23.0607 (23.0607)	loss 2.6390 (2.6390)	grad_norm 0.5886 (0.5886)	mem 38886MB
Train: [112/180][50/625]	eta 0:12:51 lr 0.249667	data 0.0009 (0.4117)	batch 0.8709 (1.3416)	loss 2.8060 (2.8299)	grad_norm 0.5840 (0.5801)	mem 38886MB
Train: [112/180][100/625]	eta 0:09:51 lr 0.249150	data 0.0007 (0.2084)	batch 0.9060 (1.1266)	loss 2.7319 (2.8135)	grad_norm 0.5984 (0.5795)	mem 38886MB
Train: [112/180][150/625]	eta 0:08:20 lr 0.248633	data 0.0008 (0.1399)	batch 0.9112 (1.0541)	loss 2.9778 (2.8099)	grad_norm 0.6101 (0.5800)	mem 38886MB
Train: [112/180][200/625]	eta 0:07:12 lr 0.248116	data 0.0007 (0.1053)	batch 0.9744 (1.0175)	loss 2.9122 (2.8080)	grad_norm 0.5879 (0.5800)	mem 38886MB
Train: [112/180][250/625]	eta 0:06:12 lr 0.247599	data 0.0006 (0.0845)	batch 0.9023 (0.9946)	loss 2.7903 (2.8058)	grad_norm 0.5911 (0.5807)	mem 38886MB
Train: [112/180][300/625]	eta 0:05:18 lr 0.247083	data 0.0005 (0.0706)	batch 0.8824 (0.9792)	loss 3.0878 (2.8056)	grad_norm 0.5730 (0.5812)	mem 38886MB
Train: [112/180][350/625]	eta 0:04:26 lr 0.246567	data 0.0006 (0.0606)	batch 0.8938 (0.9695)	loss 2.7031 (2.8074)	grad_norm 0.5846 (0.5816)	mem 38886MB
Train: [112/180][400/625]	eta 0:03:36 lr 0.246052	data 0.0008 (0.0532)	batch 0.8791 (0.9618)	loss 2.7273 (2.8115)	grad_norm 0.5889 (0.5817)	mem 38886MB
Train: [112/180][450/625]	eta 0:02:47 lr 0.245537	data 0.0006 (0.0473)	batch 0.9070 (0.9552)	loss 2.6754 (2.8113)	grad_norm 0.5655 (0.5817)	mem 38886MB
Train: [112/180][500/625]	eta 0:01:58 lr 0.245022	data 0.0006 (0.0427)	batch 0.8700 (0.9502)	loss 2.6057 (2.8086)	grad_norm 0.5687 (0.5815)	mem 38886MB
Train: [112/180][550/625]	eta 0:01:10 lr 0.244507	data 0.0005 (0.0389)	batch 0.9408 (0.9460)	loss 2.8965 (2.8101)	grad_norm 0.5976 (0.5813)	mem 38886MB
Train: [112/180][600/625]	eta 0:00:23 lr 0.243992	data 0.0008 (0.0357)	batch 0.8796 (0.9425)	loss 2.7598 (2.8117)	grad_norm 0.5996 (0.5814)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 112 training takes 0:09:49
Test: [0/25]	Time 15.140 (15.140)	Loss 1.0695 (1.0695)	Acc@1 76.074 (76.074)	Acc@5 92.285 (92.285)	Mem 38886MB
 * Acc@1 65.524 Acc@5 86.472
Accuracy of the network on the 50000 test images: 65.52%
Max accuracy (after decay): 65.52%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [113/180][0/625]	eta 3:55:46 lr 0.243735	data 20.9548 (20.9548)	batch 22.6337 (22.6337)	loss 2.7911 (2.7911)	grad_norm 0.5796 (0.5796)	mem 38886MB
Train: [113/180][50/625]	eta 0:12:48 lr 0.243221	data 0.0005 (0.4115)	batch 0.9038 (1.3363)	loss 2.7424 (2.8163)	grad_norm 0.5976 (0.5813)	mem 38886MB
Train: [113/180][100/625]	eta 0:09:51 lr 0.242708	data 0.0007 (0.2081)	batch 1.0969 (1.1275)	loss 2.7866 (2.8016)	grad_norm 0.5759 (0.5807)	mem 38886MB
Train: [113/180][150/625]	eta 0:08:21 lr 0.242194	data 0.0005 (0.1394)	batch 0.9373 (1.0549)	loss 2.8114 (2.7942)	grad_norm 0.5971 (0.5814)	mem 38886MB
Train: [113/180][200/625]	eta 0:07:12 lr 0.241681	data 0.0005 (0.1048)	batch 0.9253 (1.0176)	loss 2.6609 (2.7944)	grad_norm 0.5867 (0.5817)	mem 38886MB
Train: [113/180][250/625]	eta 0:06:13 lr 0.241169	data 0.0005 (0.0841)	batch 0.8849 (0.9947)	loss 2.8677 (2.7944)	grad_norm 0.5805 (0.5815)	mem 38886MB
Train: [113/180][300/625]	eta 0:05:18 lr 0.240656	data 0.0005 (0.0702)	batch 0.9028 (0.9802)	loss 2.9638 (2.7901)	grad_norm 0.5982 (0.5822)	mem 38886MB
Train: [113/180][350/625]	eta 0:04:26 lr 0.240144	data 0.0005 (0.0603)	batch 0.8788 (0.9704)	loss 2.7297 (2.7915)	grad_norm 0.5713 (0.5823)	mem 38886MB
Train: [113/180][400/625]	eta 0:03:36 lr 0.239633	data 0.0005 (0.0528)	batch 0.9477 (0.9623)	loss 2.9435 (2.7933)	grad_norm 0.5940 (0.5827)	mem 38886MB
Train: [113/180][450/625]	eta 0:02:47 lr 0.239121	data 0.0004 (0.0470)	batch 0.8948 (0.9558)	loss 2.8502 (2.7920)	grad_norm 0.5955 (0.5832)	mem 38886MB
Train: [113/180][500/625]	eta 0:01:58 lr 0.238610	data 0.0006 (0.0424)	batch 0.9212 (0.9509)	loss 2.8910 (2.7936)	grad_norm 0.5883 (0.5833)	mem 38886MB
Train: [113/180][550/625]	eta 0:01:11 lr 0.238099	data 0.0005 (0.0386)	batch 0.9067 (0.9468)	loss 2.7841 (2.7942)	grad_norm 0.5856 (0.5835)	mem 38886MB
Train: [113/180][600/625]	eta 0:00:23 lr 0.237589	data 0.0006 (0.0354)	batch 0.8549 (0.9438)	loss 2.8191 (2.7945)	grad_norm 0.6064 (0.5835)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 113 training takes 0:09:50
Test: [0/25]	Time 14.912 (14.912)	Loss 1.0336 (1.0336)	Acc@1 77.344 (77.344)	Acc@5 92.627 (92.627)	Mem 38886MB
 * Acc@1 65.602 Acc@5 86.532
Accuracy of the network on the 50000 test images: 65.60%
Max accuracy (after decay): 65.60%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [114/180][0/625]	eta 3:59:44 lr 0.237333	data 21.5449 (21.5449)	batch 23.0155 (23.0155)	loss 2.8866 (2.8866)	grad_norm 0.5873 (0.5873)	mem 38886MB
Train: [114/180][50/625]	eta 0:12:56 lr 0.236823	data 0.0010 (0.4232)	batch 0.9202 (1.3509)	loss 3.0392 (2.7722)	grad_norm 0.5924 (0.5855)	mem 38886MB
Train: [114/180][100/625]	eta 0:09:55 lr 0.236314	data 0.0005 (0.2140)	batch 0.8872 (1.1335)	loss 2.7094 (2.7802)	grad_norm 0.5761 (0.5859)	mem 38886MB
Train: [114/180][150/625]	eta 0:08:22 lr 0.235804	data 0.0005 (0.1434)	batch 0.9280 (1.0586)	loss 2.8617 (2.7826)	grad_norm 0.5965 (0.5873)	mem 38886MB
Train: [114/180][200/625]	eta 0:07:13 lr 0.235295	data 0.0005 (0.1078)	batch 0.8986 (1.0207)	loss 2.9510 (2.7844)	grad_norm 0.5793 (0.5867)	mem 38886MB
Train: [114/180][250/625]	eta 0:06:14 lr 0.234786	data 0.0006 (0.0865)	batch 0.8430 (0.9983)	loss 2.7819 (2.7861)	grad_norm 0.5843 (0.5859)	mem 38886MB
Train: [114/180][300/625]	eta 0:05:19 lr 0.234278	data 0.0005 (0.0722)	batch 0.8799 (0.9832)	loss 2.8605 (2.7882)	grad_norm 0.5913 (0.5863)	mem 38886MB
Train: [114/180][350/625]	eta 0:04:27 lr 0.233770	data 0.0005 (0.0620)	batch 0.9123 (0.9725)	loss 2.5757 (2.7930)	grad_norm 0.5878 (0.5866)	mem 38886MB
Train: [114/180][400/625]	eta 0:03:36 lr 0.233262	data 0.0006 (0.0543)	batch 0.9082 (0.9632)	loss 2.7239 (2.7911)	grad_norm 0.5849 (0.5866)	mem 38886MB
Train: [114/180][450/625]	eta 0:02:47 lr 0.232755	data 0.0005 (0.0484)	batch 0.8910 (0.9566)	loss 2.8475 (2.7935)	grad_norm 0.6029 (0.5864)	mem 38886MB
Train: [114/180][500/625]	eta 0:01:58 lr 0.232248	data 0.0005 (0.0436)	batch 0.9105 (0.9516)	loss 2.6777 (2.7953)	grad_norm 0.5920 (0.5866)	mem 38886MB
Train: [114/180][550/625]	eta 0:01:11 lr 0.231741	data 0.0005 (0.0397)	batch 0.8932 (0.9475)	loss 2.7864 (2.7958)	grad_norm 0.5819 (0.5869)	mem 38886MB
Train: [114/180][600/625]	eta 0:00:23 lr 0.231234	data 0.0007 (0.0364)	batch 0.8809 (0.9441)	loss 2.7194 (2.7951)	grad_norm 0.5862 (0.5871)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 114 training takes 0:09:50
Test: [0/25]	Time 15.076 (15.076)	Loss 1.0494 (1.0494)	Acc@1 77.441 (77.441)	Acc@5 92.578 (92.578)	Mem 38886MB
 * Acc@1 65.788 Acc@5 86.862
Accuracy of the network on the 50000 test images: 65.79%
Max accuracy (after decay): 65.79%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [115/180][0/625]	eta 3:57:15 lr 0.230981	data 20.4392 (20.4392)	batch 22.7761 (22.7761)	loss 2.9097 (2.9097)	grad_norm 0.5992 (0.5992)	mem 38886MB
Train: [115/180][50/625]	eta 0:12:46 lr 0.230475	data 0.0006 (0.4015)	batch 0.9135 (1.3337)	loss 2.7772 (2.7811)	grad_norm 0.5826 (0.5866)	mem 38886MB
Train: [115/180][100/625]	eta 0:09:50 lr 0.229970	data 0.0011 (0.2031)	batch 0.8874 (1.1256)	loss 2.8876 (2.7876)	grad_norm 0.6104 (0.5875)	mem 38886MB
Train: [115/180][150/625]	eta 0:08:19 lr 0.229464	data 0.0006 (0.1361)	batch 0.8588 (1.0518)	loss 2.8736 (2.7942)	grad_norm 0.6043 (0.5884)	mem 38886MB
Train: [115/180][200/625]	eta 0:07:12 lr 0.228959	data 0.0007 (0.1025)	batch 0.8650 (1.0172)	loss 2.6041 (2.7910)	grad_norm 0.5906 (0.5891)	mem 38886MB
Train: [115/180][250/625]	eta 0:06:13 lr 0.228455	data 0.0009 (0.0822)	batch 0.8921 (0.9950)	loss 2.7877 (2.7889)	grad_norm 0.5876 (0.5891)	mem 38886MB
Train: [115/180][300/625]	eta 0:05:18 lr 0.227950	data 0.0005 (0.0687)	batch 0.9509 (0.9803)	loss 2.8816 (2.7919)	grad_norm 0.5935 (0.5894)	mem 38886MB
Train: [115/180][350/625]	eta 0:04:26 lr 0.227446	data 0.0010 (0.0590)	batch 0.9018 (0.9701)	loss 2.8540 (2.7910)	grad_norm 0.5904 (0.5896)	mem 38886MB
Train: [115/180][400/625]	eta 0:03:36 lr 0.226943	data 0.0004 (0.0517)	batch 0.9082 (0.9622)	loss 2.5876 (2.7886)	grad_norm 0.5897 (0.5897)	mem 38886MB
Train: [115/180][450/625]	eta 0:02:47 lr 0.226439	data 0.0007 (0.0461)	batch 0.8853 (0.9564)	loss 2.7658 (2.7886)	grad_norm 0.5807 (0.5901)	mem 38886MB
Train: [115/180][500/625]	eta 0:01:58 lr 0.225936	data 0.0007 (0.0416)	batch 0.8745 (0.9511)	loss 2.8790 (2.7902)	grad_norm 0.6031 (0.5901)	mem 38886MB
Train: [115/180][550/625]	eta 0:01:11 lr 0.225434	data 0.0007 (0.0379)	batch 0.9157 (0.9469)	loss 2.8232 (2.7896)	grad_norm 0.6084 (0.5903)	mem 38886MB
Train: [115/180][600/625]	eta 0:00:23 lr 0.224931	data 0.0007 (0.0348)	batch 0.8976 (0.9436)	loss 2.6617 (2.7881)	grad_norm 0.5796 (0.5901)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 115 training takes 0:09:50
Test: [0/25]	Time 14.936 (14.936)	Loss 1.0413 (1.0413)	Acc@1 77.051 (77.051)	Acc@5 92.578 (92.578)	Mem 38886MB
 * Acc@1 65.796 Acc@5 86.688
Accuracy of the network on the 50000 test images: 65.80%
Max accuracy (after decay): 65.80%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [116/180][0/625]	eta 3:53:44 lr 0.224680	data 20.7261 (20.7261)	batch 22.4386 (22.4386)	loss 2.9678 (2.9678)	grad_norm 0.6010 (0.6010)	mem 38886MB
Train: [116/180][50/625]	eta 0:12:50 lr 0.224179	data 0.0005 (0.4070)	batch 0.9158 (1.3392)	loss 2.9257 (2.7751)	grad_norm 0.6051 (0.5905)	mem 38886MB
Train: [116/180][100/625]	eta 0:09:50 lr 0.223677	data 0.0005 (0.2059)	batch 0.8814 (1.1246)	loss 2.7828 (2.7793)	grad_norm 0.5784 (0.5918)	mem 38886MB
Train: [116/180][150/625]	eta 0:08:19 lr 0.223176	data 0.0005 (0.1379)	batch 0.8625 (1.0514)	loss 2.7524 (2.7790)	grad_norm 0.5959 (0.5919)	mem 38886MB
Train: [116/180][200/625]	eta 0:07:11 lr 0.222675	data 0.0005 (0.1040)	batch 0.8813 (1.0154)	loss 2.6149 (2.7804)	grad_norm 0.5898 (0.5923)	mem 38886MB
Train: [116/180][250/625]	eta 0:06:12 lr 0.222175	data 0.0006 (0.0834)	batch 0.8764 (0.9924)	loss 2.8874 (2.7814)	grad_norm 0.6063 (0.5922)	mem 38886MB
Train: [116/180][300/625]	eta 0:05:17 lr 0.221675	data 0.0004 (0.0696)	batch 0.9066 (0.9779)	loss 2.7109 (2.7823)	grad_norm 0.5909 (0.5930)	mem 38886MB
Train: [116/180][350/625]	eta 0:04:25 lr 0.221175	data 0.0006 (0.0598)	batch 0.8995 (0.9668)	loss 2.8904 (2.7840)	grad_norm 0.6109 (0.5930)	mem 38886MB
Train: [116/180][400/625]	eta 0:03:35 lr 0.220676	data 0.0006 (0.0524)	batch 0.9114 (0.9586)	loss 2.7392 (2.7834)	grad_norm 0.5929 (0.5930)	mem 38886MB
Train: [116/180][450/625]	eta 0:02:46 lr 0.220177	data 0.0005 (0.0467)	batch 0.8919 (0.9531)	loss 2.6549 (2.7812)	grad_norm 0.5731 (0.5933)	mem 38886MB
Train: [116/180][500/625]	eta 0:01:58 lr 0.219678	data 0.0007 (0.0421)	batch 0.8676 (0.9477)	loss 2.8809 (2.7808)	grad_norm 0.5986 (0.5935)	mem 38886MB
Train: [116/180][550/625]	eta 0:01:10 lr 0.219180	data 0.0005 (0.0383)	batch 0.9494 (0.9440)	loss 2.5976 (2.7825)	grad_norm 0.5877 (0.5936)	mem 38886MB
Train: [116/180][600/625]	eta 0:00:23 lr 0.218682	data 0.0005 (0.0352)	batch 0.9376 (0.9408)	loss 2.5599 (2.7834)	grad_norm 0.5972 (0.5936)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 116 training takes 0:09:48
Test: [0/25]	Time 14.697 (14.697)	Loss 1.0915 (1.0915)	Acc@1 77.734 (77.734)	Acc@5 92.139 (92.139)	Mem 38886MB
 * Acc@1 65.960 Acc@5 86.752
Accuracy of the network on the 50000 test images: 65.96%
Max accuracy (after decay): 65.96%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [117/180][0/625]	eta 3:52:53 lr 0.218433	data 21.0672 (21.0672)	batch 22.3576 (22.3576)	loss 2.7826 (2.7826)	grad_norm 0.5722 (0.5722)	mem 38886MB
Train: [117/180][50/625]	eta 0:12:44 lr 0.217935	data 0.0004 (0.4141)	batch 0.8908 (1.3299)	loss 2.6963 (2.7678)	grad_norm 0.6091 (0.5921)	mem 38886MB
Train: [117/180][100/625]	eta 0:09:47 lr 0.217438	data 0.0006 (0.2094)	batch 0.9152 (1.1188)	loss 2.8793 (2.7584)	grad_norm 0.5818 (0.5938)	mem 38886MB
Train: [117/180][150/625]	eta 0:08:18 lr 0.216942	data 0.0007 (0.1404)	batch 0.8781 (1.0491)	loss 2.6879 (2.7653)	grad_norm 0.5875 (0.5943)	mem 38886MB
Train: [117/180][200/625]	eta 0:07:11 lr 0.216445	data 0.0006 (0.1058)	batch 0.9001 (1.0145)	loss 2.9040 (2.7662)	grad_norm 0.6013 (0.5940)	mem 38886MB
Train: [117/180][250/625]	eta 0:06:12 lr 0.215949	data 0.0005 (0.0849)	batch 0.9410 (0.9932)	loss 2.5324 (2.7673)	grad_norm 0.5868 (0.5950)	mem 38886MB
Train: [117/180][300/625]	eta 0:05:17 lr 0.215454	data 0.0006 (0.0709)	batch 0.8659 (0.9784)	loss 2.8106 (2.7707)	grad_norm 0.5944 (0.5955)	mem 38886MB
Train: [117/180][350/625]	eta 0:04:26 lr 0.214958	data 0.0006 (0.0609)	batch 0.9006 (0.9676)	loss 2.8794 (2.7788)	grad_norm 0.5841 (0.5959)	mem 38886MB
Train: [117/180][400/625]	eta 0:03:35 lr 0.214463	data 0.0005 (0.0533)	batch 0.8823 (0.9593)	loss 2.6114 (2.7775)	grad_norm 0.5922 (0.5960)	mem 38886MB
Train: [117/180][450/625]	eta 0:02:46 lr 0.213969	data 0.0003 (0.0475)	batch 0.8791 (0.9541)	loss 2.6210 (2.7754)	grad_norm 0.5845 (0.5964)	mem 38886MB
Train: [117/180][500/625]	eta 0:01:58 lr 0.213475	data 0.0005 (0.0428)	batch 0.8940 (0.9491)	loss 2.7995 (2.7775)	grad_norm 0.5848 (0.5971)	mem 38886MB
Train: [117/180][550/625]	eta 0:01:10 lr 0.212981	data 0.0005 (0.0390)	batch 0.9252 (0.9447)	loss 2.7509 (2.7779)	grad_norm 0.5955 (0.5968)	mem 38886MB
Train: [117/180][600/625]	eta 0:00:23 lr 0.212487	data 0.0005 (0.0358)	batch 0.9068 (0.9413)	loss 2.6473 (2.7802)	grad_norm 0.5814 (0.5968)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 117 training takes 0:09:48
Test: [0/25]	Time 14.577 (14.577)	Loss 1.0582 (1.0582)	Acc@1 76.562 (76.562)	Acc@5 92.383 (92.383)	Mem 38886MB
 * Acc@1 65.834 Acc@5 86.682
Accuracy of the network on the 50000 test images: 65.83%
Max accuracy (after decay): 65.96%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [118/180][0/625]	eta 3:59:45 lr 0.212241	data 21.2216 (21.2216)	batch 23.0171 (23.0171)	loss 2.8723 (2.8723)	grad_norm 0.6042 (0.6042)	mem 38886MB
Train: [118/180][50/625]	eta 0:12:53 lr 0.211748	data 0.0007 (0.4169)	batch 0.8626 (1.3460)	loss 2.6775 (2.7644)	grad_norm 0.5965 (0.5964)	mem 38886MB
Train: [118/180][100/625]	eta 0:09:52 lr 0.211255	data 0.0011 (0.2109)	batch 0.8750 (1.1285)	loss 2.8177 (2.7535)	grad_norm 0.5892 (0.5966)	mem 38886MB
Train: [118/180][150/625]	eta 0:08:20 lr 0.210763	data 0.0007 (0.1413)	batch 0.8951 (1.0544)	loss 2.8643 (2.7615)	grad_norm 0.5817 (0.5977)	mem 38886MB
Train: [118/180][200/625]	eta 0:07:12 lr 0.210271	data 0.0005 (0.1063)	batch 0.8879 (1.0172)	loss 2.7049 (2.7589)	grad_norm 0.5827 (0.5971)	mem 38886MB
Train: [118/180][250/625]	eta 0:06:13 lr 0.209780	data 0.0013 (0.0853)	batch 0.8797 (0.9961)	loss 2.6891 (2.7636)	grad_norm 0.5990 (0.5976)	mem 38886MB
Train: [118/180][300/625]	eta 0:05:18 lr 0.209289	data 0.0005 (0.0712)	batch 0.8904 (0.9812)	loss 2.8882 (2.7663)	grad_norm 0.6002 (0.5983)	mem 38886MB
Train: [118/180][350/625]	eta 0:04:27 lr 0.208798	data 0.0004 (0.0612)	batch 0.9590 (0.9710)	loss 2.8314 (2.7685)	grad_norm 0.6152 (0.5982)	mem 38886MB
Train: [118/180][400/625]	eta 0:03:36 lr 0.208308	data 0.0005 (0.0536)	batch 0.9185 (0.9630)	loss 2.6282 (2.7674)	grad_norm 0.6043 (0.5984)	mem 38886MB
Train: [118/180][450/625]	eta 0:02:47 lr 0.207818	data 0.0004 (0.0477)	batch 0.9130 (0.9564)	loss 2.5759 (2.7706)	grad_norm 0.5949 (0.5986)	mem 38886MB
Train: [118/180][500/625]	eta 0:01:58 lr 0.207328	data 0.0006 (0.0430)	batch 0.8705 (0.9514)	loss 2.6164 (2.7691)	grad_norm 0.5930 (0.5985)	mem 38886MB
Train: [118/180][550/625]	eta 0:01:11 lr 0.206839	data 0.0003 (0.0392)	batch 0.9045 (0.9478)	loss 2.7795 (2.7725)	grad_norm 0.5997 (0.5986)	mem 38886MB
Train: [118/180][600/625]	eta 0:00:23 lr 0.206350	data 0.0005 (0.0359)	batch 0.9002 (0.9447)	loss 2.8308 (2.7742)	grad_norm 0.5844 (0.5987)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 118 training takes 0:09:51
Test: [0/25]	Time 14.686 (14.686)	Loss 1.0674 (1.0674)	Acc@1 76.074 (76.074)	Acc@5 93.115 (93.115)	Mem 38886MB
 * Acc@1 66.140 Acc@5 86.978
Accuracy of the network on the 50000 test images: 66.14%
Max accuracy (after decay): 66.14%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [119/180][0/625]	eta 4:05:19 lr 0.206106	data 20.6313 (20.6313)	batch 23.5505 (23.5505)	loss 2.8782 (2.8782)	grad_norm 0.6077 (0.6077)	mem 38886MB
Train: [119/180][50/625]	eta 0:12:55 lr 0.205618	data 0.0003 (0.4053)	batch 0.8914 (1.3495)	loss 2.6729 (2.7466)	grad_norm 0.5935 (0.5976)	mem 38886MB
Train: [119/180][100/625]	eta 0:09:53 lr 0.205130	data 0.0005 (0.2050)	batch 0.8998 (1.1303)	loss 2.7192 (2.7500)	grad_norm 0.6135 (0.5981)	mem 38886MB
Train: [119/180][150/625]	eta 0:08:20 lr 0.204642	data 0.0004 (0.1373)	batch 0.9027 (1.0544)	loss 2.8512 (2.7523)	grad_norm 0.6010 (0.6002)	mem 38886MB
Train: [119/180][200/625]	eta 0:07:12 lr 0.204155	data 0.0007 (0.1033)	batch 0.8507 (1.0185)	loss 2.8666 (2.7589)	grad_norm 0.6038 (0.6010)	mem 38886MB
Train: [119/180][250/625]	eta 0:06:13 lr 0.203668	data 0.0005 (0.0828)	batch 0.9119 (0.9965)	loss 2.7669 (2.7621)	grad_norm 0.5980 (0.6018)	mem 38886MB
Train: [119/180][300/625]	eta 0:05:19 lr 0.203182	data 0.0006 (0.0692)	batch 0.9015 (0.9822)	loss 2.7980 (2.7673)	grad_norm 0.6068 (0.6020)	mem 38886MB
Train: [119/180][350/625]	eta 0:04:27 lr 0.202696	data 0.0005 (0.0594)	batch 0.9152 (0.9717)	loss 2.7921 (2.7679)	grad_norm 0.6200 (0.6024)	mem 38886MB
Train: [119/180][400/625]	eta 0:03:36 lr 0.202210	data 0.0006 (0.0521)	batch 0.9014 (0.9632)	loss 2.6878 (2.7687)	grad_norm 0.5896 (0.6024)	mem 38886MB
Train: [119/180][450/625]	eta 0:02:47 lr 0.201725	data 0.0010 (0.0464)	batch 0.8714 (0.9570)	loss 2.6404 (2.7691)	grad_norm 0.5988 (0.6022)	mem 38886MB
Train: [119/180][500/625]	eta 0:01:59 lr 0.201240	data 0.0004 (0.0418)	batch 0.9305 (0.9523)	loss 2.7949 (2.7705)	grad_norm 0.5955 (0.6023)	mem 38886MB
Train: [119/180][550/625]	eta 0:01:11 lr 0.200756	data 0.0006 (0.0381)	batch 0.9003 (0.9484)	loss 2.8033 (2.7724)	grad_norm 0.5938 (0.6026)	mem 38886MB
Train: [119/180][600/625]	eta 0:00:23 lr 0.200272	data 0.0007 (0.0349)	batch 0.8949 (0.9450)	loss 2.7391 (2.7737)	grad_norm 0.6108 (0.6027)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 119 training takes 0:09:51
Test: [0/25]	Time 14.975 (14.975)	Loss 0.9997 (0.9997)	Acc@1 77.783 (77.783)	Acc@5 92.920 (92.920)	Mem 38886MB
 * Acc@1 66.020 Acc@5 86.756
Accuracy of the network on the 50000 test images: 66.02%
Max accuracy (after decay): 66.14%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [120/180][0/625]	eta 3:59:46 lr 0.200030	data 20.7764 (20.7764)	batch 23.0177 (23.0177)	loss 2.8252 (2.8252)	grad_norm 0.6011 (0.6011)	mem 38886MB
Train: [120/180][50/625]	eta 0:12:51 lr 0.199547	data 0.0006 (0.4081)	batch 1.0470 (1.3420)	loss 2.8043 (2.7385)	grad_norm 0.6402 (0.6052)	mem 38886MB
Train: [120/180][100/625]	eta 0:09:49 lr 0.199063	data 0.0008 (0.2064)	batch 0.8526 (1.1235)	loss 2.6570 (2.7456)	grad_norm 0.5981 (0.6068)	mem 38886MB
Train: [120/180][150/625]	eta 0:08:18 lr 0.198581	data 0.0004 (0.1382)	batch 0.8984 (1.0493)	loss 2.7820 (2.7548)	grad_norm 0.6175 (0.6069)	mem 38886MB
Train: [120/180][200/625]	eta 0:07:09 lr 0.198099	data 0.0005 (0.1040)	batch 0.8983 (1.0113)	loss 2.7797 (2.7586)	grad_norm 0.6129 (0.6067)	mem 38886MB
Train: [120/180][250/625]	eta 0:06:11 lr 0.197617	data 0.0007 (0.0834)	batch 0.8385 (0.9905)	loss 2.7886 (2.7600)	grad_norm 0.6105 (0.6067)	mem 38886MB
Train: [120/180][300/625]	eta 0:05:17 lr 0.197135	data 0.0005 (0.0696)	batch 0.9234 (0.9756)	loss 2.8226 (2.7600)	grad_norm 0.5997 (0.6065)	mem 38886MB
Train: [120/180][350/625]	eta 0:04:25 lr 0.196654	data 0.0005 (0.0598)	batch 0.9470 (0.9651)	loss 2.6106 (2.7605)	grad_norm 0.5920 (0.6064)	mem 38886MB
Train: [120/180][400/625]	eta 0:03:35 lr 0.196173	data 0.0006 (0.0524)	batch 0.8820 (0.9566)	loss 2.7190 (2.7626)	grad_norm 0.6113 (0.6064)	mem 38886MB
Train: [120/180][450/625]	eta 0:02:46 lr 0.195693	data 0.0004 (0.0466)	batch 0.9418 (0.9508)	loss 2.6633 (2.7624)	grad_norm 0.6080 (0.6065)	mem 38886MB
Train: [120/180][500/625]	eta 0:01:58 lr 0.195213	data 0.0005 (0.0420)	batch 0.9184 (0.9459)	loss 2.8191 (2.7626)	grad_norm 0.6097 (0.6064)	mem 38886MB
Train: [120/180][550/625]	eta 0:01:10 lr 0.194734	data 0.0004 (0.0383)	batch 0.8931 (0.9417)	loss 2.8217 (2.7627)	grad_norm 0.6014 (0.6063)	mem 38886MB
Train: [120/180][600/625]	eta 0:00:23 lr 0.194254	data 0.0007 (0.0351)	batch 0.8896 (0.9384)	loss 2.9019 (2.7648)	grad_norm 0.6167 (0.6065)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 120 training takes 0:09:46
Test: [0/25]	Time 14.773 (14.773)	Loss 1.0187 (1.0187)	Acc@1 76.660 (76.660)	Acc@5 92.480 (92.480)	Mem 38886MB
 * Acc@1 66.064 Acc@5 86.874
Accuracy of the network on the 50000 test images: 66.06%
Max accuracy (after decay): 66.14%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [121/180][0/625]	eta 3:57:40 lr 0.194015	data 21.6366 (21.6366)	batch 22.8174 (22.8174)	loss 2.7189 (2.7189)	grad_norm 0.5979 (0.5979)	mem 38886MB
Train: [121/180][50/625]	eta 0:12:49 lr 0.193537	data 0.0008 (0.4249)	batch 0.8927 (1.3381)	loss 2.7133 (2.7341)	grad_norm 0.6116 (0.6069)	mem 38886MB
Train: [121/180][100/625]	eta 0:09:52 lr 0.193058	data 0.0005 (0.2149)	batch 0.9880 (1.1278)	loss 2.7098 (2.7406)	grad_norm 0.5994 (0.6078)	mem 38886MB
Train: [121/180][150/625]	eta 0:08:20 lr 0.192581	data 0.0008 (0.1440)	batch 0.8831 (1.0529)	loss 2.7587 (2.7476)	grad_norm 0.6111 (0.6079)	mem 38886MB
Train: [121/180][200/625]	eta 0:07:12 lr 0.192103	data 0.0012 (0.1084)	batch 0.8463 (1.0166)	loss 2.8078 (2.7512)	grad_norm 0.6135 (0.6086)	mem 38886MB
Train: [121/180][250/625]	eta 0:06:13 lr 0.191627	data 0.0005 (0.0870)	batch 0.8934 (0.9949)	loss 2.8312 (2.7497)	grad_norm 0.6064 (0.6093)	mem 38886MB
Train: [121/180][300/625]	eta 0:05:18 lr 0.191150	data 0.0008 (0.0726)	batch 0.8731 (0.9813)	loss 2.8000 (2.7528)	grad_norm 0.6074 (0.6095)	mem 38886MB
Train: [121/180][350/625]	eta 0:04:26 lr 0.190674	data 0.0022 (0.0624)	batch 0.8903 (0.9705)	loss 2.9411 (2.7517)	grad_norm 0.6017 (0.6092)	mem 38886MB
Train: [121/180][400/625]	eta 0:03:36 lr 0.190198	data 0.0009 (0.0547)	batch 0.9280 (0.9624)	loss 2.5617 (2.7561)	grad_norm 0.5932 (0.6098)	mem 38886MB
Train: [121/180][450/625]	eta 0:02:47 lr 0.189723	data 0.0007 (0.0488)	batch 0.8935 (0.9562)	loss 2.5292 (2.7573)	grad_norm 0.6083 (0.6099)	mem 38886MB
Train: [121/180][500/625]	eta 0:01:59 lr 0.189248	data 0.0004 (0.0440)	batch 0.8860 (0.9521)	loss 2.9174 (2.7582)	grad_norm 0.6043 (0.6100)	mem 38886MB
Train: [121/180][550/625]	eta 0:01:11 lr 0.188774	data 0.0006 (0.0400)	batch 0.9800 (0.9483)	loss 2.7345 (2.7578)	grad_norm 0.6071 (0.6101)	mem 38886MB
Train: [121/180][600/625]	eta 0:00:23 lr 0.188300	data 0.0009 (0.0368)	batch 0.9001 (0.9453)	loss 2.7577 (2.7580)	grad_norm 0.6151 (0.6100)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 121 training takes 0:09:51
Test: [0/25]	Time 14.775 (14.775)	Loss 1.0481 (1.0481)	Acc@1 77.441 (77.441)	Acc@5 93.018 (93.018)	Mem 38886MB
 * Acc@1 66.396 Acc@5 87.124
Accuracy of the network on the 50000 test images: 66.40%
Max accuracy (after decay): 66.40%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [122/180][0/625]	eta 3:58:10 lr 0.188063	data 21.9316 (21.9316)	batch 22.8649 (22.8649)	loss 2.7167 (2.7167)	grad_norm 0.5979 (0.5979)	mem 38886MB
Train: [122/180][50/625]	eta 0:12:48 lr 0.187589	data 0.0008 (0.4309)	batch 0.9072 (1.3359)	loss 2.7968 (2.7427)	grad_norm 0.5950 (0.6071)	mem 38886MB
Train: [122/180][100/625]	eta 0:09:49 lr 0.187116	data 0.0008 (0.2180)	batch 0.8984 (1.1223)	loss 2.6781 (2.7477)	grad_norm 0.6096 (0.6075)	mem 38886MB
Train: [122/180][150/625]	eta 0:08:19 lr 0.186644	data 0.0009 (0.1461)	batch 0.9330 (1.0515)	loss 2.6951 (2.7505)	grad_norm 0.6096 (0.6105)	mem 38886MB
Train: [122/180][200/625]	eta 0:07:11 lr 0.186172	data 0.0005 (0.1099)	batch 0.8975 (1.0151)	loss 2.9235 (2.7545)	grad_norm 0.6077 (0.6113)	mem 38886MB
Train: [122/180][250/625]	eta 0:06:12 lr 0.185700	data 0.0006 (0.0882)	batch 0.8982 (0.9946)	loss 2.6063 (2.7512)	grad_norm 0.6149 (0.6116)	mem 38886MB
Train: [122/180][300/625]	eta 0:05:18 lr 0.185229	data 0.0007 (0.0737)	batch 1.0835 (0.9805)	loss 2.7578 (2.7514)	grad_norm 0.6259 (0.6122)	mem 38886MB
Train: [122/180][350/625]	eta 0:04:26 lr 0.184758	data 0.0008 (0.0633)	batch 0.9027 (0.9697)	loss 2.6996 (2.7527)	grad_norm 0.6086 (0.6122)	mem 38886MB
Train: [122/180][400/625]	eta 0:03:36 lr 0.184287	data 0.0007 (0.0555)	batch 0.8820 (0.9624)	loss 2.7372 (2.7521)	grad_norm 0.6232 (0.6123)	mem 38886MB
Train: [122/180][450/625]	eta 0:02:47 lr 0.183817	data 0.0006 (0.0494)	batch 0.8823 (0.9561)	loss 2.7181 (2.7530)	grad_norm 0.6313 (0.6124)	mem 38886MB
Train: [122/180][500/625]	eta 0:01:58 lr 0.183348	data 0.0007 (0.0446)	batch 0.9052 (0.9508)	loss 2.3789 (2.7562)	grad_norm 0.6041 (0.6124)	mem 38886MB
Train: [122/180][550/625]	eta 0:01:10 lr 0.182878	data 0.0008 (0.0407)	batch 0.8969 (0.9464)	loss 2.7327 (2.7577)	grad_norm 0.6151 (0.6125)	mem 38886MB
Train: [122/180][600/625]	eta 0:00:23 lr 0.182410	data 0.0006 (0.0373)	batch 0.9032 (0.9435)	loss 2.7937 (2.7591)	grad_norm 0.6023 (0.6126)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 122 training takes 0:09:50
Test: [0/25]	Time 14.864 (14.864)	Loss 1.0408 (1.0408)	Acc@1 78.223 (78.223)	Acc@5 92.480 (92.480)	Mem 38886MB
 * Acc@1 66.462 Acc@5 87.036
Accuracy of the network on the 50000 test images: 66.46%
Max accuracy (after decay): 66.46%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [123/180][0/625]	eta 3:55:56 lr 0.182175	data 20.7187 (20.7187)	batch 22.6505 (22.6505)	loss 2.7443 (2.7443)	grad_norm 0.6044 (0.6044)	mem 38886MB
Train: [123/180][50/625]	eta 0:12:47 lr 0.181707	data 0.0006 (0.4069)	batch 0.8807 (1.3341)	loss 2.7073 (2.7282)	grad_norm 0.6136 (0.6120)	mem 38886MB
Train: [123/180][100/625]	eta 0:09:48 lr 0.181239	data 0.0005 (0.2057)	batch 1.0279 (1.1203)	loss 2.8363 (2.7275)	grad_norm 0.6338 (0.6119)	mem 38886MB
Train: [123/180][150/625]	eta 0:08:18 lr 0.180772	data 0.0006 (0.1378)	batch 0.8824 (1.0500)	loss 2.5643 (2.7344)	grad_norm 0.6189 (0.6121)	mem 38886MB
Train: [123/180][200/625]	eta 0:07:10 lr 0.180305	data 0.0004 (0.1036)	batch 0.9047 (1.0130)	loss 2.9225 (2.7444)	grad_norm 0.6179 (0.6128)	mem 38886MB
Train: [123/180][250/625]	eta 0:06:12 lr 0.179839	data 0.0005 (0.0831)	batch 0.9355 (0.9922)	loss 2.7338 (2.7442)	grad_norm 0.6046 (0.6134)	mem 38886MB
Train: [123/180][300/625]	eta 0:05:17 lr 0.179373	data 0.0009 (0.0694)	batch 0.9083 (0.9776)	loss 2.6587 (2.7474)	grad_norm 0.6088 (0.6138)	mem 38886MB
Train: [123/180][350/625]	eta 0:04:25 lr 0.178907	data 0.0005 (0.0596)	batch 0.9010 (0.9668)	loss 2.7229 (2.7489)	grad_norm 0.6162 (0.6140)	mem 38886MB
Train: [123/180][400/625]	eta 0:03:36 lr 0.178442	data 0.0005 (0.0522)	batch 0.8980 (0.9602)	loss 2.7199 (2.7491)	grad_norm 0.6224 (0.6142)	mem 38886MB
Train: [123/180][450/625]	eta 0:02:46 lr 0.177977	data 0.0007 (0.0465)	batch 0.8969 (0.9537)	loss 2.7090 (2.7498)	grad_norm 0.6049 (0.6149)	mem 38886MB
Train: [123/180][500/625]	eta 0:01:58 lr 0.177513	data 0.0005 (0.0419)	batch 0.8835 (0.9493)	loss 2.8658 (2.7527)	grad_norm 0.6491 (0.6155)	mem 38886MB
Train: [123/180][550/625]	eta 0:01:10 lr 0.177049	data 0.0005 (0.0382)	batch 0.9119 (0.9449)	loss 2.6975 (2.7549)	grad_norm 0.6311 (0.6156)	mem 38886MB
Train: [123/180][600/625]	eta 0:00:23 lr 0.176586	data 0.0005 (0.0350)	batch 0.9263 (0.9418)	loss 2.7850 (2.7554)	grad_norm 0.6139 (0.6158)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 123 training takes 0:09:49
Test: [0/25]	Time 14.806 (14.806)	Loss 1.0365 (1.0365)	Acc@1 77.832 (77.832)	Acc@5 92.871 (92.871)	Mem 38886MB
 * Acc@1 66.372 Acc@5 87.208
Accuracy of the network on the 50000 test images: 66.37%
Max accuracy (after decay): 66.46%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [124/180][0/625]	eta 4:00:08 lr 0.176354	data 21.8378 (21.8378)	batch 23.0538 (23.0538)	loss 2.6940 (2.6940)	grad_norm 0.6013 (0.6013)	mem 38886MB
Train: [124/180][50/625]	eta 0:12:51 lr 0.175891	data 0.0005 (0.4290)	batch 0.9072 (1.3413)	loss 2.7578 (2.7411)	grad_norm 0.6268 (0.6132)	mem 38886MB
Train: [124/180][100/625]	eta 0:09:51 lr 0.175429	data 0.0004 (0.2169)	batch 0.8657 (1.1273)	loss 2.5685 (2.7415)	grad_norm 0.6072 (0.6151)	mem 38886MB
Train: [124/180][150/625]	eta 0:08:20 lr 0.174967	data 0.0005 (0.1453)	batch 0.9129 (1.0538)	loss 2.7148 (2.7407)	grad_norm 0.6237 (0.6166)	mem 38886MB
Train: [124/180][200/625]	eta 0:07:11 lr 0.174506	data 0.0005 (0.1093)	batch 0.9064 (1.0163)	loss 2.5407 (2.7407)	grad_norm 0.6023 (0.6173)	mem 38886MB
Train: [124/180][250/625]	eta 0:06:13 lr 0.174044	data 0.0006 (0.0876)	batch 0.8882 (0.9950)	loss 2.8569 (2.7427)	grad_norm 0.6227 (0.6187)	mem 38886MB
Train: [124/180][300/625]	eta 0:05:18 lr 0.173584	data 0.0005 (0.0731)	batch 0.9208 (0.9808)	loss 2.8957 (2.7445)	grad_norm 0.6153 (0.6185)	mem 38886MB
Train: [124/180][350/625]	eta 0:04:26 lr 0.173124	data 0.0005 (0.0628)	batch 0.9421 (0.9706)	loss 2.7117 (2.7453)	grad_norm 0.6273 (0.6186)	mem 38886MB
Train: [124/180][400/625]	eta 0:03:36 lr 0.172664	data 0.0005 (0.0550)	batch 0.8720 (0.9635)	loss 2.7621 (2.7421)	grad_norm 0.6142 (0.6186)	mem 38886MB
Train: [124/180][450/625]	eta 0:02:47 lr 0.172205	data 0.0007 (0.0490)	batch 0.8509 (0.9565)	loss 2.7117 (2.7433)	grad_norm 0.6371 (0.6189)	mem 38886MB
Train: [124/180][500/625]	eta 0:01:59 lr 0.171746	data 0.0006 (0.0442)	batch 0.8637 (0.9520)	loss 2.7868 (2.7429)	grad_norm 0.6203 (0.6190)	mem 38886MB
Train: [124/180][550/625]	eta 0:01:11 lr 0.171288	data 0.0006 (0.0403)	batch 0.8827 (0.9480)	loss 2.7813 (2.7458)	grad_norm 0.6166 (0.6190)	mem 38886MB
Train: [124/180][600/625]	eta 0:00:23 lr 0.170830	data 0.0005 (0.0370)	batch 0.9034 (0.9444)	loss 2.5140 (2.7464)	grad_norm 0.6174 (0.6188)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 124 training takes 0:09:50
Test: [0/25]	Time 14.865 (14.865)	Loss 1.0185 (1.0185)	Acc@1 77.148 (77.148)	Acc@5 93.359 (93.359)	Mem 38886MB
 * Acc@1 66.598 Acc@5 87.150
Accuracy of the network on the 50000 test images: 66.60%
Max accuracy (after decay): 66.60%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [125/180][0/625]	eta 3:59:57 lr 0.170601	data 21.4107 (21.4107)	batch 23.0361 (23.0361)	loss 2.6797 (2.6797)	grad_norm 0.6135 (0.6135)	mem 38886MB
Train: [125/180][50/625]	eta 0:12:52 lr 0.170144	data 0.0007 (0.4206)	batch 0.9530 (1.3427)	loss 2.5994 (2.7092)	grad_norm 0.6126 (0.6205)	mem 38886MB
Train: [125/180][100/625]	eta 0:09:51 lr 0.169687	data 0.0006 (0.2128)	batch 0.9110 (1.1265)	loss 2.7284 (2.7102)	grad_norm 0.6287 (0.6205)	mem 38886MB
Train: [125/180][150/625]	eta 0:08:20 lr 0.169230	data 0.0007 (0.1426)	batch 0.9125 (1.0547)	loss 2.9924 (2.7122)	grad_norm 0.6250 (0.6204)	mem 38886MB
Train: [125/180][200/625]	eta 0:07:12 lr 0.168775	data 0.0005 (0.1073)	batch 0.9100 (1.0176)	loss 2.8296 (2.7235)	grad_norm 0.6301 (0.6211)	mem 38886MB
Train: [125/180][250/625]	eta 0:06:12 lr 0.168319	data 0.0003 (0.0860)	batch 0.9143 (0.9941)	loss 2.6962 (2.7248)	grad_norm 0.6020 (0.6216)	mem 38886MB
Train: [125/180][300/625]	eta 0:05:18 lr 0.167864	data 0.0005 (0.0719)	batch 0.8511 (0.9790)	loss 2.7162 (2.7270)	grad_norm 0.6149 (0.6214)	mem 38886MB
Train: [125/180][350/625]	eta 0:04:26 lr 0.167410	data 0.0006 (0.0617)	batch 0.9144 (0.9684)	loss 2.8565 (2.7308)	grad_norm 0.6065 (0.6216)	mem 38886MB
Train: [125/180][400/625]	eta 0:03:36 lr 0.166955	data 0.0005 (0.0541)	batch 1.1584 (0.9620)	loss 2.6589 (2.7348)	grad_norm 0.6156 (0.6220)	mem 38886MB
Train: [125/180][450/625]	eta 0:02:47 lr 0.166502	data 0.0004 (0.0481)	batch 0.8912 (0.9556)	loss 2.6576 (2.7381)	grad_norm 0.6221 (0.6222)	mem 38886MB
Train: [125/180][500/625]	eta 0:01:58 lr 0.166049	data 0.0003 (0.0434)	batch 0.8897 (0.9506)	loss 2.8076 (2.7370)	grad_norm 0.6388 (0.6224)	mem 38886MB
Train: [125/180][550/625]	eta 0:01:10 lr 0.165596	data 0.0005 (0.0395)	batch 0.9285 (0.9462)	loss 2.6858 (2.7386)	grad_norm 0.6124 (0.6225)	mem 38886MB
Train: [125/180][600/625]	eta 0:00:23 lr 0.165144	data 0.0004 (0.0363)	batch 0.9347 (0.9427)	loss 2.7202 (2.7391)	grad_norm 0.6204 (0.6225)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 125 training takes 0:09:49
Test: [0/25]	Time 14.681 (14.681)	Loss 1.0069 (1.0069)	Acc@1 77.246 (77.246)	Acc@5 93.262 (93.262)	Mem 38886MB
 * Acc@1 66.544 Acc@5 87.180
Accuracy of the network on the 50000 test images: 66.54%
Max accuracy (after decay): 66.60%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [126/180][0/625]	eta 3:57:47 lr 0.164918	data 20.9543 (20.9543)	batch 22.8285 (22.8285)	loss 2.9062 (2.9062)	grad_norm 0.6222 (0.6222)	mem 38886MB
Train: [126/180][50/625]	eta 0:12:50 lr 0.164466	data 0.0013 (0.4116)	batch 0.9164 (1.3406)	loss 2.8662 (2.7353)	grad_norm 0.6171 (0.6206)	mem 38886MB
Train: [126/180][100/625]	eta 0:09:50 lr 0.164015	data 0.0008 (0.2082)	batch 0.8767 (1.1246)	loss 2.6899 (2.7467)	grad_norm 0.6204 (0.6232)	mem 38886MB
Train: [126/180][150/625]	eta 0:08:21 lr 0.163564	data 0.0008 (0.1396)	batch 1.1215 (1.0564)	loss 2.5732 (2.7373)	grad_norm 0.6136 (0.6227)	mem 38886MB
Train: [126/180][200/625]	eta 0:07:12 lr 0.163114	data 0.0008 (0.1050)	batch 0.8803 (1.0186)	loss 2.9370 (2.7402)	grad_norm 0.6378 (0.6245)	mem 38886MB
Train: [126/180][250/625]	eta 0:06:13 lr 0.162664	data 0.0006 (0.0843)	batch 0.8951 (0.9972)	loss 2.7454 (2.7365)	grad_norm 0.6299 (0.6249)	mem 38886MB
Train: [126/180][300/625]	eta 0:05:18 lr 0.162215	data 0.0006 (0.0704)	batch 0.8788 (0.9811)	loss 2.6792 (2.7383)	grad_norm 0.6166 (0.6252)	mem 38886MB
Train: [126/180][350/625]	eta 0:04:26 lr 0.161766	data 0.0006 (0.0605)	batch 0.9562 (0.9703)	loss 2.8510 (2.7375)	grad_norm 0.6290 (0.6257)	mem 38886MB
Train: [126/180][400/625]	eta 0:03:36 lr 0.161318	data 0.0007 (0.0530)	batch 0.8899 (0.9634)	loss 2.9707 (2.7405)	grad_norm 0.6316 (0.6259)	mem 38886MB
Train: [126/180][450/625]	eta 0:02:47 lr 0.160870	data 0.0013 (0.0474)	batch 0.9205 (0.9572)	loss 2.7322 (2.7412)	grad_norm 0.6339 (0.6258)	mem 38886MB
Train: [126/180][500/625]	eta 0:01:58 lr 0.160423	data 0.0007 (0.0427)	batch 0.8930 (0.9517)	loss 2.6243 (2.7433)	grad_norm 0.6371 (0.6261)	mem 38886MB
Train: [126/180][550/625]	eta 0:01:11 lr 0.159976	data 0.0006 (0.0389)	batch 0.9308 (0.9475)	loss 2.5882 (2.7406)	grad_norm 0.6817 (0.6262)	mem 38886MB
Train: [126/180][600/625]	eta 0:00:23 lr 0.159529	data 0.0009 (0.0357)	batch 0.8882 (0.9442)	loss 2.7840 (2.7401)	grad_norm 0.6326 (0.6262)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 126 training takes 0:09:50
Test: [0/25]	Time 14.983 (14.983)	Loss 0.9769 (0.9769)	Acc@1 78.809 (78.809)	Acc@5 92.822 (92.822)	Mem 38886MB
 * Acc@1 66.742 Acc@5 87.356
Accuracy of the network on the 50000 test images: 66.74%
Max accuracy (after decay): 66.74%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [127/180][0/625]	eta 3:57:45 lr 0.159306	data 20.8592 (20.8592)	batch 22.8246 (22.8246)	loss 2.7620 (2.7620)	grad_norm 0.6074 (0.6074)	mem 38886MB
Train: [127/180][50/625]	eta 0:12:53 lr 0.158860	data 0.0009 (0.4097)	batch 0.8903 (1.3453)	loss 2.8357 (2.7259)	grad_norm 0.6211 (0.6224)	mem 38886MB
Train: [127/180][100/625]	eta 0:09:52 lr 0.158415	data 0.0005 (0.2072)	batch 0.9001 (1.1290)	loss 2.7123 (2.7243)	grad_norm 0.6213 (0.6241)	mem 38886MB
Train: [127/180][150/625]	eta 0:08:21 lr 0.157970	data 0.0006 (0.1389)	batch 0.9075 (1.0567)	loss 2.6694 (2.7221)	grad_norm 0.6266 (0.6260)	mem 38886MB
Train: [127/180][200/625]	eta 0:07:13 lr 0.157526	data 0.0006 (0.1045)	batch 0.9074 (1.0202)	loss 2.5727 (2.7197)	grad_norm 0.6275 (0.6265)	mem 38886MB
Train: [127/180][250/625]	eta 0:06:14 lr 0.157082	data 0.0006 (0.0838)	batch 0.8924 (0.9992)	loss 2.8535 (2.7233)	grad_norm 0.6243 (0.6273)	mem 38886MB
Train: [127/180][300/625]	eta 0:05:20 lr 0.156638	data 0.0007 (0.0700)	batch 0.8949 (0.9857)	loss 2.7804 (2.7297)	grad_norm 0.6350 (0.6280)	mem 38886MB
Train: [127/180][350/625]	eta 0:04:28 lr 0.156195	data 0.0008 (0.0601)	batch 0.8817 (0.9746)	loss 2.7364 (2.7288)	grad_norm 0.6043 (0.6282)	mem 38886MB
Train: [127/180][400/625]	eta 0:03:37 lr 0.155753	data 0.0008 (0.0527)	batch 0.8899 (0.9662)	loss 2.8207 (2.7327)	grad_norm 0.6240 (0.6285)	mem 38886MB
Train: [127/180][450/625]	eta 0:02:47 lr 0.155311	data 0.0007 (0.0470)	batch 0.8772 (0.9597)	loss 2.7644 (2.7314)	grad_norm 0.6252 (0.6284)	mem 38886MB
Train: [127/180][500/625]	eta 0:01:59 lr 0.154869	data 0.0007 (0.0423)	batch 0.8754 (0.9541)	loss 2.6554 (2.7309)	grad_norm 0.6151 (0.6285)	mem 38886MB
Train: [127/180][550/625]	eta 0:01:11 lr 0.154428	data 0.0008 (0.0386)	batch 1.0254 (0.9503)	loss 2.7586 (2.7323)	grad_norm 0.6225 (0.6286)	mem 38886MB
Train: [127/180][600/625]	eta 0:00:23 lr 0.153988	data 0.0005 (0.0354)	batch 0.9107 (0.9469)	loss 2.7290 (2.7326)	grad_norm 0.6325 (0.6286)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 127 training takes 0:09:52
Test: [0/25]	Time 14.826 (14.826)	Loss 1.0083 (1.0083)	Acc@1 77.588 (77.588)	Acc@5 93.457 (93.457)	Mem 38886MB
 * Acc@1 66.968 Acc@5 87.444
Accuracy of the network on the 50000 test images: 66.97%
Max accuracy (after decay): 66.97%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [128/180][0/625]	eta 4:00:56 lr 0.153768	data 22.1551 (22.1551)	batch 23.1301 (23.1301)	loss 2.8050 (2.8050)	grad_norm 0.6299 (0.6299)	mem 38886MB
Train: [128/180][50/625]	eta 0:13:00 lr 0.153328	data 0.0006 (0.4354)	batch 0.8959 (1.3569)	loss 2.6045 (2.7366)	grad_norm 0.6459 (0.6288)	mem 38886MB
Train: [128/180][100/625]	eta 0:09:55 lr 0.152889	data 0.0006 (0.2202)	batch 0.9227 (1.1338)	loss 2.6480 (2.7220)	grad_norm 0.6297 (0.6292)	mem 38886MB
Train: [128/180][150/625]	eta 0:08:22 lr 0.152450	data 0.0007 (0.1476)	batch 0.8855 (1.0588)	loss 2.6816 (2.7217)	grad_norm 0.6358 (0.6303)	mem 38886MB
Train: [128/180][200/625]	eta 0:07:14 lr 0.152011	data 0.0006 (0.1110)	batch 0.9183 (1.0220)	loss 2.7316 (2.7250)	grad_norm 0.6240 (0.6300)	mem 38886MB
Train: [128/180][250/625]	eta 0:06:14 lr 0.151573	data 0.0007 (0.0891)	batch 0.8949 (0.9984)	loss 2.6150 (2.7265)	grad_norm 0.6324 (0.6312)	mem 38886MB
Train: [128/180][300/625]	eta 0:05:19 lr 0.151136	data 0.0009 (0.0744)	batch 0.9075 (0.9838)	loss 2.6820 (2.7285)	grad_norm 0.6153 (0.6313)	mem 38886MB
Train: [128/180][350/625]	eta 0:04:27 lr 0.150699	data 0.0006 (0.0639)	batch 0.9097 (0.9725)	loss 2.6173 (2.7273)	grad_norm 0.6177 (0.6313)	mem 38886MB
Train: [128/180][400/625]	eta 0:03:37 lr 0.150262	data 0.0013 (0.0560)	batch 0.8797 (0.9648)	loss 2.6686 (2.7258)	grad_norm 0.6342 (0.6318)	mem 38886MB
Train: [128/180][450/625]	eta 0:02:47 lr 0.149826	data 0.0020 (0.0499)	batch 0.9123 (0.9588)	loss 2.7959 (2.7276)	grad_norm 0.6331 (0.6322)	mem 38886MB
Train: [128/180][500/625]	eta 0:01:59 lr 0.149391	data 0.0007 (0.0450)	batch 0.8588 (0.9536)	loss 2.6611 (2.7281)	grad_norm 0.6325 (0.6328)	mem 38886MB
Train: [128/180][550/625]	eta 0:01:11 lr 0.148956	data 0.0008 (0.0410)	batch 0.8953 (0.9489)	loss 2.8377 (2.7272)	grad_norm 0.6224 (0.6329)	mem 38886MB
Train: [128/180][600/625]	eta 0:00:23 lr 0.148522	data 0.0006 (0.0376)	batch 0.8892 (0.9450)	loss 2.7565 (2.7289)	grad_norm 0.6293 (0.6331)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 128 training takes 0:09:51
Test: [0/25]	Time 14.711 (14.711)	Loss 0.9901 (0.9901)	Acc@1 78.418 (78.418)	Acc@5 93.018 (93.018)	Mem 38886MB
 * Acc@1 66.868 Acc@5 87.272
Accuracy of the network on the 50000 test images: 66.87%
Max accuracy (after decay): 66.97%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [129/180][0/625]	eta 4:03:58 lr 0.148304	data 21.7752 (21.7752)	batch 23.4219 (23.4219)	loss 2.7813 (2.7813)	grad_norm 0.6198 (0.6198)	mem 38886MB
Train: [129/180][50/625]	eta 0:13:01 lr 0.147871	data 0.0004 (0.4278)	batch 1.1573 (1.3599)	loss 2.6924 (2.7162)	grad_norm 0.6372 (0.6319)	mem 38886MB
Train: [129/180][100/625]	eta 0:09:56 lr 0.147437	data 0.0005 (0.2163)	batch 0.9432 (1.1357)	loss 2.6560 (2.7164)	grad_norm 0.6293 (0.6340)	mem 38886MB
Train: [129/180][150/625]	eta 0:08:24 lr 0.147005	data 0.0005 (0.1448)	batch 0.9131 (1.0622)	loss 2.7766 (2.7124)	grad_norm 0.6369 (0.6360)	mem 38886MB
Train: [129/180][200/625]	eta 0:07:16 lr 0.146572	data 0.0005 (0.1089)	batch 0.9029 (1.0260)	loss 2.8451 (2.7140)	grad_norm 0.6306 (0.6357)	mem 38886MB
Train: [129/180][250/625]	eta 0:06:16 lr 0.146140	data 0.0005 (0.0873)	batch 0.9000 (1.0030)	loss 2.6824 (2.7215)	grad_norm 0.6583 (0.6357)	mem 38886MB
Train: [129/180][300/625]	eta 0:05:21 lr 0.145709	data 0.0005 (0.0729)	batch 0.9263 (0.9879)	loss 2.7447 (2.7206)	grad_norm 0.6317 (0.6359)	mem 38886MB
Train: [129/180][350/625]	eta 0:04:28 lr 0.145278	data 0.0006 (0.0626)	batch 0.9093 (0.9768)	loss 2.8332 (2.7221)	grad_norm 0.6356 (0.6360)	mem 38886MB
Train: [129/180][400/625]	eta 0:03:37 lr 0.144848	data 0.0005 (0.0549)	batch 0.9009 (0.9680)	loss 2.6015 (2.7253)	grad_norm 0.6245 (0.6360)	mem 38886MB
Train: [129/180][450/625]	eta 0:02:48 lr 0.144418	data 0.0005 (0.0489)	batch 0.8982 (0.9623)	loss 2.7376 (2.7273)	grad_norm 0.6310 (0.6364)	mem 38886MB
Train: [129/180][500/625]	eta 0:01:59 lr 0.143989	data 0.0005 (0.0440)	batch 0.8752 (0.9566)	loss 2.6280 (2.7275)	grad_norm 0.6166 (0.6364)	mem 38886MB
Train: [129/180][550/625]	eta 0:01:11 lr 0.143560	data 0.0005 (0.0401)	batch 0.9221 (0.9523)	loss 2.7262 (2.7297)	grad_norm 0.6413 (0.6367)	mem 38886MB
Train: [129/180][600/625]	eta 0:00:23 lr 0.143132	data 0.0005 (0.0368)	batch 0.9358 (0.9485)	loss 2.8912 (2.7314)	grad_norm 0.6476 (0.6371)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 129 training takes 0:09:53
Test: [0/25]	Time 14.839 (14.839)	Loss 1.0034 (1.0034)	Acc@1 78.320 (78.320)	Acc@5 93.750 (93.750)	Mem 38886MB
 * Acc@1 66.782 Acc@5 87.242
Accuracy of the network on the 50000 test images: 66.78%
Max accuracy (after decay): 66.97%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [130/180][0/625]	eta 3:58:29 lr 0.142918	data 21.4266 (21.4266)	batch 22.8959 (22.8959)	loss 2.6493 (2.6493)	grad_norm 0.6220 (0.6220)	mem 38886MB
Train: [130/180][50/625]	eta 0:12:53 lr 0.142490	data 0.0005 (0.4208)	batch 0.9005 (1.3447)	loss 2.7049 (2.6910)	grad_norm 0.6278 (0.6364)	mem 38886MB
Train: [130/180][100/625]	eta 0:09:52 lr 0.142063	data 0.0005 (0.2128)	batch 0.8732 (1.1287)	loss 2.6558 (2.7009)	grad_norm 0.6426 (0.6360)	mem 38886MB
Train: [130/180][150/625]	eta 0:08:21 lr 0.141637	data 0.0004 (0.1425)	batch 0.8981 (1.0560)	loss 2.6900 (2.7061)	grad_norm 0.6431 (0.6367)	mem 38886MB
Train: [130/180][200/625]	eta 0:07:13 lr 0.141211	data 0.0006 (0.1072)	batch 0.8779 (1.0198)	loss 2.6568 (2.7077)	grad_norm 0.6213 (0.6379)	mem 38886MB
Train: [130/180][250/625]	eta 0:06:13 lr 0.140785	data 0.0008 (0.0861)	batch 0.9002 (0.9970)	loss 2.8394 (2.7084)	grad_norm 0.6285 (0.6381)	mem 38886MB
Train: [130/180][300/625]	eta 0:05:19 lr 0.140360	data 0.0005 (0.0720)	batch 0.8948 (0.9827)	loss 2.5741 (2.7090)	grad_norm 0.6347 (0.6381)	mem 38886MB
Train: [130/180][350/625]	eta 0:04:27 lr 0.139935	data 0.0004 (0.0618)	batch 0.9096 (0.9713)	loss 2.8432 (2.7137)	grad_norm 0.6408 (0.6383)	mem 38886MB
Train: [130/180][400/625]	eta 0:03:36 lr 0.139511	data 0.0006 (0.0542)	batch 0.9123 (0.9633)	loss 2.7878 (2.7117)	grad_norm 0.6361 (0.6383)	mem 38886MB
Train: [130/180][450/625]	eta 0:02:47 lr 0.139088	data 0.0008 (0.0483)	batch 0.8824 (0.9577)	loss 2.6662 (2.7126)	grad_norm 0.6505 (0.6384)	mem 38886MB
Train: [130/180][500/625]	eta 0:01:59 lr 0.138665	data 0.0007 (0.0435)	batch 0.9584 (0.9530)	loss 2.7309 (2.7141)	grad_norm 0.6376 (0.6387)	mem 38886MB
Train: [130/180][550/625]	eta 0:01:11 lr 0.138242	data 0.0005 (0.0396)	batch 0.9207 (0.9497)	loss 2.7647 (2.7175)	grad_norm 0.6519 (0.6389)	mem 38886MB
Train: [130/180][600/625]	eta 0:00:23 lr 0.137820	data 0.0004 (0.0364)	batch 0.9007 (0.9462)	loss 2.7845 (2.7176)	grad_norm 0.6259 (0.6388)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 130 training takes 0:09:51
Test: [0/25]	Time 14.933 (14.933)	Loss 0.9766 (0.9766)	Acc@1 78.662 (78.662)	Acc@5 93.262 (93.262)	Mem 38886MB
 * Acc@1 67.290 Acc@5 87.652
Accuracy of the network on the 50000 test images: 67.29%
Max accuracy (after decay): 67.29%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [131/180][0/625]	eta 3:54:45 lr 0.137610	data 20.2444 (20.2444)	batch 22.5364 (22.5364)	loss 2.5765 (2.5765)	grad_norm 0.6465 (0.6465)	mem 38886MB
Train: [131/180][50/625]	eta 0:12:43 lr 0.137188	data 0.0004 (0.3976)	batch 0.9238 (1.3279)	loss 2.7845 (2.6606)	grad_norm 0.6515 (0.6378)	mem 38886MB
Train: [131/180][100/625]	eta 0:09:48 lr 0.136768	data 0.0008 (0.2011)	batch 0.9174 (1.1208)	loss 2.5706 (2.6746)	grad_norm 0.6269 (0.6414)	mem 38886MB
Train: [131/180][150/625]	eta 0:08:19 lr 0.136347	data 0.0005 (0.1347)	batch 0.9040 (1.0505)	loss 2.7469 (2.6843)	grad_norm 0.6291 (0.6417)	mem 38886MB
Train: [131/180][200/625]	eta 0:07:11 lr 0.135928	data 0.0007 (0.1013)	batch 0.8890 (1.0149)	loss 2.6719 (2.6909)	grad_norm 0.6700 (0.6426)	mem 38886MB
Train: [131/180][250/625]	eta 0:06:12 lr 0.135508	data 0.0006 (0.0812)	batch 0.9313 (0.9939)	loss 2.6994 (2.6901)	grad_norm 0.6284 (0.6428)	mem 38886MB
Train: [131/180][300/625]	eta 0:05:18 lr 0.135090	data 0.0005 (0.0678)	batch 0.8871 (0.9785)	loss 2.7766 (2.6979)	grad_norm 0.6386 (0.6429)	mem 38886MB
Train: [131/180][350/625]	eta 0:04:26 lr 0.134672	data 0.0005 (0.0583)	batch 0.8687 (0.9690)	loss 2.7186 (2.6947)	grad_norm 0.6307 (0.6430)	mem 38886MB
Train: [131/180][400/625]	eta 0:03:36 lr 0.134254	data 0.0006 (0.0511)	batch 0.8580 (0.9618)	loss 2.6826 (2.7022)	grad_norm 0.6590 (0.6429)	mem 38886MB
Train: [131/180][450/625]	eta 0:02:47 lr 0.133837	data 0.0004 (0.0455)	batch 0.8738 (0.9563)	loss 2.6902 (2.7009)	grad_norm 0.6250 (0.6430)	mem 38886MB
Train: [131/180][500/625]	eta 0:01:58 lr 0.133420	data 0.0004 (0.0410)	batch 0.8920 (0.9513)	loss 2.8331 (2.7044)	grad_norm 0.6366 (0.6429)	mem 38886MB
Train: [131/180][550/625]	eta 0:01:11 lr 0.133004	data 0.0004 (0.0373)	batch 0.9184 (0.9470)	loss 2.8216 (2.7073)	grad_norm 0.6499 (0.6433)	mem 38886MB
Train: [131/180][600/625]	eta 0:00:23 lr 0.132589	data 0.0004 (0.0342)	batch 0.8975 (0.9447)	loss 2.7979 (2.7092)	grad_norm 0.6531 (0.6433)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 131 training takes 0:09:50
Test: [0/25]	Time 14.732 (14.732)	Loss 0.9713 (0.9713)	Acc@1 78.076 (78.076)	Acc@5 93.311 (93.311)	Mem 38886MB
 * Acc@1 67.310 Acc@5 87.466
Accuracy of the network on the 50000 test images: 67.31%
Max accuracy (after decay): 67.31%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [132/180][0/625]	eta 3:59:09 lr 0.132381	data 20.9414 (20.9414)	batch 22.9593 (22.9593)	loss 2.5663 (2.5663)	grad_norm 0.6396 (0.6396)	mem 38886MB
Train: [132/180][50/625]	eta 0:12:51 lr 0.131966	data 0.0004 (0.4118)	batch 0.9604 (1.3421)	loss 2.5624 (2.7050)	grad_norm 0.6336 (0.6418)	mem 38886MB
Train: [132/180][100/625]	eta 0:09:52 lr 0.131552	data 0.0008 (0.2082)	batch 0.9112 (1.1281)	loss 2.6557 (2.7015)	grad_norm 0.6270 (0.6423)	mem 38886MB
Train: [132/180][150/625]	eta 0:08:21 lr 0.131138	data 0.0006 (0.1395)	batch 0.8734 (1.0553)	loss 2.6059 (2.6963)	grad_norm 0.6451 (0.6429)	mem 38886MB
Train: [132/180][200/625]	eta 0:07:13 lr 0.130725	data 0.0005 (0.1049)	batch 0.8916 (1.0195)	loss 2.7088 (2.6962)	grad_norm 0.6416 (0.6433)	mem 38886MB
Train: [132/180][250/625]	eta 0:06:14 lr 0.130313	data 0.0004 (0.0843)	batch 0.9130 (0.9976)	loss 2.7090 (2.6964)	grad_norm 0.6407 (0.6434)	mem 38886MB
Train: [132/180][300/625]	eta 0:05:19 lr 0.129900	data 0.0006 (0.0704)	batch 0.9203 (0.9825)	loss 2.9833 (2.7014)	grad_norm 0.6541 (0.6434)	mem 38886MB
Train: [132/180][350/625]	eta 0:04:27 lr 0.129489	data 0.0006 (0.0604)	batch 0.8879 (0.9727)	loss 2.7792 (2.7051)	grad_norm 0.6482 (0.6444)	mem 38886MB
Train: [132/180][400/625]	eta 0:03:37 lr 0.129078	data 0.0006 (0.0530)	batch 0.9205 (0.9652)	loss 2.6053 (2.7062)	grad_norm 0.6372 (0.6445)	mem 38886MB
Train: [132/180][450/625]	eta 0:02:47 lr 0.128667	data 0.0007 (0.0472)	batch 0.9050 (0.9587)	loss 2.8216 (2.7105)	grad_norm 0.6702 (0.6452)	mem 38886MB
Train: [132/180][500/625]	eta 0:01:59 lr 0.128257	data 0.0005 (0.0425)	batch 0.9096 (0.9529)	loss 2.5368 (2.7119)	grad_norm 0.6378 (0.6456)	mem 38886MB
Train: [132/180][550/625]	eta 0:01:11 lr 0.127848	data 0.0007 (0.0387)	batch 0.8967 (0.9486)	loss 2.8844 (2.7129)	grad_norm 0.6504 (0.6458)	mem 38886MB
Train: [132/180][600/625]	eta 0:00:23 lr 0.127439	data 0.0005 (0.0355)	batch 0.8994 (0.9454)	loss 2.8459 (2.7122)	grad_norm 0.6504 (0.6462)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 132 training takes 0:09:51
Test: [0/25]	Time 14.803 (14.803)	Loss 0.9576 (0.9576)	Acc@1 77.832 (77.832)	Acc@5 93.457 (93.457)	Mem 38886MB
 * Acc@1 67.356 Acc@5 87.648
Accuracy of the network on the 50000 test images: 67.36%
Max accuracy (after decay): 67.36%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [133/180][0/625]	eta 3:55:24 lr 0.127234	data 21.3716 (21.3716)	batch 22.6000 (22.6000)	loss 2.6043 (2.6043)	grad_norm 0.6562 (0.6562)	mem 38886MB
Train: [133/180][50/625]	eta 0:12:47 lr 0.126826	data 0.0006 (0.4197)	batch 0.8969 (1.3354)	loss 2.5350 (2.6797)	grad_norm 0.6349 (0.6453)	mem 38886MB
Train: [133/180][100/625]	eta 0:09:49 lr 0.126418	data 0.0005 (0.2122)	batch 0.8939 (1.1233)	loss 2.8480 (2.6998)	grad_norm 0.6397 (0.6472)	mem 38886MB
Train: [133/180][150/625]	eta 0:08:19 lr 0.126011	data 0.0006 (0.1421)	batch 0.8659 (1.0516)	loss 2.6459 (2.6922)	grad_norm 0.6442 (0.6476)	mem 38886MB
Train: [133/180][200/625]	eta 0:07:13 lr 0.125605	data 0.0005 (0.1069)	batch 0.8865 (1.0192)	loss 2.7031 (2.6939)	grad_norm 0.6400 (0.6477)	mem 38886MB
Train: [133/180][250/625]	eta 0:06:13 lr 0.125199	data 0.0006 (0.0857)	batch 0.8735 (0.9969)	loss 2.7480 (2.6963)	grad_norm 0.6433 (0.6481)	mem 38886MB
Train: [133/180][300/625]	eta 0:05:18 lr 0.124793	data 0.0005 (0.0716)	batch 0.9058 (0.9815)	loss 2.8445 (2.7010)	grad_norm 0.6450 (0.6481)	mem 38886MB
Train: [133/180][350/625]	eta 0:04:27 lr 0.124388	data 0.0005 (0.0615)	batch 0.9232 (0.9719)	loss 2.6714 (2.7039)	grad_norm 0.6296 (0.6487)	mem 38886MB
Train: [133/180][400/625]	eta 0:03:36 lr 0.123984	data 0.0007 (0.0539)	batch 0.9342 (0.9641)	loss 2.8613 (2.7044)	grad_norm 0.6590 (0.6492)	mem 38886MB
Train: [133/180][450/625]	eta 0:02:47 lr 0.123580	data 0.0006 (0.0480)	batch 0.8795 (0.9581)	loss 2.8540 (2.7047)	grad_norm 0.6460 (0.6496)	mem 38886MB
Train: [133/180][500/625]	eta 0:01:59 lr 0.123177	data 0.0005 (0.0432)	batch 0.9126 (0.9533)	loss 2.4871 (2.7054)	grad_norm 0.6553 (0.6501)	mem 38886MB
Train: [133/180][550/625]	eta 0:01:11 lr 0.122774	data 0.0004 (0.0394)	batch 0.9357 (0.9491)	loss 2.5987 (2.7074)	grad_norm 0.6425 (0.6503)	mem 38886MB
Train: [133/180][600/625]	eta 0:00:23 lr 0.122371	data 0.0007 (0.0361)	batch 0.8843 (0.9461)	loss 2.8295 (2.7067)	grad_norm 0.6458 (0.6506)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 133 training takes 0:09:51
Test: [0/25]	Time 14.942 (14.942)	Loss 0.9781 (0.9781)	Acc@1 78.662 (78.662)	Acc@5 93.604 (93.604)	Mem 38886MB
 * Acc@1 67.352 Acc@5 87.622
Accuracy of the network on the 50000 test images: 67.35%
Max accuracy (after decay): 67.36%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [134/180][0/625]	eta 3:59:32 lr 0.122171	data 21.5860 (21.5860)	batch 22.9961 (22.9961)	loss 2.6624 (2.6624)	grad_norm 0.6317 (0.6317)	mem 38886MB
Train: [134/180][50/625]	eta 0:12:54 lr 0.121769	data 0.0008 (0.4240)	batch 0.8759 (1.3469)	loss 2.6802 (2.6683)	grad_norm 0.6453 (0.6496)	mem 38886MB
Train: [134/180][100/625]	eta 0:09:53 lr 0.121368	data 0.0012 (0.2145)	batch 0.9195 (1.1305)	loss 2.5931 (2.6839)	grad_norm 0.6420 (0.6511)	mem 38886MB
Train: [134/180][150/625]	eta 0:08:20 lr 0.120968	data 0.0004 (0.1437)	batch 0.8859 (1.0538)	loss 2.6497 (2.6807)	grad_norm 0.6578 (0.6523)	mem 38886MB
Train: [134/180][200/625]	eta 0:07:12 lr 0.120568	data 0.0006 (0.1081)	batch 0.8920 (1.0180)	loss 2.8004 (2.6918)	grad_norm 0.6535 (0.6531)	mem 38886MB
Train: [134/180][250/625]	eta 0:06:13 lr 0.120169	data 0.0008 (0.0867)	batch 0.8926 (0.9947)	loss 2.5097 (2.6969)	grad_norm 0.6607 (0.6542)	mem 38886MB
Train: [134/180][300/625]	eta 0:05:18 lr 0.119770	data 0.0007 (0.0724)	batch 0.8790 (0.9804)	loss 2.7190 (2.6991)	grad_norm 0.6510 (0.6540)	mem 38886MB
Train: [134/180][350/625]	eta 0:04:27 lr 0.119372	data 0.0013 (0.0622)	batch 0.9044 (0.9716)	loss 2.5926 (2.7030)	grad_norm 0.6698 (0.6540)	mem 38886MB
Train: [134/180][400/625]	eta 0:03:36 lr 0.118974	data 0.0011 (0.0546)	batch 0.9251 (0.9630)	loss 2.8302 (2.7052)	grad_norm 0.6435 (0.6540)	mem 38886MB
Train: [134/180][450/625]	eta 0:02:47 lr 0.118577	data 0.0006 (0.0486)	batch 0.8802 (0.9579)	loss 2.6848 (2.7048)	grad_norm 0.6445 (0.6543)	mem 38886MB
Train: [134/180][500/625]	eta 0:01:59 lr 0.118180	data 0.0008 (0.0438)	batch 0.8965 (0.9525)	loss 2.7235 (2.7036)	grad_norm 0.6612 (0.6546)	mem 38886MB
Train: [134/180][550/625]	eta 0:01:11 lr 0.117784	data 0.0010 (0.0399)	batch 0.9070 (0.9474)	loss 2.9066 (2.7043)	grad_norm 0.6582 (0.6547)	mem 38886MB
Train: [134/180][600/625]	eta 0:00:23 lr 0.117389	data 0.0006 (0.0367)	batch 0.9344 (0.9436)	loss 2.8013 (2.7038)	grad_norm 0.6583 (0.6549)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 134 training takes 0:09:49
Test: [0/25]	Time 14.538 (14.538)	Loss 0.9584 (0.9584)	Acc@1 78.662 (78.662)	Acc@5 93.945 (93.945)	Mem 38886MB
 * Acc@1 67.082 Acc@5 87.600
Accuracy of the network on the 50000 test images: 67.08%
Max accuracy (after decay): 67.36%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [135/180][0/625]	eta 3:59:36 lr 0.117191	data 20.5854 (20.5854)	batch 23.0025 (23.0025)	loss 2.6033 (2.6033)	grad_norm 0.6318 (0.6318)	mem 38886MB
Train: [135/180][50/625]	eta 0:12:54 lr 0.116797	data 0.0008 (0.4043)	batch 1.0242 (1.3462)	loss 2.6517 (2.7038)	grad_norm 0.6634 (0.6530)	mem 38886MB
Train: [135/180][100/625]	eta 0:09:54 lr 0.116403	data 0.0008 (0.2045)	batch 0.9108 (1.1316)	loss 2.6026 (2.6854)	grad_norm 0.6420 (0.6547)	mem 38886MB
Train: [135/180][150/625]	eta 0:08:21 lr 0.116009	data 0.0006 (0.1370)	batch 0.8792 (1.0556)	loss 2.5962 (2.6860)	grad_norm 0.6506 (0.6546)	mem 38886MB
Train: [135/180][200/625]	eta 0:07:12 lr 0.115616	data 0.0013 (0.1031)	batch 0.9267 (1.0188)	loss 2.7837 (2.6911)	grad_norm 0.6592 (0.6555)	mem 38886MB
Train: [135/180][250/625]	eta 0:06:14 lr 0.115224	data 0.0005 (0.0827)	batch 0.9349 (0.9992)	loss 2.7164 (2.6972)	grad_norm 0.6517 (0.6565)	mem 38886MB
Train: [135/180][300/625]	eta 0:05:19 lr 0.114832	data 0.0008 (0.0691)	batch 0.8907 (0.9832)	loss 2.8045 (2.6982)	grad_norm 0.6544 (0.6569)	mem 38886MB
Train: [135/180][350/625]	eta 0:04:27 lr 0.114441	data 0.0006 (0.0593)	batch 0.9328 (0.9725)	loss 2.7745 (2.7018)	grad_norm 0.6476 (0.6572)	mem 38886MB
Train: [135/180][400/625]	eta 0:03:36 lr 0.114050	data 0.0007 (0.0520)	batch 0.9023 (0.9636)	loss 2.6609 (2.7032)	grad_norm 0.6431 (0.6573)	mem 38886MB
Train: [135/180][450/625]	eta 0:02:47 lr 0.113660	data 0.0007 (0.0463)	batch 0.9536 (0.9568)	loss 2.6552 (2.7017)	grad_norm 0.6616 (0.6573)	mem 38886MB
Train: [135/180][500/625]	eta 0:01:59 lr 0.113270	data 0.0010 (0.0418)	batch 0.8925 (0.9524)	loss 2.6214 (2.7043)	grad_norm 0.6346 (0.6574)	mem 38886MB
Train: [135/180][550/625]	eta 0:01:11 lr 0.112881	data 0.0007 (0.0381)	batch 0.9106 (0.9482)	loss 2.7044 (2.7053)	grad_norm 0.6557 (0.6576)	mem 38886MB
Train: [135/180][600/625]	eta 0:00:23 lr 0.112493	data 0.0009 (0.0350)	batch 0.8850 (0.9453)	loss 2.8773 (2.7055)	grad_norm 0.6695 (0.6576)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 135 training takes 0:09:51
Test: [0/25]	Time 14.827 (14.827)	Loss 0.9740 (0.9740)	Acc@1 78.760 (78.760)	Acc@5 93.164 (93.164)	Mem 38886MB
 * Acc@1 67.560 Acc@5 87.774
Accuracy of the network on the 50000 test images: 67.56%
Max accuracy (after decay): 67.56%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [136/180][0/625]	eta 4:05:46 lr 0.112298	data 22.0362 (22.0362)	batch 23.5947 (23.5947)	loss 2.5994 (2.5994)	grad_norm 0.6436 (0.6436)	mem 38886MB
Train: [136/180][50/625]	eta 0:13:01 lr 0.111911	data 0.0006 (0.4328)	batch 0.9382 (1.3584)	loss 2.8546 (2.6864)	grad_norm 0.6589 (0.6595)	mem 38886MB
Train: [136/180][100/625]	eta 0:09:56 lr 0.111524	data 0.0008 (0.2189)	batch 0.8705 (1.1363)	loss 2.6287 (2.6946)	grad_norm 0.6445 (0.6596)	mem 38886MB
Train: [136/180][150/625]	eta 0:08:23 lr 0.111137	data 0.0007 (0.1467)	batch 0.9752 (1.0603)	loss 2.5830 (2.6921)	grad_norm 0.6614 (0.6590)	mem 38886MB
Train: [136/180][200/625]	eta 0:07:13 lr 0.110751	data 0.0005 (0.1104)	batch 0.9284 (1.0206)	loss 2.4146 (2.6924)	grad_norm 0.6470 (0.6594)	mem 38886MB
Train: [136/180][250/625]	eta 0:06:14 lr 0.110366	data 0.0010 (0.0886)	batch 0.8619 (0.9988)	loss 2.7207 (2.6913)	grad_norm 0.6620 (0.6596)	mem 38886MB
Train: [136/180][300/625]	eta 0:05:19 lr 0.109981	data 0.0007 (0.0740)	batch 0.8720 (0.9834)	loss 2.8859 (2.6944)	grad_norm 0.6737 (0.6595)	mem 38886MB
Train: [136/180][350/625]	eta 0:04:27 lr 0.109597	data 0.0011 (0.0636)	batch 0.9042 (0.9736)	loss 2.7347 (2.6919)	grad_norm 0.6604 (0.6595)	mem 38886MB
Train: [136/180][400/625]	eta 0:03:36 lr 0.109213	data 0.0006 (0.0557)	batch 0.9081 (0.9644)	loss 2.7640 (2.6973)	grad_norm 0.6624 (0.6602)	mem 38886MB
Train: [136/180][450/625]	eta 0:02:47 lr 0.108830	data 0.0006 (0.0496)	batch 0.9504 (0.9579)	loss 2.7416 (2.6966)	grad_norm 0.6558 (0.6605)	mem 38886MB
Train: [136/180][500/625]	eta 0:01:59 lr 0.108447	data 0.0007 (0.0447)	batch 0.8720 (0.9526)	loss 2.6592 (2.6961)	grad_norm 0.6812 (0.6605)	mem 38886MB
Train: [136/180][550/625]	eta 0:01:11 lr 0.108065	data 0.0007 (0.0407)	batch 0.9287 (0.9483)	loss 2.9077 (2.6960)	grad_norm 0.6737 (0.6606)	mem 38886MB
Train: [136/180][600/625]	eta 0:00:23 lr 0.107684	data 0.0006 (0.0374)	batch 0.8725 (0.9445)	loss 3.0441 (2.6961)	grad_norm 0.6708 (0.6606)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 136 training takes 0:09:51
Test: [0/25]	Time 14.817 (14.817)	Loss 0.9652 (0.9652)	Acc@1 79.102 (79.102)	Acc@5 93.262 (93.262)	Mem 38886MB
 * Acc@1 67.544 Acc@5 87.706
Accuracy of the network on the 50000 test images: 67.54%
Max accuracy (after decay): 67.56%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [137/180][0/625]	eta 4:00:45 lr 0.107493	data 20.8576 (20.8576)	batch 23.1127 (23.1127)	loss 2.6211 (2.6211)	grad_norm 0.6577 (0.6577)	mem 38886MB
Train: [137/180][50/625]	eta 0:12:49 lr 0.107113	data 0.0006 (0.4098)	batch 0.8665 (1.3388)	loss 2.5315 (2.6710)	grad_norm 0.6545 (0.6588)	mem 38886MB
Train: [137/180][100/625]	eta 0:09:51 lr 0.106733	data 0.0005 (0.2072)	batch 0.9159 (1.1265)	loss 2.7802 (2.6829)	grad_norm 0.6634 (0.6617)	mem 38886MB
Train: [137/180][150/625]	eta 0:08:20 lr 0.106353	data 0.0005 (0.1388)	batch 0.8755 (1.0547)	loss 2.7112 (2.6807)	grad_norm 0.6599 (0.6607)	mem 38886MB
Train: [137/180][200/625]	eta 0:07:12 lr 0.105974	data 0.0005 (0.1044)	batch 0.8604 (1.0180)	loss 2.5224 (2.6798)	grad_norm 0.6692 (0.6621)	mem 38886MB
Train: [137/180][250/625]	eta 0:06:14 lr 0.105596	data 0.0005 (0.0838)	batch 0.9000 (0.9976)	loss 2.8203 (2.6862)	grad_norm 0.6579 (0.6622)	mem 38886MB
Train: [137/180][300/625]	eta 0:05:19 lr 0.105218	data 0.0005 (0.0700)	batch 0.9044 (0.9827)	loss 2.7975 (2.6824)	grad_norm 0.6640 (0.6624)	mem 38886MB
Train: [137/180][350/625]	eta 0:04:27 lr 0.104841	data 0.0004 (0.0601)	batch 0.8927 (0.9720)	loss 2.6085 (2.6857)	grad_norm 0.6646 (0.6627)	mem 38886MB
Train: [137/180][400/625]	eta 0:03:36 lr 0.104464	data 0.0005 (0.0527)	batch 0.9066 (0.9640)	loss 2.7555 (2.6908)	grad_norm 0.6833 (0.6629)	mem 38886MB
Train: [137/180][450/625]	eta 0:02:47 lr 0.104088	data 0.0005 (0.0469)	batch 0.8767 (0.9576)	loss 2.5673 (2.6919)	grad_norm 0.6683 (0.6631)	mem 38886MB
Train: [137/180][500/625]	eta 0:01:59 lr 0.103713	data 0.0005 (0.0423)	batch 0.8998 (0.9535)	loss 2.5396 (2.6930)	grad_norm 0.6755 (0.6635)	mem 38886MB
Train: [137/180][550/625]	eta 0:01:11 lr 0.103338	data 0.0005 (0.0385)	batch 0.8874 (0.9490)	loss 2.8072 (2.6937)	grad_norm 0.6787 (0.6637)	mem 38886MB
Train: [137/180][600/625]	eta 0:00:23 lr 0.102964	data 0.0005 (0.0353)	batch 0.9074 (0.9456)	loss 2.5294 (2.6923)	grad_norm 0.6615 (0.6638)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 137 training takes 0:09:51
Test: [0/25]	Time 14.726 (14.726)	Loss 0.9838 (0.9838)	Acc@1 79.004 (79.004)	Acc@5 93.213 (93.213)	Mem 38886MB
 * Acc@1 67.658 Acc@5 87.882
Accuracy of the network on the 50000 test images: 67.66%
Max accuracy (after decay): 67.66%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [138/180][0/625]	eta 3:54:18 lr 0.102777	data 20.7728 (20.7728)	batch 22.4940 (22.4940)	loss 2.6629 (2.6629)	grad_norm 0.6461 (0.6461)	mem 38886MB
Train: [138/180][50/625]	eta 0:12:44 lr 0.102404	data 0.0007 (0.4080)	batch 0.8641 (1.3302)	loss 2.6879 (2.6537)	grad_norm 0.6760 (0.6637)	mem 38886MB
Train: [138/180][100/625]	eta 0:09:49 lr 0.102031	data 0.0005 (0.2064)	batch 0.9253 (1.1220)	loss 2.8252 (2.6674)	grad_norm 0.6611 (0.6645)	mem 38886MB
Train: [138/180][150/625]	eta 0:08:19 lr 0.101658	data 0.0006 (0.1383)	batch 0.9755 (1.0520)	loss 2.8104 (2.6659)	grad_norm 0.6690 (0.6647)	mem 38886MB
Train: [138/180][200/625]	eta 0:07:11 lr 0.101287	data 0.0009 (0.1041)	batch 0.8782 (1.0158)	loss 2.6271 (2.6696)	grad_norm 0.6587 (0.6656)	mem 38886MB
Train: [138/180][250/625]	eta 0:06:13 lr 0.100916	data 0.0005 (0.0835)	batch 0.8856 (0.9956)	loss 2.6487 (2.6684)	grad_norm 0.6741 (0.6660)	mem 38886MB
Train: [138/180][300/625]	eta 0:05:18 lr 0.100545	data 0.0007 (0.0697)	batch 0.9017 (0.9812)	loss 2.8422 (2.6715)	grad_norm 0.6724 (0.6664)	mem 38886MB
Train: [138/180][350/625]	eta 0:04:27 lr 0.100175	data 0.0005 (0.0599)	batch 0.8778 (0.9709)	loss 2.7016 (2.6721)	grad_norm 0.6794 (0.6664)	mem 38886MB
Train: [138/180][400/625]	eta 0:03:36 lr 0.099806	data 0.0006 (0.0525)	batch 0.9211 (0.9642)	loss 2.6507 (2.6745)	grad_norm 0.6725 (0.6669)	mem 38886MB
Train: [138/180][450/625]	eta 0:02:47 lr 0.099437	data 0.0006 (0.0468)	batch 0.8926 (0.9576)	loss 2.7199 (2.6737)	grad_norm 0.6804 (0.6671)	mem 38886MB
Train: [138/180][500/625]	eta 0:01:59 lr 0.099069	data 0.0006 (0.0422)	batch 0.8448 (0.9524)	loss 2.7194 (2.6769)	grad_norm 0.6995 (0.6674)	mem 38886MB
Train: [138/180][550/625]	eta 0:01:11 lr 0.098702	data 0.0009 (0.0384)	batch 0.8657 (0.9482)	loss 2.6390 (2.6767)	grad_norm 0.6752 (0.6674)	mem 38886MB
Train: [138/180][600/625]	eta 0:00:23 lr 0.098335	data 0.0005 (0.0353)	batch 0.9576 (0.9451)	loss 2.8615 (2.6778)	grad_norm 0.6641 (0.6676)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 138 training takes 0:09:51
Test: [0/25]	Time 14.716 (14.716)	Loss 1.0008 (1.0008)	Acc@1 78.174 (78.174)	Acc@5 93.457 (93.457)	Mem 38886MB
 * Acc@1 67.632 Acc@5 87.912
Accuracy of the network on the 50000 test images: 67.63%
Max accuracy (after decay): 67.66%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [139/180][0/625]	eta 4:00:29 lr 0.098151	data 20.8952 (20.8952)	batch 23.0873 (23.0873)	loss 2.7199 (2.7199)	grad_norm 0.6670 (0.6670)	mem 38886MB
Train: [139/180][50/625]	eta 0:12:53 lr 0.097785	data 0.0008 (0.4104)	batch 0.8718 (1.3451)	loss 2.9325 (2.6905)	grad_norm 0.6802 (0.6664)	mem 38886MB
Train: [139/180][100/625]	eta 0:09:50 lr 0.097420	data 0.0007 (0.2077)	batch 0.9036 (1.1251)	loss 2.8244 (2.6859)	grad_norm 0.6693 (0.6667)	mem 38886MB
Train: [139/180][150/625]	eta 0:08:19 lr 0.097055	data 0.0010 (0.1391)	batch 0.9332 (1.0513)	loss 2.6413 (2.6897)	grad_norm 0.6719 (0.6690)	mem 38886MB
Train: [139/180][200/625]	eta 0:07:11 lr 0.096690	data 0.0005 (0.1047)	batch 0.9109 (1.0143)	loss 2.5470 (2.6875)	grad_norm 0.6797 (0.6696)	mem 38886MB
Train: [139/180][250/625]	eta 0:06:12 lr 0.096327	data 0.0005 (0.0840)	batch 0.8809 (0.9940)	loss 2.6460 (2.6854)	grad_norm 0.6716 (0.6699)	mem 38886MB
Train: [139/180][300/625]	eta 0:05:18 lr 0.095964	data 0.0007 (0.0701)	batch 0.9063 (0.9790)	loss 2.6418 (2.6814)	grad_norm 0.6711 (0.6697)	mem 38886MB
Train: [139/180][350/625]	eta 0:04:26 lr 0.095601	data 0.0005 (0.0602)	batch 0.8930 (0.9677)	loss 2.6402 (2.6809)	grad_norm 0.6789 (0.6697)	mem 38886MB
Train: [139/180][400/625]	eta 0:03:35 lr 0.095239	data 0.0006 (0.0528)	batch 0.9000 (0.9599)	loss 2.5497 (2.6806)	grad_norm 0.6664 (0.6701)	mem 38886MB
Train: [139/180][450/625]	eta 0:02:46 lr 0.094878	data 0.0006 (0.0470)	batch 0.8743 (0.9537)	loss 2.7810 (2.6823)	grad_norm 0.6972 (0.6705)	mem 38886MB
Train: [139/180][500/625]	eta 0:01:58 lr 0.094517	data 0.0005 (0.0424)	batch 0.8636 (0.9483)	loss 2.8054 (2.6821)	grad_norm 0.6813 (0.6705)	mem 38886MB
Train: [139/180][550/625]	eta 0:01:10 lr 0.094157	data 0.0006 (0.0386)	batch 0.8955 (0.9444)	loss 2.5656 (2.6819)	grad_norm 0.6587 (0.6706)	mem 38886MB
Train: [139/180][600/625]	eta 0:00:23 lr 0.093797	data 0.0006 (0.0354)	batch 0.9116 (0.9410)	loss 2.7373 (2.6824)	grad_norm 0.7042 (0.6709)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 139 training takes 0:09:48
Test: [0/25]	Time 14.648 (14.648)	Loss 0.9772 (0.9772)	Acc@1 78.467 (78.467)	Acc@5 93.311 (93.311)	Mem 38886MB
 * Acc@1 67.834 Acc@5 87.974
Accuracy of the network on the 50000 test images: 67.83%
Max accuracy (after decay): 67.83%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [140/180][0/625]	eta 3:55:52 lr 0.093618	data 21.4616 (21.4616)	batch 22.6440 (22.6440)	loss 2.6425 (2.6425)	grad_norm 0.6597 (0.6597)	mem 38886MB
Train: [140/180][50/625]	eta 0:12:51 lr 0.093259	data 0.0005 (0.4215)	batch 0.9022 (1.3412)	loss 2.6638 (2.6612)	grad_norm 0.6599 (0.6697)	mem 38886MB
Train: [140/180][100/625]	eta 0:09:51 lr 0.092901	data 0.0006 (0.2131)	batch 0.9058 (1.1266)	loss 2.6571 (2.6571)	grad_norm 0.6672 (0.6701)	mem 38886MB
Train: [140/180][150/625]	eta 0:08:19 lr 0.092543	data 0.0007 (0.1427)	batch 0.8833 (1.0524)	loss 2.6271 (2.6683)	grad_norm 0.6628 (0.6715)	mem 38886MB
Train: [140/180][200/625]	eta 0:07:11 lr 0.092186	data 0.0007 (0.1074)	batch 0.8936 (1.0155)	loss 2.5504 (2.6709)	grad_norm 0.6877 (0.6728)	mem 38886MB
Train: [140/180][250/625]	eta 0:06:12 lr 0.091830	data 0.0004 (0.0861)	batch 0.8827 (0.9925)	loss 2.8663 (2.6688)	grad_norm 0.6709 (0.6737)	mem 38886MB
Train: [140/180][300/625]	eta 0:05:18 lr 0.091474	data 0.0005 (0.0719)	batch 0.8925 (0.9787)	loss 2.5523 (2.6703)	grad_norm 0.6420 (0.6736)	mem 38886MB
Train: [140/180][350/625]	eta 0:04:26 lr 0.091119	data 0.0005 (0.0617)	batch 0.9012 (0.9688)	loss 2.5151 (2.6708)	grad_norm 0.6708 (0.6737)	mem 38886MB
Train: [140/180][400/625]	eta 0:03:36 lr 0.090765	data 0.0005 (0.0541)	batch 0.8902 (0.9605)	loss 2.6165 (2.6701)	grad_norm 0.6631 (0.6738)	mem 38886MB
Train: [140/180][450/625]	eta 0:02:47 lr 0.090411	data 0.0005 (0.0482)	batch 0.8984 (0.9545)	loss 2.7260 (2.6691)	grad_norm 0.6882 (0.6743)	mem 38886MB
Train: [140/180][500/625]	eta 0:01:58 lr 0.090058	data 0.0006 (0.0434)	batch 0.8583 (0.9497)	loss 2.7309 (2.6705)	grad_norm 0.6827 (0.6747)	mem 38886MB
Train: [140/180][550/625]	eta 0:01:10 lr 0.089705	data 0.0005 (0.0395)	batch 0.9288 (0.9456)	loss 2.7208 (2.6722)	grad_norm 0.6803 (0.6748)	mem 38886MB
Train: [140/180][600/625]	eta 0:00:23 lr 0.089353	data 0.0004 (0.0363)	batch 0.9241 (0.9425)	loss 3.0047 (2.6753)	grad_norm 0.6937 (0.6749)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 140 training takes 0:09:49
Test: [0/25]	Time 14.815 (14.815)	Loss 0.9634 (0.9634)	Acc@1 78.955 (78.955)	Acc@5 93.213 (93.213)	Mem 38886MB
 * Acc@1 67.764 Acc@5 88.078
Accuracy of the network on the 50000 test images: 67.76%
Max accuracy (after decay): 67.83%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [141/180][0/625]	eta 4:02:05 lr 0.089177	data 21.7347 (21.7347)	batch 23.2415 (23.2415)	loss 2.4748 (2.4748)	grad_norm 0.6538 (0.6538)	mem 38886MB
Train: [141/180][50/625]	eta 0:12:54 lr 0.088826	data 0.0005 (0.4269)	batch 0.9156 (1.3465)	loss 2.4558 (2.6523)	grad_norm 0.6632 (0.6743)	mem 38886MB
Train: [141/180][100/625]	eta 0:09:52 lr 0.088475	data 0.0006 (0.2159)	batch 0.9389 (1.1285)	loss 2.6051 (2.6502)	grad_norm 0.6784 (0.6755)	mem 38886MB
Train: [141/180][150/625]	eta 0:08:20 lr 0.088126	data 0.0007 (0.1447)	batch 0.8992 (1.0545)	loss 2.7881 (2.6461)	grad_norm 0.6775 (0.6758)	mem 38886MB
Train: [141/180][200/625]	eta 0:07:12 lr 0.087776	data 0.0006 (0.1089)	batch 0.8694 (1.0180)	loss 2.7583 (2.6535)	grad_norm 0.6887 (0.6766)	mem 38886MB
Train: [141/180][250/625]	eta 0:06:13 lr 0.087427	data 0.0003 (0.0873)	batch 0.9046 (0.9957)	loss 2.6461 (2.6592)	grad_norm 0.6922 (0.6773)	mem 38886MB
Train: [141/180][300/625]	eta 0:05:18 lr 0.087079	data 0.0008 (0.0730)	batch 0.9413 (0.9808)	loss 2.6057 (2.6636)	grad_norm 0.6835 (0.6776)	mem 38886MB
Train: [141/180][350/625]	eta 0:04:26 lr 0.086732	data 0.0007 (0.0627)	batch 0.9089 (0.9708)	loss 2.7057 (2.6667)	grad_norm 0.6738 (0.6778)	mem 38886MB
Train: [141/180][400/625]	eta 0:03:36 lr 0.086385	data 0.0006 (0.0550)	batch 0.9000 (0.9630)	loss 2.5656 (2.6660)	grad_norm 0.6709 (0.6779)	mem 38886MB
Train: [141/180][450/625]	eta 0:02:47 lr 0.086039	data 0.0005 (0.0489)	batch 0.8842 (0.9573)	loss 2.7174 (2.6645)	grad_norm 0.6934 (0.6783)	mem 38886MB
Train: [141/180][500/625]	eta 0:01:59 lr 0.085693	data 0.0007 (0.0441)	batch 0.8827 (0.9523)	loss 2.6330 (2.6655)	grad_norm 0.7050 (0.6784)	mem 38886MB
Train: [141/180][550/625]	eta 0:01:11 lr 0.085348	data 0.0008 (0.0402)	batch 0.9145 (0.9482)	loss 2.7905 (2.6684)	grad_norm 0.7146 (0.6786)	mem 38886MB
Train: [141/180][600/625]	eta 0:00:23 lr 0.085003	data 0.0005 (0.0369)	batch 0.8804 (0.9452)	loss 2.5849 (2.6687)	grad_norm 0.6670 (0.6787)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 141 training takes 0:09:51
Test: [0/25]	Time 14.900 (14.900)	Loss 0.9647 (0.9647)	Acc@1 78.076 (78.076)	Acc@5 93.457 (93.457)	Mem 38886MB
 * Acc@1 67.762 Acc@5 87.902
Accuracy of the network on the 50000 test images: 67.76%
Max accuracy (after decay): 67.83%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [142/180][0/625]	eta 3:55:38 lr 0.084831	data 21.2849 (21.2849)	batch 22.6216 (22.6216)	loss 2.4969 (2.4969)	grad_norm 0.6658 (0.6658)	mem 38886MB
Train: [142/180][50/625]	eta 0:12:49 lr 0.084488	data 0.0010 (0.4180)	batch 0.9186 (1.3380)	loss 2.6646 (2.6588)	grad_norm 0.6880 (0.6768)	mem 38886MB
Train: [142/180][100/625]	eta 0:09:51 lr 0.084145	data 0.0010 (0.2118)	batch 0.9064 (1.1261)	loss 2.7665 (2.6648)	grad_norm 0.6634 (0.6780)	mem 38886MB
Train: [142/180][150/625]	eta 0:08:19 lr 0.083803	data 0.0009 (0.1419)	batch 0.9300 (1.0514)	loss 2.6440 (2.6679)	grad_norm 0.6775 (0.6801)	mem 38886MB
Train: [142/180][200/625]	eta 0:07:12 lr 0.083461	data 0.0005 (0.1068)	batch 0.9013 (1.0170)	loss 2.8481 (2.6709)	grad_norm 0.6951 (0.6801)	mem 38886MB
Train: [142/180][250/625]	eta 0:06:13 lr 0.083120	data 0.0005 (0.0856)	batch 0.8627 (0.9957)	loss 2.8142 (2.6651)	grad_norm 0.6928 (0.6805)	mem 38886MB
Train: [142/180][300/625]	eta 0:05:18 lr 0.082780	data 0.0009 (0.0715)	batch 0.9094 (0.9809)	loss 2.5757 (2.6671)	grad_norm 0.6767 (0.6809)	mem 38886MB
Train: [142/180][350/625]	eta 0:04:26 lr 0.082440	data 0.0005 (0.0614)	batch 0.8974 (0.9702)	loss 2.5820 (2.6693)	grad_norm 0.6778 (0.6807)	mem 38886MB
Train: [142/180][400/625]	eta 0:03:36 lr 0.082101	data 0.0004 (0.0538)	batch 0.8802 (0.9614)	loss 2.8351 (2.6695)	grad_norm 0.6804 (0.6810)	mem 38886MB
Train: [142/180][450/625]	eta 0:02:47 lr 0.081762	data 0.0005 (0.0479)	batch 0.9036 (0.9551)	loss 2.4881 (2.6685)	grad_norm 0.6719 (0.6809)	mem 38886MB
Train: [142/180][500/625]	eta 0:01:58 lr 0.081424	data 0.0005 (0.0432)	batch 0.9082 (0.9503)	loss 2.7341 (2.6672)	grad_norm 0.6897 (0.6815)	mem 38886MB
Train: [142/180][550/625]	eta 0:01:10 lr 0.081087	data 0.0005 (0.0393)	batch 0.9266 (0.9461)	loss 2.8057 (2.6653)	grad_norm 0.6876 (0.6820)	mem 38886MB
Train: [142/180][600/625]	eta 0:00:23 lr 0.080750	data 0.0005 (0.0361)	batch 0.9386 (0.9431)	loss 2.7517 (2.6662)	grad_norm 0.6990 (0.6825)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 142 training takes 0:09:49
Test: [0/25]	Time 14.752 (14.752)	Loss 0.9857 (0.9857)	Acc@1 78.320 (78.320)	Acc@5 93.506 (93.506)	Mem 38886MB
 * Acc@1 67.862 Acc@5 87.950
Accuracy of the network on the 50000 test images: 67.86%
Max accuracy (after decay): 67.86%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [143/180][0/625]	eta 3:57:17 lr 0.080582	data 20.6373 (20.6373)	batch 22.7803 (22.7803)	loss 2.6119 (2.6119)	grad_norm 0.6790 (0.6790)	mem 38886MB
Train: [143/180][50/625]	eta 0:12:47 lr 0.080246	data 0.0004 (0.4054)	batch 0.8983 (1.3350)	loss 2.6088 (2.6492)	grad_norm 0.6766 (0.6806)	mem 38886MB
Train: [143/180][100/625]	eta 0:09:51 lr 0.079911	data 0.0005 (0.2050)	batch 0.9051 (1.1272)	loss 2.6270 (2.6615)	grad_norm 0.6814 (0.6835)	mem 38886MB
Train: [143/180][150/625]	eta 0:08:21 lr 0.079576	data 0.0006 (0.1373)	batch 0.8710 (1.0563)	loss 2.5966 (2.6591)	grad_norm 0.6814 (0.6845)	mem 38886MB
Train: [143/180][200/625]	eta 0:07:13 lr 0.079242	data 0.0003 (0.1033)	batch 0.9299 (1.0196)	loss 2.6791 (2.6673)	grad_norm 0.6583 (0.6847)	mem 38886MB
Train: [143/180][250/625]	eta 0:06:14 lr 0.078909	data 0.0005 (0.0828)	batch 0.8930 (0.9978)	loss 2.6944 (2.6625)	grad_norm 0.6763 (0.6840)	mem 38886MB
Train: [143/180][300/625]	eta 0:05:19 lr 0.078576	data 0.0005 (0.0691)	batch 0.9296 (0.9826)	loss 2.8409 (2.6605)	grad_norm 0.6926 (0.6836)	mem 38886MB
Train: [143/180][350/625]	eta 0:04:27 lr 0.078244	data 0.0005 (0.0594)	batch 0.8980 (0.9730)	loss 2.7688 (2.6598)	grad_norm 0.6784 (0.6834)	mem 38886MB
Train: [143/180][400/625]	eta 0:03:37 lr 0.077913	data 0.0006 (0.0520)	batch 0.9191 (0.9648)	loss 2.8264 (2.6619)	grad_norm 0.7038 (0.6842)	mem 38886MB
Train: [143/180][450/625]	eta 0:02:47 lr 0.077582	data 0.0005 (0.0463)	batch 0.9036 (0.9581)	loss 2.7987 (2.6641)	grad_norm 0.6931 (0.6844)	mem 38886MB
Train: [143/180][500/625]	eta 0:01:59 lr 0.077252	data 0.0003 (0.0418)	batch 0.9154 (0.9525)	loss 2.7333 (2.6632)	grad_norm 0.6861 (0.6851)	mem 38886MB
Train: [143/180][550/625]	eta 0:01:11 lr 0.076922	data 0.0005 (0.0380)	batch 0.8855 (0.9481)	loss 2.7560 (2.6648)	grad_norm 0.6915 (0.6853)	mem 38886MB
Train: [143/180][600/625]	eta 0:00:23 lr 0.076594	data 0.0004 (0.0349)	batch 0.9082 (0.9448)	loss 2.6914 (2.6632)	grad_norm 0.6911 (0.6856)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 143 training takes 0:09:51
Test: [0/25]	Time 14.712 (14.712)	Loss 0.9439 (0.9439)	Acc@1 79.053 (79.053)	Acc@5 93.555 (93.555)	Mem 38886MB
 * Acc@1 68.192 Acc@5 88.124
Accuracy of the network on the 50000 test images: 68.19%
Max accuracy (after decay): 68.19%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [144/180][0/625]	eta 4:04:22 lr 0.076429	data 20.9573 (20.9573)	batch 23.4600 (23.4600)	loss 2.6416 (2.6416)	grad_norm 0.6641 (0.6641)	mem 38886MB
Train: [144/180][50/625]	eta 0:12:57 lr 0.076101	data 0.0006 (0.4116)	batch 1.0102 (1.3530)	loss 2.7221 (2.6600)	grad_norm 0.6800 (0.6833)	mem 38886MB
Train: [144/180][100/625]	eta 0:09:54 lr 0.075774	data 0.0005 (0.2087)	batch 0.9217 (1.1331)	loss 2.4912 (2.6533)	grad_norm 0.6876 (0.6847)	mem 38886MB
Train: [144/180][150/625]	eta 0:08:22 lr 0.075447	data 0.0008 (0.1398)	batch 0.8815 (1.0586)	loss 2.4657 (2.6493)	grad_norm 0.6803 (0.6864)	mem 38886MB
Train: [144/180][200/625]	eta 0:07:14 lr 0.075121	data 0.0006 (0.1054)	batch 0.8716 (1.0218)	loss 2.7888 (2.6538)	grad_norm 0.6929 (0.6867)	mem 38886MB
Train: [144/180][250/625]	eta 0:06:14 lr 0.074796	data 0.0019 (0.0846)	batch 0.9462 (0.9988)	loss 2.6823 (2.6506)	grad_norm 0.6826 (0.6874)	mem 38886MB
Train: [144/180][300/625]	eta 0:05:19 lr 0.074471	data 0.0011 (0.0706)	batch 0.9099 (0.9830)	loss 2.7048 (2.6529)	grad_norm 0.6693 (0.6871)	mem 38886MB
Train: [144/180][350/625]	eta 0:04:27 lr 0.074147	data 0.0007 (0.0607)	batch 0.8721 (0.9730)	loss 2.6899 (2.6522)	grad_norm 0.6909 (0.6872)	mem 38886MB
Train: [144/180][400/625]	eta 0:03:37 lr 0.073824	data 0.0006 (0.0532)	batch 0.8847 (0.9649)	loss 2.7010 (2.6579)	grad_norm 0.7006 (0.6874)	mem 38886MB
Train: [144/180][450/625]	eta 0:02:47 lr 0.073501	data 0.0007 (0.0474)	batch 0.9141 (0.9591)	loss 2.6416 (2.6579)	grad_norm 0.6991 (0.6883)	mem 38886MB
Train: [144/180][500/625]	eta 0:01:59 lr 0.073178	data 0.0007 (0.0428)	batch 0.8694 (0.9535)	loss 2.7710 (2.6609)	grad_norm 0.6956 (0.6886)	mem 38886MB
Train: [144/180][550/625]	eta 0:01:11 lr 0.072857	data 0.0006 (0.0390)	batch 0.9063 (0.9492)	loss 2.4525 (2.6618)	grad_norm 0.6984 (0.6887)	mem 38886MB
Train: [144/180][600/625]	eta 0:00:23 lr 0.072536	data 0.0007 (0.0358)	batch 0.8686 (0.9461)	loss 2.5160 (2.6600)	grad_norm 0.6606 (0.6888)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 144 training takes 0:09:51
Test: [0/25]	Time 14.669 (14.669)	Loss 0.9536 (0.9536)	Acc@1 79.443 (79.443)	Acc@5 93.213 (93.213)	Mem 38886MB
 * Acc@1 68.168 Acc@5 88.124
Accuracy of the network on the 50000 test images: 68.17%
Max accuracy (after decay): 68.19%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [145/180][0/625]	eta 4:03:19 lr 0.072376	data 20.9143 (20.9143)	batch 23.3587 (23.3587)	loss 2.5624 (2.5624)	grad_norm 0.7034 (0.7034)	mem 38886MB
Train: [145/180][50/625]	eta 0:12:54 lr 0.072056	data 0.0008 (0.4111)	batch 0.8697 (1.3478)	loss 2.5188 (2.6245)	grad_norm 0.6859 (0.6883)	mem 38886MB
Train: [145/180][100/625]	eta 0:09:53 lr 0.071736	data 0.0006 (0.2080)	batch 0.8765 (1.1307)	loss 2.6690 (2.6367)	grad_norm 0.6902 (0.6880)	mem 38886MB
Train: [145/180][150/625]	eta 0:08:21 lr 0.071417	data 0.0008 (0.1394)	batch 0.8721 (1.0561)	loss 2.4052 (2.6293)	grad_norm 0.6949 (0.6887)	mem 38886MB
Train: [145/180][200/625]	eta 0:07:13 lr 0.071099	data 0.0007 (0.1049)	batch 0.8795 (1.0202)	loss 2.5310 (2.6316)	grad_norm 0.6839 (0.6897)	mem 38886MB
Train: [145/180][250/625]	eta 0:06:14 lr 0.070782	data 0.0005 (0.0842)	batch 0.8818 (0.9978)	loss 2.7980 (2.6328)	grad_norm 0.6970 (0.6904)	mem 38886MB
Train: [145/180][300/625]	eta 0:05:19 lr 0.070465	data 0.0007 (0.0703)	batch 0.8908 (0.9826)	loss 2.6252 (2.6350)	grad_norm 0.7181 (0.6905)	mem 38886MB
Train: [145/180][350/625]	eta 0:04:27 lr 0.070149	data 0.0008 (0.0604)	batch 0.9259 (0.9721)	loss 2.5181 (2.6373)	grad_norm 0.6915 (0.6905)	mem 38886MB
Train: [145/180][400/625]	eta 0:03:36 lr 0.069833	data 0.0005 (0.0530)	batch 0.9415 (0.9634)	loss 2.6304 (2.6400)	grad_norm 0.6773 (0.6910)	mem 38886MB
Train: [145/180][450/625]	eta 0:02:47 lr 0.069519	data 0.0006 (0.0472)	batch 0.9045 (0.9571)	loss 2.6018 (2.6413)	grad_norm 0.6761 (0.6912)	mem 38886MB
Train: [145/180][500/625]	eta 0:01:59 lr 0.069204	data 0.0006 (0.0425)	batch 0.8727 (0.9524)	loss 2.8139 (2.6436)	grad_norm 0.6983 (0.6914)	mem 38886MB
Train: [145/180][550/625]	eta 0:01:11 lr 0.068891	data 0.0005 (0.0387)	batch 0.8887 (0.9479)	loss 2.9450 (2.6441)	grad_norm 0.6985 (0.6915)	mem 38886MB
Train: [145/180][600/625]	eta 0:00:23 lr 0.068578	data 0.0005 (0.0355)	batch 0.9749 (0.9445)	loss 2.5050 (2.6447)	grad_norm 0.6818 (0.6920)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 145 training takes 0:09:50
Test: [0/25]	Time 14.816 (14.816)	Loss 0.9539 (0.9539)	Acc@1 79.102 (79.102)	Acc@5 93.848 (93.848)	Mem 38886MB
 * Acc@1 68.308 Acc@5 88.336
Accuracy of the network on the 50000 test images: 68.31%
Max accuracy (after decay): 68.31%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [146/180][0/625]	eta 3:55:13 lr 0.068422	data 20.9053 (20.9053)	batch 22.5809 (22.5809)	loss 2.6799 (2.6799)	grad_norm 0.6998 (0.6998)	mem 38886MB
Train: [146/180][50/625]	eta 0:12:45 lr 0.068110	data 0.0006 (0.4108)	batch 0.9080 (1.3317)	loss 2.7267 (2.6318)	grad_norm 0.6949 (0.6907)	mem 38886MB
Train: [146/180][100/625]	eta 0:09:49 lr 0.067798	data 0.0008 (0.2084)	batch 0.9039 (1.1227)	loss 2.4146 (2.6388)	grad_norm 0.6862 (0.6919)	mem 38886MB
Train: [146/180][150/625]	eta 0:08:19 lr 0.067488	data 0.0007 (0.1396)	batch 0.8862 (1.0520)	loss 2.6771 (2.6399)	grad_norm 0.6915 (0.6918)	mem 38886MB
Train: [146/180][200/625]	eta 0:07:12 lr 0.067178	data 0.0004 (0.1051)	batch 0.9080 (1.0171)	loss 2.7217 (2.6385)	grad_norm 0.6937 (0.6917)	mem 38886MB
Train: [146/180][250/625]	eta 0:06:13 lr 0.066868	data 0.0011 (0.0843)	batch 0.9457 (0.9956)	loss 2.5390 (2.6396)	grad_norm 0.7065 (0.6924)	mem 38886MB
Train: [146/180][300/625]	eta 0:05:18 lr 0.066559	data 0.0004 (0.0704)	batch 0.8902 (0.9809)	loss 2.7257 (2.6386)	grad_norm 0.6987 (0.6929)	mem 38886MB
Train: [146/180][350/625]	eta 0:04:26 lr 0.066251	data 0.0006 (0.0605)	batch 0.9071 (0.9701)	loss 2.8441 (2.6379)	grad_norm 0.7078 (0.6937)	mem 38886MB
Train: [146/180][400/625]	eta 0:03:36 lr 0.065944	data 0.0007 (0.0530)	batch 0.8891 (0.9635)	loss 2.6397 (2.6421)	grad_norm 0.7290 (0.6943)	mem 38886MB
Train: [146/180][450/625]	eta 0:02:47 lr 0.065637	data 0.0006 (0.0472)	batch 0.9768 (0.9576)	loss 2.7073 (2.6393)	grad_norm 0.6999 (0.6947)	mem 38886MB
Train: [146/180][500/625]	eta 0:01:59 lr 0.065331	data 0.0006 (0.0426)	batch 0.9589 (0.9521)	loss 2.8101 (2.6398)	grad_norm 0.7024 (0.6947)	mem 38886MB
Train: [146/180][550/625]	eta 0:01:11 lr 0.065026	data 0.0006 (0.0388)	batch 0.9227 (0.9480)	loss 2.5473 (2.6405)	grad_norm 0.6997 (0.6950)	mem 38886MB
Train: [146/180][600/625]	eta 0:00:23 lr 0.064721	data 0.0006 (0.0356)	batch 0.9580 (0.9446)	loss 2.7865 (2.6404)	grad_norm 0.7045 (0.6951)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 146 training takes 0:09:50
Test: [0/25]	Time 14.834 (14.834)	Loss 0.9300 (0.9300)	Acc@1 79.932 (79.932)	Acc@5 93.994 (93.994)	Mem 38886MB
 * Acc@1 68.080 Acc@5 88.322
Accuracy of the network on the 50000 test images: 68.08%
Max accuracy (after decay): 68.31%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [147/180][0/625]	eta 3:56:12 lr 0.064569	data 20.9896 (20.9896)	batch 22.6752 (22.6752)	loss 2.7320 (2.7320)	grad_norm 0.6999 (0.6999)	mem 38886MB
Train: [147/180][50/625]	eta 0:12:49 lr 0.064265	data 0.0005 (0.4121)	batch 0.8891 (1.3390)	loss 2.6079 (2.6350)	grad_norm 0.6847 (0.6960)	mem 38886MB
Train: [147/180][100/625]	eta 0:09:49 lr 0.063962	data 0.0005 (0.2084)	batch 0.9398 (1.1234)	loss 2.6262 (2.6369)	grad_norm 0.6911 (0.6972)	mem 38886MB
Train: [147/180][150/625]	eta 0:08:19 lr 0.063659	data 0.0005 (0.1395)	batch 0.9052 (1.0515)	loss 2.6240 (2.6304)	grad_norm 0.6986 (0.6971)	mem 38886MB
Train: [147/180][200/625]	eta 0:07:11 lr 0.063357	data 0.0004 (0.1050)	batch 0.8975 (1.0146)	loss 2.7503 (2.6322)	grad_norm 0.6953 (0.6974)	mem 38886MB
Train: [147/180][250/625]	eta 0:06:12 lr 0.063056	data 0.0005 (0.0842)	batch 0.8999 (0.9936)	loss 2.6676 (2.6318)	grad_norm 0.7045 (0.6973)	mem 38886MB
Train: [147/180][300/625]	eta 0:05:18 lr 0.062755	data 0.0004 (0.0703)	batch 0.9789 (0.9791)	loss 2.6523 (2.6356)	grad_norm 0.6865 (0.6975)	mem 38886MB
Train: [147/180][350/625]	eta 0:04:26 lr 0.062455	data 0.0004 (0.0603)	batch 0.9342 (0.9686)	loss 2.6129 (2.6334)	grad_norm 0.7054 (0.6978)	mem 38886MB
Train: [147/180][400/625]	eta 0:03:36 lr 0.062156	data 0.0007 (0.0529)	batch 1.0464 (0.9615)	loss 2.6531 (2.6336)	grad_norm 0.6923 (0.6980)	mem 38886MB
Train: [147/180][450/625]	eta 0:02:47 lr 0.061858	data 0.0005 (0.0471)	batch 0.9349 (0.9556)	loss 2.7635 (2.6336)	grad_norm 0.7005 (0.6979)	mem 38886MB
Train: [147/180][500/625]	eta 0:01:58 lr 0.061560	data 0.0005 (0.0424)	batch 0.8860 (0.9505)	loss 2.5264 (2.6342)	grad_norm 0.6900 (0.6982)	mem 38886MB
Train: [147/180][550/625]	eta 0:01:10 lr 0.061262	data 0.0007 (0.0386)	batch 0.8731 (0.9462)	loss 2.7811 (2.6361)	grad_norm 0.7143 (0.6983)	mem 38886MB
Train: [147/180][600/625]	eta 0:00:23 lr 0.060966	data 0.0004 (0.0354)	batch 0.9028 (0.9425)	loss 2.6537 (2.6392)	grad_norm 0.6935 (0.6982)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 147 training takes 0:09:49
Test: [0/25]	Time 14.721 (14.721)	Loss 0.9256 (0.9256)	Acc@1 79.834 (79.834)	Acc@5 94.385 (94.385)	Mem 38886MB
 * Acc@1 68.488 Acc@5 88.318
Accuracy of the network on the 50000 test images: 68.49%
Max accuracy (after decay): 68.49%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [148/180][0/625]	eta 4:00:15 lr 0.060818	data 20.7335 (20.7335)	batch 23.0645 (23.0645)	loss 2.8277 (2.8277)	grad_norm 0.7003 (0.7003)	mem 38886MB
Train: [148/180][50/625]	eta 0:12:53 lr 0.060522	data 0.0005 (0.4074)	batch 0.8799 (1.3446)	loss 2.6123 (2.6305)	grad_norm 0.7107 (0.6950)	mem 38886MB
Train: [148/180][100/625]	eta 0:09:50 lr 0.060227	data 0.0005 (0.2060)	batch 0.9168 (1.1241)	loss 2.5861 (2.6358)	grad_norm 0.7048 (0.6973)	mem 38886MB
Train: [148/180][150/625]	eta 0:08:19 lr 0.059933	data 0.0006 (0.1380)	batch 0.9060 (1.0526)	loss 2.6414 (2.6309)	grad_norm 0.6910 (0.6974)	mem 38886MB
Train: [148/180][200/625]	eta 0:07:12 lr 0.059639	data 0.0006 (0.1038)	batch 0.9216 (1.0166)	loss 2.5785 (2.6366)	grad_norm 0.6939 (0.6984)	mem 38886MB
Train: [148/180][250/625]	eta 0:06:12 lr 0.059346	data 0.0004 (0.0832)	batch 0.8906 (0.9934)	loss 2.5730 (2.6323)	grad_norm 0.7256 (0.6994)	mem 38886MB
Train: [148/180][300/625]	eta 0:05:18 lr 0.059054	data 0.0005 (0.0695)	batch 0.9347 (0.9805)	loss 2.4741 (2.6368)	grad_norm 0.6832 (0.6997)	mem 38886MB
Train: [148/180][350/625]	eta 0:04:26 lr 0.058762	data 0.0005 (0.0597)	batch 0.8828 (0.9694)	loss 2.6193 (2.6365)	grad_norm 0.7384 (0.7006)	mem 38886MB
Train: [148/180][400/625]	eta 0:03:36 lr 0.058471	data 0.0008 (0.0523)	batch 0.8986 (0.9616)	loss 2.6282 (2.6353)	grad_norm 0.7227 (0.7009)	mem 38886MB
Train: [148/180][450/625]	eta 0:02:47 lr 0.058181	data 0.0005 (0.0466)	batch 0.8766 (0.9553)	loss 2.8387 (2.6354)	grad_norm 0.6986 (0.7014)	mem 38886MB
Train: [148/180][500/625]	eta 0:01:58 lr 0.057891	data 0.0005 (0.0420)	batch 0.8824 (0.9500)	loss 2.5862 (2.6346)	grad_norm 0.7031 (0.7015)	mem 38886MB
Train: [148/180][550/625]	eta 0:01:10 lr 0.057602	data 0.0004 (0.0382)	batch 0.9011 (0.9465)	loss 2.6684 (2.6356)	grad_norm 0.7188 (0.7017)	mem 38886MB
Train: [148/180][600/625]	eta 0:00:23 lr 0.057314	data 0.0005 (0.0351)	batch 0.8774 (0.9428)	loss 2.7770 (2.6372)	grad_norm 0.6998 (0.7021)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 148 training takes 0:09:49
Test: [0/25]	Time 14.584 (14.584)	Loss 0.9345 (0.9345)	Acc@1 80.127 (80.127)	Acc@5 93.945 (93.945)	Mem 38886MB
 * Acc@1 68.394 Acc@5 88.340
Accuracy of the network on the 50000 test images: 68.39%
Max accuracy (after decay): 68.49%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [149/180][0/625]	eta 4:07:01 lr 0.057170	data 21.8089 (21.8089)	batch 23.7147 (23.7147)	loss 2.6222 (2.6222)	grad_norm 0.7128 (0.7128)	mem 38886MB
Train: [149/180][50/625]	eta 0:12:59 lr 0.056883	data 0.0006 (0.4284)	batch 0.8890 (1.3560)	loss 2.7270 (2.6173)	grad_norm 0.7174 (0.7010)	mem 38886MB
Train: [149/180][100/625]	eta 0:09:55 lr 0.056596	data 0.0005 (0.2166)	batch 0.9656 (1.1340)	loss 2.6313 (2.6180)	grad_norm 0.6979 (0.7024)	mem 38886MB
Train: [149/180][150/625]	eta 0:08:23 lr 0.056310	data 0.0005 (0.1451)	batch 0.8877 (1.0595)	loss 2.5417 (2.6243)	grad_norm 0.7268 (0.7033)	mem 38886MB
Train: [149/180][200/625]	eta 0:07:14 lr 0.056025	data 0.0006 (0.1091)	batch 0.9580 (1.0219)	loss 2.6721 (2.6232)	grad_norm 0.7171 (0.7034)	mem 38886MB
Train: [149/180][250/625]	eta 0:06:15 lr 0.055740	data 0.0005 (0.0875)	batch 0.9432 (1.0004)	loss 2.5619 (2.6243)	grad_norm 0.6945 (0.7035)	mem 38886MB
Train: [149/180][300/625]	eta 0:05:20 lr 0.055456	data 0.0006 (0.0732)	batch 0.8925 (0.9854)	loss 2.7694 (2.6249)	grad_norm 0.7278 (0.7037)	mem 38886MB
Train: [149/180][350/625]	eta 0:04:28 lr 0.055173	data 0.0005 (0.0628)	batch 0.9343 (0.9746)	loss 2.7947 (2.6290)	grad_norm 0.7170 (0.7040)	mem 38886MB
Train: [149/180][400/625]	eta 0:03:37 lr 0.054891	data 0.0005 (0.0551)	batch 0.9334 (0.9664)	loss 2.6056 (2.6250)	grad_norm 0.6877 (0.7040)	mem 38886MB
Train: [149/180][450/625]	eta 0:02:48 lr 0.054609	data 0.0007 (0.0490)	batch 0.8948 (0.9603)	loss 2.7130 (2.6275)	grad_norm 0.6938 (0.7045)	mem 38886MB
Train: [149/180][500/625]	eta 0:01:59 lr 0.054327	data 0.0004 (0.0442)	batch 1.0343 (0.9552)	loss 2.7527 (2.6317)	grad_norm 0.7122 (0.7053)	mem 38886MB
Train: [149/180][550/625]	eta 0:01:11 lr 0.054047	data 0.0005 (0.0402)	batch 0.8994 (0.9514)	loss 2.6072 (2.6334)	grad_norm 0.7065 (0.7055)	mem 38886MB
Train: [149/180][600/625]	eta 0:00:23 lr 0.053767	data 0.0006 (0.0369)	batch 0.8959 (0.9482)	loss 2.6089 (2.6350)	grad_norm 0.7078 (0.7053)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 149 training takes 0:09:53
Test: [0/25]	Time 14.725 (14.725)	Loss 0.9267 (0.9267)	Acc@1 79.883 (79.883)	Acc@5 93.701 (93.701)	Mem 38886MB
 * Acc@1 68.574 Acc@5 88.304
Accuracy of the network on the 50000 test images: 68.57%
Max accuracy (after decay): 68.57%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [150/180][0/625]	eta 3:54:35 lr 0.053627	data 21.1915 (21.1915)	batch 22.5214 (22.5214)	loss 2.7170 (2.7170)	grad_norm 0.7187 (0.7187)	mem 38886MB
Train: [150/180][50/625]	eta 0:12:49 lr 0.053348	data 0.0005 (0.4162)	batch 0.8984 (1.3375)	loss 2.4788 (2.6321)	grad_norm 0.7016 (0.7052)	mem 38886MB
Train: [150/180][100/625]	eta 0:09:51 lr 0.053070	data 0.0006 (0.2105)	batch 0.8881 (1.1258)	loss 2.6648 (2.6387)	grad_norm 0.7122 (0.7068)	mem 38886MB
Train: [150/180][150/625]	eta 0:08:20 lr 0.052792	data 0.0005 (0.1410)	batch 0.9098 (1.0539)	loss 2.5562 (2.6293)	grad_norm 0.6936 (0.7062)	mem 38886MB
Train: [150/180][200/625]	eta 0:07:12 lr 0.052516	data 0.0005 (0.1060)	batch 0.8979 (1.0183)	loss 2.5774 (2.6353)	grad_norm 0.7051 (0.7072)	mem 38886MB
Train: [150/180][250/625]	eta 0:06:13 lr 0.052239	data 0.0004 (0.0850)	batch 0.9162 (0.9960)	loss 2.5461 (2.6353)	grad_norm 0.6928 (0.7074)	mem 38886MB
Train: [150/180][300/625]	eta 0:05:19 lr 0.051964	data 0.0005 (0.0710)	batch 0.8952 (0.9846)	loss 2.7426 (2.6388)	grad_norm 0.7132 (0.7071)	mem 38886MB
Train: [150/180][350/625]	eta 0:04:28 lr 0.051689	data 0.0005 (0.0609)	batch 0.9225 (0.9770)	loss 2.5236 (2.6363)	grad_norm 0.7170 (0.7074)	mem 38886MB
Train: [150/180][400/625]	eta 0:03:42 lr 0.051415	data 0.0005 (0.0534)	batch 1.0520 (0.9878)	loss 2.5613 (2.6357)	grad_norm 0.7106 (0.7079)	mem 38886MB
Train: [150/180][450/625]	eta 0:02:56 lr 0.051141	data 0.0006 (0.0476)	batch 1.1912 (1.0062)	loss 2.5250 (2.6356)	grad_norm 0.7036 (0.7076)	mem 38886MB
Train: [150/180][500/625]	eta 0:02:07 lr 0.050869	data 0.0005 (0.0429)	batch 1.2131 (1.0177)	loss 2.7250 (2.6353)	grad_norm 0.7023 (0.7079)	mem 38886MB
Train: [150/180][550/625]	eta 0:01:17 lr 0.050597	data 0.0004 (0.0391)	batch 1.1957 (1.0279)	loss 2.5305 (2.6352)	grad_norm 0.7060 (0.7079)	mem 38886MB
Train: [150/180][600/625]	eta 0:00:25 lr 0.050325	data 0.0006 (0.0359)	batch 1.1348 (1.0363)	loss 2.7239 (2.6369)	grad_norm 0.7190 (0.7084)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 150 training takes 0:10:51
Test: [0/25]	Time 15.088 (15.088)	Loss 0.9119 (0.9119)	Acc@1 80.957 (80.957)	Acc@5 94.336 (94.336)	Mem 38886MB
 * Acc@1 68.594 Acc@5 88.462
Accuracy of the network on the 50000 test images: 68.59%
Max accuracy (after decay): 68.59%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [151/180][0/625]	eta 4:02:41 lr 0.050190	data 21.9159 (21.9159)	batch 23.2981 (23.2981)	loss 2.5366 (2.5366)	grad_norm 0.6973 (0.6973)	mem 38886MB
Train: [151/180][50/625]	eta 0:15:23 lr 0.049919	data 0.0005 (0.4306)	batch 1.2163 (1.6063)	loss 2.6927 (2.6064)	grad_norm 0.7039 (0.7112)	mem 38886MB
Train: [151/180][100/625]	eta 0:12:10 lr 0.049649	data 0.0005 (0.2177)	batch 1.2200 (1.3905)	loss 2.4065 (2.6139)	grad_norm 0.7182 (0.7106)	mem 38886MB
Train: [151/180][150/625]	eta 0:10:24 lr 0.049380	data 0.0005 (0.1458)	batch 1.1646 (1.3155)	loss 2.7716 (2.6304)	grad_norm 0.7261 (0.7111)	mem 38886MB
Train: [151/180][200/625]	eta 0:09:03 lr 0.049112	data 0.0005 (0.1097)	batch 1.1659 (1.2799)	loss 2.5835 (2.6295)	grad_norm 0.7201 (0.7113)	mem 38886MB
Train: [151/180][250/625]	eta 0:07:51 lr 0.048844	data 0.0005 (0.0879)	batch 1.1117 (1.2566)	loss 2.6615 (2.6243)	grad_norm 0.7151 (0.7110)	mem 38886MB
Train: [151/180][300/625]	eta 0:06:43 lr 0.048577	data 0.0010 (0.0734)	batch 1.1443 (1.2421)	loss 2.6989 (2.6248)	grad_norm 0.6958 (0.7111)	mem 38886MB
Train: [151/180][350/625]	eta 0:05:38 lr 0.048311	data 0.0006 (0.0631)	batch 1.1498 (1.2291)	loss 2.5734 (2.6236)	grad_norm 0.7250 (0.7110)	mem 38886MB
Train: [151/180][400/625]	eta 0:04:33 lr 0.048045	data 0.0008 (0.0553)	batch 1.1809 (1.2168)	loss 2.5393 (2.6244)	grad_norm 0.7002 (0.7109)	mem 38886MB
Train: [151/180][450/625]	eta 0:03:31 lr 0.047780	data 0.0004 (0.0492)	batch 1.1717 (1.2113)	loss 2.8526 (2.6232)	grad_norm 0.7166 (0.7109)	mem 38886MB
Train: [151/180][500/625]	eta 0:02:30 lr 0.047516	data 0.0005 (0.0443)	batch 1.0826 (1.2066)	loss 2.7783 (2.6237)	grad_norm 0.7146 (0.7110)	mem 38886MB
Train: [151/180][550/625]	eta 0:01:30 lr 0.047253	data 0.0006 (0.0404)	batch 1.1122 (1.2028)	loss 2.4701 (2.6234)	grad_norm 0.7190 (0.7110)	mem 38886MB
Train: [151/180][600/625]	eta 0:00:29 lr 0.046990	data 0.0005 (0.0371)	batch 1.1887 (1.1995)	loss 2.5579 (2.6250)	grad_norm 0.7095 (0.7110)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 151 training takes 0:12:30
Test: [0/25]	Time 15.082 (15.082)	Loss 0.9104 (0.9104)	Acc@1 79.736 (79.736)	Acc@5 94.043 (94.043)	Mem 38886MB
 * Acc@1 68.494 Acc@5 88.398
Accuracy of the network on the 50000 test images: 68.49%
Max accuracy (after decay): 68.59%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [152/180][0/625]	eta 4:03:13 lr 0.046859	data 22.0389 (22.0389)	batch 23.3490 (23.3490)	loss 2.4797 (2.4797)	grad_norm 0.7120 (0.7120)	mem 38886MB
Train: [152/180][50/625]	eta 0:15:24 lr 0.046597	data 0.0011 (0.4329)	batch 1.1830 (1.6086)	loss 2.4480 (2.6099)	grad_norm 0.7130 (0.7096)	mem 38886MB
Train: [152/180][100/625]	eta 0:12:09 lr 0.046336	data 0.0005 (0.2189)	batch 1.2047 (1.3897)	loss 2.6624 (2.6162)	grad_norm 0.7142 (0.7114)	mem 38886MB
Train: [152/180][150/625]	eta 0:09:52 lr 0.046075	data 0.0005 (0.1466)	batch 0.9232 (1.2467)	loss 2.7377 (2.6149)	grad_norm 0.7321 (0.7132)	mem 38886MB
Train: [152/180][200/625]	eta 0:08:14 lr 0.045815	data 0.0004 (0.1102)	batch 0.9121 (1.1635)	loss 2.5692 (2.6203)	grad_norm 0.7137 (0.7133)	mem 38886MB
Train: [152/180][250/625]	eta 0:06:56 lr 0.045556	data 0.0005 (0.0884)	batch 0.8947 (1.1110)	loss 2.7705 (2.6172)	grad_norm 0.7623 (0.7133)	mem 38886MB
Train: [152/180][300/625]	eta 0:05:49 lr 0.045298	data 0.0004 (0.0738)	batch 0.9694 (1.0769)	loss 2.5790 (2.6213)	grad_norm 0.7090 (0.7139)	mem 38886MB
Train: [152/180][350/625]	eta 0:04:49 lr 0.045040	data 0.0005 (0.0634)	batch 0.9107 (1.0520)	loss 2.5725 (2.6206)	grad_norm 0.7058 (0.7138)	mem 38886MB
Train: [152/180][400/625]	eta 0:03:52 lr 0.044783	data 0.0011 (0.0555)	batch 0.9055 (1.0333)	loss 2.5717 (2.6202)	grad_norm 0.7225 (0.7141)	mem 38886MB
Train: [152/180][450/625]	eta 0:02:58 lr 0.044527	data 0.0007 (0.0494)	batch 0.9098 (1.0195)	loss 2.6978 (2.6195)	grad_norm 0.7230 (0.7140)	mem 38886MB
Train: [152/180][500/625]	eta 0:02:05 lr 0.044271	data 0.0006 (0.0446)	batch 0.8460 (1.0077)	loss 2.6356 (2.6205)	grad_norm 0.7280 (0.7140)	mem 38886MB
Train: [152/180][550/625]	eta 0:01:14 lr 0.044016	data 0.0006 (0.0406)	batch 0.9140 (0.9980)	loss 2.6677 (2.6184)	grad_norm 0.7249 (0.7141)	mem 38886MB
Train: [152/180][600/625]	eta 0:00:24 lr 0.043762	data 0.0007 (0.0373)	batch 0.8826 (0.9902)	loss 2.5764 (2.6183)	grad_norm 0.6996 (0.7141)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 152 training takes 0:10:18
Test: [0/25]	Time 15.048 (15.048)	Loss 0.9300 (0.9300)	Acc@1 80.176 (80.176)	Acc@5 93.994 (93.994)	Mem 38886MB
 * Acc@1 68.790 Acc@5 88.528
Accuracy of the network on the 50000 test images: 68.79%
Max accuracy (after decay): 68.79%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [153/180][0/625]	eta 3:59:53 lr 0.043635	data 21.4343 (21.4343)	batch 23.0297 (23.0297)	loss 2.5687 (2.5687)	grad_norm 0.7222 (0.7222)	mem 38886MB
Train: [153/180][50/625]	eta 0:12:56 lr 0.043382	data 0.0006 (0.4212)	batch 0.8775 (1.3505)	loss 2.5516 (2.5964)	grad_norm 0.7318 (0.7146)	mem 38886MB
Train: [153/180][100/625]	eta 0:09:52 lr 0.043130	data 0.0008 (0.2130)	batch 0.8510 (1.1293)	loss 2.7236 (2.6094)	grad_norm 0.7004 (0.7130)	mem 38886MB
Train: [153/180][150/625]	eta 0:08:21 lr 0.042878	data 0.0011 (0.1427)	batch 0.9925 (1.0558)	loss 2.5406 (2.6095)	grad_norm 0.7135 (0.7132)	mem 38886MB
Train: [153/180][200/625]	eta 0:07:12 lr 0.042627	data 0.0007 (0.1074)	batch 0.9474 (1.0180)	loss 2.6541 (2.6179)	grad_norm 0.7077 (0.7139)	mem 38886MB
Train: [153/180][250/625]	eta 0:06:12 lr 0.042376	data 0.0008 (0.0861)	batch 0.9019 (0.9946)	loss 2.6495 (2.6240)	grad_norm 0.7232 (0.7146)	mem 38886MB
Train: [153/180][300/625]	eta 0:05:18 lr 0.042126	data 0.0007 (0.0719)	batch 0.8669 (0.9807)	loss 2.6079 (2.6302)	grad_norm 0.7225 (0.7156)	mem 38886MB
Train: [153/180][350/625]	eta 0:04:26 lr 0.041877	data 0.0006 (0.0618)	batch 0.9013 (0.9697)	loss 2.6070 (2.6274)	grad_norm 0.7168 (0.7164)	mem 38886MB
Train: [153/180][400/625]	eta 0:03:36 lr 0.041629	data 0.0006 (0.0541)	batch 0.8797 (0.9615)	loss 2.5433 (2.6249)	grad_norm 0.7232 (0.7164)	mem 38886MB
Train: [153/180][450/625]	eta 0:02:47 lr 0.041382	data 0.0005 (0.0482)	batch 0.8903 (0.9551)	loss 2.5265 (2.6268)	grad_norm 0.7138 (0.7168)	mem 38886MB
Train: [153/180][500/625]	eta 0:01:58 lr 0.041135	data 0.0134 (0.0435)	batch 0.9790 (0.9496)	loss 2.5640 (2.6268)	grad_norm 0.7312 (0.7170)	mem 38886MB
Train: [153/180][550/625]	eta 0:01:10 lr 0.040888	data 0.0006 (0.0396)	batch 0.9086 (0.9450)	loss 2.5321 (2.6262)	grad_norm 0.7147 (0.7170)	mem 38886MB
Train: [153/180][600/625]	eta 0:00:23 lr 0.040643	data 0.0009 (0.0363)	batch 0.8746 (0.9416)	loss 2.6332 (2.6257)	grad_norm 0.7300 (0.7168)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 153 training takes 0:09:49
Test: [0/25]	Time 14.973 (14.973)	Loss 0.9232 (0.9232)	Acc@1 80.273 (80.273)	Acc@5 93.945 (93.945)	Mem 38886MB
 * Acc@1 68.764 Acc@5 88.428
Accuracy of the network on the 50000 test images: 68.76%
Max accuracy (after decay): 68.79%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [154/180][0/625]	eta 4:02:38 lr 0.040520	data 22.2898 (22.2898)	batch 23.2938 (23.2938)	loss 2.4803 (2.4803)	grad_norm 0.7249 (0.7249)	mem 38886MB
Train: [154/180][50/625]	eta 0:12:56 lr 0.040276	data 0.0005 (0.4376)	batch 0.8612 (1.3498)	loss 2.5651 (2.5969)	grad_norm 0.7086 (0.7184)	mem 38886MB
Train: [154/180][100/625]	eta 0:09:53 lr 0.040032	data 0.0006 (0.2212)	batch 0.8682 (1.1306)	loss 2.5208 (2.5887)	grad_norm 0.7321 (0.7189)	mem 38886MB
Train: [154/180][150/625]	eta 0:08:21 lr 0.039789	data 0.0005 (0.1482)	batch 0.9082 (1.0567)	loss 2.6677 (2.5893)	grad_norm 0.7359 (0.7191)	mem 38886MB
Train: [154/180][200/625]	eta 0:07:13 lr 0.039547	data 0.0005 (0.1114)	batch 0.9003 (1.0210)	loss 2.4997 (2.5983)	grad_norm 0.7094 (0.7182)	mem 38886MB
Train: [154/180][250/625]	eta 0:06:14 lr 0.039305	data 0.0006 (0.0894)	batch 0.8692 (0.9990)	loss 2.5975 (2.6028)	grad_norm 0.7203 (0.7185)	mem 38886MB
Train: [154/180][300/625]	eta 0:05:19 lr 0.039064	data 0.0005 (0.0746)	batch 0.9479 (0.9840)	loss 2.5822 (2.6046)	grad_norm 0.7147 (0.7183)	mem 38886MB
Train: [154/180][350/625]	eta 0:04:27 lr 0.038824	data 0.0006 (0.0640)	batch 0.8885 (0.9730)	loss 2.7096 (2.6017)	grad_norm 0.7363 (0.7180)	mem 38886MB
Train: [154/180][400/625]	eta 0:03:37 lr 0.038584	data 0.0004 (0.0561)	batch 1.1047 (0.9647)	loss 2.6386 (2.6026)	grad_norm 0.7175 (0.7183)	mem 38886MB
Train: [154/180][450/625]	eta 0:02:47 lr 0.038345	data 0.0005 (0.0500)	batch 0.8974 (0.9583)	loss 2.6876 (2.6073)	grad_norm 0.7326 (0.7186)	mem 38886MB
Train: [154/180][500/625]	eta 0:01:59 lr 0.038107	data 0.0005 (0.0450)	batch 0.9023 (0.9535)	loss 2.8427 (2.6104)	grad_norm 0.7235 (0.7188)	mem 38886MB
Train: [154/180][550/625]	eta 0:01:11 lr 0.037870	data 0.0006 (0.0410)	batch 0.8942 (0.9488)	loss 2.6784 (2.6116)	grad_norm 0.7337 (0.7191)	mem 38886MB
Train: [154/180][600/625]	eta 0:00:23 lr 0.037633	data 0.0005 (0.0376)	batch 0.9041 (0.9453)	loss 2.7318 (2.6143)	grad_norm 0.7267 (0.7194)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 154 training takes 0:09:51
Test: [0/25]	Time 14.928 (14.928)	Loss 0.9266 (0.9266)	Acc@1 79.883 (79.883)	Acc@5 93.750 (93.750)	Mem 38886MB
 * Acc@1 68.914 Acc@5 88.522
Accuracy of the network on the 50000 test images: 68.91%
Max accuracy (after decay): 68.91%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [155/180][0/625]	eta 4:02:53 lr 0.037515	data 21.5645 (21.5645)	batch 23.3175 (23.3175)	loss 2.3991 (2.3991)	grad_norm 0.7073 (0.7073)	mem 38886MB
Train: [155/180][50/625]	eta 0:12:55 lr 0.037279	data 0.0005 (0.4239)	batch 0.9298 (1.3494)	loss 2.7007 (2.6015)	grad_norm 0.7615 (0.7220)	mem 38886MB
Train: [155/180][100/625]	eta 0:09:54 lr 0.037044	data 0.0005 (0.2144)	batch 0.8803 (1.1328)	loss 2.6730 (2.6036)	grad_norm 0.7279 (0.7211)	mem 38886MB
Train: [155/180][150/625]	eta 0:08:22 lr 0.036810	data 0.0011 (0.1437)	batch 0.9925 (1.0584)	loss 2.7306 (2.6052)	grad_norm 0.7282 (0.7220)	mem 38886MB
Train: [155/180][200/625]	eta 0:07:14 lr 0.036577	data 0.0006 (0.1081)	batch 0.9532 (1.0213)	loss 2.3473 (2.5959)	grad_norm 0.7143 (0.7226)	mem 38886MB
Train: [155/180][250/625]	eta 0:06:14 lr 0.036344	data 0.0007 (0.0867)	batch 0.8939 (0.9988)	loss 2.4609 (2.6040)	grad_norm 0.7007 (0.7222)	mem 38886MB
Train: [155/180][300/625]	eta 0:05:19 lr 0.036112	data 0.0008 (0.0724)	batch 0.9057 (0.9834)	loss 2.4655 (2.6046)	grad_norm 0.7036 (0.7225)	mem 38886MB
Train: [155/180][350/625]	eta 0:04:27 lr 0.035880	data 0.0006 (0.0622)	batch 0.9144 (0.9726)	loss 2.4707 (2.6071)	grad_norm 0.7275 (0.7225)	mem 38886MB
Train: [155/180][400/625]	eta 0:03:36 lr 0.035649	data 0.0005 (0.0545)	batch 0.8948 (0.9641)	loss 2.5241 (2.6080)	grad_norm 0.7255 (0.7225)	mem 38886MB
Train: [155/180][450/625]	eta 0:02:47 lr 0.035419	data 0.0007 (0.0486)	batch 0.9341 (0.9579)	loss 2.5475 (2.6076)	grad_norm 0.7204 (0.7227)	mem 38886MB
Train: [155/180][500/625]	eta 0:01:59 lr 0.035190	data 0.0011 (0.0438)	batch 0.8948 (0.9533)	loss 2.5263 (2.6073)	grad_norm 0.7173 (0.7225)	mem 38886MB
Train: [155/180][550/625]	eta 0:01:11 lr 0.034962	data 0.0005 (0.0399)	batch 0.9406 (0.9507)	loss 2.5946 (2.6094)	grad_norm 0.7345 (0.7227)	mem 38886MB
Train: [155/180][600/625]	eta 0:00:23 lr 0.034734	data 0.0004 (0.0366)	batch 1.1421 (0.9555)	loss 2.6253 (2.6108)	grad_norm 0.7469 (0.7230)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 155 training takes 0:10:00
Test: [0/25]	Time 14.434 (14.434)	Loss 0.9376 (0.9376)	Acc@1 79.980 (79.980)	Acc@5 93.506 (93.506)	Mem 38886MB
 * Acc@1 68.876 Acc@5 88.548
Accuracy of the network on the 50000 test images: 68.88%
Max accuracy (after decay): 68.91%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [156/180][0/625]	eta 3:59:22 lr 0.034620	data 20.9759 (20.9759)	batch 22.9802 (22.9802)	loss 2.4407 (2.4407)	grad_norm 0.7107 (0.7107)	mem 38886MB
Train: [156/180][50/625]	eta 0:12:51 lr 0.034393	data 0.0005 (0.4119)	batch 0.8897 (1.3425)	loss 2.5685 (2.6047)	grad_norm 0.7286 (0.7213)	mem 38886MB
Train: [156/180][100/625]	eta 0:09:51 lr 0.034167	data 0.0005 (0.2082)	batch 0.8951 (1.1263)	loss 2.5015 (2.6055)	grad_norm 0.7178 (0.7221)	mem 38886MB
Train: [156/180][150/625]	eta 0:08:20 lr 0.033942	data 0.0005 (0.1395)	batch 0.8935 (1.0527)	loss 2.7244 (2.6087)	grad_norm 0.7388 (0.7231)	mem 38886MB
Train: [156/180][200/625]	eta 0:07:11 lr 0.033717	data 0.0006 (0.1049)	batch 0.8948 (1.0162)	loss 2.4896 (2.6070)	grad_norm 0.7176 (0.7227)	mem 38886MB
Train: [156/180][250/625]	eta 0:06:12 lr 0.033493	data 0.0005 (0.0841)	batch 0.9131 (0.9946)	loss 2.6663 (2.6132)	grad_norm 0.7375 (0.7236)	mem 38886MB
Train: [156/180][300/625]	eta 0:05:19 lr 0.033270	data 0.0005 (0.0702)	batch 0.9453 (0.9823)	loss 2.7661 (2.6136)	grad_norm 0.7228 (0.7233)	mem 38886MB
Train: [156/180][350/625]	eta 0:04:30 lr 0.033047	data 0.0004 (0.0603)	batch 1.1848 (0.9845)	loss 2.4982 (2.6081)	grad_norm 0.7227 (0.7236)	mem 38886MB
Train: [156/180][400/625]	eta 0:03:39 lr 0.032826	data 0.0005 (0.0528)	batch 0.8950 (0.9766)	loss 2.6328 (2.6083)	grad_norm 0.7417 (0.7237)	mem 38886MB
Train: [156/180][450/625]	eta 0:02:49 lr 0.032605	data 0.0007 (0.0470)	batch 0.9421 (0.9681)	loss 2.5644 (2.6073)	grad_norm 0.7266 (0.7238)	mem 38886MB
Train: [156/180][500/625]	eta 0:02:00 lr 0.032384	data 0.0005 (0.0424)	batch 0.9241 (0.9644)	loss 2.7143 (2.6069)	grad_norm 0.7254 (0.7239)	mem 38886MB
Train: [156/180][550/625]	eta 0:01:13 lr 0.032165	data 0.0005 (0.0386)	batch 1.1530 (0.9764)	loss 2.5660 (2.6063)	grad_norm 0.7236 (0.7240)	mem 38886MB
Train: [156/180][600/625]	eta 0:00:24 lr 0.031946	data 0.0005 (0.0354)	batch 1.1421 (0.9917)	loss 2.5112 (2.6059)	grad_norm 0.7435 (0.7245)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 156 training takes 0:10:19
Test: [0/25]	Time 15.007 (15.007)	Loss 0.9332 (0.9332)	Acc@1 80.225 (80.225)	Acc@5 93.896 (93.896)	Mem 38886MB
 * Acc@1 69.018 Acc@5 88.644
Accuracy of the network on the 50000 test images: 69.02%
Max accuracy (after decay): 69.02%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [157/180][0/625]	eta 4:01:49 lr 0.031836	data 22.2433 (22.2433)	batch 23.2146 (23.2146)	loss 2.6994 (2.6994)	grad_norm 0.7033 (0.7033)	mem 38886MB
Train: [157/180][50/625]	eta 0:12:56 lr 0.031619	data 0.0005 (0.4367)	batch 0.9357 (1.3513)	loss 2.5943 (2.6051)	grad_norm 0.7245 (0.7253)	mem 38886MB
Train: [157/180][100/625]	eta 0:09:54 lr 0.031401	data 0.0005 (0.2208)	batch 0.9141 (1.1319)	loss 2.7259 (2.6046)	grad_norm 0.7277 (0.7228)	mem 38886MB
Train: [157/180][150/625]	eta 0:08:23 lr 0.031185	data 0.0005 (0.1478)	batch 0.8750 (1.0603)	loss 2.6718 (2.6048)	grad_norm 0.7232 (0.7237)	mem 38886MB
Train: [157/180][200/625]	eta 0:07:13 lr 0.030969	data 0.0005 (0.1112)	batch 0.9035 (1.0208)	loss 2.4814 (2.6061)	grad_norm 0.7123 (0.7251)	mem 38886MB
Train: [157/180][250/625]	eta 0:06:13 lr 0.030754	data 0.0005 (0.0891)	batch 0.8978 (0.9967)	loss 2.4289 (2.6076)	grad_norm 0.7146 (0.7254)	mem 38886MB
Train: [157/180][300/625]	eta 0:05:19 lr 0.030540	data 0.0004 (0.0744)	batch 0.9113 (0.9824)	loss 2.6551 (2.6030)	grad_norm 0.7313 (0.7257)	mem 38886MB
Train: [157/180][350/625]	eta 0:04:27 lr 0.030327	data 0.0005 (0.0639)	batch 0.9095 (0.9715)	loss 2.6977 (2.6058)	grad_norm 0.7340 (0.7259)	mem 38886MB
Train: [157/180][400/625]	eta 0:03:36 lr 0.030114	data 0.0004 (0.0560)	batch 0.8733 (0.9623)	loss 2.6654 (2.6066)	grad_norm 0.7178 (0.7261)	mem 38886MB
Train: [157/180][450/625]	eta 0:02:47 lr 0.029902	data 0.0005 (0.0499)	batch 0.9931 (0.9555)	loss 2.6797 (2.6053)	grad_norm 0.7071 (0.7259)	mem 38886MB
Train: [157/180][500/625]	eta 0:01:58 lr 0.029690	data 0.0004 (0.0449)	batch 0.8499 (0.9502)	loss 2.6442 (2.6035)	grad_norm 0.7138 (0.7259)	mem 38886MB
Train: [157/180][550/625]	eta 0:01:10 lr 0.029480	data 0.0005 (0.0409)	batch 0.8843 (0.9463)	loss 2.3661 (2.6042)	grad_norm 0.7212 (0.7258)	mem 38886MB
Train: [157/180][600/625]	eta 0:00:23 lr 0.029270	data 0.0005 (0.0375)	batch 0.9122 (0.9423)	loss 2.6174 (2.6045)	grad_norm 0.7191 (0.7259)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 157 training takes 0:09:49
Test: [0/25]	Time 14.658 (14.658)	Loss 0.9148 (0.9148)	Acc@1 80.420 (80.420)	Acc@5 94.287 (94.287)	Mem 38886MB
 * Acc@1 69.118 Acc@5 88.680
Accuracy of the network on the 50000 test images: 69.12%
Max accuracy (after decay): 69.12%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [158/180][0/625]	eta 4:07:54 lr 0.029165	data 22.8460 (22.8460)	batch 23.7999 (23.7999)	loss 2.5018 (2.5018)	grad_norm 0.7248 (0.7248)	mem 38886MB
Train: [158/180][50/625]	eta 0:12:57 lr 0.028956	data 0.0004 (0.4487)	batch 0.9148 (1.3517)	loss 2.5873 (2.5877)	grad_norm 0.7127 (0.7264)	mem 38886MB
Train: [158/180][100/625]	eta 0:09:53 lr 0.028748	data 0.0006 (0.2269)	batch 0.9358 (1.1299)	loss 2.5925 (2.5925)	grad_norm 0.7111 (0.7279)	mem 38886MB
Train: [158/180][150/625]	eta 0:08:22 lr 0.028541	data 0.0006 (0.1519)	batch 0.8631 (1.0570)	loss 2.5299 (2.5960)	grad_norm 0.7197 (0.7271)	mem 38886MB
Train: [158/180][200/625]	eta 0:07:12 lr 0.028334	data 0.0004 (0.1142)	batch 0.9150 (1.0185)	loss 2.5872 (2.5959)	grad_norm 0.7409 (0.7278)	mem 38886MB
Train: [158/180][250/625]	eta 0:06:13 lr 0.028128	data 0.0007 (0.0916)	batch 0.9090 (0.9960)	loss 2.4526 (2.5913)	grad_norm 0.7303 (0.7284)	mem 38886MB
Train: [158/180][300/625]	eta 0:05:18 lr 0.027923	data 0.0006 (0.0765)	batch 0.8477 (0.9803)	loss 2.8788 (2.5940)	grad_norm 0.7267 (0.7288)	mem 38886MB
Train: [158/180][350/625]	eta 0:04:26 lr 0.027718	data 0.0005 (0.0658)	batch 0.9116 (0.9688)	loss 2.6072 (2.5961)	grad_norm 0.7299 (0.7285)	mem 38886MB
Train: [158/180][400/625]	eta 0:03:36 lr 0.027514	data 0.0004 (0.0577)	batch 0.8819 (0.9606)	loss 2.7400 (2.5959)	grad_norm 0.7198 (0.7284)	mem 38886MB
Train: [158/180][450/625]	eta 0:02:46 lr 0.027311	data 0.0005 (0.0513)	batch 0.8781 (0.9534)	loss 2.8517 (2.5968)	grad_norm 0.7179 (0.7288)	mem 38886MB
Train: [158/180][500/625]	eta 0:01:58 lr 0.027109	data 0.0005 (0.0462)	batch 0.8652 (0.9492)	loss 2.5143 (2.5971)	grad_norm 0.7222 (0.7288)	mem 38886MB
Train: [158/180][550/625]	eta 0:01:10 lr 0.026908	data 0.0005 (0.0421)	batch 0.9312 (0.9451)	loss 2.4948 (2.5975)	grad_norm 0.7167 (0.7290)	mem 38886MB
Train: [158/180][600/625]	eta 0:00:23 lr 0.026707	data 0.0005 (0.0386)	batch 0.9845 (0.9447)	loss 2.6322 (2.5987)	grad_norm 0.7307 (0.7291)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 158 training takes 0:09:56
Test: [0/25]	Time 15.006 (15.006)	Loss 0.9144 (0.9144)	Acc@1 80.322 (80.322)	Acc@5 93.945 (93.945)	Mem 38886MB
 * Acc@1 69.106 Acc@5 88.712
Accuracy of the network on the 50000 test images: 69.11%
Max accuracy (after decay): 69.12%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [159/180][0/625]	eta 4:06:05 lr 0.026607	data 22.3768 (22.3768)	batch 23.6240 (23.6240)	loss 2.6455 (2.6455)	grad_norm 0.7227 (0.7227)	mem 38886MB
Train: [159/180][50/625]	eta 0:15:22 lr 0.026407	data 0.0006 (0.4394)	batch 1.1312 (1.6052)	loss 2.6145 (2.6013)	grad_norm 0.7390 (0.7298)	mem 38886MB
Train: [159/180][100/625]	eta 0:12:07 lr 0.026208	data 0.0007 (0.2222)	batch 1.1515 (1.3852)	loss 2.6686 (2.5824)	grad_norm 0.7511 (0.7270)	mem 38886MB
Train: [159/180][150/625]	eta 0:10:24 lr 0.026009	data 0.0006 (0.1488)	batch 1.1277 (1.3138)	loss 2.6333 (2.5859)	grad_norm 0.7530 (0.7277)	mem 38886MB
Train: [159/180][200/625]	eta 0:09:02 lr 0.025812	data 0.0006 (0.1119)	batch 1.1675 (1.2763)	loss 2.7960 (2.5850)	grad_norm 0.7218 (0.7277)	mem 38886MB
Train: [159/180][250/625]	eta 0:07:50 lr 0.025615	data 0.0003 (0.0898)	batch 1.1812 (1.2553)	loss 2.5289 (2.5893)	grad_norm 0.7153 (0.7283)	mem 38886MB
Train: [159/180][300/625]	eta 0:06:43 lr 0.025419	data 0.0005 (0.0750)	batch 1.2263 (1.2405)	loss 2.4281 (2.5890)	grad_norm 0.7336 (0.7293)	mem 38886MB
Train: [159/180][350/625]	eta 0:05:38 lr 0.025223	data 0.0005 (0.0644)	batch 1.1709 (1.2293)	loss 2.5712 (2.5914)	grad_norm 0.7418 (0.7297)	mem 38886MB
Train: [159/180][400/625]	eta 0:04:34 lr 0.025029	data 0.0007 (0.0564)	batch 1.0865 (1.2212)	loss 2.8215 (2.5963)	grad_norm 0.7444 (0.7299)	mem 38886MB
Train: [159/180][450/625]	eta 0:03:32 lr 0.024835	data 0.0006 (0.0502)	batch 1.1580 (1.2149)	loss 2.5782 (2.5951)	grad_norm 0.7378 (0.7301)	mem 38886MB
Train: [159/180][500/625]	eta 0:02:31 lr 0.024642	data 0.0006 (0.0453)	batch 1.1571 (1.2095)	loss 2.5544 (2.5938)	grad_norm 0.7202 (0.7296)	mem 38886MB
Train: [159/180][550/625]	eta 0:01:30 lr 0.024449	data 0.0005 (0.0412)	batch 1.1758 (1.2048)	loss 2.5151 (2.5950)	grad_norm 0.7275 (0.7298)	mem 38886MB
Train: [159/180][600/625]	eta 0:00:30 lr 0.024257	data 0.0006 (0.0378)	batch 1.1760 (1.2013)	loss 2.5707 (2.5969)	grad_norm 0.7280 (0.7301)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 159 training takes 0:12:31
Test: [0/25]	Time 15.318 (15.318)	Loss 0.9153 (0.9153)	Acc@1 80.273 (80.273)	Acc@5 94.043 (94.043)	Mem 38886MB
 * Acc@1 69.186 Acc@5 88.826
Accuracy of the network on the 50000 test images: 69.19%
Max accuracy (after decay): 69.19%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [160/180][0/625]	eta 4:00:04 lr 0.024162	data 21.6525 (21.6525)	batch 23.0479 (23.0479)	loss 2.5383 (2.5383)	grad_norm 0.7384 (0.7384)	mem 38886MB
Train: [160/180][50/625]	eta 0:15:25 lr 0.023971	data 0.0006 (0.4256)	batch 1.1816 (1.6089)	loss 2.5584 (2.5955)	grad_norm 0.7371 (0.7306)	mem 38886MB
Train: [160/180][100/625]	eta 0:12:10 lr 0.023781	data 0.0010 (0.2153)	batch 1.1922 (1.3921)	loss 2.6785 (2.5807)	grad_norm 0.7588 (0.7314)	mem 38886MB
Train: [160/180][150/625]	eta 0:10:26 lr 0.023592	data 0.0006 (0.1442)	batch 1.1485 (1.3199)	loss 2.6644 (2.5813)	grad_norm 0.7058 (0.7324)	mem 38886MB
Train: [160/180][200/625]	eta 0:09:05 lr 0.023404	data 0.0006 (0.1085)	batch 1.1748 (1.2830)	loss 2.7084 (2.5808)	grad_norm 0.7400 (0.7319)	mem 38886MB
Train: [160/180][250/625]	eta 0:07:53 lr 0.023216	data 0.0008 (0.0871)	batch 1.1721 (1.2618)	loss 2.7381 (2.5829)	grad_norm 0.7489 (0.7322)	mem 38886MB
Train: [160/180][300/625]	eta 0:06:45 lr 0.023029	data 0.0006 (0.0727)	batch 1.1775 (1.2476)	loss 2.5397 (2.5859)	grad_norm 0.7381 (0.7323)	mem 38886MB
Train: [160/180][350/625]	eta 0:05:40 lr 0.022843	data 0.0006 (0.0624)	batch 1.1418 (1.2364)	loss 2.5587 (2.5901)	grad_norm 0.7425 (0.7321)	mem 38886MB
Train: [160/180][400/625]	eta 0:04:36 lr 0.022657	data 0.0005 (0.0547)	batch 1.1713 (1.2289)	loss 2.4829 (2.5894)	grad_norm 0.7319 (0.7324)	mem 38886MB
Train: [160/180][450/625]	eta 0:03:33 lr 0.022472	data 0.0004 (0.0487)	batch 1.2109 (1.2218)	loss 2.8361 (2.5880)	grad_norm 0.7225 (0.7327)	mem 38886MB
Train: [160/180][500/625]	eta 0:02:32 lr 0.022288	data 0.0006 (0.0439)	batch 1.1681 (1.2164)	loss 2.6667 (2.5886)	grad_norm 0.7462 (0.7327)	mem 38886MB
Train: [160/180][550/625]	eta 0:01:30 lr 0.022105	data 0.0005 (0.0400)	batch 1.1853 (1.2121)	loss 2.5847 (2.5864)	grad_norm 0.7242 (0.7328)	mem 38886MB
Train: [160/180][600/625]	eta 0:00:30 lr 0.021922	data 0.0005 (0.0367)	batch 1.1433 (1.2089)	loss 2.6343 (2.5900)	grad_norm 0.7414 (0.7330)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 160 training takes 0:12:35
Test: [0/25]	Time 15.401 (15.401)	Loss 0.8980 (0.8980)	Acc@1 80.322 (80.322)	Acc@5 94.531 (94.531)	Mem 38886MB
 * Acc@1 69.178 Acc@5 88.926
Accuracy of the network on the 50000 test images: 69.18%
Max accuracy (after decay): 69.19%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [161/180][0/625]	eta 4:09:02 lr 0.021831	data 22.6781 (22.6781)	batch 23.9080 (23.9080)	loss 2.6764 (2.6764)	grad_norm 0.7220 (0.7220)	mem 38886MB
Train: [161/180][50/625]	eta 0:15:37 lr 0.021650	data 0.0006 (0.4455)	batch 1.1929 (1.6296)	loss 2.6844 (2.5687)	grad_norm 0.7460 (0.7316)	mem 38886MB
Train: [161/180][100/625]	eta 0:12:15 lr 0.021469	data 0.0007 (0.2253)	batch 1.1522 (1.4014)	loss 2.5263 (2.5675)	grad_norm 0.7377 (0.7330)	mem 38886MB
Train: [161/180][150/625]	eta 0:10:30 lr 0.021289	data 0.0006 (0.1509)	batch 1.1923 (1.3280)	loss 2.5101 (2.5726)	grad_norm 0.7180 (0.7327)	mem 38886MB
Train: [161/180][200/625]	eta 0:09:08 lr 0.021110	data 0.0006 (0.1135)	batch 1.1691 (1.2908)	loss 2.6398 (2.5773)	grad_norm 0.7420 (0.7325)	mem 38886MB
Train: [161/180][250/625]	eta 0:07:55 lr 0.020932	data 0.0005 (0.0910)	batch 1.1890 (1.2678)	loss 2.6541 (2.5791)	grad_norm 0.7475 (0.7334)	mem 38886MB
Train: [161/180][300/625]	eta 0:06:46 lr 0.020754	data 0.0006 (0.0760)	batch 1.0358 (1.2514)	loss 2.6797 (2.5799)	grad_norm 0.7308 (0.7334)	mem 38886MB
Train: [161/180][350/625]	eta 0:05:41 lr 0.020577	data 0.0005 (0.0652)	batch 1.1875 (1.2405)	loss 2.5314 (2.5781)	grad_norm 0.7310 (0.7335)	mem 38886MB
Train: [161/180][400/625]	eta 0:04:37 lr 0.020401	data 0.0007 (0.0572)	batch 1.1550 (1.2329)	loss 2.5464 (2.5745)	grad_norm 0.7261 (0.7335)	mem 38886MB
Train: [161/180][450/625]	eta 0:03:34 lr 0.020225	data 0.0004 (0.0509)	batch 1.1795 (1.2264)	loss 2.8178 (2.5771)	grad_norm 0.7370 (0.7335)	mem 38886MB
Train: [161/180][500/625]	eta 0:02:32 lr 0.020050	data 0.0006 (0.0459)	batch 1.1814 (1.2212)	loss 2.7398 (2.5772)	grad_norm 0.7413 (0.7337)	mem 38886MB
Train: [161/180][550/625]	eta 0:01:31 lr 0.019876	data 0.0005 (0.0418)	batch 1.1449 (1.2165)	loss 2.5619 (2.5791)	grad_norm 0.7274 (0.7339)	mem 38886MB
Train: [161/180][600/625]	eta 0:00:30 lr 0.019703	data 0.0003 (0.0383)	batch 1.2656 (1.2127)	loss 2.3545 (2.5771)	grad_norm 0.7317 (0.7340)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 161 training takes 0:12:38
Test: [0/25]	Time 15.517 (15.517)	Loss 0.9054 (0.9054)	Acc@1 80.811 (80.811)	Acc@5 94.336 (94.336)	Mem 38886MB
 * Acc@1 69.284 Acc@5 88.788
Accuracy of the network on the 50000 test images: 69.28%
Max accuracy (after decay): 69.28%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [162/180][0/625]	eta 4:04:08 lr 0.019616	data 22.0818 (22.0818)	batch 23.4370 (23.4370)	loss 2.5805 (2.5805)	grad_norm 0.7323 (0.7323)	mem 38886MB
Train: [162/180][50/625]	eta 0:15:29 lr 0.019444	data 0.0005 (0.4338)	batch 1.2182 (1.6171)	loss 2.6192 (2.5773)	grad_norm 0.7355 (0.7373)	mem 38886MB
Train: [162/180][100/625]	eta 0:12:15 lr 0.019273	data 0.0012 (0.2194)	batch 1.1777 (1.4014)	loss 2.4568 (2.5824)	grad_norm 0.7213 (0.7360)	mem 38886MB
Train: [162/180][150/625]	eta 0:10:30 lr 0.019102	data 0.0005 (0.1469)	batch 1.1941 (1.3278)	loss 2.4023 (2.5894)	grad_norm 0.7334 (0.7359)	mem 38886MB
Train: [162/180][200/625]	eta 0:09:07 lr 0.018932	data 0.0007 (0.1105)	batch 1.2082 (1.2883)	loss 2.5683 (2.5907)	grad_norm 0.7472 (0.7360)	mem 38886MB
Train: [162/180][250/625]	eta 0:07:54 lr 0.018763	data 0.0008 (0.0886)	batch 1.1550 (1.2651)	loss 2.5100 (2.5889)	grad_norm 0.7203 (0.7350)	mem 38886MB
Train: [162/180][300/625]	eta 0:06:46 lr 0.018594	data 0.0005 (0.0740)	batch 1.1907 (1.2512)	loss 2.5618 (2.5868)	grad_norm 0.7291 (0.7352)	mem 38886MB
Train: [162/180][350/625]	eta 0:05:41 lr 0.018427	data 0.0005 (0.0636)	batch 1.1752 (1.2405)	loss 2.4445 (2.5812)	grad_norm 0.7358 (0.7354)	mem 38886MB
Train: [162/180][400/625]	eta 0:04:37 lr 0.018260	data 0.0005 (0.0557)	batch 1.1680 (1.2328)	loss 2.4516 (2.5837)	grad_norm 0.7520 (0.7357)	mem 38886MB
Train: [162/180][450/625]	eta 0:03:34 lr 0.018093	data 0.0008 (0.0496)	batch 1.1209 (1.2260)	loss 2.6317 (2.5826)	grad_norm 0.7455 (0.7358)	mem 38886MB
Train: [162/180][500/625]	eta 0:02:32 lr 0.017928	data 0.0005 (0.0447)	batch 1.1375 (1.2201)	loss 2.5078 (2.5835)	grad_norm 0.7303 (0.7363)	mem 38886MB
Train: [162/180][550/625]	eta 0:01:31 lr 0.017763	data 0.0005 (0.0407)	batch 1.1572 (1.2161)	loss 2.5598 (2.5843)	grad_norm 0.7271 (0.7363)	mem 38886MB
Train: [162/180][600/625]	eta 0:00:30 lr 0.017599	data 0.0006 (0.0374)	batch 1.1580 (1.2126)	loss 2.6502 (2.5842)	grad_norm 0.7412 (0.7365)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 162 training takes 0:12:38
Test: [0/25]	Time 15.106 (15.106)	Loss 0.9053 (0.9053)	Acc@1 80.713 (80.713)	Acc@5 94.287 (94.287)	Mem 38886MB
 * Acc@1 69.338 Acc@5 88.932
Accuracy of the network on the 50000 test images: 69.34%
Max accuracy (after decay): 69.34%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [163/180][0/625]	eta 4:10:19 lr 0.017517	data 22.3613 (22.3613)	batch 24.0309 (24.0309)	loss 2.5119 (2.5119)	grad_norm 0.7353 (0.7353)	mem 38886MB
Train: [163/180][50/625]	eta 0:15:27 lr 0.017354	data 0.0006 (0.4391)	batch 1.1305 (1.6130)	loss 2.6076 (2.5958)	grad_norm 0.7371 (0.7346)	mem 38886MB
Train: [163/180][100/625]	eta 0:12:11 lr 0.017192	data 0.0005 (0.2220)	batch 1.1501 (1.3926)	loss 2.5396 (2.5862)	grad_norm 0.7321 (0.7350)	mem 38886MB
Train: [163/180][150/625]	eta 0:10:25 lr 0.017031	data 0.0005 (0.1487)	batch 1.2154 (1.3164)	loss 2.4191 (2.5811)	grad_norm 0.7187 (0.7358)	mem 38886MB
Train: [163/180][200/625]	eta 0:09:03 lr 0.016870	data 0.0006 (0.1119)	batch 1.1823 (1.2790)	loss 2.5641 (2.5787)	grad_norm 0.7412 (0.7366)	mem 38886MB
Train: [163/180][250/625]	eta 0:07:51 lr 0.016710	data 0.0005 (0.0897)	batch 1.1838 (1.2573)	loss 2.5518 (2.5803)	grad_norm 0.7415 (0.7374)	mem 38886MB
Train: [163/180][300/625]	eta 0:06:43 lr 0.016551	data 0.0005 (0.0749)	batch 1.1500 (1.2418)	loss 2.3382 (2.5760)	grad_norm 0.7142 (0.7374)	mem 38886MB
Train: [163/180][350/625]	eta 0:05:38 lr 0.016393	data 0.0007 (0.0643)	batch 1.1432 (1.2309)	loss 2.5847 (2.5739)	grad_norm 0.7304 (0.7374)	mem 38886MB
Train: [163/180][400/625]	eta 0:04:35 lr 0.016235	data 0.0004 (0.0564)	batch 1.1743 (1.2235)	loss 2.5060 (2.5737)	grad_norm 0.7340 (0.7374)	mem 38886MB
Train: [163/180][450/625]	eta 0:03:32 lr 0.016078	data 0.0005 (0.0502)	batch 1.1772 (1.2168)	loss 2.7481 (2.5728)	grad_norm 0.7306 (0.7374)	mem 38886MB
Train: [163/180][500/625]	eta 0:02:31 lr 0.015922	data 0.0005 (0.0452)	batch 1.1402 (1.2113)	loss 2.6120 (2.5732)	grad_norm 0.7312 (0.7378)	mem 38886MB
Train: [163/180][550/625]	eta 0:01:30 lr 0.015766	data 0.0005 (0.0412)	batch 1.2081 (1.2073)	loss 2.4391 (2.5755)	grad_norm 0.7234 (0.7378)	mem 38886MB
Train: [163/180][600/625]	eta 0:00:30 lr 0.015612	data 0.0005 (0.0378)	batch 1.1397 (1.2035)	loss 2.6766 (2.5765)	grad_norm 0.7274 (0.7378)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 163 training takes 0:12:32
Test: [0/25]	Time 15.471 (15.471)	Loss 0.9044 (0.9044)	Acc@1 80.615 (80.615)	Acc@5 94.482 (94.482)	Mem 38886MB
 * Acc@1 69.370 Acc@5 88.920
Accuracy of the network on the 50000 test images: 69.37%
Max accuracy (after decay): 69.37%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [164/180][0/625]	eta 4:07:16 lr 0.015535	data 21.9903 (21.9903)	batch 23.7392 (23.7392)	loss 2.6532 (2.6532)	grad_norm 0.7299 (0.7299)	mem 38886MB
Train: [164/180][50/625]	eta 0:15:26 lr 0.015381	data 0.0005 (0.4317)	batch 1.1974 (1.6110)	loss 2.6311 (2.5619)	grad_norm 0.7575 (0.7348)	mem 38886MB
Train: [164/180][100/625]	eta 0:12:10 lr 0.015228	data 0.0006 (0.2183)	batch 1.1717 (1.3920)	loss 2.5259 (2.5572)	grad_norm 0.7402 (0.7357)	mem 38886MB
Train: [164/180][150/625]	eta 0:10:24 lr 0.015076	data 0.0005 (0.1462)	batch 1.1211 (1.3156)	loss 2.6141 (2.5619)	grad_norm 0.7287 (0.7357)	mem 38886MB
Train: [164/180][200/625]	eta 0:09:03 lr 0.014925	data 0.0005 (0.1100)	batch 1.1724 (1.2783)	loss 2.5264 (2.5721)	grad_norm 0.7468 (0.7366)	mem 38886MB
Train: [164/180][250/625]	eta 0:07:51 lr 0.014774	data 0.0005 (0.0882)	batch 1.1532 (1.2562)	loss 2.8350 (2.5807)	grad_norm 0.7481 (0.7366)	mem 38886MB
Train: [164/180][300/625]	eta 0:06:43 lr 0.014624	data 0.0005 (0.0736)	batch 1.1770 (1.2428)	loss 2.7250 (2.5816)	grad_norm 0.7361 (0.7368)	mem 38886MB
Train: [164/180][350/625]	eta 0:05:38 lr 0.014475	data 0.0006 (0.0632)	batch 1.2002 (1.2310)	loss 2.5377 (2.5813)	grad_norm 0.7350 (0.7374)	mem 38886MB
Train: [164/180][400/625]	eta 0:04:35 lr 0.014327	data 0.0006 (0.0554)	batch 1.1473 (1.2228)	loss 2.7124 (2.5805)	grad_norm 0.7536 (0.7379)	mem 38886MB
Train: [164/180][450/625]	eta 0:03:32 lr 0.014180	data 0.0006 (0.0493)	batch 1.1396 (1.2165)	loss 2.5895 (2.5797)	grad_norm 0.7412 (0.7381)	mem 38886MB
Train: [164/180][500/625]	eta 0:02:31 lr 0.014033	data 0.0005 (0.0445)	batch 1.1678 (1.2119)	loss 2.5809 (2.5810)	grad_norm 0.7441 (0.7384)	mem 38886MB
Train: [164/180][550/625]	eta 0:01:30 lr 0.013887	data 0.0005 (0.0405)	batch 1.1687 (1.2080)	loss 2.6229 (2.5796)	grad_norm 0.7333 (0.7384)	mem 38886MB
Train: [164/180][600/625]	eta 0:00:30 lr 0.013741	data 0.0006 (0.0371)	batch 1.1422 (1.2041)	loss 2.5987 (2.5791)	grad_norm 0.7283 (0.7386)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 164 training takes 0:12:33
Test: [0/25]	Time 15.017 (15.017)	Loss 0.9003 (0.9003)	Acc@1 80.469 (80.469)	Acc@5 94.629 (94.629)	Mem 38886MB
 * Acc@1 69.362 Acc@5 88.866
Accuracy of the network on the 50000 test images: 69.36%
Max accuracy (after decay): 69.37%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [165/180][0/625]	eta 4:04:08 lr 0.013669	data 22.0302 (22.0302)	batch 23.4368 (23.4368)	loss 2.4831 (2.4831)	grad_norm 0.7169 (0.7169)	mem 38886MB
Train: [165/180][50/625]	eta 0:15:28 lr 0.013525	data 0.0006 (0.4330)	batch 1.1826 (1.6141)	loss 2.5774 (2.5652)	grad_norm 0.7294 (0.7387)	mem 38886MB
Train: [165/180][100/625]	eta 0:12:25 lr 0.013381	data 0.0006 (0.2193)	batch 1.1487 (1.4207)	loss 2.6375 (2.5602)	grad_norm 0.7558 (0.7392)	mem 38886MB
Train: [165/180][150/625]	eta 0:10:35 lr 0.013239	data 0.0005 (0.1469)	batch 1.1549 (1.3383)	loss 2.6616 (2.5603)	grad_norm 0.7477 (0.7398)	mem 38886MB
Train: [165/180][200/625]	eta 0:09:14 lr 0.013097	data 0.0005 (0.1107)	batch 1.1675 (1.3044)	loss 2.6472 (2.5678)	grad_norm 0.7474 (0.7397)	mem 38886MB
Train: [165/180][250/625]	eta 0:07:59 lr 0.012956	data 0.0004 (0.0888)	batch 1.1827 (1.2776)	loss 2.5374 (2.5678)	grad_norm 0.7160 (0.7393)	mem 38886MB
Train: [165/180][300/625]	eta 0:06:49 lr 0.012815	data 0.0005 (0.0741)	batch 1.2023 (1.2602)	loss 2.6905 (2.5714)	grad_norm 0.7308 (0.7391)	mem 38886MB
Train: [165/180][350/625]	eta 0:05:42 lr 0.012676	data 0.0005 (0.0637)	batch 1.2133 (1.2470)	loss 2.5292 (2.5700)	grad_norm 0.7202 (0.7397)	mem 38886MB
Train: [165/180][400/625]	eta 0:04:38 lr 0.012537	data 0.0005 (0.0558)	batch 1.1664 (1.2369)	loss 2.4987 (2.5687)	grad_norm 0.7301 (0.7400)	mem 38886MB
Train: [165/180][450/625]	eta 0:03:35 lr 0.012399	data 0.0006 (0.0497)	batch 1.1574 (1.2298)	loss 2.5302 (2.5677)	grad_norm 0.7390 (0.7401)	mem 38886MB
Train: [165/180][500/625]	eta 0:02:32 lr 0.012261	data 0.0005 (0.0448)	batch 1.3255 (1.2234)	loss 2.6766 (2.5700)	grad_norm 0.7251 (0.7400)	mem 38886MB
Train: [165/180][550/625]	eta 0:01:31 lr 0.012125	data 0.0005 (0.0408)	batch 1.1556 (1.2184)	loss 2.5319 (2.5702)	grad_norm 0.7328 (0.7399)	mem 38886MB
Train: [165/180][600/625]	eta 0:00:30 lr 0.011989	data 0.0005 (0.0374)	batch 1.1634 (1.2143)	loss 2.4700 (2.5690)	grad_norm 0.7352 (0.7399)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 165 training takes 0:12:39
Test: [0/25]	Time 15.060 (15.060)	Loss 0.8934 (0.8934)	Acc@1 80.518 (80.518)	Acc@5 94.482 (94.482)	Mem 38886MB
 * Acc@1 69.438 Acc@5 88.890
Accuracy of the network on the 50000 test images: 69.44%
Max accuracy (after decay): 69.44%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [166/180][0/625]	eta 4:08:52 lr 0.011921	data 22.8815 (22.8815)	batch 23.8928 (23.8928)	loss 2.5533 (2.5533)	grad_norm 0.7316 (0.7316)	mem 38886MB
Train: [166/180][50/625]	eta 0:15:31 lr 0.011786	data 0.0007 (0.4497)	batch 1.0954 (1.6203)	loss 2.4636 (2.5826)	grad_norm 0.7296 (0.7376)	mem 38886MB
Train: [166/180][100/625]	eta 0:12:12 lr 0.011652	data 0.0007 (0.2274)	batch 1.1488 (1.3944)	loss 2.5296 (2.5761)	grad_norm 0.7395 (0.7382)	mem 38886MB
Train: [166/180][150/625]	eta 0:10:26 lr 0.011519	data 0.0005 (0.1523)	batch 1.1636 (1.3198)	loss 2.4650 (2.5686)	grad_norm 0.7482 (0.7390)	mem 38886MB
Train: [166/180][200/625]	eta 0:09:05 lr 0.011387	data 0.0005 (0.1146)	batch 1.1441 (1.2843)	loss 2.6847 (2.5723)	grad_norm 0.7480 (0.7390)	mem 38886MB
Train: [166/180][250/625]	eta 0:07:53 lr 0.011255	data 0.0006 (0.0919)	batch 1.1913 (1.2616)	loss 2.6284 (2.5787)	grad_norm 0.7459 (0.7396)	mem 38886MB
Train: [166/180][300/625]	eta 0:06:45 lr 0.011124	data 0.0005 (0.0767)	batch 1.1541 (1.2470)	loss 2.3770 (2.5746)	grad_norm 0.7661 (0.7398)	mem 38886MB
Train: [166/180][350/625]	eta 0:05:39 lr 0.010994	data 0.0006 (0.0659)	batch 1.2029 (1.2358)	loss 2.5360 (2.5777)	grad_norm 0.7425 (0.7404)	mem 38886MB
Train: [166/180][400/625]	eta 0:04:36 lr 0.010864	data 0.0005 (0.0577)	batch 1.2025 (1.2276)	loss 2.3068 (2.5751)	grad_norm 0.7227 (0.7406)	mem 38886MB
Train: [166/180][450/625]	eta 0:03:33 lr 0.010736	data 0.0006 (0.0514)	batch 1.1894 (1.2210)	loss 2.7145 (2.5727)	grad_norm 0.7483 (0.7406)	mem 38886MB
Train: [166/180][500/625]	eta 0:02:32 lr 0.010608	data 0.0005 (0.0463)	batch 1.1932 (1.2161)	loss 2.5868 (2.5730)	grad_norm 0.7257 (0.7403)	mem 38886MB
Train: [166/180][550/625]	eta 0:01:30 lr 0.010481	data 0.0006 (0.0422)	batch 1.1662 (1.2121)	loss 2.4826 (2.5726)	grad_norm 0.7240 (0.7404)	mem 38886MB
Train: [166/180][600/625]	eta 0:00:30 lr 0.010354	data 0.0006 (0.0387)	batch 1.1370 (1.2082)	loss 2.6182 (2.5741)	grad_norm 0.7426 (0.7410)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 166 training takes 0:12:35
Test: [0/25]	Time 14.792 (14.792)	Loss 0.9000 (0.9000)	Acc@1 80.908 (80.908)	Acc@5 94.434 (94.434)	Mem 38886MB
 * Acc@1 69.446 Acc@5 88.974
Accuracy of the network on the 50000 test images: 69.45%
Max accuracy (after decay): 69.45%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [167/180][0/625]	eta 4:14:10 lr 0.010291	data 23.2173 (23.2173)	batch 24.4002 (24.4002)	loss 2.5432 (2.5432)	grad_norm 0.7258 (0.7258)	mem 38886MB
Train: [167/180][50/625]	eta 0:15:33 lr 0.010166	data 0.0005 (0.4559)	batch 1.1859 (1.6235)	loss 2.5160 (2.5607)	grad_norm 0.7334 (0.7376)	mem 38886MB
Train: [167/180][100/625]	eta 0:12:14 lr 0.010042	data 0.0005 (0.2305)	batch 1.1595 (1.3982)	loss 2.5067 (2.5684)	grad_norm 0.7351 (0.7391)	mem 38886MB
Train: [167/180][150/625]	eta 0:10:28 lr 0.009918	data 0.0005 (0.1543)	batch 1.1611 (1.3231)	loss 2.3605 (2.5745)	grad_norm 0.7210 (0.7394)	mem 38886MB
Train: [167/180][200/625]	eta 0:09:06 lr 0.009795	data 0.0005 (0.1161)	batch 1.1800 (1.2863)	loss 2.5832 (2.5768)	grad_norm 0.7363 (0.7398)	mem 38886MB
Train: [167/180][250/625]	eta 0:07:53 lr 0.009673	data 0.0008 (0.0931)	batch 1.1127 (1.2632)	loss 2.6927 (2.5792)	grad_norm 0.7592 (0.7401)	mem 38886MB
Train: [167/180][300/625]	eta 0:06:45 lr 0.009551	data 0.0006 (0.0777)	batch 1.1591 (1.2485)	loss 2.4549 (2.5818)	grad_norm 0.7534 (0.7405)	mem 38886MB
Train: [167/180][350/625]	eta 0:05:40 lr 0.009431	data 0.0006 (0.0667)	batch 1.1610 (1.2365)	loss 2.5727 (2.5811)	grad_norm 0.7363 (0.7406)	mem 38886MB
Train: [167/180][400/625]	eta 0:04:36 lr 0.009311	data 0.0006 (0.0585)	batch 1.1786 (1.2289)	loss 2.5519 (2.5796)	grad_norm 0.7286 (0.7408)	mem 38886MB
Train: [167/180][450/625]	eta 0:03:33 lr 0.009192	data 0.0005 (0.0521)	batch 1.2201 (1.2226)	loss 2.6972 (2.5804)	grad_norm 0.7664 (0.7411)	mem 38886MB
Train: [167/180][500/625]	eta 0:02:32 lr 0.009073	data 0.0005 (0.0469)	batch 1.1034 (1.2168)	loss 2.7099 (2.5817)	grad_norm 0.7445 (0.7412)	mem 38886MB
Train: [167/180][550/625]	eta 0:01:30 lr 0.008956	data 0.0005 (0.0427)	batch 1.0900 (1.2129)	loss 2.4477 (2.5829)	grad_norm 0.7413 (0.7415)	mem 38886MB
Train: [167/180][600/625]	eta 0:00:30 lr 0.008839	data 0.0005 (0.0392)	batch 1.1652 (1.2091)	loss 2.7816 (2.5831)	grad_norm 0.7298 (0.7418)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 167 training takes 0:12:36
Test: [0/25]	Time 15.282 (15.282)	Loss 0.9025 (0.9025)	Acc@1 80.957 (80.957)	Acc@5 94.385 (94.385)	Mem 38886MB
 * Acc@1 69.424 Acc@5 88.928
Accuracy of the network on the 50000 test images: 69.42%
Max accuracy (after decay): 69.45%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [168/180][0/625]	eta 4:08:53 lr 0.008781	data 22.6087 (22.6087)	batch 23.8933 (23.8933)	loss 2.4361 (2.4361)	grad_norm 0.7296 (0.7296)	mem 38886MB
Train: [168/180][50/625]	eta 0:15:28 lr 0.008665	data 0.0006 (0.4440)	batch 1.1047 (1.6140)	loss 2.5989 (2.5662)	grad_norm 0.7518 (0.7415)	mem 38886MB
Train: [168/180][100/625]	eta 0:12:11 lr 0.008550	data 0.0005 (0.2245)	batch 1.2154 (1.3926)	loss 2.4507 (2.5677)	grad_norm 0.7239 (0.7418)	mem 38886MB
Train: [168/180][150/625]	eta 0:10:27 lr 0.008436	data 0.0005 (0.1504)	batch 1.1926 (1.3200)	loss 2.5124 (2.5711)	grad_norm 0.7286 (0.7414)	mem 38886MB
Train: [168/180][200/625]	eta 0:09:05 lr 0.008322	data 0.0006 (0.1131)	batch 1.1395 (1.2840)	loss 2.5059 (2.5745)	grad_norm 0.7363 (0.7422)	mem 38886MB
Train: [168/180][250/625]	eta 0:07:53 lr 0.008209	data 0.0005 (0.0907)	batch 1.1999 (1.2616)	loss 2.5774 (2.5711)	grad_norm 0.7398 (0.7416)	mem 38886MB
Train: [168/180][300/625]	eta 0:06:45 lr 0.008098	data 0.0005 (0.0757)	batch 1.1729 (1.2468)	loss 2.5392 (2.5733)	grad_norm 0.7452 (0.7418)	mem 38886MB
Train: [168/180][350/625]	eta 0:05:39 lr 0.007986	data 0.0005 (0.0650)	batch 1.1330 (1.2355)	loss 2.7218 (2.5746)	grad_norm 0.7561 (0.7415)	mem 38886MB
Train: [168/180][400/625]	eta 0:04:36 lr 0.007876	data 0.0005 (0.0570)	batch 1.2912 (1.2277)	loss 2.3577 (2.5731)	grad_norm 0.7371 (0.7415)	mem 38886MB
Train: [168/180][450/625]	eta 0:03:33 lr 0.007766	data 0.0006 (0.0507)	batch 1.1596 (1.2209)	loss 2.5744 (2.5734)	grad_norm 0.7381 (0.7418)	mem 38886MB
Train: [168/180][500/625]	eta 0:02:31 lr 0.007658	data 0.0005 (0.0457)	batch 1.1775 (1.2155)	loss 2.8310 (2.5742)	grad_norm 0.7257 (0.7422)	mem 38886MB
Train: [168/180][550/625]	eta 0:01:30 lr 0.007549	data 0.0005 (0.0416)	batch 1.1688 (1.2112)	loss 2.5333 (2.5744)	grad_norm 0.7458 (0.7424)	mem 38886MB
Train: [168/180][600/625]	eta 0:00:30 lr 0.007442	data 0.0006 (0.0382)	batch 1.0998 (1.2079)	loss 2.8075 (2.5729)	grad_norm 0.7338 (0.7426)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 168 training takes 0:12:35
Test: [0/25]	Time 14.955 (14.955)	Loss 0.9042 (0.9042)	Acc@1 80.420 (80.420)	Acc@5 94.238 (94.238)	Mem 38886MB
 * Acc@1 69.520 Acc@5 88.884
Accuracy of the network on the 50000 test images: 69.52%
Max accuracy (after decay): 69.52%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [169/180][0/625]	eta 4:03:34 lr 0.007389	data 22.3741 (22.3741)	batch 23.3836 (23.3836)	loss 2.4666 (2.4666)	grad_norm 0.7460 (0.7460)	mem 38886MB
Train: [169/180][50/625]	eta 0:15:26 lr 0.007283	data 0.0008 (0.4398)	batch 1.1830 (1.6109)	loss 2.6537 (2.5764)	grad_norm 0.7363 (0.7409)	mem 38886MB
Train: [169/180][100/625]	eta 0:12:11 lr 0.007177	data 0.0006 (0.2224)	batch 1.1875 (1.3935)	loss 2.6625 (2.5728)	grad_norm 0.7569 (0.7414)	mem 38886MB
Train: [169/180][150/625]	eta 0:10:26 lr 0.007073	data 0.0007 (0.1489)	batch 1.1672 (1.3185)	loss 2.5280 (2.5710)	grad_norm 0.7463 (0.7419)	mem 38886MB
Train: [169/180][200/625]	eta 0:09:04 lr 0.006969	data 0.0005 (0.1120)	batch 1.2218 (1.2822)	loss 2.7014 (2.5734)	grad_norm 0.7625 (0.7423)	mem 38886MB
Train: [169/180][250/625]	eta 0:07:52 lr 0.006866	data 0.0005 (0.0898)	batch 1.1756 (1.2606)	loss 2.6059 (2.5717)	grad_norm 0.7726 (0.7427)	mem 38886MB
Train: [169/180][300/625]	eta 0:06:44 lr 0.006763	data 0.0006 (0.0750)	batch 1.1880 (1.2453)	loss 2.5371 (2.5705)	grad_norm 0.7510 (0.7425)	mem 38886MB
Train: [169/180][350/625]	eta 0:05:39 lr 0.006662	data 0.0006 (0.0644)	batch 1.1739 (1.2349)	loss 2.4789 (2.5710)	grad_norm 0.7616 (0.7429)	mem 38886MB
Train: [169/180][400/625]	eta 0:04:36 lr 0.006561	data 0.0006 (0.0565)	batch 1.1887 (1.2267)	loss 2.4806 (2.5717)	grad_norm 0.7371 (0.7425)	mem 38886MB
Train: [169/180][450/625]	eta 0:03:33 lr 0.006461	data 0.0006 (0.0503)	batch 1.2099 (1.2207)	loss 2.6235 (2.5697)	grad_norm 0.7482 (0.7423)	mem 38886MB
Train: [169/180][500/625]	eta 0:02:31 lr 0.006361	data 0.0008 (0.0453)	batch 1.1515 (1.2156)	loss 2.5863 (2.5732)	grad_norm 0.7474 (0.7426)	mem 38886MB
Train: [169/180][550/625]	eta 0:01:30 lr 0.006263	data 0.0006 (0.0413)	batch 1.2128 (1.2113)	loss 2.6232 (2.5740)	grad_norm 0.7214 (0.7428)	mem 38886MB
Train: [169/180][600/625]	eta 0:00:30 lr 0.006165	data 0.0006 (0.0379)	batch 1.1448 (1.2080)	loss 2.3628 (2.5724)	grad_norm 0.7156 (0.7429)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 169 training takes 0:12:35
Test: [0/25]	Time 14.875 (14.875)	Loss 0.8964 (0.8964)	Acc@1 80.566 (80.566)	Acc@5 94.434 (94.434)	Mem 38886MB
 * Acc@1 69.500 Acc@5 88.926
Accuracy of the network on the 50000 test images: 69.50%
Max accuracy (after decay): 69.52%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [170/180][0/625]	eta 4:10:21 lr 0.006117	data 22.9485 (22.9485)	batch 24.0340 (24.0340)	loss 2.6518 (2.6518)	grad_norm 0.7527 (0.7527)	mem 38886MB
Train: [170/180][50/625]	eta 0:15:32 lr 0.006020	data 0.0007 (0.4512)	batch 1.1917 (1.6217)	loss 2.5591 (2.5589)	grad_norm 0.7208 (0.7417)	mem 38886MB
Train: [170/180][100/625]	eta 0:12:17 lr 0.005924	data 0.0006 (0.2282)	batch 1.1277 (1.4041)	loss 2.4302 (2.5617)	grad_norm 0.7288 (0.7424)	mem 38886MB
Train: [170/180][150/625]	eta 0:10:30 lr 0.005829	data 0.0006 (0.1529)	batch 1.1682 (1.3272)	loss 2.5374 (2.5605)	grad_norm 0.7384 (0.7427)	mem 38886MB
Train: [170/180][200/625]	eta 0:09:08 lr 0.005735	data 0.0007 (0.1150)	batch 1.1702 (1.2900)	loss 2.5244 (2.5645)	grad_norm 0.7276 (0.7438)	mem 38886MB
Train: [170/180][250/625]	eta 0:07:54 lr 0.005641	data 0.0005 (0.0922)	batch 1.1831 (1.2652)	loss 2.5358 (2.5657)	grad_norm 0.7280 (0.7431)	mem 38886MB
Train: [170/180][300/625]	eta 0:06:46 lr 0.005549	data 0.0005 (0.0770)	batch 1.2335 (1.2504)	loss 2.6731 (2.5669)	grad_norm 0.7391 (0.7433)	mem 38886MB
Train: [170/180][350/625]	eta 0:05:41 lr 0.005457	data 0.0005 (0.0661)	batch 1.1850 (1.2401)	loss 2.4444 (2.5662)	grad_norm 0.7512 (0.7435)	mem 38886MB
Train: [170/180][400/625]	eta 0:04:37 lr 0.005365	data 0.0004 (0.0579)	batch 1.1924 (1.2312)	loss 2.4900 (2.5649)	grad_norm 0.7415 (0.7436)	mem 38886MB
Train: [170/180][450/625]	eta 0:03:34 lr 0.005275	data 0.0008 (0.0516)	batch 1.1659 (1.2245)	loss 2.5429 (2.5657)	grad_norm 0.7317 (0.7436)	mem 38886MB
Train: [170/180][500/625]	eta 0:02:32 lr 0.005185	data 0.0006 (0.0465)	batch 1.2037 (1.2190)	loss 2.3848 (2.5669)	grad_norm 0.7410 (0.7435)	mem 38886MB
Train: [170/180][550/625]	eta 0:01:31 lr 0.005096	data 0.0005 (0.0423)	batch 1.1943 (1.2153)	loss 2.4888 (2.5673)	grad_norm 0.7379 (0.7434)	mem 38886MB
Train: [170/180][600/625]	eta 0:00:30 lr 0.005008	data 0.0005 (0.0388)	batch 1.1519 (1.2123)	loss 2.5390 (2.5682)	grad_norm 0.7365 (0.7435)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 170 training takes 0:12:37
Test: [0/25]	Time 15.002 (15.002)	Loss 0.9010 (0.9010)	Acc@1 80.127 (80.127)	Acc@5 94.336 (94.336)	Mem 38886MB
 * Acc@1 69.416 Acc@5 88.920
Accuracy of the network on the 50000 test images: 69.42%
Max accuracy (after decay): 69.52%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [171/180][0/625]	eta 4:04:25 lr 0.004964	data 22.2630 (22.2630)	batch 23.4641 (23.4641)	loss 2.7233 (2.7233)	grad_norm 0.7283 (0.7283)	mem 38886MB
Train: [171/180][50/625]	eta 0:15:20 lr 0.004877	data 0.0005 (0.4371)	batch 1.1781 (1.6003)	loss 2.5088 (2.5674)	grad_norm 0.7393 (0.7433)	mem 38886MB
Train: [171/180][100/625]	eta 0:12:09 lr 0.004791	data 0.0005 (0.2210)	batch 1.1695 (1.3888)	loss 2.5439 (2.5616)	grad_norm 0.7213 (0.7450)	mem 38886MB
Train: [171/180][150/625]	eta 0:10:25 lr 0.004706	data 0.0008 (0.1480)	batch 1.1820 (1.3158)	loss 2.5030 (2.5571)	grad_norm 0.7264 (0.7444)	mem 38886MB
Train: [171/180][200/625]	eta 0:09:04 lr 0.004621	data 0.0005 (0.1114)	batch 1.1522 (1.2817)	loss 2.7075 (2.5571)	grad_norm 0.7458 (0.7441)	mem 38886MB
Train: [171/180][250/625]	eta 0:07:52 lr 0.004537	data 0.0006 (0.0893)	batch 1.1750 (1.2609)	loss 2.5305 (2.5635)	grad_norm 0.7262 (0.7433)	mem 38886MB
Train: [171/180][300/625]	eta 0:06:45 lr 0.004454	data 0.0004 (0.0745)	batch 1.1850 (1.2469)	loss 2.5401 (2.5660)	grad_norm 0.7483 (0.7439)	mem 38886MB
Train: [171/180][350/625]	eta 0:05:40 lr 0.004372	data 0.0005 (0.0640)	batch 1.1781 (1.2370)	loss 2.7117 (2.5669)	grad_norm 0.7567 (0.7444)	mem 38886MB
Train: [171/180][400/625]	eta 0:04:36 lr 0.004290	data 0.0005 (0.0561)	batch 1.1567 (1.2285)	loss 2.4518 (2.5664)	grad_norm 0.7164 (0.7443)	mem 38886MB
Train: [171/180][450/625]	eta 0:03:33 lr 0.004209	data 0.0005 (0.0499)	batch 1.1947 (1.2225)	loss 2.5266 (2.5673)	grad_norm 0.7395 (0.7440)	mem 38886MB
Train: [171/180][500/625]	eta 0:02:32 lr 0.004129	data 0.0005 (0.0450)	batch 1.1864 (1.2169)	loss 2.6062 (2.5686)	grad_norm 0.7527 (0.7441)	mem 38886MB
Train: [171/180][550/625]	eta 0:01:30 lr 0.004050	data 0.0005 (0.0410)	batch 1.1837 (1.2120)	loss 2.6094 (2.5679)	grad_norm 0.7429 (0.7439)	mem 38886MB
Train: [171/180][600/625]	eta 0:00:30 lr 0.003972	data 0.0005 (0.0376)	batch 1.2202 (1.2083)	loss 2.4271 (2.5672)	grad_norm 0.7383 (0.7440)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 171 training takes 0:12:35
Test: [0/25]	Time 15.342 (15.342)	Loss 0.9030 (0.9030)	Acc@1 80.518 (80.518)	Acc@5 94.580 (94.580)	Mem 38886MB
 * Acc@1 69.518 Acc@5 88.948
Accuracy of the network on the 50000 test images: 69.52%
Max accuracy (after decay): 69.52%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [172/180][0/625]	eta 4:05:51 lr 0.003933	data 22.2940 (22.2940)	batch 23.6026 (23.6026)	loss 2.4484 (2.4484)	grad_norm 0.7447 (0.7447)	mem 38886MB
Train: [172/180][50/625]	eta 0:15:26 lr 0.003855	data 0.0005 (0.4377)	batch 1.1429 (1.6116)	loss 2.5825 (2.5639)	grad_norm 0.7469 (0.7432)	mem 38886MB
Train: [172/180][100/625]	eta 0:12:13 lr 0.003779	data 0.0005 (0.2213)	batch 1.1825 (1.3968)	loss 2.5005 (2.5637)	grad_norm 0.7475 (0.7427)	mem 38886MB
Train: [172/180][150/625]	eta 0:10:27 lr 0.003703	data 0.0005 (0.1482)	batch 1.1978 (1.3207)	loss 2.4390 (2.5709)	grad_norm 0.7219 (0.7434)	mem 38886MB
Train: [172/180][200/625]	eta 0:09:05 lr 0.003628	data 0.0006 (0.1115)	batch 1.1446 (1.2828)	loss 2.5502 (2.5693)	grad_norm 0.7270 (0.7433)	mem 38886MB
Train: [172/180][250/625]	eta 0:07:53 lr 0.003554	data 0.0005 (0.0894)	batch 1.1807 (1.2614)	loss 2.5993 (2.5651)	grad_norm 0.7551 (0.7431)	mem 38886MB
Train: [172/180][300/625]	eta 0:06:45 lr 0.003480	data 0.0005 (0.0746)	batch 1.1990 (1.2472)	loss 2.5946 (2.5650)	grad_norm 0.7347 (0.7428)	mem 38886MB
Train: [172/180][350/625]	eta 0:05:40 lr 0.003407	data 0.0005 (0.0641)	batch 1.1508 (1.2371)	loss 2.7562 (2.5664)	grad_norm 0.7567 (0.7432)	mem 38886MB
Train: [172/180][400/625]	eta 0:04:36 lr 0.003336	data 0.0005 (0.0562)	batch 1.2023 (1.2292)	loss 2.4194 (2.5624)	grad_norm 0.7415 (0.7433)	mem 38886MB
Train: [172/180][450/625]	eta 0:03:33 lr 0.003264	data 0.0005 (0.0500)	batch 1.2012 (1.2224)	loss 2.5657 (2.5627)	grad_norm 0.7270 (0.7432)	mem 38886MB
Train: [172/180][500/625]	eta 0:02:32 lr 0.003194	data 0.0004 (0.0451)	batch 1.1892 (1.2171)	loss 2.5091 (2.5617)	grad_norm 0.7402 (0.7435)	mem 38886MB
Train: [172/180][550/625]	eta 0:01:30 lr 0.003124	data 0.0005 (0.0410)	batch 1.1944 (1.2131)	loss 2.5644 (2.5622)	grad_norm 0.7280 (0.7434)	mem 38886MB
Train: [172/180][600/625]	eta 0:00:30 lr 0.003056	data 0.0010 (0.0377)	batch 1.1365 (1.2099)	loss 2.6197 (2.5629)	grad_norm 0.7479 (0.7434)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 172 training takes 0:12:36
Test: [0/25]	Time 15.609 (15.609)	Loss 0.9039 (0.9039)	Acc@1 80.566 (80.566)	Acc@5 94.385 (94.385)	Mem 38886MB
 * Acc@1 69.472 Acc@5 88.938
Accuracy of the network on the 50000 test images: 69.47%
Max accuracy (after decay): 69.52%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [173/180][0/625]	eta 4:05:30 lr 0.003021	data 21.9668 (21.9668)	batch 23.5696 (23.5696)	loss 2.4117 (2.4117)	grad_norm 0.7326 (0.7326)	mem 38886MB
Train: [173/180][50/625]	eta 0:15:23 lr 0.002954	data 0.0006 (0.4314)	batch 1.1948 (1.6058)	loss 2.4512 (2.5534)	grad_norm 0.7431 (0.7447)	mem 38886MB
Train: [173/180][100/625]	eta 0:12:10 lr 0.002887	data 0.0005 (0.2181)	batch 1.1685 (1.3920)	loss 2.6082 (2.5687)	grad_norm 0.7360 (0.7444)	mem 38886MB
Train: [173/180][150/625]	eta 0:09:52 lr 0.002821	data 0.0009 (0.1461)	batch 0.8473 (1.2476)	loss 2.4937 (2.5754)	grad_norm 0.7481 (0.7445)	mem 38886MB
Train: [173/180][200/625]	eta 0:08:13 lr 0.002755	data 0.0005 (0.1099)	batch 0.8955 (1.1612)	loss 2.6608 (2.5705)	grad_norm 0.7438 (0.7447)	mem 38886MB
Train: [173/180][250/625]	eta 0:06:56 lr 0.002691	data 0.0005 (0.0881)	batch 0.8938 (1.1105)	loss 2.4584 (2.5655)	grad_norm 0.7279 (0.7443)	mem 38886MB
Train: [173/180][300/625]	eta 0:05:49 lr 0.002627	data 0.0005 (0.0736)	batch 0.8535 (1.0755)	loss 2.4712 (2.5643)	grad_norm 0.7422 (0.7442)	mem 38886MB
Train: [173/180][350/625]	eta 0:04:49 lr 0.002564	data 0.0005 (0.0631)	batch 0.9083 (1.0518)	loss 2.7850 (2.5597)	grad_norm 0.7559 (0.7442)	mem 38886MB
Train: [173/180][400/625]	eta 0:03:52 lr 0.002502	data 0.0004 (0.0553)	batch 0.9232 (1.0341)	loss 2.6306 (2.5603)	grad_norm 0.7176 (0.7444)	mem 38886MB
Train: [173/180][450/625]	eta 0:02:58 lr 0.002440	data 0.0005 (0.0493)	batch 0.8875 (1.0199)	loss 2.6340 (2.5620)	grad_norm 0.7470 (0.7446)	mem 38886MB
Train: [173/180][500/625]	eta 0:02:06 lr 0.002379	data 0.0007 (0.0444)	batch 0.8846 (1.0082)	loss 2.6536 (2.5643)	grad_norm 0.7556 (0.7445)	mem 38886MB
Train: [173/180][550/625]	eta 0:01:14 lr 0.002320	data 0.0006 (0.0404)	batch 0.8628 (0.9987)	loss 2.5821 (2.5637)	grad_norm 0.7417 (0.7445)	mem 38886MB
Train: [173/180][600/625]	eta 0:00:24 lr 0.002260	data 0.0006 (0.0371)	batch 0.8986 (0.9903)	loss 2.4683 (2.5636)	grad_norm 0.7430 (0.7447)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 173 training takes 0:10:18
Test: [0/25]	Time 14.778 (14.778)	Loss 0.8970 (0.8970)	Acc@1 80.566 (80.566)	Acc@5 94.385 (94.385)	Mem 38886MB
 * Acc@1 69.570 Acc@5 88.946
Accuracy of the network on the 50000 test images: 69.57%
Max accuracy (after decay): 69.57%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [174/180][0/625]	eta 4:00:16 lr 0.002231	data 22.1903 (22.1903)	batch 23.0658 (23.0658)	loss 2.5893 (2.5893)	grad_norm 0.7541 (0.7541)	mem 38886MB
Train: [174/180][50/625]	eta 0:12:53 lr 0.002173	data 0.0005 (0.4360)	batch 0.9151 (1.3457)	loss 2.5243 (2.5400)	grad_norm 0.7250 (0.7432)	mem 38886MB
Train: [174/180][100/625]	eta 0:09:51 lr 0.002116	data 0.0005 (0.2204)	batch 0.9199 (1.1260)	loss 2.4512 (2.5495)	grad_norm 0.7343 (0.7423)	mem 38886MB
Train: [174/180][150/625]	eta 0:08:20 lr 0.002059	data 0.0005 (0.1476)	batch 0.8330 (1.0529)	loss 2.5877 (2.5580)	grad_norm 0.7519 (0.7427)	mem 38886MB
Train: [174/180][200/625]	eta 0:07:11 lr 0.002004	data 0.0006 (0.1110)	batch 0.8829 (1.0148)	loss 2.6785 (2.5561)	grad_norm 0.7422 (0.7435)	mem 38886MB
Train: [174/180][250/625]	eta 0:06:11 lr 0.001949	data 0.0007 (0.0890)	batch 0.8766 (0.9909)	loss 2.4674 (2.5598)	grad_norm 0.7371 (0.7437)	mem 38886MB
Train: [174/180][300/625]	eta 0:05:17 lr 0.001895	data 0.0005 (0.0743)	batch 0.9300 (0.9767)	loss 2.6402 (2.5620)	grad_norm 0.7623 (0.7435)	mem 38886MB
Train: [174/180][350/625]	eta 0:04:25 lr 0.001842	data 0.0006 (0.0638)	batch 0.8935 (0.9666)	loss 2.4791 (2.5623)	grad_norm 0.7350 (0.7432)	mem 38886MB
Train: [174/180][400/625]	eta 0:03:35 lr 0.001789	data 0.0005 (0.0559)	batch 0.8808 (0.9589)	loss 2.7112 (2.5640)	grad_norm 0.7671 (0.7437)	mem 38886MB
Train: [174/180][450/625]	eta 0:02:46 lr 0.001737	data 0.0004 (0.0498)	batch 0.9158 (0.9523)	loss 2.6764 (2.5675)	grad_norm 0.7467 (0.7438)	mem 38886MB
Train: [174/180][500/625]	eta 0:01:58 lr 0.001686	data 0.0005 (0.0449)	batch 0.9102 (0.9475)	loss 2.4477 (2.5674)	grad_norm 0.7577 (0.7439)	mem 38886MB
Train: [174/180][550/625]	eta 0:01:10 lr 0.001636	data 0.0005 (0.0408)	batch 0.8720 (0.9434)	loss 2.5659 (2.5671)	grad_norm 0.7405 (0.7439)	mem 38886MB
Train: [174/180][600/625]	eta 0:00:23 lr 0.001586	data 0.0005 (0.0375)	batch 0.9057 (0.9401)	loss 2.6097 (2.5684)	grad_norm 0.7375 (0.7438)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 174 training takes 0:09:48
Test: [0/25]	Time 14.909 (14.909)	Loss 0.9018 (0.9018)	Acc@1 80.664 (80.664)	Acc@5 94.336 (94.336)	Mem 38886MB
 * Acc@1 69.556 Acc@5 88.940
Accuracy of the network on the 50000 test images: 69.56%
Max accuracy (after decay): 69.57%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [175/180][0/625]	eta 4:01:35 lr 0.001562	data 20.7383 (20.7383)	batch 23.1929 (23.1929)	loss 2.5468 (2.5468)	grad_norm 0.7393 (0.7393)	mem 38886MB
Train: [175/180][50/625]	eta 0:12:48 lr 0.001514	data 0.0004 (0.4074)	batch 0.8968 (1.3364)	loss 2.4486 (2.5757)	grad_norm 0.7149 (0.7436)	mem 38886MB
Train: [175/180][100/625]	eta 0:09:47 lr 0.001466	data 0.0004 (0.2060)	batch 0.9174 (1.1188)	loss 2.4946 (2.5462)	grad_norm 0.7562 (0.7436)	mem 38886MB
Train: [175/180][150/625]	eta 0:08:18 lr 0.001420	data 0.0005 (0.1379)	batch 0.8943 (1.0502)	loss 2.5129 (2.5582)	grad_norm 0.7638 (0.7436)	mem 38886MB
Train: [175/180][200/625]	eta 0:07:11 lr 0.001374	data 0.0005 (0.1038)	batch 0.8892 (1.0149)	loss 2.5972 (2.5629)	grad_norm 0.7731 (0.7440)	mem 38886MB
Train: [175/180][250/625]	eta 0:06:12 lr 0.001328	data 0.0005 (0.0832)	batch 0.8749 (0.9928)	loss 2.5939 (2.5589)	grad_norm 0.7337 (0.7440)	mem 38886MB
Train: [175/180][300/625]	eta 0:05:17 lr 0.001284	data 0.0006 (0.0695)	batch 0.8594 (0.9776)	loss 2.3187 (2.5587)	grad_norm 0.7400 (0.7440)	mem 38886MB
Train: [175/180][350/625]	eta 0:04:26 lr 0.001240	data 0.0005 (0.0597)	batch 0.9032 (0.9677)	loss 2.5531 (2.5592)	grad_norm 0.7516 (0.7442)	mem 38886MB
Train: [175/180][400/625]	eta 0:03:35 lr 0.001198	data 0.0008 (0.0523)	batch 0.9338 (0.9597)	loss 2.4024 (2.5608)	grad_norm 0.7287 (0.7440)	mem 38886MB
Train: [175/180][450/625]	eta 0:02:46 lr 0.001155	data 0.0005 (0.0466)	batch 0.9271 (0.9537)	loss 2.6161 (2.5629)	grad_norm 0.7478 (0.7442)	mem 38886MB
Train: [175/180][500/625]	eta 0:01:58 lr 0.001114	data 0.0005 (0.0420)	batch 0.8966 (0.9485)	loss 2.7251 (2.5616)	grad_norm 0.7542 (0.7443)	mem 38886MB
Train: [175/180][550/625]	eta 0:01:10 lr 0.001074	data 0.0005 (0.0382)	batch 0.8782 (0.9440)	loss 2.6363 (2.5614)	grad_norm 0.7382 (0.7442)	mem 38886MB
Train: [175/180][600/625]	eta 0:00:23 lr 0.001034	data 0.0007 (0.0351)	batch 0.9064 (0.9410)	loss 2.5645 (2.5608)	grad_norm 0.7519 (0.7443)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 175 training takes 0:09:48
Test: [0/25]	Time 15.246 (15.246)	Loss 0.9009 (0.9009)	Acc@1 80.713 (80.713)	Acc@5 94.385 (94.385)	Mem 38886MB
 * Acc@1 69.536 Acc@5 89.036
Accuracy of the network on the 50000 test images: 69.54%
Max accuracy (after decay): 69.57%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [176/180][0/625]	eta 4:00:01 lr 0.001014	data 21.7212 (21.7212)	batch 23.0429 (23.0429)	loss 2.3042 (2.3042)	grad_norm 0.7246 (0.7246)	mem 38886MB
Train: [176/180][50/625]	eta 0:12:51 lr 0.000976	data 0.0005 (0.4266)	batch 0.9188 (1.3418)	loss 2.6917 (2.5628)	grad_norm 0.7290 (0.7440)	mem 38886MB
Train: [176/180][100/625]	eta 0:09:52 lr 0.000938	data 0.0008 (0.2161)	batch 0.8562 (1.1290)	loss 2.6320 (2.5570)	grad_norm 0.7536 (0.7453)	mem 38886MB
Train: [176/180][150/625]	eta 0:08:22 lr 0.000901	data 0.0005 (0.1448)	batch 0.8741 (1.0570)	loss 2.4814 (2.5559)	grad_norm 0.7509 (0.7455)	mem 38886MB
Train: [176/180][200/625]	eta 0:07:13 lr 0.000865	data 0.0005 (0.1089)	batch 0.8906 (1.0195)	loss 2.7165 (2.5530)	grad_norm 0.7477 (0.7448)	mem 38886MB
Train: [176/180][250/625]	eta 0:06:13 lr 0.000829	data 0.0006 (0.0873)	batch 0.8954 (0.9969)	loss 2.3260 (2.5534)	grad_norm 0.7293 (0.7441)	mem 38886MB
Train: [176/180][300/625]	eta 0:05:18 lr 0.000795	data 0.0004 (0.0729)	batch 0.8848 (0.9812)	loss 2.6429 (2.5519)	grad_norm 0.7495 (0.7440)	mem 38886MB
Train: [176/180][350/625]	eta 0:04:26 lr 0.000761	data 0.0005 (0.0626)	batch 0.8951 (0.9706)	loss 2.5114 (2.5539)	grad_norm 0.7494 (0.7445)	mem 38886MB
Train: [176/180][400/625]	eta 0:03:36 lr 0.000728	data 0.0005 (0.0549)	batch 0.9171 (0.9622)	loss 2.5389 (2.5547)	grad_norm 0.7271 (0.7443)	mem 38886MB
Train: [176/180][450/625]	eta 0:02:47 lr 0.000695	data 0.0004 (0.0488)	batch 0.9309 (0.9560)	loss 2.6069 (2.5568)	grad_norm 0.7265 (0.7444)	mem 38886MB
Train: [176/180][500/625]	eta 0:01:58 lr 0.000664	data 0.0004 (0.0440)	batch 0.9084 (0.9508)	loss 2.4991 (2.5553)	grad_norm 0.7510 (0.7445)	mem 38886MB
Train: [176/180][550/625]	eta 0:01:10 lr 0.000633	data 0.0006 (0.0401)	batch 0.8821 (0.9461)	loss 2.6261 (2.5559)	grad_norm 0.7476 (0.7442)	mem 38886MB
Train: [176/180][600/625]	eta 0:00:23 lr 0.000603	data 0.0007 (0.0368)	batch 0.8928 (0.9429)	loss 2.4425 (2.5558)	grad_norm 0.7320 (0.7441)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 176 training takes 0:09:49
Test: [0/25]	Time 15.011 (15.011)	Loss 0.9004 (0.9004)	Acc@1 80.469 (80.469)	Acc@5 94.482 (94.482)	Mem 38886MB
 * Acc@1 69.532 Acc@5 88.988
Accuracy of the network on the 50000 test images: 69.53%
Max accuracy (after decay): 69.57%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [177/180][0/625]	eta 3:57:47 lr 0.000588	data 20.9124 (20.9124)	batch 22.8274 (22.8274)	loss 2.4138 (2.4138)	grad_norm 0.7276 (0.7276)	mem 38886MB
Train: [177/180][50/625]	eta 0:12:54 lr 0.000559	data 0.0008 (0.4109)	batch 0.8686 (1.3477)	loss 2.5462 (2.5746)	grad_norm 0.7556 (0.7430)	mem 38886MB
Train: [177/180][100/625]	eta 0:09:55 lr 0.000531	data 0.0005 (0.2083)	batch 0.9763 (1.1341)	loss 2.4885 (2.5639)	grad_norm 0.7630 (0.7445)	mem 38886MB
Train: [177/180][150/625]	eta 0:08:23 lr 0.000504	data 0.0006 (0.1396)	batch 0.9295 (1.0593)	loss 2.6682 (2.5630)	grad_norm 0.7509 (0.7448)	mem 38886MB
Train: [177/180][200/625]	eta 0:07:14 lr 0.000477	data 0.0007 (0.1051)	batch 0.8856 (1.0219)	loss 2.5156 (2.5637)	grad_norm 0.7647 (0.7443)	mem 38886MB
Train: [177/180][250/625]	eta 0:06:14 lr 0.000452	data 0.0007 (0.0845)	batch 0.9041 (0.9989)	loss 2.7296 (2.5627)	grad_norm 0.7298 (0.7446)	mem 38886MB
Train: [177/180][300/625]	eta 0:05:20 lr 0.000427	data 0.0007 (0.0706)	batch 0.9393 (0.9853)	loss 2.4105 (2.5590)	grad_norm 0.7402 (0.7443)	mem 38886MB
Train: [177/180][350/625]	eta 0:04:27 lr 0.000403	data 0.0010 (0.0606)	batch 0.9123 (0.9733)	loss 2.7166 (2.5625)	grad_norm 0.7645 (0.7446)	mem 38886MB
Train: [177/180][400/625]	eta 0:03:37 lr 0.000379	data 0.0007 (0.0533)	batch 0.8931 (0.9653)	loss 2.6717 (2.5583)	grad_norm 0.7453 (0.7444)	mem 38886MB
Train: [177/180][450/625]	eta 0:02:47 lr 0.000357	data 0.0007 (0.0474)	batch 0.8880 (0.9590)	loss 2.5194 (2.5559)	grad_norm 0.7372 (0.7442)	mem 38886MB
Train: [177/180][500/625]	eta 0:01:59 lr 0.000335	data 0.0008 (0.0428)	batch 0.8958 (0.9542)	loss 2.5432 (2.5550)	grad_norm 0.7552 (0.7440)	mem 38886MB
Train: [177/180][550/625]	eta 0:01:11 lr 0.000314	data 0.0006 (0.0390)	batch 0.9079 (0.9504)	loss 2.6328 (2.5562)	grad_norm 0.7422 (0.7440)	mem 38886MB
Train: [177/180][600/625]	eta 0:00:23 lr 0.000293	data 0.0005 (0.0358)	batch 0.8648 (0.9469)	loss 2.5651 (2.5536)	grad_norm 0.7380 (0.7438)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 177 training takes 0:09:52
Test: [0/25]	Time 14.846 (14.846)	Loss 0.8980 (0.8980)	Acc@1 80.566 (80.566)	Acc@5 94.385 (94.385)	Mem 38886MB
 * Acc@1 69.580 Acc@5 89.016
Accuracy of the network on the 50000 test images: 69.58%
Max accuracy (after decay): 69.58%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [178/180][0/625]	eta 4:04:32 lr 0.000284	data 22.5874 (22.5874)	batch 23.4766 (23.4766)	loss 2.5686 (2.5686)	grad_norm 0.7560 (0.7560)	mem 38886MB
Train: [178/180][50/625]	eta 0:12:54 lr 0.000265	data 0.0007 (0.4438)	batch 0.9237 (1.3462)	loss 2.6431 (2.5659)	grad_norm 0.7660 (0.7448)	mem 38886MB
Train: [178/180][100/625]	eta 0:09:51 lr 0.000246	data 0.0005 (0.2244)	batch 0.8965 (1.1272)	loss 2.3881 (2.5689)	grad_norm 0.7173 (0.7425)	mem 38886MB
Train: [178/180][150/625]	eta 0:08:20 lr 0.000229	data 0.0005 (0.1503)	batch 0.8916 (1.0547)	loss 2.6794 (2.5722)	grad_norm 0.7472 (0.7432)	mem 38886MB
Train: [178/180][200/625]	eta 0:07:12 lr 0.000212	data 0.0005 (0.1131)	batch 0.8861 (1.0185)	loss 2.4952 (2.5750)	grad_norm 0.7691 (0.7430)	mem 38886MB
Train: [178/180][250/625]	eta 0:06:13 lr 0.000196	data 0.0005 (0.0907)	batch 0.9163 (0.9952)	loss 2.5133 (2.5707)	grad_norm 0.7499 (0.7435)	mem 38886MB
Train: [178/180][300/625]	eta 0:05:18 lr 0.000181	data 0.0005 (0.0757)	batch 0.9135 (0.9811)	loss 2.5210 (2.5730)	grad_norm 0.7213 (0.7437)	mem 38886MB
Train: [178/180][350/625]	eta 0:04:26 lr 0.000166	data 0.0005 (0.0650)	batch 0.8966 (0.9700)	loss 2.6882 (2.5716)	grad_norm 0.7359 (0.7436)	mem 38886MB
Train: [178/180][400/625]	eta 0:03:36 lr 0.000153	data 0.0006 (0.0569)	batch 0.9293 (0.9624)	loss 2.6687 (2.5703)	grad_norm 0.7311 (0.7436)	mem 38886MB
Train: [178/180][450/625]	eta 0:02:47 lr 0.000140	data 0.0005 (0.0507)	batch 0.8892 (0.9563)	loss 2.6524 (2.5686)	grad_norm 0.7681 (0.7436)	mem 38886MB
Train: [178/180][500/625]	eta 0:01:58 lr 0.000128	data 0.0005 (0.0457)	batch 0.8691 (0.9511)	loss 2.5649 (2.5668)	grad_norm 0.7357 (0.7435)	mem 38886MB
Train: [178/180][550/625]	eta 0:01:11 lr 0.000116	data 0.0006 (0.0416)	batch 0.8917 (0.9473)	loss 2.5437 (2.5665)	grad_norm 0.7224 (0.7435)	mem 38886MB
Train: [178/180][600/625]	eta 0:00:23 lr 0.000106	data 0.0005 (0.0382)	batch 0.9323 (0.9440)	loss 2.5282 (2.5650)	grad_norm 0.7370 (0.7435)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 178 training takes 0:09:50
Test: [0/25]	Time 14.414 (14.414)	Loss 0.8961 (0.8961)	Acc@1 80.859 (80.859)	Acc@5 94.531 (94.531)	Mem 38886MB
 * Acc@1 69.616 Acc@5 88.932
Accuracy of the network on the 50000 test images: 69.62%
Max accuracy (after decay): 69.62%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Train: [179/180][0/625]	eta 3:57:03 lr 0.000101	data 21.8043 (21.8043)	batch 22.7574 (22.7574)	loss 2.5373 (2.5373)	grad_norm 0.7356 (0.7356)	mem 38886MB
Train: [179/180][50/625]	eta 0:12:47 lr 0.000092	data 0.0007 (0.4281)	batch 0.9065 (1.3342)	loss 2.4211 (2.5669)	grad_norm 0.7436 (0.7440)	mem 38886MB
Train: [179/180][100/625]	eta 0:09:49 lr 0.000083	data 0.0006 (0.2165)	batch 0.8992 (1.1229)	loss 2.7957 (2.5609)	grad_norm 0.7375 (0.7442)	mem 38886MB
Train: [179/180][150/625]	eta 0:08:19 lr 0.000075	data 0.0004 (0.1450)	batch 0.9374 (1.0518)	loss 2.7469 (2.5681)	grad_norm 0.7402 (0.7442)	mem 38886MB
Train: [179/180][200/625]	eta 0:07:12 lr 0.000068	data 0.0005 (0.1091)	batch 0.9491 (1.0171)	loss 2.6903 (2.5632)	grad_norm 0.7347 (0.7438)	mem 38886MB
Train: [179/180][250/625]	eta 0:06:13 lr 0.000062	data 0.0006 (0.0874)	batch 0.9082 (0.9949)	loss 2.4772 (2.5628)	grad_norm 0.7469 (0.7436)	mem 38886MB
Train: [179/180][300/625]	eta 0:05:18 lr 0.000056	data 0.0005 (0.0730)	batch 0.8970 (0.9792)	loss 2.3928 (2.5606)	grad_norm 0.7293 (0.7436)	mem 38886MB
Train: [179/180][350/625]	eta 0:04:26 lr 0.000052	data 0.0006 (0.0627)	batch 0.8780 (0.9693)	loss 2.6704 (2.5645)	grad_norm 0.7470 (0.7439)	mem 38886MB
Train: [179/180][400/625]	eta 0:03:36 lr 0.000048	data 0.0476 (0.0550)	batch 0.8970 (0.9613)	loss 2.4541 (2.5636)	grad_norm 0.7133 (0.7434)	mem 38886MB
Train: [179/180][450/625]	eta 0:02:47 lr 0.000045	data 0.0006 (0.0490)	batch 0.9201 (0.9549)	loss 2.5640 (2.5641)	grad_norm 0.7743 (0.7436)	mem 38886MB
Train: [179/180][500/625]	eta 0:01:58 lr 0.000042	data 0.0004 (0.0442)	batch 0.8849 (0.9502)	loss 2.3975 (2.5637)	grad_norm 0.7629 (0.7438)	mem 38886MB
Train: [179/180][550/625]	eta 0:01:10 lr 0.000041	data 0.0008 (0.0402)	batch 0.8644 (0.9462)	loss 2.5783 (2.5647)	grad_norm 0.7587 (0.7442)	mem 38886MB
Train: [179/180][600/625]	eta 0:00:23 lr 0.000040	data 0.0006 (0.0369)	batch 0.9178 (0.9427)	loss 2.6311 (2.5657)	grad_norm 0.7508 (0.7440)	mem 38886MB
Current slope: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1] 	
EPOCH 179 training takes 0:09:49
Test: [0/25]	Time 14.909 (14.909)	Loss 0.8976 (0.8976)	Acc@1 80.420 (80.420)	Acc@5 94.434 (94.434)	Mem 38886MB
 * Acc@1 69.578 Acc@5 89.006
Accuracy of the network on the 50000 test images: 69.58%
Max accuracy (after decay): 69.62%
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saving......
manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth saved !!!
Training time 1 day, 8:14:16
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 256
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 1138.781
  - 1789.29
  - 885.087
  - 489.339
  - 436.431
  - 221.807
  - 221.807
  - 295.533
  - 314.24
  - 314.24
  - 314.24
  - 453.318
  - 670.935
  - 670.935
  - 768.199
  - 707.067
  - 707.067
  - 1378.05
  - 2300.13
  LAT_BEFORE:
  - 1850.39
  - 5902.79
  - 6770.49
  - 6106.57
  - 3034.38
  - 2339.04
  - 2339.04
  - 1365.89
  - 1857.97
  - 1857.97
  - 1857.97
  - 2115.64
  - 3521.2
  - 3521.2
  - 2336.29
  - 2597.8
  - 2597.8
  - 3426.1
  - 2300.13
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: false
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.8
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 4.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 4.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
Keep 40.0%  activation funtions: []
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 256
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 41.78
  - 5.45
  - 6.68
  - 3.23
  - 4.12
  - 4.12
  - 2.38
  - 2.72
  - 2.72
  - 2.72
  - 3.75
  - 5.04
  - 5.04
  - 3.44
  - 2.8
  - 2.8
  - 4.38
  - 0
  LAT_BEFORE:
  - 0
  - 56.97
  - 138.79
  - 82.45
  - 47.03
  - 34.51
  - 34.51
  - 21.19
  - 17.91
  - 17.91
  - 17.91
  - 20.75
  - 31.27
  - 31.27
  - 16.67
  - 14.21
  - 14.21
  - 18.77
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: false
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.8
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 4.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 4.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
Keep 40.0%  activation funtions: []
Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
Keep 40.0%  activation funtions: []
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 256
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 1138.781
  - 1789.29
  - 885.087
  - 489.339
  - 436.431
  - 221.807
  - 221.807
  - 295.533
  - 314.24
  - 314.24
  - 314.24
  - 453.318
  - 670.935
  - 670.935
  - 768.199
  - 707.067
  - 707.067
  - 1378.05
  - 2300.13
  LAT_BEFORE:
  - 1850.39
  - 5902.79
  - 6770.49
  - 6106.57
  - 3034.38
  - 2339.04
  - 2339.04
  - 1365.89
  - 1857.97
  - 1857.97
  - 1857.97
  - 2115.64
  - 3521.2
  - 3521.2
  - 2336.29
  - 2597.8
  - 2597.8
  - 3426.1
  - 2300.13
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.8
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 4.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 4.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108795
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 1138.781
  - 1789.29
  - 885.087
  - 489.339
  - 436.431
  - 221.807
  - 221.807
  - 295.533
  - 314.24
  - 314.24
  - 314.24
  - 453.318
  - 670.935
  - 670.935
  - 768.199
  - 707.067
  - 707.067
  - 1378.05
  - 2300.13
  LAT_BEFORE:
  - 1850.39
  - 5902.79
  - 6770.49
  - 6106.57
  - 3034.38
  - 2339.04
  - 2339.04
  - 1365.89
  - 1857.97
  - 1857.97
  - 1857.97
  - 2115.64
  - 3521.2
  - 3521.2
  - 2336.29
  - 2597.8
  - 2597.8
  - 3426.1
  - 2300.13
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108795
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/1251]	eta 8:52:12 lr 0.400000	data 19.9903 (19.9903)	batch 25.5255 (25.5255)	loss 6.9324 (6.9324)	grad_norm 1.3793 (1.3793)	mem 24443MB
Train: [0/180][50/1251]	eta 0:45:14 lr 0.400000	data 0.0004 (0.3925)	batch 1.7916 (2.2604)	loss -228.9727 (-96.9981)	grad_norm 1.3175 (1.3903)	mem 24443MB
Train: [0/180][100/1251]	eta 0:38:55 lr 0.400000	data 0.0005 (0.1985)	batch 1.8640 (2.0294)	loss -509.1145 (-233.0347)	grad_norm 1.3335 (1.3658)	mem 24443MB
Train: [0/180][150/1251]	eta 0:36:03 lr 0.400000	data 0.0004 (0.1330)	batch 1.8210 (1.9647)	loss -788.9730 (-371.7361)	grad_norm 1.3207 (1.3554)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 1138.781
  - 1789.29
  - 885.087
  - 489.339
  - 436.431
  - 221.807
  - 221.807
  - 295.533
  - 314.24
  - 314.24
  - 314.24
  - 453.318
  - 670.935
  - 670.935
  - 768.199
  - 707.067
  - 707.067
  - 1378.05
  - 2300.13
  LAT_BEFORE:
  - 1850.39
  - 5902.79
  - 6770.49
  - 6106.57
  - 3034.38
  - 2339.04
  - 2339.04
  - 1365.89
  - 1857.97
  - 1857.97
  - 1857.97
  - 2115.64
  - 3521.2
  - 3521.2
  - 2336.29
  - 2597.8
  - 2597.8
  - 3426.1
  - 2300.13
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108795
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/1251]	eta 9:04:55 lr 0.400000	data 21.3073 (21.3073)	batch 26.1354 (26.1354)	loss 6.9324 (6.9324)	grad_norm 1.3789 (1.3789)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 1138.781
  - 1789.29
  - 885.087
  - 489.339
  - 436.431
  - 221.807
  - 221.807
  - 295.533
  - 314.24
  - 314.24
  - 314.24
  - 453.318
  - 670.935
  - 670.935
  - 768.199
  - 707.067
  - 707.067
  - 1378.05
  - 2300.13
  LAT_BEFORE:
  - 1850.39
  - 5902.79
  - 6770.49
  - 6106.57
  - 3034.38
  - 2339.04
  - 2339.04
  - 1365.89
  - 1857.97
  - 1857.97
  - 1857.97
  - 2115.64
  - 3521.2
  - 3521.2
  - 2336.29
  - 2597.8
  - 2597.8
  - 3426.1
  - 2300.13
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108795
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/1251]	eta 8:40:29 lr 0.400000	data 19.9522 (19.9522)	batch 24.9635 (24.9635)	loss 6.9324 (6.9324)	grad_norm 1.3783 (1.3783)	mem 24443MB
Train: [0/180][50/1251]	eta 0:46:04 lr 0.400000	data 0.0006 (0.3918)	batch 1.8439 (2.3018)	loss -228.9529 (-96.9952)	grad_norm 1.3128 (1.3925)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 1138.781
  - 1789.29
  - 885.087
  - 489.339
  - 436.431
  - 221.807
  - 221.807
  - 295.533
  - 314.24
  - 314.24
  - 314.24
  - 453.318
  - 670.935
  - 670.935
  - 768.199
  - 707.067
  - 707.067
  - 1378.05
  - 2300.13
  LAT_BEFORE:
  - 1850.39
  - 5902.79
  - 6770.49
  - 6106.57
  - 3034.38
  - 2339.04
  - 2339.04
  - 1365.89
  - 1857.97
  - 1857.97
  - 1857.97
  - 2115.64
  - 3521.2
  - 3521.2
  - 2336.29
  - 2597.8
  - 2597.8
  - 3426.1
  - 2300.13
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108795
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/1251]	eta 8:58:38 lr 0.400000	data 21.4346 (21.4346)	batch 25.8345 (25.8345)	loss 6.9324 (6.9324)	grad_norm 1.3788 (1.3788)	mem 24443MB
Train: [0/180][50/1251]	eta 0:46:12 lr 0.400000	data 0.0004 (0.4208)	batch 1.8439 (2.3088)	loss -228.9302 (-97.0028)	grad_norm 1.3204 (1.3829)	mem 24443MB
Train: [0/180][100/1251]	eta 0:39:52 lr 0.400000	data 0.0005 (0.2127)	batch 1.8633 (2.0786)	loss -509.0854 (-233.0486)	grad_norm 1.3230 (1.3620)	mem 24443MB
Train: [0/180][150/1251]	eta 0:36:42 lr 0.400000	data 0.0005 (0.1425)	batch 1.8575 (2.0006)	loss -788.9047 (-371.7459)	grad_norm 1.3645 (1.3545)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 0
  - 41.78
  - 5.45
  - 6.68
  - 3.23
  - 4.12
  - 4.12
  - 2.38
  - 2.72
  - 2.72
  - 2.72
  - 3.75
  - 5.04
  - 5.04
  - 3.44
  - 2.8
  - 2.8
  - 4.38
  - 0
  LAT_BEFORE:
  - 0
  - 56.97
  - 138.79
  - 82.45
  - 47.03
  - 34.51
  - 34.51
  - 21.19
  - 17.91
  - 17.91
  - 17.91
  - 20.75
  - 31.27
  - 31.27
  - 16.67
  - 14.21
  - 14.21
  - 18.77
  - 0
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108795
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/1251]	eta 8:59:07 lr 0.400000	data 21.3485 (21.3485)	batch 25.8577 (25.8577)	loss 6.9324 (6.9324)	grad_norm 0.7073 (0.7073)	mem 24443MB
Train: [0/180][50/1251]	eta 0:46:35 lr 0.400000	data 0.0005 (0.4191)	batch 1.8488 (2.3277)	loss 6.4931 (6.7846)	grad_norm 0.6044 (0.7564)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 1138.781
  - 1789.29
  - 885.087
  - 489.339
  - 436.431
  - 221.807
  - 221.807
  - 295.533
  - 314.24
  - 314.24
  - 314.24
  - 453.318
  - 670.935
  - 670.935
  - 768.199
  - 707.067
  - 707.067
  - 1378.05
  - 2300.13
  LAT_BEFORE:
  - 1850.39
  - 5902.79
  - 6770.49
  - 6106.57
  - 3034.38
  - 2339.04
  - 2339.04
  - 1365.89
  - 1857.97
  - 1857.97
  - 1857.97
  - 2115.64
  - 3521.2
  - 3521.2
  - 2336.29
  - 2597.8
  - 2597.8
  - 3426.1
  - 2300.13
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108795
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/1251]	eta 8:57:25 lr 0.400000	data 20.4352 (20.4352)	batch 25.7757 (25.7757)	loss 6.9324 (6.9324)	grad_norm 1.3787 (1.3787)	mem 24443MB
Train: [0/180][50/1251]	eta 0:46:18 lr 0.400000	data 0.0004 (0.4012)	batch 1.8542 (2.3132)	loss -229.0219 (-97.0032)	grad_norm 1.3535 (1.3883)	mem 24443MB
Train: [0/180][100/1251]	eta 0:39:56 lr 0.400000	data 0.0005 (0.2028)	batch 1.8251 (2.0817)	loss -509.0994 (-233.0472)	grad_norm 1.3319 (1.3678)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108795
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/1251]	eta 8:45:41 lr 0.400000	data 19.3495 (19.3495)	batch 25.2129 (25.2129)	loss 6.9324 (6.9324)	grad_norm 0.7074 (0.7074)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108795
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/1251]	eta 9:00:37 lr 0.400000	data 20.6175 (20.6175)	batch 25.9291 (25.9291)	loss 6.9324 (6.9324)	grad_norm 0.7068 (0.7068)	mem 24443MB
Train: [0/180][50/1251]	eta 0:46:07 lr 0.400000	data 0.0004 (0.4048)	batch 1.8717 (2.3045)	loss 6.5998 (6.8185)	grad_norm 0.6277 (0.7344)	mem 24443MB
Train: [0/180][100/1251]	eta 0:39:37 lr 0.400000	data 0.0005 (0.2046)	batch 1.8235 (2.0659)	loss 6.4266 (6.6578)	grad_norm 0.7418 (0.6862)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108795
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/1251]	eta 8:58:40 lr 0.400000	data 19.8288 (19.8288)	batch 25.8359 (25.8359)	loss 6.9324 (6.9324)	grad_norm 0.7079 (0.7079)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108795
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/1251]	eta 8:55:44 lr 0.400000	data 20.4594 (20.4594)	batch 25.6949 (25.6949)	loss 6.9324 (6.9324)	grad_norm 0.7076 (0.7076)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108795
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/1251]	eta 8:57:36 lr 0.400000	data 20.7534 (20.7534)	batch 25.7843 (25.7843)	loss 6.9324 (6.9324)	grad_norm 0.7069 (0.7069)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108795
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/1251]	eta 8:58:13 lr 0.400000	data 21.0798 (21.0798)	batch 25.8144 (25.8144)	loss 6.9323 (6.9323)	grad_norm 0.7075 (0.7075)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (2): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (3): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (3): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (4): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (5): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (1): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
      (2): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
    (6): Sequential(
      (0): InvertedResidual_Share_Act(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (final_act): Identity()
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108795
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/1251]	eta 8:54:59 lr 0.400000	data 20.9961 (20.9961)	batch 25.6593 (25.6593)	loss 6.9324 (6.9324)	grad_norm 0.7073 (0.7073)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108811
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108811
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108811
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/1251]	eta 9:04:59 lr 0.400000	data 21.2737 (21.2737)	batch 26.1387 (26.1387)	loss 6.9323 (6.9323)	grad_norm 0.6715 (0.6715)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108811
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/1251]	eta 9:18:56 lr 0.400000	data 21.4587 (21.4587)	batch 26.8079 (26.8079)	loss 6.9323 (6.9323)	grad_norm 0.6705 (0.6705)	mem 24443MB
Train: [0/180][50/1251]	eta 0:45:01 lr 0.400000	data 0.0005 (0.4212)	batch 1.7344 (2.2495)	loss 6.7795 (6.9365)	grad_norm 0.7641 (0.6818)	mem 24443MB
Train: [0/180][100/1251]	eta 0:38:26 lr 0.400000	data 0.0004 (0.2129)	batch 1.7431 (2.0043)	loss 6.5063 (6.7685)	grad_norm 0.6043 (0.6725)	mem 24443MB
Train: [0/180][150/1251]	eta 0:35:14 lr 0.400000	data 0.0004 (0.1426)	batch 1.7931 (1.9201)	loss 6.2592 (6.6337)	grad_norm 0.5600 (0.6531)	mem 24443MB
Train: [0/180][200/1251]	eta 0:32:51 lr 0.399999	data 0.0004 (0.1072)	batch 1.7451 (1.8760)	loss 6.0279 (6.5304)	grad_norm 0.5896 (0.6371)	mem 24443MB
Train: [0/180][250/1251]	eta 0:30:52 lr 0.399999	data 0.0004 (0.0860)	batch 1.7436 (1.8504)	loss 6.1406 (6.4389)	grad_norm 0.5674 (0.6298)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108811
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/1251]	eta 8:56:14 lr 0.400000	data 19.6851 (19.6851)	batch 25.7191 (25.7191)	loss 6.9323 (6.9323)	grad_norm 0.6710 (0.6710)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108811
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/1251]	eta 8:57:12 lr 0.400000	data 20.1069 (20.1069)	batch 25.7650 (25.7650)	loss 6.9323 (6.9323)	grad_norm 0.6705 (0.6705)	mem 24443MB
Train: [0/180][50/1251]	eta 0:44:40 lr 0.400000	data 0.0005 (0.3948)	batch 1.7428 (2.2319)	loss 6.7060 (6.9299)	grad_norm 0.7001 (0.6832)	mem 24443MB
Train: [0/180][100/1251]	eta 0:38:16 lr 0.400000	data 0.0005 (0.1996)	batch 1.7807 (1.9951)	loss 6.5285 (6.7604)	grad_norm 0.6706 (0.6838)	mem 24443MB
Train: [0/180][150/1251]	eta 0:35:08 lr 0.400000	data 0.0007 (0.1337)	batch 1.7347 (1.9147)	loss 6.2794 (6.6275)	grad_norm 0.5810 (0.6623)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108811
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/1251]	eta 9:10:37 lr 0.400000	data 20.8254 (20.8254)	batch 26.4089 (26.4089)	loss 6.9323 (6.9323)	grad_norm 0.6696 (0.6696)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108811
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/1251]	eta 9:00:22 lr 0.400000	data 20.7008 (20.7008)	batch 25.9171 (25.9171)	loss 6.9323 (6.9323)	grad_norm 0.6713 (0.6713)	mem 24443MB
Train: [0/180][50/1251]	eta 0:44:42 lr 0.400000	data 0.0006 (0.4064)	batch 1.7362 (2.2335)	loss 6.7271 (6.9543)	grad_norm 0.7250 (0.6736)	mem 24443MB
Train: [0/180][100/1251]	eta 0:38:14 lr 0.400000	data 0.0004 (0.2054)	batch 1.7321 (1.9939)	loss 6.5427 (6.7921)	grad_norm 0.6086 (0.6601)	mem 24443MB
Train: [0/180][150/1251]	eta 0:35:05 lr 0.400000	data 0.0004 (0.1376)	batch 1.7363 (1.9127)	loss 6.3310 (6.6588)	grad_norm 0.5656 (0.6405)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108811
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/1251]	eta 9:01:33 lr 0.400000	data 19.8631 (19.8631)	batch 25.9738 (25.9738)	loss 6.9323 (6.9323)	grad_norm 0.6719 (0.6719)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/1251]	eta 8:53:49 lr 0.400000	data 20.7923 (20.7923)	batch 25.6029 (25.6029)	loss 6.9462 (6.9462)	grad_norm 3.7122 (3.7122)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/1251]	eta 8:56:25 lr 0.400000	data 19.5784 (19.5784)	batch 25.7275 (25.7275)	loss 6.9462 (6.9462)	grad_norm 3.8355 (3.8355)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/1251]	eta 9:01:27 lr 0.400000	data 20.1400 (20.1400)	batch 25.9691 (25.9691)	loss 6.9462 (6.9462)	grad_norm 3.7974 (3.7974)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10002
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10002
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10002
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10002
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.4
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.0e-06
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 8
dist_url: tcp://127.0.0.1:10002
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 256
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.1
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 5.0e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 5.0e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10002
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10002
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10001
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 45 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 10:15:46 lr 0.050000	data 17.6551 (17.6551)	batch 20.9558 (20.9558)	loss 6.9676 (6.9676)	grad_norm 10.2987 (10.2987)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 17:14:08 lr 0.050000	data 20.0511 (20.0511)	batch 23.4637 (23.4637)	loss 6.9677 (6.9677)	grad_norm 10.0275 (10.0275)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 14:38:42 lr 0.050000	data 18.7836 (18.7836)	batch 22.5320 (22.5320)	loss 6.9677 (6.9677)	grad_norm 10.0236 (10.0236)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 13:18:56 lr 0.050000	data 18.5668 (18.5668)	batch 22.0538 (22.0538)	loss 6.9677 (6.9677)	grad_norm 10.0456 (10.0456)	mem 24443MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 14:01:28 lr 0.050000	data 19.1939 (19.1939)	batch 22.3088 (22.3088)	loss 6.9676 (6.9676)	grad_norm 10.2987 (10.2987)	mem 28674MB
Train: [0/180][50/10009]	eta 4:42:03 lr 0.050000	data 0.0006 (0.3769)	batch 1.4090 (1.6993)	loss 7.0771 (7.0450)	grad_norm 3.7549 (4.9378)	mem 28674MB
Train: [0/180][100/10009]	eta 4:06:52 lr 0.050000	data 0.0005 (0.1906)	batch 1.1977 (1.4948)	loss 7.0758 (7.0680)	grad_norm 2.9898 (4.1532)	mem 28674MB
Train: [0/180][150/10009]	eta 3:55:54 lr 0.050000	data 0.0005 (0.1276)	batch 1.5673 (1.4357)	loss 7.0394 (7.0690)	grad_norm 2.6699 (3.7063)	mem 28674MB
Train: [0/180][200/10009]	eta 3:48:05 lr 0.050000	data 0.0005 (0.0960)	batch 1.0019 (1.3952)	loss 7.0121 (7.0625)	grad_norm 2.2807 (3.4035)	mem 28674MB
Train: [0/180][250/10009]	eta 3:42:59 lr 0.050000	data 0.0005 (0.0770)	batch 1.0725 (1.3709)	loss 6.9926 (7.0480)	grad_norm 2.0398 (3.1571)	mem 28674MB
Train: [0/180][300/10009]	eta 3:39:52 lr 0.050000	data 0.0005 (0.0643)	batch 1.3975 (1.3588)	loss 6.9475 (7.0296)	grad_norm 1.8486 (2.9568)	mem 28674MB
Train: [0/180][350/10009]	eta 3:37:29 lr 0.050000	data 0.0005 (0.0552)	batch 1.3733 (1.3510)	loss 6.8348 (7.0082)	grad_norm 1.6161 (2.7786)	mem 28674MB
Train: [0/180][400/10009]	eta 3:35:21 lr 0.050000	data 0.0005 (0.0484)	batch 1.1990 (1.3448)	loss 6.7350 (6.9862)	grad_norm 1.4610 (2.6233)	mem 28674MB
Train: [0/180][450/10009]	eta 3:33:12 lr 0.050000	data 0.0005 (0.0431)	batch 1.2199 (1.3382)	loss 6.7801 (6.9636)	grad_norm 1.3747 (2.4886)	mem 28674MB
Train: [0/180][500/10009]	eta 3:31:17 lr 0.050000	data 0.0005 (0.0388)	batch 0.9955 (1.3332)	loss 6.7141 (6.9401)	grad_norm 1.3339 (2.3734)	mem 28674MB
Train: [0/180][550/10009]	eta 3:29:42 lr 0.050000	data 0.0005 (0.0354)	batch 1.3746 (1.3302)	loss 6.6086 (6.9189)	grad_norm 1.3452 (2.2771)	mem 28674MB
Train: [0/180][600/10009]	eta 3:28:12 lr 0.050000	data 0.0005 (0.0325)	batch 1.3867 (1.3277)	loss 6.5904 (6.8991)	grad_norm 1.2804 (2.1916)	mem 28674MB
Train: [0/180][650/10009]	eta 3:26:43 lr 0.050000	data 0.0005 (0.0300)	batch 1.1430 (1.3253)	loss 6.6591 (6.8800)	grad_norm 1.1680 (2.1178)	mem 28674MB
Train: [0/180][700/10009]	eta 3:25:12 lr 0.050000	data 0.0004 (0.0279)	batch 1.2366 (1.3227)	loss 6.5917 (6.8621)	grad_norm 1.1607 (2.0551)	mem 28674MB
Train: [0/180][750/10009]	eta 3:23:48 lr 0.050000	data 0.0005 (0.0261)	batch 1.0016 (1.3207)	loss 6.4922 (6.8450)	grad_norm 1.2277 (2.0003)	mem 28674MB
Train: [0/180][800/10009]	eta 3:22:30 lr 0.050000	data 0.0005 (0.0245)	batch 1.4045 (1.3194)	loss 6.4542 (6.8283)	grad_norm 1.1928 (1.9517)	mem 28674MB
Train: [0/180][850/10009]	eta 3:21:15 lr 0.050000	data 0.0005 (0.0231)	batch 1.3856 (1.3185)	loss 6.4900 (6.8116)	grad_norm 1.1890 (1.9100)	mem 28674MB
Train: [0/180][900/10009]	eta 3:19:59 lr 0.050000	data 0.0004 (0.0218)	batch 1.2562 (1.3173)	loss 6.5540 (6.7969)	grad_norm 1.2385 (1.8734)	mem 28674MB
Train: [0/180][950/10009]	eta 3:18:38 lr 0.050000	data 0.0005 (0.0207)	batch 1.2929 (1.3157)	loss 6.4588 (6.7829)	grad_norm 1.2304 (1.8409)	mem 28674MB
Train: [0/180][1000/10009]	eta 3:17:22 lr 0.050000	data 0.0004 (0.0197)	batch 1.3577 (1.3146)	loss 6.5402 (6.7693)	grad_norm 1.2285 (1.8107)	mem 28674MB
Train: [0/180][1050/10009]	eta 3:16:03 lr 0.050000	data 0.0004 (0.0188)	batch 1.2898 (1.3131)	loss 6.4727 (6.7565)	grad_norm 1.2861 (1.7821)	mem 28674MB
Train: [0/180][1100/10009]	eta 3:14:53 lr 0.050000	data 0.0005 (0.0179)	batch 1.2835 (1.3126)	loss 6.5043 (6.7439)	grad_norm 1.2167 (1.7574)	mem 28674MB
Train: [0/180][1150/10009]	eta 3:13:38 lr 0.050000	data 0.0009 (0.0172)	batch 1.0904 (1.3115)	loss 6.4493 (6.7303)	grad_norm 1.1812 (1.7356)	mem 28674MB
Train: [0/180][1200/10009]	eta 3:12:29 lr 0.050000	data 0.0004 (0.0165)	batch 1.5558 (1.3111)	loss 6.3786 (6.7170)	grad_norm 1.2538 (1.7163)	mem 28674MB
Train: [0/180][1250/10009]	eta 3:11:20 lr 0.050000	data 0.0005 (0.0159)	batch 1.5361 (1.3107)	loss 6.5118 (6.7047)	grad_norm 1.3546 (1.6977)	mem 28674MB
Train: [0/180][1300/10009]	eta 3:10:00 lr 0.050000	data 0.0005 (0.0153)	batch 1.1586 (1.3090)	loss 6.3776 (6.6930)	grad_norm 1.1654 (1.6805)	mem 28674MB
Train: [0/180][1350/10009]	eta 3:08:46 lr 0.050000	data 0.0005 (0.0147)	batch 1.4246 (1.3080)	loss 6.3794 (6.6806)	grad_norm 1.2473 (1.6659)	mem 28674MB
Train: [0/180][1400/10009]	eta 3:07:23 lr 0.050000	data 0.0005 (0.0142)	batch 1.1964 (1.3060)	loss 6.4144 (6.6696)	grad_norm 1.3643 (1.6516)	mem 28674MB
Train: [0/180][1450/10009]	eta 3:06:14 lr 0.050000	data 0.0005 (0.0138)	batch 1.2987 (1.3056)	loss 6.3657 (6.6587)	grad_norm 1.2469 (1.6386)	mem 28674MB
Train: [0/180][1500/10009]	eta 3:05:01 lr 0.050000	data 0.0006 (0.0133)	batch 0.7569 (1.3046)	loss 6.4441 (6.6485)	grad_norm 1.2526 (1.6267)	mem 28674MB
Train: [0/180][1550/10009]	eta 3:03:55 lr 0.050000	data 0.0004 (0.0129)	batch 1.2746 (1.3046)	loss 6.4031 (6.6376)	grad_norm 1.3216 (1.6167)	mem 28674MB
Train: [0/180][1600/10009]	eta 3:02:47 lr 0.050000	data 0.0004 (0.0125)	batch 1.0950 (1.3043)	loss 6.2662 (6.6269)	grad_norm 1.3538 (1.6072)	mem 28674MB
Train: [0/180][1650/10009]	eta 3:01:41 lr 0.050000	data 0.0005 (0.0121)	batch 0.8836 (1.3041)	loss 6.3441 (6.6160)	grad_norm 1.3611 (1.5990)	mem 28674MB
Train: [0/180][1700/10009]	eta 3:00:33 lr 0.050000	data 0.0007 (0.0118)	batch 1.0668 (1.3039)	loss 6.2344 (6.6064)	grad_norm 1.4448 (1.5915)	mem 28674MB
Train: [0/180][1750/10009]	eta 2:59:24 lr 0.050000	data 0.0005 (0.0115)	batch 1.2204 (1.3033)	loss 6.2030 (6.5963)	grad_norm 1.2820 (1.5839)	mem 28674MB
Train: [0/180][1800/10009]	eta 2:58:15 lr 0.050000	data 0.0005 (0.0112)	batch 1.1160 (1.3029)	loss 6.2949 (6.5869)	grad_norm 1.3044 (1.5768)	mem 28674MB
Train: [0/180][1850/10009]	eta 2:57:02 lr 0.050000	data 0.0004 (0.0109)	batch 1.3155 (1.3020)	loss 6.2567 (6.5773)	grad_norm 1.3299 (1.5695)	mem 28674MB
Train: [0/180][1900/10009]	eta 2:55:57 lr 0.050000	data 0.0004 (0.0106)	batch 1.4342 (1.3019)	loss 6.4884 (6.5680)	grad_norm 1.3738 (1.5631)	mem 28674MB
Train: [0/180][1950/10009]	eta 2:54:50 lr 0.050000	data 0.0006 (0.0104)	batch 1.5488 (1.3017)	loss 6.0510 (6.5581)	grad_norm 1.3451 (1.5574)	mem 28674MB
Train: [0/180][2000/10009]	eta 2:53:40 lr 0.050000	data 0.0004 (0.0101)	batch 1.5433 (1.3011)	loss 6.2069 (6.5490)	grad_norm 1.3599 (1.5521)	mem 28674MB
Train: [0/180][2050/10009]	eta 2:52:33 lr 0.050000	data 0.0005 (0.0099)	batch 1.3316 (1.3008)	loss 6.2723 (6.5404)	grad_norm 1.2844 (1.5467)	mem 28674MB
Train: [0/180][2100/10009]	eta 2:51:26 lr 0.050000	data 0.0006 (0.0096)	batch 1.3805 (1.3006)	loss 6.0677 (6.5317)	grad_norm 1.2998 (1.5412)	mem 28674MB
Train: [0/180][2150/10009]	eta 2:50:19 lr 0.050000	data 0.0004 (0.0094)	batch 1.0999 (1.3003)	loss 6.0532 (6.5230)	grad_norm 1.3360 (1.5364)	mem 28674MB
Train: [0/180][2200/10009]	eta 2:49:12 lr 0.050000	data 0.0004 (0.0092)	batch 1.5339 (1.3001)	loss 6.1491 (6.5146)	grad_norm 1.3885 (1.5318)	mem 28674MB
Train: [0/180][2250/10009]	eta 2:48:06 lr 0.050000	data 0.0006 (0.0090)	batch 1.4582 (1.2999)	loss 6.0701 (6.5062)	grad_norm 1.2678 (1.5273)	mem 28674MB
Train: [0/180][2300/10009]	eta 2:47:00 lr 0.050000	data 0.0005 (0.0089)	batch 1.1551 (1.2999)	loss 6.0027 (6.4978)	grad_norm 1.3249 (1.5229)	mem 28674MB
Train: [0/180][2350/10009]	eta 2:45:54 lr 0.050000	data 0.0004 (0.0087)	batch 0.9461 (1.2997)	loss 6.0735 (6.4898)	grad_norm 1.3526 (1.5190)	mem 28674MB
Train: [0/180][2400/10009]	eta 2:44:47 lr 0.050000	data 0.0007 (0.0085)	batch 1.1423 (1.2995)	loss 6.1387 (6.4817)	grad_norm 1.3503 (1.5161)	mem 28674MB
Train: [0/180][2450/10009]	eta 2:43:41 lr 0.050000	data 0.0004 (0.0083)	batch 1.2152 (1.2993)	loss 6.2910 (6.4738)	grad_norm 1.3559 (1.5128)	mem 28674MB
Train: [0/180][2500/10009]	eta 2:42:34 lr 0.050000	data 0.0005 (0.0082)	batch 1.1755 (1.2991)	loss 6.1258 (6.4662)	grad_norm 1.3111 (1.5096)	mem 28674MB
Train: [0/180][2550/10009]	eta 2:41:29 lr 0.050000	data 0.0004 (0.0080)	batch 1.3098 (1.2991)	loss 6.0483 (6.4584)	grad_norm 1.3318 (1.5066)	mem 28674MB
Train: [0/180][2600/10009]	eta 2:40:23 lr 0.050000	data 0.0005 (0.0079)	batch 1.3486 (1.2989)	loss 6.0132 (6.4507)	grad_norm 1.3250 (1.5035)	mem 28674MB
Train: [0/180][2650/10009]	eta 2:39:18 lr 0.050000	data 0.0004 (0.0078)	batch 1.5500 (1.2988)	loss 6.2552 (6.4434)	grad_norm 1.4222 (1.5012)	mem 28674MB
Train: [0/180][2700/10009]	eta 2:38:11 lr 0.050000	data 0.0005 (0.0076)	batch 1.5677 (1.2986)	loss 6.1234 (6.4361)	grad_norm 1.4148 (1.4989)	mem 28674MB
Train: [0/180][2750/10009]	eta 2:37:05 lr 0.050000	data 0.0005 (0.0075)	batch 1.3997 (1.2985)	loss 6.1618 (6.4287)	grad_norm 1.3817 (1.4967)	mem 28674MB
Train: [0/180][2800/10009]	eta 2:35:59 lr 0.050000	data 0.0004 (0.0074)	batch 1.3456 (1.2982)	loss 6.1139 (6.4210)	grad_norm 1.4326 (1.4949)	mem 28674MB
Train: [0/180][2850/10009]	eta 2:34:52 lr 0.050000	data 0.0005 (0.0072)	batch 1.3628 (1.2980)	loss 6.0257 (6.4142)	grad_norm 1.3490 (1.4923)	mem 28674MB
Train: [0/180][2900/10009]	eta 2:33:46 lr 0.050000	data 0.0004 (0.0071)	batch 1.3770 (1.2979)	loss 5.8861 (6.4073)	grad_norm 1.3771 (1.4901)	mem 28674MB
Train: [0/180][2950/10009]	eta 2:32:40 lr 0.050000	data 0.0004 (0.0070)	batch 1.1199 (1.2977)	loss 6.0661 (6.4006)	grad_norm 1.4692 (1.4881)	mem 28674MB
Train: [0/180][3000/10009]	eta 2:31:32 lr 0.050000	data 0.0005 (0.0069)	batch 1.0429 (1.2973)	loss 5.9742 (6.3937)	grad_norm 1.4043 (1.4865)	mem 28674MB
Train: [0/180][3050/10009]	eta 2:30:28 lr 0.050000	data 0.0005 (0.0068)	batch 1.1200 (1.2973)	loss 5.7203 (6.3869)	grad_norm 1.2849 (1.4848)	mem 28674MB
Train: [0/180][3100/10009]	eta 2:29:23 lr 0.050000	data 0.0004 (0.0067)	batch 1.2607 (1.2973)	loss 6.1401 (6.3799)	grad_norm 1.4167 (1.4835)	mem 28674MB
Train: [0/180][3150/10009]	eta 2:28:17 lr 0.050000	data 0.0004 (0.0066)	batch 1.3554 (1.2973)	loss 6.0239 (6.3731)	grad_norm 1.3125 (1.4823)	mem 28674MB
Train: [0/180][3200/10009]	eta 2:27:12 lr 0.050000	data 0.0004 (0.0065)	batch 1.2248 (1.2972)	loss 6.0778 (6.3666)	grad_norm 1.4068 (1.4810)	mem 28674MB
Train: [0/180][3250/10009]	eta 2:26:06 lr 0.050000	data 0.0005 (0.0064)	batch 1.2365 (1.2970)	loss 5.9511 (6.3599)	grad_norm 1.4134 (1.4798)	mem 28674MB
Train: [0/180][3300/10009]	eta 2:25:00 lr 0.050000	data 0.0004 (0.0063)	batch 1.1367 (1.2969)	loss 6.0410 (6.3531)	grad_norm 1.3508 (1.4787)	mem 28674MB
Train: [0/180][3350/10009]	eta 2:23:54 lr 0.050000	data 0.0004 (0.0062)	batch 1.1453 (1.2967)	loss 5.7869 (6.3466)	grad_norm 1.3711 (1.4776)	mem 28674MB
Train: [0/180][3400/10009]	eta 2:22:49 lr 0.050000	data 0.0004 (0.0062)	batch 1.5374 (1.2966)	loss 5.9675 (6.3402)	grad_norm 1.4355 (1.4764)	mem 28674MB
Train: [0/180][3450/10009]	eta 2:21:45 lr 0.050000	data 0.0005 (0.0061)	batch 1.5586 (1.2967)	loss 5.8290 (6.3341)	grad_norm 1.3749 (1.4754)	mem 28674MB
Train: [0/180][3500/10009]	eta 2:20:37 lr 0.050000	data 0.0005 (0.0060)	batch 1.5740 (1.2963)	loss 6.0430 (6.3279)	grad_norm 1.4864 (1.4748)	mem 28674MB
Train: [0/180][3550/10009]	eta 2:19:32 lr 0.050000	data 0.0005 (0.0059)	batch 1.3214 (1.2963)	loss 6.1288 (6.3216)	grad_norm 1.5260 (1.4740)	mem 28674MB
Train: [0/180][3600/10009]	eta 2:18:27 lr 0.050000	data 0.0005 (0.0058)	batch 1.3840 (1.2962)	loss 5.9530 (6.3152)	grad_norm 1.6283 (1.4737)	mem 28674MB
Train: [0/180][3650/10009]	eta 2:17:22 lr 0.049999	data 0.0005 (0.0058)	batch 1.3417 (1.2962)	loss 5.8055 (6.3089)	grad_norm 1.3356 (1.4730)	mem 28674MB
Train: [0/180][3700/10009]	eta 2:16:15 lr 0.049999	data 0.0005 (0.0057)	batch 0.7173 (1.2959)	loss 5.9054 (6.3026)	grad_norm 1.4622 (1.4726)	mem 28674MB
Train: [0/180][3750/10009]	eta 2:15:11 lr 0.049999	data 0.0005 (0.0056)	batch 1.2883 (1.2960)	loss 5.8968 (6.2962)	grad_norm 1.4230 (1.4720)	mem 28674MB
Train: [0/180][3800/10009]	eta 2:14:07 lr 0.049999	data 0.0004 (0.0056)	batch 1.3867 (1.2961)	loss 5.9460 (6.2902)	grad_norm 1.4716 (1.4715)	mem 28674MB
Train: [0/180][3850/10009]	eta 2:13:02 lr 0.049999	data 0.0004 (0.0055)	batch 1.3922 (1.2960)	loss 5.8412 (6.2842)	grad_norm 1.4499 (1.4716)	mem 28674MB
Train: [0/180][3900/10009]	eta 2:11:57 lr 0.049999	data 0.0005 (0.0054)	batch 1.2365 (1.2960)	loss 5.7584 (6.2784)	grad_norm 1.4520 (1.4711)	mem 28674MB
Train: [0/180][3950/10009]	eta 2:10:51 lr 0.049999	data 0.0004 (0.0054)	batch 1.2165 (1.2958)	loss 5.9559 (6.2725)	grad_norm 1.3711 (1.4708)	mem 28674MB
Train: [0/180][4000/10009]	eta 2:09:46 lr 0.049999	data 0.0005 (0.0053)	batch 1.1872 (1.2957)	loss 5.8248 (6.2666)	grad_norm 1.3724 (1.4706)	mem 28674MB
Train: [0/180][4050/10009]	eta 2:08:40 lr 0.049999	data 0.0004 (0.0053)	batch 1.0939 (1.2956)	loss 5.9277 (6.2611)	grad_norm 1.4695 (1.4704)	mem 28674MB
Train: [0/180][4100/10009]	eta 2:07:35 lr 0.049999	data 0.0005 (0.0052)	batch 1.5447 (1.2956)	loss 5.8397 (6.2554)	grad_norm 1.5215 (1.4702)	mem 28674MB
Train: [0/180][4150/10009]	eta 2:06:30 lr 0.049999	data 0.0005 (0.0051)	batch 1.5572 (1.2954)	loss 5.5762 (6.2496)	grad_norm 1.4407 (1.4700)	mem 28674MB
Train: [0/180][4200/10009]	eta 2:05:24 lr 0.049999	data 0.0005 (0.0051)	batch 1.5854 (1.2954)	loss 5.9829 (6.2444)	grad_norm 1.4456 (1.4698)	mem 28674MB
Train: [0/180][4250/10009]	eta 2:04:20 lr 0.049999	data 0.0004 (0.0050)	batch 1.4060 (1.2954)	loss 5.6843 (6.2386)	grad_norm 1.5062 (1.4699)	mem 28674MB
Train: [0/180][4300/10009]	eta 2:03:14 lr 0.049999	data 0.0004 (0.0050)	batch 1.3116 (1.2953)	loss 5.7360 (6.2329)	grad_norm 1.4232 (1.4702)	mem 28674MB
Train: [0/180][4350/10009]	eta 2:02:09 lr 0.049999	data 0.0006 (0.0049)	batch 1.1711 (1.2952)	loss 5.6944 (6.2273)	grad_norm 1.5189 (1.4703)	mem 28674MB
Train: [0/180][4400/10009]	eta 2:01:03 lr 0.049999	data 0.0005 (0.0049)	batch 0.9252 (1.2950)	loss 5.8539 (6.2214)	grad_norm 1.5103 (1.4709)	mem 28674MB
Train: [0/180][4450/10009]	eta 1:59:58 lr 0.049999	data 0.0005 (0.0048)	batch 1.2641 (1.2950)	loss 5.5155 (6.2159)	grad_norm 1.3873 (1.4710)	mem 28674MB
Train: [0/180][4500/10009]	eta 1:58:51 lr 0.049999	data 0.0005 (0.0048)	batch 1.2084 (1.2945)	loss 5.4957 (6.2101)	grad_norm 1.4801 (1.4712)	mem 28674MB
Train: [0/180][4550/10009]	eta 1:57:45 lr 0.049999	data 0.0006 (0.0047)	batch 1.4086 (1.2943)	loss 5.6876 (6.2045)	grad_norm 1.4326 (1.4716)	mem 28674MB
Train: [0/180][4600/10009]	eta 1:56:40 lr 0.049999	data 0.0005 (0.0047)	batch 1.3738 (1.2943)	loss 5.6086 (6.1990)	grad_norm 1.5779 (1.4719)	mem 28674MB
Train: [0/180][4650/10009]	eta 1:55:35 lr 0.049999	data 0.0005 (0.0046)	batch 1.3845 (1.2942)	loss 5.6864 (6.1937)	grad_norm 1.3884 (1.4721)	mem 28674MB
Train: [0/180][4700/10009]	eta 1:54:30 lr 0.049999	data 0.0005 (0.0046)	batch 1.1262 (1.2941)	loss 5.3772 (6.1882)	grad_norm 1.4229 (1.4725)	mem 28674MB
Train: [0/180][4750/10009]	eta 1:53:25 lr 0.049999	data 0.0006 (0.0046)	batch 1.4913 (1.2941)	loss 5.5960 (6.1826)	grad_norm 1.4642 (1.4729)	mem 28674MB
Train: [0/180][4800/10009]	eta 1:52:20 lr 0.049999	data 0.0004 (0.0045)	batch 1.5558 (1.2940)	loss 5.7654 (6.1772)	grad_norm 1.5040 (1.4735)	mem 28674MB
Train: [0/180][4850/10009]	eta 1:51:15 lr 0.049999	data 0.0004 (0.0045)	batch 1.4132 (1.2940)	loss 5.6192 (6.1718)	grad_norm 1.6229 (1.4739)	mem 28674MB
Train: [0/180][4900/10009]	eta 1:50:10 lr 0.049999	data 0.0005 (0.0044)	batch 1.0636 (1.2939)	loss 5.5900 (6.1662)	grad_norm 1.5792 (1.4746)	mem 28674MB
Train: [0/180][4950/10009]	eta 1:49:05 lr 0.049999	data 0.0006 (0.0044)	batch 1.1598 (1.2939)	loss 5.3916 (6.1606)	grad_norm 1.4831 (1.4751)	mem 28674MB
Train: [0/180][5000/10009]	eta 1:48:00 lr 0.049999	data 0.0005 (0.0044)	batch 1.2403 (1.2939)	loss 5.8128 (6.1556)	grad_norm 1.5365 (1.4754)	mem 28674MB
Train: [0/180][5050/10009]	eta 1:46:56 lr 0.049999	data 0.0005 (0.0043)	batch 1.2192 (1.2939)	loss 5.8861 (6.1501)	grad_norm 1.5797 (1.4759)	mem 28674MB
Train: [0/180][5100/10009]	eta 1:45:51 lr 0.049999	data 0.0005 (0.0043)	batch 1.0673 (1.2938)	loss 5.5108 (6.1447)	grad_norm 1.5304 (1.4763)	mem 28674MB
Train: [0/180][5150/10009]	eta 1:44:46 lr 0.049999	data 0.0004 (0.0042)	batch 1.3079 (1.2937)	loss 5.4399 (6.1394)	grad_norm 1.4478 (1.4768)	mem 28674MB
Train: [0/180][5200/10009]	eta 1:43:41 lr 0.049999	data 0.0004 (0.0042)	batch 1.3804 (1.2938)	loss 5.7750 (6.1343)	grad_norm 1.4443 (1.4775)	mem 28674MB
Train: [0/180][5250/10009]	eta 1:42:37 lr 0.049999	data 0.0004 (0.0042)	batch 1.3407 (1.2939)	loss 5.8777 (6.1290)	grad_norm 1.5401 (1.4780)	mem 28674MB
Train: [0/180][5300/10009]	eta 1:41:32 lr 0.049999	data 0.0004 (0.0041)	batch 1.2571 (1.2938)	loss 5.5526 (6.1239)	grad_norm 1.5583 (1.4784)	mem 28674MB
Train: [0/180][5350/10009]	eta 1:40:27 lr 0.049999	data 0.0005 (0.0041)	batch 1.2686 (1.2938)	loss 5.4824 (6.1189)	grad_norm 1.5887 (1.4789)	mem 28674MB
Train: [0/180][5400/10009]	eta 1:39:21 lr 0.049999	data 0.0007 (0.0041)	batch 1.4720 (1.2935)	loss 5.8342 (6.1140)	grad_norm 1.5730 (1.4795)	mem 28674MB
Train: [0/180][5450/10009]	eta 1:38:16 lr 0.049999	data 0.0005 (0.0040)	batch 1.3793 (1.2934)	loss 5.5399 (6.1087)	grad_norm 1.5694 (1.4799)	mem 28674MB
Train: [0/180][5500/10009]	eta 1:37:11 lr 0.049999	data 0.0005 (0.0040)	batch 1.3523 (1.2934)	loss 5.4529 (6.1037)	grad_norm 1.5514 (1.4806)	mem 28674MB
Train: [0/180][5550/10009]	eta 1:36:06 lr 0.049999	data 0.0005 (0.0040)	batch 1.1501 (1.2933)	loss 5.6221 (6.0985)	grad_norm 1.6159 (1.4813)	mem 28674MB
Train: [0/180][5600/10009]	eta 1:35:02 lr 0.049999	data 0.0005 (0.0039)	batch 1.0124 (1.2933)	loss 5.5013 (6.0936)	grad_norm 1.4569 (1.4816)	mem 28674MB
Train: [0/180][5650/10009]	eta 1:33:58 lr 0.049999	data 0.0005 (0.0039)	batch 1.2992 (1.2934)	loss 5.4153 (6.0888)	grad_norm 1.5565 (1.4820)	mem 28674MB
Train: [0/180][5700/10009]	eta 1:32:53 lr 0.049999	data 0.0004 (0.0039)	batch 1.1799 (1.2934)	loss 5.6033 (6.0840)	grad_norm 1.5400 (1.4825)	mem 28674MB
Train: [0/180][5750/10009]	eta 1:31:48 lr 0.049999	data 0.0005 (0.0039)	batch 1.2329 (1.2934)	loss 5.7049 (6.0790)	grad_norm 1.6244 (1.4829)	mem 28674MB
Train: [0/180][5800/10009]	eta 1:30:43 lr 0.049999	data 0.0004 (0.0038)	batch 1.1469 (1.2934)	loss 5.5915 (6.0744)	grad_norm 1.5054 (1.4832)	mem 28674MB
Train: [0/180][5850/10009]	eta 1:29:39 lr 0.049999	data 0.0004 (0.0038)	batch 1.2131 (1.2934)	loss 5.5618 (6.0696)	grad_norm 1.5374 (1.4835)	mem 28674MB
Train: [0/180][5900/10009]	eta 1:28:34 lr 0.049999	data 0.0004 (0.0038)	batch 1.5503 (1.2934)	loss 5.6366 (6.0647)	grad_norm 1.5083 (1.4841)	mem 28674MB
Train: [0/180][5950/10009]	eta 1:27:30 lr 0.049999	data 0.0004 (0.0037)	batch 1.5260 (1.2934)	loss 5.4881 (6.0601)	grad_norm 1.5257 (1.4847)	mem 28674MB
Train: [0/180][6000/10009]	eta 1:26:25 lr 0.049999	data 0.0004 (0.0037)	batch 1.5781 (1.2934)	loss 5.4119 (6.0552)	grad_norm 1.6261 (1.4851)	mem 28674MB
Train: [0/180][6050/10009]	eta 1:25:20 lr 0.049999	data 0.0004 (0.0037)	batch 1.3438 (1.2934)	loss 5.1938 (6.0502)	grad_norm 1.5815 (1.4857)	mem 28674MB
Train: [0/180][6100/10009]	eta 1:24:16 lr 0.049999	data 0.0005 (0.0037)	batch 1.3846 (1.2934)	loss 5.4742 (6.0453)	grad_norm 1.5830 (1.4864)	mem 28674MB
Train: [0/180][6150/10009]	eta 1:23:11 lr 0.049999	data 0.0005 (0.0036)	batch 1.0986 (1.2934)	loss 5.4407 (6.0406)	grad_norm 1.6015 (1.4870)	mem 28674MB
Train: [0/180][6200/10009]	eta 1:22:06 lr 0.049999	data 0.0005 (0.0036)	batch 1.4684 (1.2933)	loss 5.5017 (6.0360)	grad_norm 1.6753 (1.4876)	mem 28674MB
Train: [0/180][6250/10009]	eta 1:21:01 lr 0.049999	data 0.0004 (0.0036)	batch 1.1784 (1.2933)	loss 5.5746 (6.0315)	grad_norm 1.4701 (1.4880)	mem 28674MB
Train: [0/180][6300/10009]	eta 1:19:56 lr 0.049998	data 0.0005 (0.0036)	batch 1.1420 (1.2933)	loss 5.3706 (6.0267)	grad_norm 1.5901 (1.4885)	mem 28674MB
Train: [0/180][6350/10009]	eta 1:18:52 lr 0.049998	data 0.0004 (0.0035)	batch 1.1506 (1.2934)	loss 5.2842 (6.0219)	grad_norm 1.6971 (1.4894)	mem 28674MB
Train: [0/180][6400/10009]	eta 1:17:47 lr 0.049998	data 0.0005 (0.0035)	batch 1.2237 (1.2934)	loss 5.2782 (6.0171)	grad_norm 1.5520 (1.4900)	mem 28674MB
Train: [0/180][6450/10009]	eta 1:16:42 lr 0.049998	data 0.0004 (0.0035)	batch 1.2310 (1.2933)	loss 5.5182 (6.0124)	grad_norm 1.5695 (1.4906)	mem 28674MB
Train: [0/180][6500/10009]	eta 1:15:38 lr 0.049998	data 0.0004 (0.0035)	batch 1.0551 (1.2933)	loss 5.4191 (6.0082)	grad_norm 1.6080 (1.4912)	mem 28674MB
Train: [0/180][6550/10009]	eta 1:14:33 lr 0.049998	data 0.0004 (0.0034)	batch 1.5317 (1.2933)	loss 5.6569 (6.0034)	grad_norm 1.6240 (1.4919)	mem 28674MB
Train: [0/180][6600/10009]	eta 1:13:28 lr 0.049998	data 0.0005 (0.0034)	batch 1.5717 (1.2933)	loss 5.2267 (5.9989)	grad_norm 1.5602 (1.4928)	mem 28674MB
Train: [0/180][6650/10009]	eta 1:12:24 lr 0.049998	data 0.0004 (0.0034)	batch 1.5640 (1.2933)	loss 5.3880 (5.9943)	grad_norm 1.5263 (1.4934)	mem 28674MB
Train: [0/180][6700/10009]	eta 1:11:19 lr 0.049998	data 0.0004 (0.0034)	batch 1.3250 (1.2933)	loss 5.5029 (5.9897)	grad_norm 1.5836 (1.4941)	mem 28674MB
Train: [0/180][6750/10009]	eta 1:10:14 lr 0.049998	data 0.0005 (0.0033)	batch 1.3821 (1.2932)	loss 5.4536 (5.9854)	grad_norm 1.5705 (1.4947)	mem 28674MB
Train: [0/180][6800/10009]	eta 1:09:09 lr 0.049998	data 0.0004 (0.0033)	batch 1.1905 (1.2932)	loss 5.2815 (5.9808)	grad_norm 1.4579 (1.4952)	mem 28674MB
Train: [0/180][6850/10009]	eta 1:08:04 lr 0.049998	data 0.0004 (0.0033)	batch 0.9789 (1.2931)	loss 5.5963 (5.9763)	grad_norm 1.6104 (1.4959)	mem 28674MB
Train: [0/180][6900/10009]	eta 1:07:00 lr 0.049998	data 0.0005 (0.0033)	batch 1.2369 (1.2932)	loss 5.1295 (5.9720)	grad_norm 1.4994 (1.4963)	mem 28674MB
Train: [0/180][6950/10009]	eta 1:05:55 lr 0.049998	data 0.0004 (0.0033)	batch 1.3936 (1.2932)	loss 5.4468 (5.9674)	grad_norm 1.6045 (1.4970)	mem 28674MB
Train: [0/180][7000/10009]	eta 1:04:51 lr 0.049998	data 0.0004 (0.0032)	batch 1.1706 (1.2933)	loss 5.6951 (5.9631)	grad_norm 1.5706 (1.4976)	mem 28674MB
Train: [0/180][7050/10009]	eta 1:03:46 lr 0.049998	data 0.0005 (0.0032)	batch 1.2201 (1.2932)	loss 5.1329 (5.9589)	grad_norm 1.5164 (1.4982)	mem 28674MB
Train: [0/180][7100/10009]	eta 1:02:41 lr 0.049998	data 0.0004 (0.0032)	batch 1.1673 (1.2932)	loss 5.4685 (5.9547)	grad_norm 1.6225 (1.4988)	mem 28674MB
Train: [0/180][7150/10009]	eta 1:01:37 lr 0.049998	data 0.0004 (0.0032)	batch 1.3009 (1.2932)	loss 5.3785 (5.9502)	grad_norm 1.6586 (1.4994)	mem 28674MB
Train: [0/180][7200/10009]	eta 1:00:32 lr 0.049998	data 0.0006 (0.0032)	batch 1.4018 (1.2932)	loss 5.1196 (5.9459)	grad_norm 1.5238 (1.5000)	mem 28674MB
Train: [0/180][7250/10009]	eta 0:59:28 lr 0.049998	data 0.0004 (0.0032)	batch 1.4874 (1.2933)	loss 5.2792 (5.9415)	grad_norm 1.6272 (1.5006)	mem 28674MB
Train: [0/180][7300/10009]	eta 0:58:23 lr 0.049998	data 0.0004 (0.0031)	batch 1.3446 (1.2932)	loss 5.3301 (5.9374)	grad_norm 1.5400 (1.5013)	mem 28674MB
Train: [0/180][7350/10009]	eta 0:57:18 lr 0.049998	data 0.0004 (0.0031)	batch 1.3442 (1.2932)	loss 5.2907 (5.9331)	grad_norm 1.4976 (1.5018)	mem 28674MB
Train: [0/180][7400/10009]	eta 0:56:13 lr 0.049998	data 0.0005 (0.0031)	batch 1.3534 (1.2932)	loss 5.1580 (5.9289)	grad_norm 1.5336 (1.5023)	mem 28674MB
Train: [0/180][7450/10009]	eta 0:55:09 lr 0.049998	data 0.0006 (0.0031)	batch 1.6069 (1.2931)	loss 5.4351 (5.9246)	grad_norm 1.6706 (1.5029)	mem 28674MB
Train: [0/180][7500/10009]	eta 0:54:04 lr 0.049998	data 0.0005 (0.0031)	batch 1.4701 (1.2931)	loss 5.4192 (5.9205)	grad_norm 1.6986 (1.5035)	mem 28674MB
Train: [0/180][7550/10009]	eta 0:52:59 lr 0.049998	data 0.0005 (0.0030)	batch 1.1702 (1.2930)	loss 5.2021 (5.9161)	grad_norm 1.5823 (1.5042)	mem 28674MB
Train: [0/180][7600/10009]	eta 0:51:54 lr 0.049998	data 0.0006 (0.0030)	batch 1.2815 (1.2930)	loss 5.1523 (5.9121)	grad_norm 1.4996 (1.5047)	mem 28674MB
Train: [0/180][7650/10009]	eta 0:50:49 lr 0.049998	data 0.0006 (0.0030)	batch 1.3763 (1.2929)	loss 5.0816 (5.9078)	grad_norm 1.5876 (1.5053)	mem 28674MB
Train: [0/180][7700/10009]	eta 0:49:45 lr 0.049998	data 0.0005 (0.0030)	batch 1.3508 (1.2929)	loss 5.0997 (5.9038)	grad_norm 1.5158 (1.5060)	mem 28674MB
Train: [0/180][7750/10009]	eta 0:48:40 lr 0.049998	data 0.0004 (0.0030)	batch 1.1826 (1.2929)	loss 5.1735 (5.8999)	grad_norm 1.5638 (1.5065)	mem 28674MB
Train: [0/180][7800/10009]	eta 0:47:35 lr 0.049998	data 0.0006 (0.0030)	batch 1.1541 (1.2928)	loss 5.2089 (5.8959)	grad_norm 1.6289 (1.5072)	mem 28674MB
Train: [0/180][7850/10009]	eta 0:46:31 lr 0.049998	data 0.0005 (0.0029)	batch 1.3518 (1.2928)	loss 5.2756 (5.8918)	grad_norm 1.5749 (1.5078)	mem 28674MB
Train: [0/180][7900/10009]	eta 0:45:26 lr 0.049998	data 0.0004 (0.0029)	batch 1.2165 (1.2927)	loss 5.1842 (5.8877)	grad_norm 1.5761 (1.5085)	mem 28674MB
Train: [0/180][7950/10009]	eta 0:44:21 lr 0.049998	data 0.0005 (0.0029)	batch 1.2189 (1.2927)	loss 5.5265 (5.8836)	grad_norm 1.5963 (1.5091)	mem 28674MB
Train: [0/180][8000/10009]	eta 0:43:16 lr 0.049998	data 0.0005 (0.0029)	batch 1.4049 (1.2926)	loss 5.1657 (5.8798)	grad_norm 1.5719 (1.5097)	mem 28674MB
Train: [0/180][8050/10009]	eta 0:42:12 lr 0.049998	data 0.0005 (0.0029)	batch 1.4669 (1.2927)	loss 5.1813 (5.8757)	grad_norm 1.5951 (1.5102)	mem 28674MB
Train: [0/180][8100/10009]	eta 0:41:07 lr 0.049998	data 0.0005 (0.0029)	batch 1.1202 (1.2927)	loss 5.1883 (5.8717)	grad_norm 1.5356 (1.5107)	mem 28674MB
Train: [0/180][8150/10009]	eta 0:40:03 lr 0.049997	data 0.0004 (0.0029)	batch 1.1242 (1.2927)	loss 5.0885 (5.8677)	grad_norm 1.5293 (1.5114)	mem 28674MB
Train: [0/180][8200/10009]	eta 0:38:58 lr 0.049997	data 0.0005 (0.0028)	batch 1.2386 (1.2927)	loss 5.2631 (5.8639)	grad_norm 1.6104 (1.5118)	mem 28674MB
Train: [0/180][8250/10009]	eta 0:37:53 lr 0.049997	data 0.0005 (0.0028)	batch 1.1225 (1.2926)	loss 5.2482 (5.8598)	grad_norm 1.5794 (1.5123)	mem 28674MB
Train: [0/180][8300/10009]	eta 0:36:48 lr 0.049997	data 0.0004 (0.0028)	batch 1.3978 (1.2924)	loss 5.1131 (5.8559)	grad_norm 1.5620 (1.5130)	mem 28674MB
Train: [0/180][8350/10009]	eta 0:35:44 lr 0.049997	data 0.0006 (0.0028)	batch 1.3439 (1.2924)	loss 5.1088 (5.8519)	grad_norm 1.5648 (1.5136)	mem 28674MB
Train: [0/180][8400/10009]	eta 0:34:39 lr 0.049997	data 0.0004 (0.0028)	batch 1.3664 (1.2924)	loss 5.2579 (5.8481)	grad_norm 1.6289 (1.5142)	mem 28674MB
Train: [0/180][8450/10009]	eta 0:33:34 lr 0.049997	data 0.0004 (0.0028)	batch 1.3181 (1.2924)	loss 4.8212 (5.8441)	grad_norm 1.6706 (1.5149)	mem 28674MB
Train: [0/180][8500/10009]	eta 0:32:30 lr 0.049997	data 0.0004 (0.0028)	batch 1.3485 (1.2923)	loss 5.0777 (5.8403)	grad_norm 1.6050 (1.5155)	mem 28674MB
Train: [0/180][8550/10009]	eta 0:31:25 lr 0.049997	data 0.0005 (0.0027)	batch 1.5670 (1.2923)	loss 5.0192 (5.8365)	grad_norm 1.5407 (1.5161)	mem 28674MB
Train: [0/180][8600/10009]	eta 0:30:20 lr 0.049997	data 0.0004 (0.0027)	batch 1.5538 (1.2924)	loss 5.1444 (5.8326)	grad_norm 1.6224 (1.5167)	mem 28674MB
Train: [0/180][8650/10009]	eta 0:29:16 lr 0.049997	data 0.0006 (0.0027)	batch 1.0446 (1.2924)	loss 5.1200 (5.8289)	grad_norm 1.5554 (1.5172)	mem 28674MB
Train: [0/180][8700/10009]	eta 0:28:11 lr 0.049997	data 0.0005 (0.0027)	batch 1.0156 (1.2924)	loss 5.2269 (5.8251)	grad_norm 1.6157 (1.5179)	mem 28674MB
Train: [0/180][8750/10009]	eta 0:27:07 lr 0.049997	data 0.0005 (0.0027)	batch 1.1833 (1.2924)	loss 5.1822 (5.8215)	grad_norm 1.5724 (1.5185)	mem 28674MB
Train: [0/180][8800/10009]	eta 0:26:02 lr 0.049997	data 0.0004 (0.0027)	batch 1.0033 (1.2923)	loss 5.4414 (5.8177)	grad_norm 1.6959 (1.5190)	mem 28674MB
Train: [0/180][8850/10009]	eta 0:24:57 lr 0.049997	data 0.0005 (0.0027)	batch 1.2911 (1.2923)	loss 5.2730 (5.8139)	grad_norm 1.5571 (1.5197)	mem 28674MB
Train: [0/180][8900/10009]	eta 0:23:53 lr 0.049997	data 0.0005 (0.0027)	batch 1.3346 (1.2924)	loss 5.2413 (5.8099)	grad_norm 1.7294 (1.5204)	mem 28674MB
Train: [0/180][8950/10009]	eta 0:22:48 lr 0.049997	data 0.0004 (0.0026)	batch 1.4333 (1.2924)	loss 5.0074 (5.8063)	grad_norm 1.5681 (1.5210)	mem 28674MB
Train: [0/180][9000/10009]	eta 0:21:43 lr 0.049997	data 0.0004 (0.0026)	batch 1.5302 (1.2924)	loss 5.2486 (5.8025)	grad_norm 1.6718 (1.5216)	mem 28674MB
Train: [0/180][9050/10009]	eta 0:20:39 lr 0.049997	data 0.0004 (0.0026)	batch 1.3805 (1.2924)	loss 5.0639 (5.7987)	grad_norm 1.6453 (1.5222)	mem 28674MB
Train: [0/180][9100/10009]	eta 0:19:34 lr 0.049997	data 0.0005 (0.0026)	batch 1.6061 (1.2923)	loss 5.0937 (5.7949)	grad_norm 1.5866 (1.5227)	mem 28674MB
Train: [0/180][9150/10009]	eta 0:18:30 lr 0.049997	data 0.0004 (0.0026)	batch 1.5733 (1.2923)	loss 5.4346 (5.7912)	grad_norm 1.6588 (1.5233)	mem 28674MB
Train: [0/180][9200/10009]	eta 0:17:25 lr 0.049997	data 0.0004 (0.0026)	batch 1.0456 (1.2923)	loss 5.1987 (5.7872)	grad_norm 1.7596 (1.5240)	mem 28674MB
Train: [0/180][9250/10009]	eta 0:16:20 lr 0.049997	data 0.0006 (0.0026)	batch 1.1797 (1.2923)	loss 5.3728 (5.7835)	grad_norm 1.6959 (1.5246)	mem 28674MB
Train: [0/180][9300/10009]	eta 0:15:16 lr 0.049997	data 0.0004 (0.0026)	batch 1.2401 (1.2922)	loss 5.2307 (5.7798)	grad_norm 1.5874 (1.5251)	mem 28674MB
Train: [0/180][9350/10009]	eta 0:14:11 lr 0.049997	data 0.0004 (0.0026)	batch 1.0412 (1.2922)	loss 5.3572 (5.7762)	grad_norm 1.7211 (1.5257)	mem 28674MB
Train: [0/180][9400/10009]	eta 0:13:06 lr 0.049997	data 0.0004 (0.0025)	batch 1.3354 (1.2922)	loss 5.1703 (5.7726)	grad_norm 1.7134 (1.5262)	mem 28674MB
Train: [0/180][9450/10009]	eta 0:12:02 lr 0.049997	data 0.0005 (0.0025)	batch 1.3349 (1.2923)	loss 5.3716 (5.7689)	grad_norm 1.6347 (1.5268)	mem 28674MB
Train: [0/180][9500/10009]	eta 0:10:57 lr 0.049997	data 0.0005 (0.0025)	batch 1.3570 (1.2923)	loss 4.8746 (5.7653)	grad_norm 1.6655 (1.5272)	mem 28674MB
Train: [0/180][9550/10009]	eta 0:09:53 lr 0.049997	data 0.0005 (0.0025)	batch 1.1628 (1.2923)	loss 4.9853 (5.7617)	grad_norm 1.5813 (1.5278)	mem 28674MB
Train: [0/180][9600/10009]	eta 0:08:48 lr 0.049996	data 0.0005 (0.0025)	batch 1.2727 (1.2923)	loss 5.0887 (5.7582)	grad_norm 1.5962 (1.5284)	mem 28674MB
Train: [0/180][9650/10009]	eta 0:07:43 lr 0.049996	data 0.0004 (0.0025)	batch 1.3379 (1.2923)	loss 5.1488 (5.7545)	grad_norm 1.6949 (1.5290)	mem 28674MB
Train: [0/180][9700/10009]	eta 0:06:39 lr 0.049996	data 0.0005 (0.0025)	batch 1.1955 (1.2922)	loss 4.9154 (5.7510)	grad_norm 1.5838 (1.5296)	mem 28674MB
Train: [0/180][9750/10009]	eta 0:05:34 lr 0.049996	data 0.0005 (0.0025)	batch 1.2433 (1.2922)	loss 5.1618 (5.7472)	grad_norm 1.7413 (1.5302)	mem 28674MB
Train: [0/180][9800/10009]	eta 0:04:30 lr 0.049996	data 0.0005 (0.0025)	batch 1.3578 (1.2922)	loss 5.1405 (5.7436)	grad_norm 1.6962 (1.5308)	mem 28674MB
Train: [0/180][9850/10009]	eta 0:03:25 lr 0.049996	data 0.0005 (0.0025)	batch 1.2409 (1.2921)	loss 5.1222 (5.7400)	grad_norm 1.6826 (1.5315)	mem 28674MB
Train: [0/180][9900/10009]	eta 0:02:20 lr 0.049996	data 0.0004 (0.0024)	batch 1.3735 (1.2920)	loss 5.1065 (5.7365)	grad_norm 1.7389 (1.5321)	mem 28674MB
Train: [0/180][9950/10009]	eta 0:01:16 lr 0.049996	data 0.0004 (0.0024)	batch 1.0167 (1.2919)	loss 4.8837 (5.7329)	grad_norm 1.6052 (1.5326)	mem 28674MB
Train: [0/180][10000/10009]	eta 0:00:11 lr 0.049996	data 0.0003 (0.0024)	batch 1.0303 (1.2919)	loss 5.0345 (5.7294)	grad_norm 1.6489 (1.5332)	mem 28674MB
Current slope: None 	
EPOCH 0 training takes 3:35:31
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 256
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.1
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 5.0e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 5.0e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.130632
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 13:06:12 lr 0.050000	data 17.9766 (17.9766)	batch 21.9775 (21.9775)	loss 6.9676 (6.9676)	grad_norm 10.1148 (10.1148)	mem 28674MB
Train: [0/180][50/10009]	eta 4:41:08 lr 0.050000	data 0.0006 (0.3530)	batch 1.4552 (1.6938)	loss 7.0690 (7.0434)	grad_norm 3.4840 (4.8160)	mem 28674MB
Train: [0/180][100/10009]	eta 4:04:45 lr 0.050000	data 0.0004 (0.1785)	batch 1.1005 (1.4820)	loss 7.0704 (7.0651)	grad_norm 2.8618 (3.9811)	mem 28674MB
Train: [0/180][150/10009]	eta 3:53:17 lr 0.050000	data 0.0005 (0.1196)	batch 1.3791 (1.4198)	loss 6.9632 (7.0600)	grad_norm 2.3554 (3.5132)	mem 28674MB
Train: [0/180][200/10009]	eta 3:46:26 lr 0.050000	data 0.0004 (0.0899)	batch 1.4902 (1.3851)	loss 6.9233 (7.0447)	grad_norm 2.0933 (3.1946)	mem 28674MB
Train: [0/180][250/10009]	eta 3:41:55 lr 0.050000	data 0.0005 (0.0721)	batch 1.3039 (1.3645)	loss 6.9474 (7.0245)	grad_norm 1.9092 (2.9624)	mem 28674MB
Train: [0/180][300/10009]	eta 3:38:37 lr 0.050000	data 0.0008 (0.0602)	batch 1.1888 (1.3510)	loss 6.9638 (7.0024)	grad_norm 1.6969 (2.7670)	mem 28674MB
Train: [0/180][350/10009]	eta 3:35:58 lr 0.050000	data 0.0005 (0.0517)	batch 1.1874 (1.3416)	loss 6.8038 (6.9801)	grad_norm 1.4660 (2.5937)	mem 28674MB
Train: [0/180][400/10009]	eta 3:33:50 lr 0.050000	data 0.0005 (0.0453)	batch 1.3121 (1.3352)	loss 6.7336 (6.9572)	grad_norm 1.3746 (2.4499)	mem 28674MB
Train: [0/180][450/10009]	eta 3:31:53 lr 0.050000	data 0.0004 (0.0404)	batch 1.2938 (1.3300)	loss 6.7769 (6.9339)	grad_norm 1.3666 (2.3276)	mem 28674MB
Train: [0/180][500/10009]	eta 3:30:04 lr 0.050000	data 0.0005 (0.0364)	batch 1.1690 (1.3256)	loss 6.6507 (6.9099)	grad_norm 1.3387 (2.2311)	mem 28674MB
Train: [0/180][550/10009]	eta 3:28:24 lr 0.050000	data 0.0004 (0.0331)	batch 1.5877 (1.3220)	loss 6.4917 (6.8884)	grad_norm 1.3319 (2.1496)	mem 28674MB
Train: [0/180][600/10009]	eta 3:26:50 lr 0.050000	data 0.0005 (0.0304)	batch 1.1828 (1.3190)	loss 6.5542 (6.8684)	grad_norm 1.3531 (2.0770)	mem 28674MB
Train: [0/180][650/10009]	eta 3:25:22 lr 0.050000	data 0.0006 (0.0282)	batch 1.3531 (1.3167)	loss 6.6304 (6.8483)	grad_norm 1.3289 (2.0181)	mem 28674MB
Train: [0/180][700/10009]	eta 3:23:56 lr 0.050000	data 0.0005 (0.0262)	batch 1.3657 (1.3145)	loss 6.5828 (6.8291)	grad_norm 1.2501 (1.9689)	mem 28674MB
Train: [0/180][750/10009]	eta 3:22:25 lr 0.050000	data 0.0007 (0.0245)	batch 1.3158 (1.3117)	loss 6.4130 (6.8108)	grad_norm 1.4185 (1.9254)	mem 28674MB
Train: [0/180][800/10009]	eta 3:21:02 lr 0.050000	data 0.0006 (0.0230)	batch 1.3499 (1.3099)	loss 6.4599 (6.7927)	grad_norm 1.3147 (1.8876)	mem 28674MB
Train: [0/180][850/10009]	eta 3:19:45 lr 0.050000	data 0.0005 (0.0217)	batch 1.0612 (1.3086)	loss 6.4954 (6.7751)	grad_norm 1.3325 (1.8555)	mem 28674MB
Train: [0/180][900/10009]	eta 3:18:36 lr 0.050000	data 0.0005 (0.0205)	batch 0.9688 (1.3082)	loss 6.5053 (6.7591)	grad_norm 1.3197 (1.8268)	mem 28674MB
Train: [0/180][950/10009]	eta 3:17:20 lr 0.050000	data 0.0005 (0.0195)	batch 1.0676 (1.3071)	loss 6.3583 (6.7441)	grad_norm 1.2850 (1.8005)	mem 28674MB
Train: [0/180][1000/10009]	eta 3:16:06 lr 0.050000	data 0.0006 (0.0185)	batch 1.2337 (1.3061)	loss 6.4679 (6.7298)	grad_norm 1.2971 (1.7764)	mem 28674MB
Train: [0/180][1050/10009]	eta 3:14:53 lr 0.050000	data 0.0005 (0.0177)	batch 1.5721 (1.3052)	loss 6.4158 (6.7160)	grad_norm 1.3036 (1.7542)	mem 28674MB
Train: [0/180][1100/10009]	eta 3:13:40 lr 0.050000	data 0.0005 (0.0169)	batch 1.5473 (1.3044)	loss 6.4492 (6.7020)	grad_norm 1.3431 (1.7348)	mem 28674MB
Train: [0/180][1150/10009]	eta 3:12:30 lr 0.050000	data 0.0005 (0.0162)	batch 1.5551 (1.3038)	loss 6.3810 (6.6879)	grad_norm 1.2808 (1.7180)	mem 28674MB
Train: [0/180][1200/10009]	eta 3:11:20 lr 0.050000	data 0.0006 (0.0155)	batch 1.5022 (1.3032)	loss 6.3591 (6.6739)	grad_norm 1.4548 (1.7015)	mem 28674MB
Train: [0/180][1250/10009]	eta 3:10:08 lr 0.050000	data 0.0005 (0.0149)	batch 1.1985 (1.3025)	loss 6.4854 (6.6608)	grad_norm 1.3618 (1.6876)	mem 28674MB
Train: [0/180][1300/10009]	eta 3:08:58 lr 0.050000	data 0.0005 (0.0144)	batch 1.2223 (1.3019)	loss 6.2923 (6.6479)	grad_norm 1.3203 (1.6753)	mem 28674MB
Train: [0/180][1350/10009]	eta 3:07:50 lr 0.050000	data 0.0004 (0.0138)	batch 1.1553 (1.3016)	loss 6.3236 (6.6348)	grad_norm 1.4132 (1.6644)	mem 28674MB
Train: [0/180][1400/10009]	eta 3:06:42 lr 0.050000	data 0.0004 (0.0134)	batch 1.1058 (1.3012)	loss 6.3413 (6.6228)	grad_norm 1.3950 (1.6528)	mem 28674MB
Train: [0/180][1450/10009]	eta 3:05:33 lr 0.050000	data 0.0005 (0.0129)	batch 1.4903 (1.3008)	loss 6.2609 (6.6113)	grad_norm 1.3143 (1.6412)	mem 28674MB
Train: [0/180][1500/10009]	eta 3:04:31 lr 0.050000	data 0.0004 (0.0125)	batch 1.5777 (1.3011)	loss 6.4046 (6.6002)	grad_norm 1.3792 (1.6316)	mem 28674MB
Train: [0/180][1550/10009]	eta 3:03:18 lr 0.050000	data 0.0005 (0.0121)	batch 1.5648 (1.3002)	loss 6.3551 (6.5887)	grad_norm 1.3520 (1.6229)	mem 28674MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Not implemented activation fuction:learnable_relu6_hard_snl
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Not implemented activation fuction:learnable_relu6_hard_snl
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 16:32:21 lr 0.050000	data 19.3947 (19.3947)	batch 23.2132 (23.2132)	loss 6.9677 (6.9677)	grad_norm 10.0257 (10.0257)	mem 28674MB
Train: [0/180][50/10009]	eta 4:43:32 lr 0.050000	data 0.0004 (0.3808)	batch 1.3581 (1.7083)	loss 7.0536 (7.0450)	grad_norm 3.4310 (4.7360)	mem 28674MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 17:08:55 lr 0.050000	data 19.4296 (19.4296)	batch 23.4324 (23.4324)	loss 6.9677 (6.9677)	grad_norm 10.0257 (10.0257)	mem 28674MB
Train: [0/180][50/10009]	eta 4:45:18 lr 0.050000	data 0.0006 (0.3815)	batch 1.5020 (1.7189)	loss 7.0691 (7.0472)	grad_norm 3.5460 (4.7732)	mem 28674MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 15:36:04 lr 0.050000	data 18.8577 (18.8577)	batch 22.8758 (22.8758)	loss 6.9677 (6.9677)	grad_norm 10.0257 (10.0257)	mem 28674MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 13:13:35 lr 0.050000	data 18.6167 (18.6167)	batch 22.0217 (22.0217)	loss 6.9677 (6.9677)	grad_norm 10.0257 (10.0257)	mem 28674MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108881
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108881
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108811
Unsupported operator aten::sub encountered 140 time(s)
Unsupported operator aten::mul encountered 105 time(s)
Unsupported operator aten::add encountered 105 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 15:55:48 lr 0.050000	data 18.6866 (18.6866)	batch 22.9941 (22.9941)	loss 6.9677 (6.9677)	grad_norm 10.0257 (10.0257)	mem 28674MB
Train: [0/180][50/10009]	eta 4:40:21 lr 0.050000	data 0.0004 (0.3670)	batch 1.4437 (1.6891)	loss 7.0734 (7.0451)	grad_norm 3.4552 (4.6710)	mem 28674MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108811
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 13:46:53 lr 0.050000	data 18.3811 (18.3811)	batch 22.2214 (22.2214)	loss 6.9313 (6.9313)	grad_norm 0.9162 (0.9162)	mem 28673MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108811
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108811
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108811
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108811
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108811
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108811
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 18:03:20 lr 0.050000	data 19.8939 (19.8939)	batch 23.7587 (23.7587)	loss 6.9676 (6.9676)	grad_norm 10.1559 (10.1559)	mem 28674MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 21:35:04 lr 0.050000	data 21.0118 (21.0118)	batch 25.0279 (25.0279)	loss 6.9677 (6.9677)	grad_norm 10.0257 (10.0257)	mem 28674MB
Train: [0/180][50/10009]	eta 4:50:16 lr 0.050000	data 0.0006 (0.4126)	batch 1.2616 (1.7489)	loss 7.0620 (7.0481)	grad_norm 3.4185 (4.6673)	mem 28674MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 15:02:02 lr 0.050000	data 18.6668 (18.6668)	batch 22.6718 (22.6718)	loss 6.9676 (6.9676)	grad_norm 10.4419 (10.4419)	mem 28674MB
Train: [0/180][50/10009]	eta 4:58:53 lr 0.050000	data 0.0005 (0.3666)	batch 1.3626 (1.8007)	loss 7.0596 (7.0446)	grad_norm 3.4746 (4.8063)	mem 28674MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::sub encountered 70 time(s)
Unsupported operator aten::mul encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 16:10:55 lr 0.050000	data 19.3431 (19.3431)	batch 23.0848 (23.0848)	loss 6.9677 (6.9677)	grad_norm 10.0257 (10.0257)	mem 20211MB
Train: [0/180][50/10009]	eta 4:23:33 lr 0.050000	data 0.0005 (0.3799)	batch 1.1078 (1.5879)	loss 7.0761 (7.0455)	grad_norm 3.5075 (4.8734)	mem 20211MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.458776
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.458776
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.458776
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.458776
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.458776
Unsupported operator aten::sub encountered 70 time(s)
Unsupported operator aten::mul encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.458776
Unsupported operator aten::sub encountered 70 time(s)
Unsupported operator aten::mul encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.458776
Unsupported operator aten::sub encountered 70 time(s)
Unsupported operator aten::mul encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.458776
Unsupported operator aten::sub encountered 70 time(s)
Unsupported operator aten::mul encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.178776
Unsupported operator aten::sub encountered 70 time(s)
Unsupported operator aten::mul encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.178776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 14:59:34 lr 0.050000	data 18.6987 (18.6987)	batch 22.6570 (22.6570)	loss 6.9677 (6.9677)	grad_norm 10.0077 (10.0077)	mem 20212MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.178776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 14:20:30 lr 0.050000	data 18.6494 (18.6494)	batch 22.4229 (22.4229)	loss 6.9677 (6.9677)	grad_norm 10.0257 (10.0257)	mem 20212MB
Train: [0/180][50/10009]	eta 4:11:41 lr 0.050000	data 0.0005 (0.3662)	batch 0.9917 (1.5163)	loss 7.0845 (7.0456)	grad_norm 3.5044 (4.8233)	mem 20212MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 17:45:59 lr 0.050000	data 20.2461 (20.2461)	batch 23.6547 (23.6547)	loss 6.9677 (6.9677)	grad_norm 9.9614 (9.9614)	mem 28674MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 18:12:05 lr 0.050000	data 19.7613 (19.7613)	batch 23.8112 (23.8112)	loss 6.9677 (6.9677)	grad_norm 10.0257 (10.0257)	mem 28674MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 15:18:43 lr 0.050000	data 18.8896 (18.8896)	batch 22.7719 (22.7719)	loss 6.9677 (6.9677)	grad_norm 10.0129 (10.0129)	mem 28674MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 16:44:16 lr 0.050000	data 19.1315 (19.1315)	batch 23.2846 (23.2846)	loss 6.9677 (6.9677)	grad_norm 10.0257 (10.0257)	mem 28674MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 21:07:09 lr 0.050000	data 20.5644 (20.5644)	batch 24.8605 (24.8605)	loss 6.9677 (6.9677)	grad_norm 10.0038 (10.0038)	mem 28674MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 18:55:22 lr 0.050000	data 20.1609 (20.1609)	batch 24.0706 (24.0706)	loss 6.9677 (6.9677)	grad_norm 10.0257 (10.0257)	mem 28674MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 19:12:32 lr 0.050000	data 20.5281 (20.5281)	batch 24.1735 (24.1735)	loss 6.9677 (6.9677)	grad_norm 10.0260 (10.0260)	mem 28674MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 17:08:55 lr 0.050000	data 20.2241 (20.2241)	batch 23.4325 (23.4325)	loss 6.9677 (6.9677)	grad_norm 10.3560 (10.3560)	mem 28674MB
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Full config saved to manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/config.json
AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m5-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /opt/dataset/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 6
  PIN_MEMORY: true
  PREFETCH_FACTOR: 6
  ZIP_MODE: false
DISTILL: false
DS:
  ACT_DISTRIB: first
  ACT_FROM_LIST: false
  ACT_FROM_SEARCH: true
  ACT_FUN: learnable_relu6_hard_snl
  ACT_LIST: []
  ADD_FINAL_ACT: relu6
  DECAY_MODE: iter
  DECAY_SLOPE: false
  DISTILL: false
  DISTILL_FEATURE: false
  DISTILL_FEATURE_WEIGHT: 0.001
  DISTILL_WEIGHT: 0.7
  EA:
    CYCLES: 5000
    POP_SIZE: 64
    SAMPLE_SIZE: 16
    SEARCH: false
    SPARSE_RATIO: 0.5
  END_EPOCH: 0
  END_SLOPE: 1
  EXPAND_RATIO: 6
  FINAL_ACT_LR_SCALE: 1.0
  GS_SAMPLE:
    DECAY_RATE: 0.95
    ENABLE: false
    EPOCH: 60
    INIT_TEMP: 3
  KEEP_ALL_ACT: false
  L0_SPARSITY: 0.4
  L1_WEIGHT: 0.0
  LAT_AFTER:
  - 11.38781
  - 17.8929
  - 8.85087
  - 4.89339
  - 4.36431
  - 2.21807
  - 2.21807
  - 2.95533
  - 3.1424
  - 3.1424
  - 3.1424
  - 4.53318
  - 6.70935
  - 6.70935
  - 7.68199
  - 7.07067
  - 7.07067
  - 13.7805
  - 23.0013
  LAT_BEFORE:
  - 18.5039
  - 59.0279
  - 67.7049
  - 61.0657
  - 30.3438
  - 23.3904
  - 23.3904
  - 13.6589
  - 18.5797
  - 18.5797
  - 18.5797
  - 21.1564
  - 35.212
  - 35.212
  - 23.3629
  - 25.978
  - 25.978
  - 34.261
  - 23.0013
  LAT_COST_WEIGHT: 0.0001
  MERGE: true
  NO_BN_STATS: false
  PRETRAINED: ''
  PROG_REMOVE: false
  PROG_REMOVE_EPOCH: 120
  PROG_REMOVE_MODE: forward
  RANDOM_DROP: false
  REMOVE_BLOCK: false
  SEARCH: true
  SEARCH_CKPT: /home/zwx/projects/DepthShrinker/manifold:/ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default/ckpt.pth
  START_EPOCH: 0
  START_SLOPE: 0
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_BLOCK_RATE: 0.0
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: mobilenetv2_140_block_ds
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mobilenetv2_140_block_ds
OUTPUT: manifold://ondevice_ai_tools/tree/users/yongganfu/experiments/depth_shrink/default
PRINT_FREQ: 50
RANK: 0
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_BATCH_SIZE: 256
  BASE_LR: 0.05
  CLIP_GRAD: 5.0
  EPOCHS: 180
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MAX: 192
  MIN_LR: 2.5e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  USE_CHECKPOINT: false
  USE_CONV_PROJ: true
  WARMUP_EPOCHS: 0
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 1.0e-05
WORLD_SIZE: 1
dist_url: tcp://127.0.0.1:10003
gpu: 0
machine_rank: 0
num_nodes: 1

Creating model:mobilenetv2_140_block_ds/mobilenetv2_140_block_ds
EfficientNet(
  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (blocks): Sequential(
    (0): Sequential(
      (0): DepthwiseSeparableConv(
        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Identity()
      )
    )
    (1): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
        (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)
        (bn2): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(528, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(816, 816, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=816, bias=False)
        (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(816, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): InvertedResidual(
        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
        (bn2): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): Changable_Act(
          (act_fun): Learnable_Relu6_Hard_SNL()
        )
        (se): Identity()
        (conv_pwl): Conv2d(1344, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): Changable_Act(
    (act_fun): Learnable_Relu6_Hard_SNL()
  )
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
  (classifier): Linear(in_features=1792, out_features=1000, bias=True)
)
number of params (M): 6.108776
Unsupported operator aten::sub encountered 105 time(s)
Unsupported operator aten::mul encountered 140 time(s)
Unsupported operator aten::add encountered 70 time(s)
Unsupported operator aten::rsub encountered 35 time(s)
Unsupported operator aten::add_ encountered 10 time(s)
number of GFLOPs: 0.60143048
Start training
Train: [0/180][0/10009]	eta 2 days, 21:49:21 lr 0.050000	data 20.6827 (20.6827)	batch 25.1136 (25.1136)	loss 6.9677 (6.9677)	grad_norm 10.0257 (10.0257)	mem 28674MB
Train: [0/180][50/10009]	eta 4:46:20 lr 0.050000	data 0.0006 (0.4062)	batch 1.3147 (1.7251)	loss 7.0551 (7.0448)	grad_norm 3.3971 (4.7232)	mem 28674MB
Train: [0/180][100/10009]	eta 4:07:23 lr 0.050000	data 0.0005 (0.2054)	batch 0.9739 (1.4980)	loss 7.0205 (7.0630)	grad_norm 2.7043 (3.8979)	mem 28674MB
